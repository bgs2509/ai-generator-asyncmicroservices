{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"INDEX/","title":"Documentation Index","text":"<p>The documentation is organised into atomic knowledge modules. Use this index as the entry point for the authoritative materials.</p>"},{"location":"INDEX/#quick-navigation","title":"Quick Navigation","text":"Need Go To Understand architecture Improved Hybrid Overview Learn core principles (DRY/KISS/YAGNI) DRY, KISS, YAGNI Principles Migrate existing project to Phase 1 Migration Guide: Phase 1 Implement a FastAPI service FastAPI Basic Setup Configure integrations Redis Connection Management Prepare infrastructure PostgreSQL Setup Set up observability Structured Logging Patterns Align testing strategy Pytest Setup Debug production issues Anti-Pattern Quick Reference (see below)"},{"location":"INDEX/#anti-pattern-quick-reference","title":"Anti-Pattern Quick Reference","text":"<p>Common anti-patterns encountered in production, documented with symptoms and solutions. Each anti-pattern is embedded in its relevant atomic document with WRONG/CORRECT code examples and monitoring commands.</p> <p>Priority Classification: - \ud83d\udd34 CRITICAL: Production crashes, data loss, security vulnerabilities - \ud83d\udfe0 HIGH: Silent failures, debugging issues, breaking changes - \ud83d\udfe1 MEDIUM: Performance degradation, maintainability issues</p>"},{"location":"INDEX/#resource-management-critical","title":"Resource Management (\ud83d\udd34 CRITICAL)","text":"Anti-Pattern Document Impact Priority Global FSM Storage Never Closed State Management Memory exhaustion, crashes after 3-7 days uptime \ud83d\udd34 CRITICAL HTTP Client Proliferation HTTP Client Patterns Connection pool exhaustion, \"connection reset\" errors \ud83d\udd34 CRITICAL Connection Pool Misuse Connection Management Redis connection leaks, \"max clients reached\" \ud83d\udd34 CRITICAL"},{"location":"INDEX/#error-handling-high","title":"Error Handling (\ud83d\udfe0 HIGH)","text":"Anti-Pattern Document Impact Priority Silent Exception Swallowing Error Handling Silent data loss, impossible debugging \ud83d\udfe0 HIGH"},{"location":"INDEX/#lifecycle-management-high","title":"Lifecycle Management (\ud83d\udfe0 HIGH)","text":"Anti-Pattern Document Impact Priority Deprecated Lifecycle APIs Lifespan Management Breaking changes on FastAPI 0.109+ upgrade \ud83d\udfe0 HIGH No Graceful Shutdown Graceful Shutdown 500 errors during deployment, data loss \ud83d\udfe0 HIGH"},{"location":"INDEX/#common-symptoms-anti-pattern-lookup","title":"Common Symptoms \u2192 Anti-Pattern Lookup","text":"Symptom Likely Anti-Pattern Document \"too many open files\" error Global FSM Storage Never Closed State Management Memory grows continuously HTTP Client Proliferation / Connection Pool Misuse HTTP Client Patterns \"connection reset by peer\" HTTP Client Proliferation / No Graceful Shutdown Graceful Shutdown Operations fail silently Silent Exception Swallowing Error Handling Deprecation warnings Deprecated Lifecycle APIs Lifespan Management 500 errors during deploy No Graceful Shutdown Graceful Shutdown <p>Note: All anti-patterns include monitoring commands (<code>docker stats</code>, <code>netstat</code>, <code>redis-cli</code>) to detect issues in production.</p>"},{"location":"INDEX/#documentation-pillars","title":"Documentation Pillars","text":""},{"location":"INDEX/#core-guides","title":"Core Guides","text":"<ul> <li>Architecture Guide \u2014 canonical architectural principles</li> <li>DRY, KISS, YAGNI Principles \u2014 comprehensive guide to core software engineering principles and framework enforcement</li> <li>AI Code Generation Master Workflow \u2014 complete 7-stage AI process (unified workflow)</li> <li>Requirements Traceability Guide \u2014 ensuring 100% requirement coverage with Req ID tracking</li> <li>Development Commands \u2014 command reference for local workflows</li> <li>Use Case Implementation Guide \u2014 step-by-step delivery process</li> <li>Shared Components Guide \u2014 shared infrastructure components</li> <li>Template Naming Guide \u2014 template service naming conventions</li> </ul>"},{"location":"INDEX/#reference-materials","title":"Reference Materials","text":"<ul> <li>Technical Specifications \u2014 platform versions and runtime constraints</li> <li>Project Structure \u2014 directory and file organization</li> <li>Troubleshooting Guide \u2014 diagnostics and recovery procedures</li> <li>Agent Context Summary \u2014 onboarding context for AI agents</li> <li>Maturity Levels \u2014 4 incremental levels from PoC to Production</li> <li>Conditional Stage Rules \u2014 stage skipping rules per maturity level</li> <li>AI Navigation Matrix \u2014 exact document mapping per workflow stage</li> <li>Agent Toolbox \u2014 machine-friendly command catalogue</li> <li>Deliverables Catalog \u2014 artefact ownership and storage rules</li> <li>Prompt Templates \u2014 reusable communication templates</li> <li>Failure Scenarios &amp; Recovery Guide \u2014 edge cases handling and recovery procedures</li> <li>Architecture Decision Log Template \u2014 ADR format and conventions</li> <li>Semantic Shortening Guide \u2014 3-part service naming formula and decision tree</li> </ul>"},{"location":"INDEX/#agent-templates-checklists","title":"Agent Templates &amp; Checklists","text":"<ul> <li>Prompt Validation Guide \u2014 pre-work validation checklist</li> <li>Requirements Intake Template \u2014 capturing functional and non-functional needs</li> <li>Implementation Plan Template \u2014 planning artefact for approvals</li> <li>Agent Verification Checklist \u2014 release quality gates</li> <li>QA Report Template \u2014 final QA handoff format</li> <li>Service Naming Checklist \u2014 3-part vs 4-part decision tool</li> <li>Automated Quality Gates \u2014 CI pipeline enforcement of DRY/KISS/YAGNI principles</li> </ul>"},{"location":"INDEX/#style-contribution","title":"Style &amp; Contribution","text":"<ul> <li>STYLE_GUIDE.md \u2014 documentation formatting standards and conventions</li> <li>Atomic Documentation Template \u2014 template for creating atomic modules</li> <li>Atomic Documentation Changelog \u2014 atomic documentation change history</li> </ul>"},{"location":"INDEX/#atomic-knowledge-base","title":"Atomic Knowledge Base","text":"<p>See Atomic Documentation Hub for contribution rules.</p>"},{"location":"INDEX/#architecture","title":"Architecture","text":"<ul> <li>Improved Hybrid Approach Overview \u2014 High-level view of the improved hybrid service model.</li> <li>Service Separation Principles \u2014 Guidelines for splitting responsibilities across services.</li> <li>Event Loop Management \u2014 Ownership, lifecycle, and orchestration rules for event loops.</li> <li>Data Access Architecture \u2014 Patterns for safe data access and service boundaries.</li> <li>DDD and Hexagonal Principles \u2014 DDD layering and hexagonal architecture applications.</li> <li>Context Registry \u2014 service context definitions and domain boundaries.</li> <li>Naming Conventions \u2014 Complete naming guide with Quick Reference Table and decision trees.</li> <li>4-Part Naming Reasons \u2014 Serious reasons for 4-part naming convention.</li> <li>Naming Conversion Guide \u2014 Converting between naming conventions.</li> <li>Database Naming \u2014 Database-specific naming conventions.</li> <li>Documentation Naming \u2014 Documentation file naming standards.</li> <li>Infrastructure Naming \u2014 Infrastructure resource naming.</li> <li>Python Naming \u2014 Python code naming conventions.</li> <li>Service Naming \u2014 Service and component naming patterns.</li> <li>Quality Standards \u2014 Quality bar, verification steps, and acceptance criteria.</li> <li>Project Structure Patterns \u2014 Reference microservice and repository structures.</li> </ul>"},{"location":"INDEX/#services","title":"Services","text":""},{"location":"INDEX/#fastapi","title":"FastAPI","text":"<ul> <li>FastAPI Basic Setup \u2014 Baseline FastAPI service bootstrap.</li> <li>FastAPI Application Factory \u2014 App factory pattern and lifecycle.</li> <li>FastAPI Lifespan Management \u2014 Startup and shutdown handling.</li> <li>FastAPI Routing Patterns \u2014 Routing structure and API design.</li> <li>FastAPI Dependency Injection \u2014 DI patterns and container usage.</li> <li>FastAPI Schema Validation \u2014 Pydantic schema patterns.</li> <li>FastAPI Error Handling \u2014 HTTP error handling strategies.</li> <li>FastAPI Security Patterns \u2014 Authentication and authorization approaches.</li> <li>FastAPI OpenAPI Documentation \u2014 OpenAPI customization and docs.</li> <li>FastAPI Performance Optimization \u2014 Performance tuning and profiling.</li> <li>FastAPI Testing Strategies \u2014 Testing guidance for FastAPI services.</li> </ul>"},{"location":"INDEX/#aiogram","title":"Aiogram","text":"<ul> <li>Aiogram Basic Setup \u2014 Baseline Aiogram bot configuration.</li> <li>Aiogram Bot Initialization \u2014 Bot and dispatcher initialization.</li> <li>Aiogram Handler Patterns \u2014 Message and callback handler structure.</li> <li>Aiogram Middleware Setup \u2014 Middleware registration and ordering.</li> <li>Aiogram State Management \u2014 Finite state machine usage.</li> <li>Aiogram Dependency Injection \u2014 DI patterns for Aiogram.</li> <li>Aiogram Webhook Configuration \u2014 Webhook versus polling configuration.</li> <li>Aiogram Testing Strategies \u2014 Testing approaches for bots.</li> </ul>"},{"location":"INDEX/#asyncio-workers","title":"AsyncIO Workers","text":"<ul> <li>AsyncIO Worker Basic Setup \u2014 Baseline AsyncIO worker bootstrap.</li> <li>AsyncIO Main Function Patterns \u2014 Patterns for worker entrypoints.</li> <li>AsyncIO Signal Handling \u2014 Graceful shutdown and signal processing.</li> <li>AsyncIO Task Management \u2014 Task orchestration and supervision.</li> <li>AsyncIO Dependency Management \u2014 Dependency wiring and context.</li> <li>AsyncIO Worker Error Handling \u2014 Failure handling and retries.</li> <li>AsyncIO Worker Testing Strategies \u2014 Testing async workers.</li> </ul>"},{"location":"INDEX/#data-services","title":"Data Services","text":"<ul> <li>PostgreSQL Service Setup \u2014 PostgreSQL-focused data service setup.</li> <li>MongoDB Service Setup \u2014 MongoDB-focused data service setup.</li> <li>Data Service Repository Patterns \u2014 Repository implementations and patterns.</li> <li>Data Service HTTP API Design \u2014 Designing HTTP APIs for data services.</li> <li>Data Service Transaction Management \u2014 Transaction and consistency guidance.</li> <li>Data Service Testing Strategies \u2014 Testing data service behaviour.</li> </ul>"},{"location":"INDEX/#integrations","title":"Integrations","text":""},{"location":"INDEX/#redis","title":"Redis","text":"<ul> <li>Redis Connection Management \u2014 Connection pooling and clients.</li> <li>Redis Key Naming Conventions \u2014 Key naming standards.</li> <li>Redis Data Serialization \u2014 Serialization practices.</li> <li>Redis Idempotency Patterns \u2014 Idempotency with Redis.</li> <li>Redis Caching Strategies \u2014 Caching patterns and TTL guidance.</li> <li>Redis and FastAPI Integration \u2014 FastAPI + Redis patterns.</li> <li>Redis and Aiogram Integration \u2014 Aiogram + Redis integration.</li> <li>Redis and AsyncIO Integration \u2014 Redis usage from workers.</li> <li>Redis Testing Patterns \u2014 Testing Redis interactions.</li> </ul>"},{"location":"INDEX/#rabbitmq","title":"RabbitMQ","text":"<ul> <li>RabbitMQ Connection Management \u2014 Connection and channel handling.</li> <li>RabbitMQ Exchange and Queue Declaration \u2014 Exchange/queue setup patterns.</li> <li>RabbitMQ Message Publishing \u2014 Publishing strategies and confirmations.</li> <li>RabbitMQ Message Consuming \u2014 Consumer patterns and ack flow.</li> <li>RabbitMQ DTO Contracts \u2014 Message DTO and schema rules.</li> <li>RabbitMQ Error Handling \u2014 Error handling and dead letters.</li> <li>RabbitMQ Idempotency Patterns \u2014 Idempotency strategies for messaging.</li> <li>RabbitMQ and FastAPI Integration \u2014 FastAPI integration patterns.</li> <li>RabbitMQ and Aiogram Integration \u2014 Aiogram integration patterns.</li> <li>RabbitMQ and AsyncIO Integration \u2014 Worker integration patterns.</li> <li>RabbitMQ Testing Patterns \u2014 Testing messaging workflows.</li> </ul>"},{"location":"INDEX/#http-communication","title":"HTTP Communication","text":"<ul> <li>Business to Data Service Calls \u2014 Business \u2192 data service HTTP patterns.</li> <li>HTTP Client Patterns \u2014 HTTP client configuration and reuse.</li> <li>HTTP Error Handling Strategies \u2014 Resilience for HTTP clients.</li> <li>HTTP Timeout and Retry Patterns \u2014 Timeouts, retries, and circuit breakers.</li> <li>HTTP Request Tracing \u2014 Request ID propagation.</li> <li>HTTP Integration Testing \u2014 Testing cross-service HTTP flows.</li> </ul>"},{"location":"INDEX/#cross-service","title":"Cross-Service","text":"<ul> <li>Cross-Service Discovery \u2014 Service discovery approaches.</li> <li>Cross-Service Health Checks \u2014 Health check patterns.</li> <li>Cross-Service Graceful Shutdown \u2014 Coordinated shutdown across services.</li> <li>Cross-Service Distributed Tracing \u2014 Cross-service trace correlation.</li> </ul>"},{"location":"INDEX/#databases","title":"Databases","text":""},{"location":"INDEX/#postgresql","title":"PostgreSQL","text":"<ul> <li>PostgreSQL Basic Setup \u2014 Docker-based PostgreSQL installation, configuration, and connection management.</li> <li>SQLAlchemy Integration \u2014 SQLAlchemy 2.0 async patterns, models, repository pattern, and best practices.</li> </ul>"},{"location":"INDEX/#postgresql-advanced","title":"PostgreSQL Advanced","text":"<ul> <li>Complex Relationship Modeling \u2014 Advanced entity relationships and join strategies.</li> <li>Multi-tenant Patterns \u2014 Multi-tenancy database design patterns.</li> <li>Performance Optimization \u2014 Query optimization, indexing, and profiling.</li> <li>Production Migrations \u2014 Safe production migration strategies with Alembic.</li> </ul>"},{"location":"INDEX/#security","title":"Security","text":"<ul> <li>Authentication &amp; Authorization Guide \u2014 Core authentication and authorization patterns and flows.</li> <li>Authorization Patterns \u2014 RBAC, ABAC, and policy enforcement strategies.</li> <li>Security Testing Guide \u2014 Security testing patterns and strategies.</li> <li>Session Management Patterns \u2014 Session lifecycle and management.</li> </ul>"},{"location":"INDEX/#file-storage-media","title":"File Storage &amp; Media","text":"<ul> <li>File Upload Patterns \u2014 Validation, scanning, and multi-storage flows.</li> <li>Cloud Storage Integration \u2014 Provider-agnostic storage adapters.</li> <li>Media Processing Workflows \u2014 Transcoding, optimization, and pipelines.</li> <li>CDN Integration \u2014 CDN patterns, edge delivery, and cache strategies.</li> <li>Backup Strategies \u2014 File backup and disaster recovery.</li> </ul>"},{"location":"INDEX/#external-integrations","title":"External Integrations","text":"<ul> <li>Payment Gateway Integration \u2014 PCI-safe payment flows and reconciliation.</li> <li>Communication APIs \u2014 Email, SMS, and voice integration patterns.</li> <li>Webhook Handling \u2014 Secure inbound webhook processing.</li> <li>API Rate Limiting \u2014 Protection against API overuse.</li> </ul>"},{"location":"INDEX/#real-time-communication","title":"Real-time Communication","text":"<ul> <li>WebSocket Patterns \u2014 Connection lifecycle, scaling, and security.</li> <li>Server-Sent Events \u2014 Streaming updates with SSE.</li> <li>Push Notifications \u2014 Device messaging workflows.</li> <li>Real-Time Synchronization Patterns \u2014 Conflict-free data sync strategies.</li> </ul>"},{"location":"INDEX/#infrastructure","title":"Infrastructure","text":""},{"location":"INDEX/#api-gateway","title":"API Gateway","text":"<ul> <li>Nginx Setup and Configuration \u2014 Basic nginx setup as API Gateway.</li> <li>Nginx Routing Patterns \u2014 Advanced routing strategies for microservices.</li> <li>Nginx Load Balancing \u2014 Load balancing strategies, health checks, and high availability.</li> <li>Nginx Security Hardening \u2014 Security best practices, rate limiting, and DDoS protection.</li> <li>Nginx SSL Configuration \u2014 HTTPS setup and certificate management.</li> </ul>"},{"location":"INDEX/#databases_1","title":"Databases","text":"<ul> <li>Database PostgreSQL Setup \u2014 PostgreSQL configuration and tuning.</li> <li>Database MongoDB Setup \u2014 MongoDB configuration and tuning.</li> <li>Database Connection Pooling \u2014 Pooling strategies.</li> <li>Database Migrations \u2014 Migration tooling and workflows.</li> <li>Database Performance Optimization \u2014 Performance troubleshooting.</li> </ul>"},{"location":"INDEX/#containerization","title":"Containerization","text":"<ul> <li>Dockerfile Patterns \u2014 Dockerfile best practices.</li> <li>Docker Compose Setup \u2014 Compose configuration standards.</li> <li>Container Networking \u2014 Networking patterns for containers.</li> <li>Container Volume Management \u2014 Volume usage and persistence.</li> <li>Multi-Stage Builds \u2014 Multi-stage Docker build patterns.</li> </ul>"},{"location":"INDEX/#configuration","title":"Configuration","text":"<ul> <li>Environment Variables Management \u2014 Managing environment variables.</li> <li>Secrets Management \u2014 Secrets storage and rotation.</li> <li>Settings Patterns \u2014 Application settings organization.</li> <li>Configuration Validation \u2014 Validating configuration at startup.</li> </ul>"},{"location":"INDEX/#deployment","title":"Deployment","text":"<ul> <li>Production Deployment \u2014 Deploying to production.</li> <li>Development Environment Setup \u2014 Local development environment.</li> <li>CI/CD Patterns \u2014 CI/CD pipeline guidance.</li> <li>Deployment Monitoring Setup \u2014 Monitoring deployed services.</li> </ul>"},{"location":"INDEX/#observability","title":"Observability","text":""},{"location":"INDEX/#logging","title":"Logging","text":"<ul> <li>Structured Logging Patterns \u2014 Structured logging guidelines.</li> <li>Request ID Tracking \u2014 Request ID and correlation IDs.</li> <li>Log Correlation \u2014 Correlating log events.</li> <li>Log Formatting Standards \u2014 Log formatting rules.</li> <li>Sensitive Data Handling \u2014 Protecting sensitive data in logs.</li> <li>Centralized Logging \u2014 Centralized log aggregation.</li> </ul>"},{"location":"INDEX/#metrics","title":"Metrics","text":"<ul> <li>Prometheus Setup \u2014 Prometheus configuration.</li> <li>Service-Level Metrics \u2014 Service-level metric expectations.</li> <li>Golden Signals Implementation \u2014 Measuring and monitoring golden signals.</li> <li>Custom Metrics Patterns \u2014 Creating custom metrics.</li> <li>Monitoring Dashboards \u2014 Grafana and dashboard practices.</li> </ul>"},{"location":"INDEX/#tracing","title":"Tracing","text":"<ul> <li>OpenTelemetry Setup \u2014 Setting up OpenTelemetry.</li> <li>Distributed Tracing \u2014 Distributed tracing strategy.</li> <li>Jaeger Configuration \u2014 Configuring Jaeger.</li> <li>Trace Correlation \u2014 Correlating traces across services.</li> <li>Tracing for Performance Monitoring \u2014 Tracing performance diagnostics.</li> </ul>"},{"location":"INDEX/#error-tracking","title":"Error Tracking","text":"<ul> <li>Sentry Integration \u2014 Integrating Sentry.</li> <li>Error Grouping Strategies \u2014 Grouping and triaging errors.</li> <li>Error Alerting Patterns \u2014 Alerting best practices.</li> </ul>"},{"location":"INDEX/#elk-stack","title":"ELK Stack","text":"<ul> <li>Elasticsearch Setup \u2014 Configuring Elasticsearch.</li> <li>Logstash Configuration \u2014 Configuring Logstash.</li> <li>Kibana Dashboards \u2014 Kibana dashboard practices.</li> <li>Filebeat Setup \u2014 Configuring Filebeat.</li> </ul>"},{"location":"INDEX/#testing","title":"Testing","text":""},{"location":"INDEX/#unit-testing","title":"Unit Testing","text":"<ul> <li>Pytest Setup \u2014 Pytest configuration and conventions.</li> <li>Test Fixture Patterns \u2014 Fixture organization.</li> <li>Mocking Strategies \u2014 Mocking guidance.</li> <li>Parametrized Tests \u2014 Using parametrized tests.</li> <li>Coverage Requirements \u2014 Coverage targets and reporting.</li> </ul>"},{"location":"INDEX/#integration-testing","title":"Integration Testing","text":"<ul> <li>Testcontainers Setup \u2014 Testcontainers usage.</li> <li>Database Integration Testing \u2014 Database integration testing.</li> <li>Redis Integration Testing \u2014 Redis integration tests.</li> <li>RabbitMQ Integration Testing \u2014 RabbitMQ integration tests.</li> <li>HTTP Integration Testing \u2014 HTTP integration validation.</li> </ul>"},{"location":"INDEX/#service-testing","title":"Service Testing","text":"<ul> <li>FastAPI Service Testing Patterns \u2014 Testing FastAPI services.</li> <li>Aiogram Service Testing Patterns \u2014 Testing Aiogram bots.</li> <li>AsyncIO Service Testing Patterns \u2014 Testing async workers.</li> <li>Data Service Testing Patterns \u2014 Testing data services.</li> </ul>"},{"location":"INDEX/#end-to-end-testing","title":"End-to-End Testing","text":"<ul> <li>End-to-End Test Setup \u2014 E2E infrastructure setup.</li> <li>User Journey Testing \u2014 User journey test design.</li> <li>End-to-End Performance Testing \u2014 Performance testing guidance.</li> </ul>"},{"location":"INDEX/#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Linting Standards \u2014 Static analysis and linting.</li> <li>Type Checking \u2014 Type checking setup.</li> <li>Code Review Checklist \u2014 Checklist for reviews.</li> </ul>"},{"location":"INDEX/#maintenance","title":"Maintenance","text":"<ul> <li>Add new guidance to the appropriate <code>docs/atomic/</code> module and keep files atomic in scope.</li> <li>Update this index whenever a new atomic topic is created.</li> <li>Validate internal links as part of CI to avoid regressions in navigation.</li> </ul>"},{"location":"LINKS_REFERENCE/","title":"Project Links Reference","text":"<p>CENTRAL REFERENCE: All project documentation links in one place. Use this table instead of duplicating links in documents.</p> <p></p>"},{"location":"LINKS_REFERENCE/#core-documentation","title":"Core Documentation","text":"Document Direct Path Submodule Path Purpose Main Entry Point AGENTS.md <code>.ai-framework/AGENTS.md</code> Complete developer guide Project Overview README.md <code>.ai-framework/README.md</code> Project introduction and quick start Architecture Guide guides/architecture-guide.md <code>.ai-framework/docs/guides/architecture-guide.md</code> Canonical source of architectural principles Technical Specifications reference/tech_stack.md <code>.ai-framework/docs/reference/tech_stack.md</code> Technology versions and configurations"},{"location":"LINKS_REFERENCE/#developer-guides","title":"Developer Guides","text":"Document Direct Path Submodule Path Purpose AI Code Generation Master Workflow guides/ai-code-generation-master-workflow.md <code>.ai-framework/docs/guides/ai-code-generation-master-workflow.md</code> Complete 7-stage AI process (unified workflow) Development Commands guides/development-commands.md <code>.ai-framework/docs/guides/development-commands.md</code> All development commands Use Case Implementation guides/use-case-implementation-guide.md <code>.ai-framework/docs/guides/use-case-implementation-guide.md</code> Step-by-step creation of new use cases Prompt Validation Guide guides/prompt-validation-guide.md <code>.ai-framework/docs/guides/prompt-validation-guide.md</code> Mandatory intake checklist before work starts Requirements Intake Template guides/requirements-intake-template.md <code>.ai-framework/docs/guides/requirements-intake-template.md</code> Structured capture of inputs Implementation Plan Template guides/implementation-plan-template.md <code>.ai-framework/docs/guides/implementation-plan-template.md</code> Planning artefact for approval Project Structure reference/project-structure.md <code>.ai-framework/docs/reference/project-structure.md</code> Directory and file organization Troubleshooting reference/troubleshooting.md <code>.ai-framework/docs/reference/troubleshooting.md</code> Diagnostics and problem solving Style Guide STYLE_GUIDE.md <code>.ai-framework/docs/STYLE_GUIDE.md</code> Documentation formatting standards"},{"location":"LINKS_REFERENCE/#agent-references","title":"Agent References","text":"Document Direct Path Submodule Path Purpose Agent Context Summary reference/agent-context-summary.md <code>.ai-framework/docs/reference/agent-context-summary.md</code> Quick orientation for AI agents Maturity Levels reference/maturity-levels.md <code>.ai-framework/docs/reference/maturity-levels.md</code> 4 incremental levels from PoC to Production Conditional Stage Rules reference/conditional-stage-rules.md <code>.ai-framework/docs/reference/conditional-stage-rules.md</code> Stage skipping rules per maturity level AI Navigation Matrix reference/ai-navigation-matrix.md <code>.ai-framework/docs/reference/ai-navigation-matrix.md</code> Exact document mapping per workflow stage Agent Toolbox reference/agent-toolbox.md <code>.ai-framework/docs/reference/agent-toolbox.md</code> Machine-friendly command catalog Deliverables Catalog reference/deliverables-catalog.md <code>.ai-framework/docs/reference/deliverables-catalog.md</code> Required artefacts and storage rules Prompt Templates reference/prompt-templates.md <code>.ai-framework/docs/reference/prompt-templates.md</code> Reusable prompts for clarification and reporting Architecture Decision Log Template reference/architecture-decision-log-template.md <code>.ai-framework/docs/reference/architecture-decision-log-template.md</code> Standardised ADR format Semantic Shortening Guide guides/semantic-shortening-guide.md <code>.ai-framework/docs/guides/semantic-shortening-guide.md</code> 3-part service naming formula and decision tree"},{"location":"LINKS_REFERENCE/#atomic-knowledge-base","title":"Atomic Knowledge Base","text":"<p>Centralised atomic documentation for domain-specific rules. See INDEX.md for the full topic list.</p> Domain Entry Point Example Topics Architecture atomic/architecture/ hybrid approach, service separation, naming conventions Services atomic/services/ FastAPI, Aiogram, AsyncIO workers, data services Integrations atomic/integrations/ Redis, RabbitMQ, HTTP, cross-service coordination Infrastructure atomic/infrastructure/ databases, containerisation, configuration, deployment Observability atomic/observability/ logging, metrics, tracing, error tracking, ELK Testing atomic/testing/ unit, integration, service, end-to-end, QA <p></p>"},{"location":"LINKS_REFERENCE/#quality-assets","title":"Quality Assets","text":"Document Direct Path Submodule Path Purpose Agent Verification Checklist quality/agent-verification-checklist.md <code>.ai-framework/docs/quality/agent-verification-checklist.md</code> Mandatory quality gates QA Report Template quality/qa-report-template.md <code>.ai-framework/docs/quality/qa-report-template.md</code> Final QA summary"},{"location":"LINKS_REFERENCE/#quick-task-navigation","title":"Quick Task Navigation","text":"Task Documents Quick start README.md \u2192 AGENTS.md Understand architecture architecture-guide.md Run commands development-commands.md Create new use case use-case-implementation-guide.md AI-led code generation ai-code-generation-master-workflow.md \u2192 ai-navigation-matrix.md Check versions tech_stack.md Solve problems troubleshooting.md"},{"location":"LINKS_REFERENCE/#link-templates","title":"Link Templates","text":"<p>For simplified linking in other documents, use these templates:</p>"},{"location":"LINKS_REFERENCE/#core-documents","title":"Core Documents","text":"<pre><code>&lt;!-- Link to architecture guide --&gt;\n[Architecture Guide](LINKS_REFERENCE.md#core-documentation)\n\n&lt;!-- Link to technical specifications --&gt;\n[Technical Specifications](LINKS_REFERENCE.md#core-documentation)\n</code></pre>"},{"location":"LINKS_REFERENCE/#usage-examples","title":"Usage Examples","text":"<pre><code>&lt;!-- Instead of long construction --&gt;\n  - Link OK: reference/tech_stack.md\n&lt;!-- Use --&gt;\nSee [technical specifications](LINKS_REFERENCE.md#core-documentation)\n</code></pre> <p>Usage: Reference this table from other documents instead of duplicating links. Update this table when adding new documents.</p>"},{"location":"STYLE_GUIDE/","title":"Documentation Style Guide","text":"<p>PURPOSE: Unified formatting standards for all project documentation to improve readability and navigation.</p>"},{"location":"STYLE_GUIDE/#header-standards","title":"Header Standards","text":""},{"location":"STYLE_GUIDE/#header-format","title":"Header Format","text":"<pre><code># Main Document Title\n## Section Header\n### Subsection\n#### Detailed Subsection\n</code></pre>"},{"location":"STYLE_GUIDE/#link-standards","title":"Link Standards","text":""},{"location":"STYLE_GUIDE/#internal-links","title":"Internal Links","text":"<pre><code>&lt;!-- PREFERRED: Links through central table --&gt;\nSee [Architecture Guide](LINKS_REFERENCE.md#core-documentation)\n\n&lt;!-- AVOID: Direct links with submodule variants --&gt;\n[Architecture Guide](guides/architecture-guide.md) *(or `.ai-framework/docs/...` in submodule mode)*\n</code></pre>"},{"location":"STYLE_GUIDE/#external-links","title":"External Links","text":"<pre><code>&lt;!-- Correct format --&gt;\n[GitHub Repository](https://github.com/user/repo)\n</code></pre>"},{"location":"STYLE_GUIDE/#emphasis-and-quote-standards","title":"Emphasis and Quote Standards","text":""},{"location":"STYLE_GUIDE/#important-blocks","title":"Important Blocks","text":"<pre><code>&lt;!-- For architectural principles --&gt;\n&gt; **ARCHITECTURAL FOUNDATION**: Principle description\n\n&lt;!-- For mandatory requirements --&gt;\n&gt; **MANDATORY**: Mandatory requirement\n\n&lt;!-- For links to additional materials --&gt;\n&gt; **DETAILS**: See [Link Standards](#link-standards) for detailed information\n</code></pre>"},{"location":"STYLE_GUIDE/#requirement-lists","title":"Requirement Lists","text":"<pre><code>#### Mandatory Requirements (MANDATORY)\n- **Requirement 1**: Description\n- **Requirement 2**: Description\n\n#### Prohibited Practices (PROHIBITED)\n- **Practice 1**: Why prohibited\n- **Practice 2**: Why prohibited\n</code></pre>"},{"location":"STYLE_GUIDE/#table-standards","title":"Table Standards","text":""},{"location":"STYLE_GUIDE/#navigation-tables","title":"Navigation Tables","text":"<pre><code>| Task | Document |\n|------|----------|\n| **Quick start** | [Example Link](guides/architecture-guide.md) |\n| **Understand architecture** | [Example Link](guides/architecture-guide.md) |\n</code></pre>"},{"location":"STYLE_GUIDE/#technical-specifications","title":"Technical Specifications","text":"<pre><code>| Component | Technology | Version | Purpose |\n|-----------|------------|---------|---------|\n| **Runtime** | Python | 3.12+ | Main platform |\n| **Web Framework** | FastAPI | Latest | API services |\n</code></pre>"},{"location":"STYLE_GUIDE/#code-standards","title":"Code Standards","text":""},{"location":"STYLE_GUIDE/#code-examples","title":"Code Examples","text":"<p><pre><code>```python\n# CORRECT: Description of correct approach\nasync def good_example():\n    return await some_async_operation()\n\n# INCORRECT: Description of incorrect approach\ndef bad_example():\n    return sync_operation()\n</code></pre> <pre><code>## Document Structure\n\n### Standard Document Template\n```markdown\n# Document Title\n\n&gt; **PURPOSE**: Brief description of document purpose\n\n## Table of Contents\n- [Header Standards](#header-standards)\n- [Link Standards](#link-standards)\n\n---\n\n## Main Content\n\nMain document content...\n\n## Related Documents\n\n- **Architecture**: [Link](LINKS_REFERENCE.md#core-documentation)\n- **Implementation Guide**: [Link](LINKS_REFERENCE.md#developer-guides)\n\n---\n\n&gt; **NAVIGATION**: To return to main guide see [AGENTS.md](LINKS_REFERENCE.md#core-documentation)\n</code></pre></p>"},{"location":"STYLE_GUIDE/#writing-principles","title":"Writing Principles","text":""},{"location":"STYLE_GUIDE/#tone-and-style","title":"Tone and Style","text":"<ul> <li>Conciseness: Avoid unnecessary words</li> <li>Precision: Use specific terms</li> <li>Structure: Logical sequence of sections</li> <li>Relevance: Regularly update content</li> </ul>"},{"location":"STYLE_GUIDE/#avoid-duplication","title":"Avoid Duplication","text":"<ul> <li>Reference central links table instead of repeating paths</li> <li>Reference canonical sources instead of copying information</li> <li>Use brief overviews + links instead of full duplication</li> </ul>"},{"location":"STYLE_GUIDE/#quality-control","title":"Quality Control","text":""},{"location":"STYLE_GUIDE/#pre-publication-checklist","title":"Pre-publication Checklist","text":"<ul> <li> All internal links work</li> <li> Consistent header style used</li> <li> No duplication of information from other documents</li> <li> Links to related documents included</li> <li> Structure follows template</li> </ul> <p>APPLICATION: Use this guide when creating and editing all project documents to maintain style consistency.</p>"},{"location":"atomic/","title":"Atomic Documentation Hub","text":"<p>The <code>docs/atomic</code> tree provides the canonical, domain-scoped knowledge base for the platform. Each Markdown file focuses on a single responsibility and serves as the definitive reference for its topic.</p>"},{"location":"atomic/#writing-new-atomic-documents","title":"\ud83d\udcdd Writing New Atomic Documents","text":"<p>ALWAYS use the universal template when creating new documentation:</p> <p>\ud83d\udc49 TEMPLATE.md \u2014 Universal template for all atomic documents</p>"},{"location":"atomic/#quick-start","title":"Quick Start","text":"<pre><code># 1. Copy template to your category\ncp docs/atomic/TEMPLATE.md docs/atomic/{category}/{your-topic}.md\n\n# 2. Edit the file and replace placeholders:\n#    - {Topic Title} \u2192 Your specific topic name\n#    - {Category-Specific Sections} \u2192 Choose from template guide\n#    - {Brief introduction} \u2192 Write 1-3 paragraphs\n#    - Add code examples, related documents\n\n# 3. Remove reference sections:\n#    - Delete \"Category-Specific Section Guide\" (it's for reference only)\n#    - Delete \"Validation Checklist\" (after checking)\n\n# 4. Validate (optional, if script exists)\npython scripts/validate_atomic_docs.py docs/atomic/{category}/{your-topic}.md\n</code></pre>"},{"location":"atomic/#example-workflow","title":"Example Workflow","text":"<pre><code># Creating a new Redis caching patterns document\n\n# Step 1: Copy template\ncp docs/atomic/TEMPLATE.md docs/atomic/integrations/redis/caching-strategies.md\n\n# Step 2: Edit file\n# - Title: \"Redis Caching Strategies\"\n# - Introduction: Explain caching patterns for Redis\n# - Sections: Configuration, Best Practices, Examples\n# - Code: Show cache-aside, write-through patterns\n# - Related docs: connection-management.md, key-naming-conventions.md\n\n# Step 3: Remove reference sections\n# - Delete \"Category-Specific Section Guide\"\n# - Delete \"Validation Checklist\"\n\n# Done! Your document follows the standard.\n</code></pre>"},{"location":"atomic/#document-standard","title":"\ud83d\udccb Document Standard","text":"<p>Each atomic document MUST include:</p> Element Required Description H1 Title \u2705 MANDATORY Clear, specific topic name (no placeholders) Introduction \u2705 MANDATORY 1-3 paragraphs explaining what, why, when Category-Specific Sections \u2705 MANDATORY Choose appropriate sections from template Code Examples \u26a0\ufe0f IF APPLICABLE CORRECT/INCORRECT patterns for practical guidance Related Documents \u2705 MANDATORY Links to 2-3+ related atomic docs"},{"location":"atomic/#mandatory-structure","title":"Mandatory Structure","text":"<pre><code># {Clear Specific Title}\n\n{Introduction: 1-3 paragraphs}\n\n## {Category-Specific Sections}\n{Content with examples}\n\n## Related Documents\n- `docs/atomic/{category}/{file}.md`\n- `docs/atomic/{category}/{file2}.md`\n</code></pre>"},{"location":"atomic/#core-principles","title":"\ud83c\udfaf Core Principles","text":"Principle Description Example Single Responsibility One topic = one file \u2705 <code>redis-connection-management.md</code>  \u274c <code>redis-everything.md</code> Concise Keep focused, typically &lt; 200 lines Short, scannable documents Definitive Authoritative source for the topic This is the SSOT Linked Reference related docs, don't duplicate Use links instead of copying Practical Include working code examples Real-world guidance Current Use latest versions (Python 3.12+, current libs) No outdated patterns"},{"location":"atomic/#category-overview","title":"\ud83d\udcc2 Category Overview","text":"Category Focus Document Count Status architecture/ Architectural principles, patterns, constraints 10 \u2705 Complete services/ Service-specific setup and patterns 28 \u2705 Complete - <code>services/fastapi/</code> FastAPI setup, routing, security, testing 11 \u2705 Complete - <code>services/aiogram/</code> Aiogram bot setup, handlers, middleware 8 \u2705 Complete - <code>services/asyncio-workers/</code> AsyncIO workers, task management 7 \u2705 Complete - <code>services/data-services/</code> Data service patterns for PostgreSQL/MongoDB 6 \u26a0\ufe0f Partial integrations/ Integration patterns for external systems 36 \u2705 Complete - <code>integrations/redis/</code> Redis connection, caching, idempotency 9 \u2705 Complete - <code>integrations/rabbitmq/</code> RabbitMQ messaging, queues, consumers 11 \u2705 Complete - <code>integrations/http-communication/</code> HTTP clients, retries, tracing 6 \u2705 Complete - <code>integrations/cross-service/</code> Service discovery, health checks 4 \u2705 Complete infrastructure/ Infrastructure setup and deployment 24 \u2705 Complete - <code>infrastructure/containerization/</code> Docker, Docker Compose patterns 5 \u2705 Complete - <code>infrastructure/api-gateway/</code> Nginx, load balancing, SSL 5 \u2705 Complete - <code>infrastructure/databases/</code> Database setup, migrations 5 \u2705 Complete - <code>infrastructure/configuration/</code> Config management, secrets 4 \u2705 Complete - <code>infrastructure/deployment/</code> CI/CD, production deployment 4 \u2705 Complete observability/ Logging, metrics, tracing, error tracking 24 \u26a0\ufe0f Need work (18 TODO) - <code>observability/logging/</code> Structured logging, correlation 6 \u26a0\ufe0f TODO - <code>observability/metrics/</code> Prometheus, custom metrics 5 \u26a0\ufe0f TODO - <code>observability/tracing/</code> OpenTelemetry, Jaeger 5 \u26a0\ufe0f TODO - <code>observability/error-tracking/</code> Sentry integration, alerting 3 \u26a0\ufe0f TODO - <code>observability/elk-stack/</code> Elasticsearch, Logstash, Kibana 4 \u26a0\ufe0f TODO testing/ Unit, integration, E2E, service testing 20 \u26a0\ufe0f Need work (20 TODO) - <code>testing/unit-testing/</code> Pytest, fixtures, mocking 5 \u26a0\ufe0f TODO - <code>testing/integration-testing/</code> Testcontainers, database testing 5 \u26a0\ufe0f TODO - <code>testing/service-testing/</code> FastAPI, Aiogram, Worker testing 4 \u26a0\ufe0f TODO - <code>testing/end-to-end-testing/</code> User journey, performance testing 3 \u26a0\ufe0f TODO - <code>testing/quality-assurance/</code> Linting, type checking, code review 3 \u26a0\ufe0f TODO databases/ Database setup and patterns 6 \u2705 Complete security/ Security patterns and implementations 4 \u2705 Complete real-time/ WebSocket, SSE, real-time patterns 4 \u2705 Complete file-storage/ File storage patterns (S3, local) 5 \u2705 Complete external-integrations/ Third-party API integrations 4 \u2705 Complete <p>Total: 162 documents | Completed: 119 (73%) | TODO: 43 (27%)</p>"},{"location":"atomic/#contributing","title":"\ud83d\ude80 Contributing","text":""},{"location":"atomic/#adding-new-documents","title":"Adding New Documents","text":"<ol> <li>Use Template: Copy <code>TEMPLATE.md</code> as starting point</li> <li>Follow Section Guide: Choose appropriate sections from template's category guide</li> <li>Write Content: Fill in introduction, sections, code examples, related links</li> <li>Remove Reference Sections: Delete \"Category-Specific Section Guide\" and \"Validation Checklist\"</li> <li>Validate: Check against template's validation checklist</li> <li>Update Indexes: Add entry to this README and <code>docs/INDEX.md</code></li> </ol>"},{"location":"atomic/#updating-existing-documents","title":"Updating Existing Documents","text":"<ol> <li>Read Current Version: Understand existing content</li> <li>Check Template Compliance: Verify structure matches <code>TEMPLATE.md</code></li> <li>Update Content: Improve clarity, add examples, update versions</li> <li>Verify Links: Ensure all related documents links work</li> <li>Update Metadata: Change \"Last Updated\" date if document has metadata section</li> </ol>"},{"location":"atomic/#quality-standards","title":"Quality Standards","text":"<p>Before submitting new/updated atomic documents:</p> <ul> <li> Structure follows <code>TEMPLATE.md</code></li> <li> H1 title is clear and specific</li> <li> Introduction has 1-3 paragraphs minimum</li> <li> Code examples use Python 3.12+ with type hints</li> <li> Code examples follow CORRECT/INCORRECT pattern (when applicable)</li> <li> \"Related Documents\" section has 2-3+ links</li> <li> No TODO placeholders</li> <li> No sensitive data (passwords, tokens, real IPs)</li> <li> Follows naming conventions (snake_case for code, kebab-case for Kubernetes)</li> <li> Links use relative paths (<code>docs/atomic/...</code>)</li> <li> No grammar/spelling errors</li> </ul>"},{"location":"atomic/#maintenance","title":"\ud83d\udd27 Maintenance","text":""},{"location":"atomic/#updating-technology-versions","title":"Updating Technology Versions","text":"<p>When underlying technologies change (Python version, library versions, etc.):</p> <ol> <li>Update relevant atomic documents</li> <li>Update code examples with new syntax/APIs</li> <li>Test updated examples</li> <li>Update \"Prerequisites\" or \"Dependencies\" sections</li> <li>Note version changes in commit message</li> </ol>"},{"location":"atomic/#archiving-obsolete-documents","title":"Archiving Obsolete Documents","text":"<p>If a pattern becomes obsolete:</p> <ol> <li>Add \"DEPRECATED\" notice at top of document</li> <li>Update links in related documents</li> <li>Remove from this README's category list</li> <li>Mark in <code>docs/INDEX.md</code> with \u26a0\ufe0f DEPRECATED marker</li> <li>Consider removal after 6 months if no usage</li> </ol>"},{"location":"atomic/#regular-maintenance-tasks","title":"Regular Maintenance Tasks","text":"<ul> <li>Monthly: Review TODO documents, prioritize filling gaps</li> <li>Quarterly: Check for broken links, outdated examples</li> <li>Per major version: Update all code examples, dependency versions</li> <li>As needed: Add new categories when introducing new technologies</li> </ul>"},{"location":"atomic/#documentation-coverage","title":"\ud83d\udcca Documentation Coverage","text":""},{"location":"atomic/#current-status","title":"Current Status","text":"<pre><code>Total Documents:     162\nCompleted:           119 (73%)\nTODO (Need Work):     43 (27%)\n\nPriority Areas:\n- testing/*          20 TODO documents (HIGH PRIORITY)\n- observability/*    18 TODO documents (HIGH PRIORITY)\n- other categories    5 TODO documents (LOW PRIORITY)\n</code></pre>"},{"location":"atomic/#filling-todo-documents","title":"Filling TODO Documents","text":"<p>High Priority (critical for quality gates): 1. <code>testing/unit-testing/</code> \u2014 5 docs (pytest-setup, fixtures, mocking, parametrized, coverage) 2. <code>testing/integration-testing/</code> \u2014 5 docs (testcontainers, database, Redis, RabbitMQ, HTTP) 3. <code>testing/service-testing/</code> \u2014 4 docs (FastAPI, Aiogram, AsyncIO, data-service testing)</p> <p>Medium Priority (important for production readiness): 1. <code>observability/logging/</code> \u2014 6 docs (structured logging, request-id, correlation, etc.) 2. <code>observability/metrics/</code> \u2014 5 docs (Prometheus, custom metrics, golden signals, etc.) 3. <code>observability/tracing/</code> \u2014 5 docs (OpenTelemetry, Jaeger, distributed tracing, etc.)</p> <p>Low Priority (nice to have): 1. Remaining observability docs (error-tracking, ELK stack) 2. Scattered TODO docs in other categories</p>"},{"location":"atomic/#finding-documents","title":"\ud83d\udd0d Finding Documents","text":""},{"location":"atomic/#by-task","title":"By Task","text":"I want to... See Category Understand architecture principles <code>architecture/</code> Set up a FastAPI service <code>services/fastapi/</code> Set up an Aiogram bot <code>services/aiogram/</code> Set up an AsyncIO worker <code>services/asyncio-workers/</code> Integrate with Redis <code>integrations/redis/</code> Integrate with RabbitMQ <code>integrations/rabbitmq/</code> Make HTTP calls between services <code>integrations/http-communication/</code> Set up Docker Compose <code>infrastructure/containerization/</code> Configure Nginx <code>infrastructure/api-gateway/</code> Deploy to production <code>infrastructure/deployment/</code> Add logging <code>observability/logging/</code> Add metrics <code>observability/metrics/</code> Add tracing <code>observability/tracing/</code> Write tests <code>testing/</code> (specific subdirectory by test type) Set up PostgreSQL <code>databases/postgresql/</code> Implement security <code>security/</code> Add WebSocket support <code>real-time/</code> Upload/download files <code>file-storage/</code> Integrate third-party API <code>external-integrations/</code>"},{"location":"atomic/#by-document-name","title":"By Document Name","text":"<p>See <code>docs/INDEX.md</code> for complete alphabetical index of all atomic documents.</p>"},{"location":"atomic/#related-documentation","title":"\ud83d\udcda Related Documentation","text":"<ul> <li>TEMPLATE.md \u2014 Universal template for atomic documents</li> <li>../INDEX.md \u2014 Complete documentation catalog</li> <li>../LINKS_REFERENCE.md \u2014 Central link reference table</li> <li>../STYLE_GUIDE.md \u2014 Formatting standards</li> <li>../guides/architecture-guide.md \u2014 Architecture overview</li> </ul>"},{"location":"atomic/#tips-for-document-authors","title":"\ud83d\udca1 Tips for Document Authors","text":""},{"location":"atomic/#writing-effective-code-examples","title":"Writing Effective Code Examples","text":"<pre><code># \u2705 GOOD: Clear, runnable, with context\nasync def create_user(user_data: UserCreateDTO) -&gt; User:\n    \"\"\"Create a new user with validation.\n\n    Args:\n        user_data: User creation data\n\n    Returns:\n        Created user instance\n\n    Raises:\n        ValidationError: If user_data is invalid\n    \"\"\"\n    # Validate email format\n    if not is_valid_email(user_data.email):\n        raise ValidationError(\"Invalid email format\")\n\n    # Create user via data service HTTP call\n    user = await postgres_client.create_user(user_data.dict())\n    return User(**user)\n\n# \u274c BAD: No context, unclear purpose\ndef create(data):\n    return db.insert(data)\n</code></pre>"},{"location":"atomic/#linking-to-related-documents","title":"Linking to Related Documents","text":"<pre><code>\u2705 GOOD:\n- `docs/atomic/services/fastapi/basic-setup.md` \u2014 FastAPI service scaffolding\n- `docs/atomic/integrations/redis/connection-management.md` \u2014 Redis client setup\n\n\u274c BAD:\n- See FastAPI docs\n- Check Redis integration\n</code></pre>"},{"location":"atomic/#structuring-sections","title":"Structuring Sections","text":"<pre><code>\u2705 GOOD: Clear hierarchy\n## Configuration\n### Client Setup\n### Connection Pooling\n### Timeouts\n\n\u274c BAD: Flat structure\n## Configuration\n## Client Setup\n## Connection Pooling\n## Timeouts\n</code></pre>"},{"location":"atomic/#common-mistakes-to-avoid","title":"\u26a0\ufe0f Common Mistakes to Avoid","text":"<ol> <li>Creating documents without using TEMPLATE.md</li> <li>Result: Inconsistent structure, missing sections</li> <li> <p>Fix: Always start with <code>cp docs/atomic/TEMPLATE.md ...</code></p> </li> <li> <p>Duplicating content from other documents</p> </li> <li>Result: Maintenance nightmare, conflicting info</li> <li> <p>Fix: Link to other docs instead of copying</p> </li> <li> <p>Writing generic documents that cover multiple topics</p> </li> <li>Result: Violates single responsibility principle</li> <li> <p>Fix: Split into multiple focused documents</p> </li> <li> <p>Using outdated code examples</p> </li> <li>Result: Users copy old patterns</li> <li> <p>Fix: Always use Python 3.12+, latest library versions</p> </li> <li> <p>Not removing reference sections from TEMPLATE.md</p> </li> <li>Result: Published docs contain meta-instructions</li> <li> <p>Fix: Delete \"Category-Specific Section Guide\" and \"Validation Checklist\"</p> </li> <li> <p>Missing Related Documents section</p> </li> <li>Result: Users can't navigate to related content</li> <li> <p>Fix: Always include 2-3+ related document links</p> </li> <li> <p>Using hyphens in Python code examples</p> </li> <li>Result: SyntaxError when users copy code</li> <li>Fix: Use snake_case (<code>finance_lending_api</code>, not <code>finance-lending-api</code>)</li> </ol>"},{"location":"atomic/#getting-help","title":"\ud83d\udcde Getting Help","text":"<ul> <li>Questions about template usage: See <code>TEMPLATE.md</code> instructions and examples</li> <li>Questions about specific categories: See existing documents in that category</li> <li>Questions about architecture: See <code>docs/guides/architecture-guide.md</code></li> <li>Questions about framework: See <code>README.md</code> at project root</li> </ul> <p>Last Updated: 2025-01-15 Maintainers: Documentation Team</p>"},{"location":"atomic/CHANGELOG/","title":"Atomic Documentation Changelog","text":"<p>All notable changes to atomic documentation are documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"atomic/CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"atomic/CHANGELOG/#010-2025-11-05","title":"[0.1.0] - 2025-11-05","text":""},{"location":"atomic/CHANGELOG/#added","title":"Added","text":"<ul> <li>Initial release of AI Generator for Async Microservices framework</li> <li>135+ atomic documentation modules covering architecture, services, infrastructure, observability, testing, security</li> <li>Complete service templates structure (Business API, Bots, Workers, PostgreSQL/MongoDB Data APIs)</li> <li>Production-ready infrastructure configurations (Docker, Nginx, CI/CD, Prometheus, Grafana, Jaeger)</li> <li>7-stage AI workflow (Validation \u2192 Requirements \u2192 Planning \u2192 Generation \u2192 Verification \u2192 Handoff)</li> <li>Improved Hybrid Architecture with strict HTTP-only data access</li> <li>Maturity levels system (PoC to Production)</li> <li>Comprehensive testing strategies and quality standards</li> </ul>"},{"location":"atomic/CHANGELOG/#versioning-guidelines","title":"Versioning Guidelines","text":""},{"location":"atomic/CHANGELOG/#version-number-format","title":"Version Number Format","text":"<ul> <li>Major version (X.0.0): Breaking changes to documentation structure or significant reorganization</li> <li>Minor version (0.X.0): New atomic documents added, sections reorganized</li> <li>Patch version (0.1.X): Link fixes, typos, clarifications, minor updates</li> </ul>"},{"location":"atomic/CHANGELOG/#what-constitutes-breaking-changes","title":"What Constitutes Breaking Changes?","text":"<ul> <li>Renaming or moving atomic files without redirects</li> <li>Removing atomic files that are referenced by multiple documents</li> <li>Changing fundamental architecture principles</li> <li>Restructuring INDEX.md navigation significantly</li> </ul>"},{"location":"atomic/CHANGELOG/#update-workflow","title":"Update Workflow","text":"<ol> <li>Make changes to atomic documentation</li> <li>Update this CHANGELOG.md under [Unreleased]</li> <li>When ready for release:</li> <li>Decide version number based on changes</li> <li>Move [Unreleased] content to new version section</li> <li>Update version date</li> <li>Tag Git repository with version</li> </ol>"},{"location":"atomic/CHANGELOG/#git-tagging","title":"Git Tagging","text":"<pre><code># Tag the release\ngit tag -a v0.1.0 -m \"Release v0.1.0: Initial framework release\"\n\n# Push tags to remote\ngit push origin v0.1.0\n</code></pre>"},{"location":"atomic/CHANGELOG/#contributing","title":"Contributing","text":"<p>When adding new atomic documentation: 1. Create the atomic file in appropriate domain directory 2. Add entry to this CHANGELOG under [Unreleased] 3. Update <code>INDEX.md</code> with new file reference 4. Run link validation: <code>./scripts/check_links.sh</code> 5. Update version in pull request based on change type</p>"},{"location":"atomic/CHANGELOG/#support","title":"Support","text":"<p>For questions about atomic documentation versions: - Check this CHANGELOG for recent changes - Review <code>INDEX.md</code> for current structure - See <code>agent-context-summary.md</code> for quick orientation</p>"},{"location":"atomic/TEMPLATE/","title":"{Topic Title}","text":"<p>INSTRUCTION: Replace <code>{Topic Title}</code> with the specific topic you are documenting (e.g., \"Redis Connection Management\", \"FastAPI Basic Setup\", \"Service Separation Principles\").</p> <p>{Brief introduction: 1-3 paragraphs describing what this pattern/concept is and why it matters}</p> <p>INSTRUCTION: Provide context. Answer: What is this? Why does it exist? When should developers use it?</p> <p>Example: \"This guide covers the minimum scaffolding required to spin up a FastAPI business service that conforms to the Improved Hybrid Approach.\"</p>"},{"location":"atomic/TEMPLATE/#category-specific-sections","title":"{Category-Specific Sections}","text":"<p>INSTRUCTION: Choose appropriate sections based on your document category. See \"Category-Specific Section Guide\" below for detailed examples per category.</p>"},{"location":"atomic/TEMPLATE/#quick-section-selector","title":"Quick Section Selector","text":"<p>For Architecture documents, use: - Guiding Rules / Principles - Responsibility Matrix (if applicable) - When to Use - Anti-Patterns to Avoid - Anti-Patterns (detailed section with WRONG/CORRECT examples)</p> <p>For Service Setup documents (services/fastapi, services/aiogram, services/asyncio-workers, services/data-services), use: - Prerequisites - Project Structure / Project Skeleton - Dependencies - Entry Point (with code example) - Checklist</p> <p>For Integration documents (integrations/redis, integrations/rabbitmq, integrations/http-communication, integrations/cross-service), use: - Client Construction / Configuration (with code example) - Best Practices / Guidelines - Observability (if applicable) - Testing (if applicable) - Failure Scenarios (if applicable)</p> <p>For Infrastructure documents (infrastructure/containerization, infrastructure/deployment, infrastructure/api-gateway, infrastructure/databases, infrastructure/configuration), use: - Structure - Best Practices - Configuration Examples (if applicable)</p> <p>For Testing documents (testing/unit-testing, testing/integration-testing, testing/service-testing, testing/end-to-end-testing, testing/quality-assurance), use: - Setup / Configuration - Test Patterns / Examples (with code) - Assertions / Expectations</p> <p>For Observability documents (observability/logging, observability/metrics, observability/tracing, observability/error-tracking, observability/elk-stack), use: - Configuration - Implementation Examples - Best Practices - Integration with Service Types (if applicable)</p> <p>For Database documents (databases/postgresql, databases/postgresql-advanced), use: - Setup / Configuration - Connection Management - Best Practices - Performance Considerations</p> <p>For Security documents, use: - Configuration - Implementation Examples - Best Practices - Threat Mitigation</p> <p>For Real-time documents, use: - Setup / Configuration - Implementation Examples - Connection Management - Best Practices</p> <p>For File Storage documents, use: - Configuration - Upload/Download Patterns - Best Practices</p> <p>For External Integrations documents, use: - Authentication / Configuration - API Client Setup - Best Practices - Error Handling</p>"},{"location":"atomic/TEMPLATE/#code-examples-if-applicable","title":"Code Examples (if applicable)","text":"<p>INSTRUCTION: Include practical code examples that demonstrate the concept. Use the CORRECT/INCORRECT pattern to show both best practices and anti-patterns.</p> <pre><code># CORRECT: Brief description of correct approach\nasync def good_example():\n    \"\"\"Docstring explaining what this does and why it's correct.\"\"\"\n    return await some_async_operation()\n\n# INCORRECT: Brief description of incorrect approach (anti-pattern)\ndef bad_example():\n    return sync_operation()  # Why this is wrong: blocks event loop\n</code></pre> <p>TIP: Code examples should be: - Runnable (or nearly runnable with minimal context) - Follow naming conventions (snake_case, underscore separators) - Include type hints (Python 3.12+ style) - Have clear docstrings - Show both positive and negative examples when relevant</p>"},{"location":"atomic/TEMPLATE/#related-documents","title":"Related Documents","text":"<p>INSTRUCTION: Link to related atomic documents that provide additional context or related patterns. Always include at least 2-3 related documents. Use relative paths starting with <code>docs/atomic/</code>.</p> <ul> <li><code>docs/atomic/{category}/{related-file}.md</code> \u2014 Brief description of what this related doc covers</li> <li><code>docs/atomic/{category}/{another-related-file}.md</code> \u2014 Brief description of what this related doc covers</li> </ul> <p>TIP: - Architecture docs \u2192 link to service setup docs that implement the principles - Service docs \u2192 link to integration docs for dependencies (Redis, RabbitMQ, etc.) - Integration docs \u2192 link to testing docs for testing patterns - Testing docs \u2192 link to service docs being tested</p>"},{"location":"atomic/TEMPLATE/#category-specific-section-guide","title":"Category-Specific Section Guide","text":"<p>FOR REFERENCE ONLY: This section provides detailed examples of middle sections commonly used in each category. Remove this entire section when creating a real document.</p>"},{"location":"atomic/TEMPLATE/#architecture-documents","title":"Architecture Documents","text":"<p>Purpose: Define principles, boundaries, and patterns for system-wide concerns.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#guiding-rules-principles","title":"## Guiding Rules / Principles","text":"<p>List 3-7 key principles that govern this architectural decision.</p> <p>Example: <pre><code>## Guiding Rules\n\n1. **Business logic stays in business services.** These services expose HTTP APIs, bot handlers, or background jobs.\n2. **Data services own persistence.** Data services wrap PostgreSQL or MongoDB and expose domain-aware HTTP endpoints.\n3. **Event loop ownership is explicit.** Each process manages exactly one event loop.\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#responsibility-matrix-if-applicable","title":"## Responsibility Matrix (if applicable)","text":"<p>Show what each service type is responsible for.</p> <p>Example: <pre><code>## Responsibility Matrix\n\n| Concern | Business Service | Data Service | Platform |\n|---------|-----------------|--------------|----------|\n| Domain logic | \u2705 | \ud83d\udeab | \ud83d\udeab |\n| Schema migrations | \ud83d\udeab | \u2705 | \ud83d\udeab |\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#when-to-use","title":"## When to Use","text":"<p>Describe scenarios where this pattern/principle applies.</p>"},{"location":"atomic/TEMPLATE/#anti-patterns-to-avoid","title":"## Anti-Patterns to Avoid","text":"<p>List common mistakes and why they're problematic.</p>"},{"location":"atomic/TEMPLATE/#enforcement-if-applicable","title":"## Enforcement (if applicable)","text":"<p>How to ensure compliance (CI checks, code reviews, etc.)</p> <p>Example files: <code>improved-hybrid-overview.md</code>, <code>service-separation-principles.md</code>, <code>event-loop-management.md</code></p>"},{"location":"atomic/TEMPLATE/#anti-patterns-section-applicable-to-all-categories","title":"Anti-Patterns Section (Applicable to ALL categories)","text":"<p>Purpose: Document common mistakes and production failures to prevent repetition.</p> <p>When to include: - Pattern causes production failures (crashes, data loss, security issues) - Pattern is commonly misunderstood or misimplemented - Pattern violates core architectural principles - Pattern has observable symptoms that need documentation</p> <p>Structure:</p> <pre><code>## Anti-Patterns\n\n### \u274c [Descriptive Anti-Pattern Name]\n\n**Problem**: [1-2 sentences describing the core issue]\n\n**Symptom**: [Observable production symptom - what developers/ops will see]\n\n**Impact**: [Business/technical consequences]\n\n**Example (WRONG)**:\n```python\n# Code demonstrating the anti-pattern\n# Include real file references when applicable (e.g., src/api/handlers/poll.py:45-48)\n# Show what NOT to do\n</code></pre> <p>Why This Matters: - [Bullet point explaining consequences] - [Technical reasons why this pattern breaks in production] - [Long-term impact on maintainability/scalability]</p> <p>Solution (CORRECT): <pre><code># Fixed version with proper implementation\n# Include comments explaining the fix\n# Show best practice approach\n</code></pre></p> <p>Architecture Rule:</p> <p>[Quoted guideline to prevent this pattern - links to architectural principles]</p> <p>Monitoring (optional, for operational anti-patterns): <pre><code># Command to detect this pattern in production\ndocker stats --no-stream service_name\ndocker exec service sh -c 'ls /proc/$$/fd | wc -l'\n</code></pre></p> <p>Related Anti-Patterns: [Links to related anti-patterns in other documents] - [Another Anti-Pattern] \u2192 <code>docs/atomic/category/file.md#anchor</code> <pre><code>**Priority Classification**:\n- \ud83d\udd34 **CRITICAL**: Production crashes, data loss, security vulnerabilities\n- \ud83d\udfe0 **HIGH**: Silent failures, debugging issues, breaking changes on upgrade\n- \ud83d\udfe1 **MEDIUM**: Performance degradation, maintainability issues\n\n**Best Practices**:\n- Keep anti-patterns concise (max 50-70 lines per anti-pattern)\n- Always show both WRONG and CORRECT examples\n- Include monitoring commands when pattern has observable metrics\n- Link to related anti-patterns for cross-reference\n- Use real production symptoms when possible\n\n---\n\n### Service Setup Documents (FastAPI, Aiogram, AsyncIO Workers, Data Services)\n\n**Purpose**: Provide step-by-step setup instructions for bootstrapping a new service.\n\n**Common sections:**\n\n#### ## Prerequisites\nList required tools, versions, and prior knowledge.\n\n**Example**:\n```markdown\n## Prerequisites\n\n- Python 3.12+ with `uv` or `pip` for dependency management\n- `src/` layout prepared according to `docs/atomic/architecture/project-structure-patterns.md`\n- Shared configuration defined in `src/core/config.py` (Pydantic `BaseSettings`)\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#project-structure-project-skeleton","title":"## Project Structure / Project Skeleton","text":"<p>Show the directory layout with explanations.</p> <p>Example: <pre><code>## Initial Project Structure\n\n\\`\\`\\`\nsrc/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 v1/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 health_router.py\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u2514\u2500\u2500 logging.py\n\u2514\u2500\u2500 main.py\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#dependencies","title":"## Dependencies","text":"<p>Show pyproject.toml or requirements with versions.</p> <p>Example: <pre><code>## Dependencies\n\n\\`\\`\\`toml\n[project]\nname = \"my_fastapi_service\"\nrequires-python = \"&gt;=3.12\"\n\n[project.dependencies]\nfastapi = \"^0.111\"\nuvicorn = \"^0.30\"\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#entry-point-with-code-example","title":"## Entry Point (with code example)","text":"<p>Show the main.py or equivalent with full code.</p>"},{"location":"atomic/TEMPLATE/#checklist","title":"## Checklist","text":"<p>Provide verification steps to confirm setup is correct.</p> <p>Example: <pre><code>## Startup Checklist\n\n- [ ] Project structure matches the reference layout\n- [ ] Logging configured once in `create_app()`\n- [ ] `/api/v1/health` endpoint returns static status\n- [ ] Uvicorn entry point uses application factory\n</code></pre></p> <p>Example files: <code>fastapi/basic-setup.md</code>, <code>aiogram/basic-setup.md</code>, <code>asyncio-workers/basic-setup.md</code></p>"},{"location":"atomic/TEMPLATE/#integration-documents-redis-rabbitmq-http-cross-service","title":"Integration Documents (Redis, RabbitMQ, HTTP, Cross-Service)","text":"<p>Purpose: Show how to integrate with external systems or services.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#client-construction-configuration","title":"## Client Construction / Configuration","text":"<p>Show how to create and configure the client.</p> <p>Example: <pre><code>## Client Construction\n\n\\`\\`\\`python\nfrom redis.asyncio import Redis\n\ndef build_redis(url: str) -&gt; Redis:\n    return Redis.from_url(\n        url,\n        encoding=\"utf-8\",\n        decode_responses=True,\n        max_connections=100,\n    )\n\\`\\`\\`\n\n- Instantiate the client inside FastAPI lifespan or Aiogram startup\n- Store the client in application state (`app.state.redis`)\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#best-practices-guidelines","title":"## Best Practices / Guidelines","text":"<p>List 3-7 important guidelines for using this integration.</p>"},{"location":"atomic/TEMPLATE/#observability-if-applicable","title":"## Observability (if applicable)","text":"<p>How to add logging, metrics, tracing for this integration.</p> <p>Example: <pre><code>## Observability\n\n- Log connection lifecycle events (`redis_connected`, `redis_disconnected`) with request IDs\n- Emit metrics for command durations and error counts\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#testing-if-applicable","title":"## Testing (if applicable)","text":"<p>How to test code that uses this integration.</p>"},{"location":"atomic/TEMPLATE/#failure-scenarios-if-applicable","title":"## Failure Scenarios (if applicable)","text":"<p>Common failure modes and how to handle them.</p> <p>Example files: <code>redis/connection-management.md</code>, <code>rabbitmq/message-publishing.md</code>, <code>http-communication/http-client-patterns.md</code></p>"},{"location":"atomic/TEMPLATE/#infrastructure-documents-docker-kubernetes-nginx-configuration-deployment","title":"Infrastructure Documents (Docker, Kubernetes, Nginx, Configuration, Deployment)","text":"<p>Purpose: Explain infrastructure setup, configuration, and deployment patterns.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#structure","title":"## Structure","text":"<p>Describe the organization of infrastructure configuration files.</p> <p>Example: <pre><code>## Structure\n\n- Define services for each microservice, data store, and supporting dependency\n- Use `.env` files for secrets-free configuration\n- Configure networks to isolate internal communication (`backend`) from external exposure (`public`)\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#best-practices","title":"## Best Practices","text":"<p>List 3-7 recommendations for configuring this infrastructure component.</p> <p>Example: <pre><code>## Best Practices\n\n- Set `depends_on` with health checks or wait scripts to avoid race conditions\n- Persist stateful data via named volumes; keep them separate per service\n- Mirror production environment variables to reduce drift\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#configuration-examples-if-applicable","title":"## Configuration Examples (if applicable)","text":"<p>Show example configuration files (docker-compose.yml, Dockerfile, nginx.conf, etc.)</p> <p>Example files: <code>containerization/docker-compose-setup.md</code>, <code>api-gateway/nginx-setup.md</code>, <code>deployment/production-deployment.md</code></p>"},{"location":"atomic/TEMPLATE/#testing-documents-unit-integration-service-e2e-qa","title":"Testing Documents (Unit, Integration, Service, E2E, QA)","text":"<p>Purpose: Document testing strategies, patterns, and tools.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#setup-configuration","title":"## Setup / Configuration","text":"<p>How to configure the testing framework.</p> <p>Example: <pre><code>## Configuration\n\n\\`\\`\\`ini\n# pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\naddopts =\n    --verbose\n    --cov=src\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#test-patterns-examples","title":"## Test Patterns / Examples","text":"<p>Show common test patterns with code.</p> <p>Example: <pre><code>## Test Patterns\n\n\\`\\`\\`python\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_user_creation():\n    user = await create_user({\"email\": \"test@example.com\"})\n    assert user.email == \"test@example.com\"\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#assertions-expectations","title":"## Assertions / Expectations","text":"<p>What to verify in tests.</p> <p>Example files: <code>unit-testing/pytest-setup.md</code>, <code>integration-testing/testcontainers-setup.md</code>, <code>service-testing/fastapi-testing-patterns.md</code></p>"},{"location":"atomic/TEMPLATE/#observability-documents-logging-metrics-tracing-error-tracking-elk","title":"Observability Documents (Logging, Metrics, Tracing, Error Tracking, ELK)","text":"<p>Purpose: Document observability implementation patterns.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#configuration","title":"## Configuration","text":"<p>How to set up the observability tool/pattern.</p> <p>Example: <pre><code>## Configuration\n\n\\`\\`\\`python\nimport structlog\n\nstructlog.configure(\n    processors=[\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.add_log_level,\n        structlog.processors.JSONRenderer(),\n    ],\n)\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#implementation-examples","title":"## Implementation Examples","text":"<p>Show how to use the observability pattern in code.</p> <p>Example: <pre><code>## Log Format\n\n\\`\\`\\`json\n{\n  \"timestamp\": \"2025-01-15T10:30:00Z\",\n  \"level\": \"info\",\n  \"event\": \"user_created\",\n  \"request_id\": \"req-123\",\n  \"user_id\": \"user-456\"\n}\n\\`\\`\\`\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#best-practices_1","title":"## Best Practices","text":"<p>Guidelines for effective observability.</p> <p>Example: <pre><code>## Best Practices\n\n- Include request_id in all logs\n- Use consistent event names\n- Never log sensitive data (passwords, tokens)\n</code></pre></p>"},{"location":"atomic/TEMPLATE/#integration-with-service-types-if-applicable","title":"## Integration with Service Types (if applicable)","text":"<p>How to use this observability pattern in FastAPI, Aiogram, Workers.</p> <p>Example files: <code>logging/structured-logging.md</code>, <code>metrics/prometheus-setup.md</code>, <code>tracing/opentelemetry-setup.md</code></p>"},{"location":"atomic/TEMPLATE/#database-documents-postgresql-mongodb","title":"Database Documents (PostgreSQL, MongoDB)","text":"<p>Purpose: Document database setup, connection management, and best practices.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#setup-configuration_1","title":"## Setup / Configuration","text":"<p>Installation and initial configuration.</p>"},{"location":"atomic/TEMPLATE/#connection-management","title":"## Connection Management","text":"<p>How to create and manage database connections.</p>"},{"location":"atomic/TEMPLATE/#best-practices_2","title":"## Best Practices","text":"<p>Database-specific recommendations (indexing, transactions, etc.)</p>"},{"location":"atomic/TEMPLATE/#performance-considerations","title":"## Performance Considerations","text":"<p>Query optimization, connection pooling, etc.</p> <p>Example files: <code>postgresql/basic-setup.md</code>, <code>postgresql-advanced/query-optimization.md</code></p>"},{"location":"atomic/TEMPLATE/#security-documents","title":"Security Documents","text":"<p>Purpose: Document security patterns and implementations.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#configuration_1","title":"## Configuration","text":"<p>Security tool/pattern setup.</p>"},{"location":"atomic/TEMPLATE/#implementation-examples_1","title":"## Implementation Examples","text":"<p>Code showing security best practices.</p>"},{"location":"atomic/TEMPLATE/#best-practices_3","title":"## Best Practices","text":"<p>Security guidelines.</p>"},{"location":"atomic/TEMPLATE/#threat-mitigation","title":"## Threat Mitigation","text":"<p>How this pattern mitigates specific threats.</p>"},{"location":"atomic/TEMPLATE/#real-time-documents-websocket-sse-etc","title":"Real-time Documents (WebSocket, SSE, etc.)","text":"<p>Purpose: Document real-time communication patterns.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#setup-configuration_2","title":"## Setup / Configuration","text":"<p>How to set up real-time communication.</p>"},{"location":"atomic/TEMPLATE/#implementation-examples_2","title":"## Implementation Examples","text":"<p>WebSocket/SSE code examples.</p>"},{"location":"atomic/TEMPLATE/#connection-management_1","title":"## Connection Management","text":"<p>Lifecycle, reconnection, heartbeats.</p>"},{"location":"atomic/TEMPLATE/#best-practices_4","title":"## Best Practices","text":"<p>Guidelines for reliable real-time communication.</p>"},{"location":"atomic/TEMPLATE/#file-storage-documents","title":"File Storage Documents","text":"<p>Purpose: Document file upload/download patterns.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#configuration_2","title":"## Configuration","text":"<p>Storage backend setup (S3, local, etc.)</p>"},{"location":"atomic/TEMPLATE/#uploaddownload-patterns","title":"## Upload/Download Patterns","text":"<p>Code examples for file operations.</p>"},{"location":"atomic/TEMPLATE/#best-practices_5","title":"## Best Practices","text":"<p>File handling guidelines (validation, size limits, security).</p>"},{"location":"atomic/TEMPLATE/#external-integrations-documents","title":"External Integrations Documents","text":"<p>Purpose: Document integration with third-party APIs.</p> <p>Common sections:</p>"},{"location":"atomic/TEMPLATE/#authentication-configuration","title":"## Authentication / Configuration","text":"<p>API keys, OAuth setup.</p>"},{"location":"atomic/TEMPLATE/#api-client-setup","title":"## API Client Setup","text":"<p>Creating HTTP client for the external service.</p>"},{"location":"atomic/TEMPLATE/#best-practices_6","title":"## Best Practices","text":"<p>Rate limiting, retries, error handling.</p>"},{"location":"atomic/TEMPLATE/#error-handling","title":"## Error Handling","text":"<p>Common API errors and how to handle them.</p>"},{"location":"atomic/TEMPLATE/#validation-checklist","title":"Validation Checklist","text":"<p>INSTRUCTION: Before publishing, verify your document meets these requirements. Remove this section in final document.</p> <ul> <li> H1 title is clear and specific (no placeholders like <code>{Topic Title}</code>)</li> <li> Introduction explains \"what\" and \"why\" (1-3 paragraphs minimum)</li> <li> At least one category-specific section included</li> <li> Code examples follow CORRECT/INCORRECT pattern (if applicable)</li> <li> Code examples use Python 3.12+ syntax with type hints</li> <li> \"Related Documents\" section with at least 2-3 links</li> <li> Anti-Patterns section included (if applicable) with WRONG/CORRECT examples</li> <li> Anti-Patterns include monitoring commands (when operational)</li> <li> No TODO placeholders remaining</li> <li> No sensitive data (passwords, tokens, real IPs, emails)</li> <li> Follows naming conventions (snake_case for Python, kebab-case for Kubernetes)</li> <li> Links use relative paths (<code>docs/atomic/...</code> format)</li> <li> All code examples are properly formatted and indented</li> <li> No grammar/spelling errors in English text</li> <li> Removed \"Category-Specific Section Guide\" section (it's reference only)</li> <li> Removed \"Validation Checklist\" section (it's reference only)</li> </ul>"},{"location":"atomic/TEMPLATE/#meta-information","title":"Meta Information","text":"<p>Document Type: Universal Template for Atomic Documentation Applies To: All <code>docs/atomic/</code> documentation across all categories Version: 1.0 Last Updated: 2025-01-15 Maintainer: Documentation Team</p>"},{"location":"atomic/TEMPLATE/#quick-reference-card","title":"Quick Reference Card","text":"Your Category Required Sections Example File architecture/ Rules, Matrix, When to Use, Anti-Patterns <code>service-separation-principles.md</code> services/* Prerequisites, Structure, Dependencies, Entry Point, Checklist <code>fastapi/basic-setup.md</code> integrations/* Configuration, Best Practices, Observability, Testing <code>redis/connection-management.md</code> infrastructure/* Structure, Best Practices, Config Examples <code>containerization/docker-compose-setup.md</code> testing/* Setup, Patterns, Code Examples <code>integration-testing/testcontainers-setup.md</code> observability/* Configuration, Examples, Best Practices <code>logging/structured-logging.md</code> databases/* Setup, Connection Management, Best Practices <code>postgresql/basic-setup.md</code> security/ Configuration, Examples, Threat Mitigation \u2014 real-time/ Setup, Examples, Connection Management \u2014 file-storage/ Configuration, Upload/Download, Best Practices \u2014 external-integrations/ Auth, Client Setup, Error Handling \u2014"},{"location":"atomic/architecture/context-registry/","title":"Context Registry","text":"<p>Purpose: Maintain a single source of truth for all context names used across the microservices framework to prevent naming conflicts and ambiguity.</p>"},{"location":"atomic/architecture/context-registry/#active-contexts","title":"Active Contexts","text":"Context Full Name Description Domain Examples Services Using It Owner/Team <code>finance</code> Financial Services Financial operations, transactions, payments <code>lending</code>, <code>crypto</code>, <code>payment</code>, <code>billing</code>, <code>trading</code> <code>finance_lending_api</code>, <code>finance_crypto_api</code>, <code>finance_payment_worker</code> @finance-team <code>healthcare</code> Healthcare &amp; Medical Medical services, appointments, patient care <code>telemedicine</code>, <code>appointment</code>, <code>pharmacy</code>, <code>mental_health</code> <code>healthcare_telemedicine_api</code>, <code>healthcare_appointment_api</code> @health-team <code>construction</code> Construction &amp; Building Construction project management <code>house</code>, <code>commercial</code>, <code>renovation</code>, <code>material</code> <code>construction_house_bot</code>, <code>construction_material_api</code> @construction-team <code>logistics</code> Logistics &amp; Delivery Transport, delivery, fleet management <code>fleet</code>, <code>delivery</code>, <code>warehouse</code> <code>logistics_fleet_tracking_api</code>, <code>logistics_delivery_tracking_api</code> @logistics-team <code>ecommerce</code> E-Commerce &amp; Retail Online commerce, marketplaces <code>marketplace</code>, <code>dropship</code>, <code>cart</code> <code>ecommerce_marketplace_api</code>, <code>ecommerce_cart_api</code> @commerce-team <code>corporate</code> Enterprise Tools Internal business tools <code>crm</code>, <code>hr</code>, <code>payroll</code> <code>corporate_crm_api</code>, <code>corporate_hr_api</code> @corporate-team <code>education</code> Education &amp; Learning Learning platforms, courses <code>lms</code>, <code>courses</code>, <code>webinar</code>, <code>assessment</code> <code>education_lms_api</code>, <code>education_courses_api</code> @education-team <code>user_management</code> User Management Authentication, profiles, permissions <code>auth</code>, <code>profile</code>, <code>permission</code> <code>user_auth_api</code>, <code>user_profile_api</code> @platform-team <code>integration</code> Third-Party Integrations External API integrations <code>stripe</code>, <code>google</code>, <code>twilio</code> <code>integration_stripe_api</code>, <code>integration_google_api</code> @platform-team <code>analytics</code> Analytics &amp; Reporting Data analytics, business intelligence <code>reporting</code>, <code>dashboard</code>, <code>data</code> <code>analytics_reporting_api</code>, <code>analytics_dashboard_api</code> @data-team <code>communication</code> Communication Services Messaging, notifications <code>notification</code>, <code>telegram</code>, <code>email</code>, <code>sms</code> <code>communication_notification_worker</code>, <code>communication_telegram_bot</code> @platform-team <code>property_management</code> Real Estate Management Property rental, tenant management <code>house</code>, <code>tenant</code>, <code>lease</code> <code>property_house_api</code>, <code>property_tenant_api</code> @property-team <code>environment</code> Environmental Services Ecology, sustainability <code>emission</code>, <code>recycling</code>, <code>carbon</code> <code>environment_emission_api</code>, <code>environment_recycling_api</code> @environment-team"},{"location":"atomic/architecture/context-registry/#reserved-contexts-planned","title":"Reserved Contexts (Planned)","text":"Context Planned Use Target Release Status <code>compliance</code> Regulatory compliance, auditing Q3 2025 Planned <code>security</code> Security services, threat detection Q2 2025 In Progress <code>gaming</code> Gaming platform services Q4 2025 Planned"},{"location":"atomic/architecture/context-registry/#deprecated-contexts-do-not-use","title":"Deprecated Contexts (DO NOT USE)","text":"Context Reason Replaced By Deprecated Date <code>log</code> Ambiguous (Logistics vs Logging) Use <code>logistics</code> or <code>observability</code> 2025-01-15 <code>property</code> Ambiguous (Real Estate vs Object Property) Use <code>property_management</code> 2025-02-01 <code>project</code> Too generic Use specific context (<code>construction</code>, <code>enterprise</code>, etc.) 2025-02-10"},{"location":"atomic/architecture/context-registry/#naming-rules","title":"Naming Rules","text":""},{"location":"atomic/architecture/context-registry/#do","title":"\u2705 DO:","text":"<ul> <li>Use specific, descriptive context names</li> <li>Choose context names that represent a business domain or functional area</li> <li>Keep contexts mutually exclusive (no overlapping meanings)</li> <li>Use snake_case for multi-word contexts (e.g., <code>user_management</code>, not <code>usermanagement</code>)</li> </ul>"},{"location":"atomic/architecture/context-registry/#dont","title":"\u274c DON'T:","text":"<ul> <li>Reuse the same context name for different meanings across projects</li> <li>Use abbreviations unless universally understood (e.g., <code>hr</code> for Human Resources is OK)</li> <li>Use generic names like <code>data</code>, <code>service</code>, <code>system</code>, <code>app</code></li> <li>Mix language contexts (stick to English)</li> </ul>"},{"location":"atomic/architecture/context-registry/#adding-a-new-context","title":"Adding a New Context","text":"<ol> <li>Check for conflicts: Ensure the name doesn't exist in Active or Deprecated sections</li> <li>Verify specificity: Context should represent a clear business domain</li> <li>Update this registry: Add row to \"Active Contexts\" table</li> <li>Notify teams: Announce new context in team channels</li> <li>Update documentation: Add to relevant guides (Architecture, Naming Conventions)</li> </ol>"},{"location":"atomic/architecture/context-registry/#context-conflict-resolution","title":"Context Conflict Resolution","text":"<p>If you discover a potential conflict:</p> <ol> <li> <p>Document the issue:    <pre><code>## Conflict Report\n- **Context**: `logistics`\n- **Conflict**: Used for both \"Logistics Services\" and \"Logging System\"\n- **Impact**: 5 services affected\n- **Proposed Resolution**: Rename logging context to `observability`\n</code></pre></p> </li> <li> <p>Discuss with stakeholders</p> </li> <li>Create migration plan (if renaming existing context)</li> <li>Update registry (move old name to Deprecated, add new name to Active)</li> <li>Execute migration (rename services, update documentation)</li> </ol>"},{"location":"atomic/architecture/context-registry/#examples-of-good-context-selection","title":"Examples of Good Context Selection","text":""},{"location":"atomic/architecture/context-registry/#good","title":"\u2705 GOOD:","text":"<ul> <li><code>finance</code> \u2192 Clear business domain</li> <li><code>healthcare</code> \u2192 Specific industry</li> <li><code>user_management</code> \u2192 Specific function</li> <li><code>integration</code> \u2192 Clear technical purpose</li> </ul>"},{"location":"atomic/architecture/context-registry/#bad","title":"\u274c BAD:","text":"<ul> <li><code>data</code> \u2192 Too generic (data for what?)</li> <li><code>api</code> \u2192 Too technical (everything has APIs)</li> <li><code>system</code> \u2192 Meaningless</li> <li><code>app</code> \u2192 Vague</li> </ul>"},{"location":"atomic/architecture/context-registry/#validation-checklist","title":"Validation Checklist","text":"<p>Before adding a context, verify:</p> <ul> <li> Context name is unique (not in Active or Deprecated tables)</li> <li> Context name describes a business domain or clear functional area</li> <li> Context name is specific enough (not generic like <code>data</code>, <code>service</code>)</li> <li> Context name won't conflict with similar contexts (e.g., <code>log</code> vs <code>logistics</code>)</li> <li> Multi-word contexts use <code>snake_case</code></li> <li> Context name is in English</li> <li> No abbreviations unless universally understood</li> <li> Owner/team assigned</li> </ul>"},{"location":"atomic/architecture/context-registry/#changelog","title":"Changelog","text":"Date Change Author 2025-10-02 Initial context registry created System 2025-10-02 Added 13 active contexts from existing services System"},{"location":"atomic/architecture/context-registry/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/naming/README.md</code> \u2014 Comprehensive naming patterns for services</li> <li><code>docs/atomic/architecture/service-separation-principles.md</code> \u2014 Service boundary definitions</li> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code> \u2014 Overall architecture approach</li> <li><code>docs/guides/template-naming-guide.md</code> \u2014 Template service renaming instructions</li> </ul> <p>Maintained by: Platform Team (@platform-team) Last Updated: 2025-10-02 Review Frequency: Quarterly</p>"},{"location":"atomic/architecture/data-access-architecture/","title":"Data Access Architecture","text":"<p>Data services encapsulate all database interactions and expose domain-specific HTTP APIs. Business services remain database agnostic and communicate through typed HTTP clients.</p>"},{"location":"atomic/architecture/data-access-architecture/#architectural-overview","title":"Architectural Overview","text":"<ul> <li>Each data service is a standalone FastAPI application dedicated to one persistence technology (PostgreSQL or MongoDB).</li> <li>Data services implement both CRUD and domain-aware operations (aggregations, joins) while keeping business logic in the calling services.</li> <li>HTTP is the only approved transport between business and data services.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#postgresql-service-guidelines","title":"PostgreSQL Service Guidelines","text":"<ul> <li>Use SQLAlchemy 2.x with async sessions and connection pooling.</li> <li>Manage transactions explicitly; roll back on exceptions to keep the pool healthy.</li> <li>Provide pagination, filtering, and sorting for list endpoints.</li> <li>Version endpoints under <code>/api/v1</code> and document them via OpenAPI.</li> <li>Maintain migrations with Alembic; migrations run as part of CI and deployment.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#mongodb-service-guidelines","title":"MongoDB Service Guidelines","text":"<ul> <li>Use Motor for non-blocking access and rely on typed Pydantic models for validation.</li> <li>Apply collection-level indexes and validate schemas to enforce structure.</li> <li>Support aggregation pipelines for analytics scenarios.</li> <li>Provide document-level access control where domain requirements demand it.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#business-service-integration","title":"Business Service Integration","text":"<ol> <li>Create typed HTTP clients that wrap <code>httpx.AsyncClient</code> calls.</li> <li>Propagate correlation headers (<code>X-Request-ID</code>, <code>X-User-ID</code>).</li> <li>Handle network failures with retries, circuit breakers, and fallback logic.</li> <li>Cache read-heavy endpoints when latency or throughput requires it (Redis, in-memory caches).</li> <li>Mock HTTP clients in unit tests; rely on Testcontainers for integration tests.</li> </ol>"},{"location":"atomic/architecture/data-access-architecture/#error-handling","title":"Error Handling","text":"<ul> <li>Use RFC 7807 Problem Details responses for consistency.</li> <li>Map validation errors to <code>400</code>, conflicts to <code>409</code>, not found to <code>404</code>, and unexpected issues to <code>500</code>.</li> <li>Log structured errors including correlation ids and service names.</li> <li>Fall back gracefully when data services are unavailable by returning meaningful error codes to callers.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Tune connection pool sizes based on workload (minimum/maximum connections, timeouts).</li> <li>Ensure every list endpoint uses pagination and query filters to avoid full table scans.</li> <li>Monitor query plans (<code>EXPLAIN ANALYZE</code>) and add indexes aligned with access patterns.</li> <li>Measure end-to-end latency (business service \u2192 data service \u2192 DB) and alert on regressions.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#security","title":"Security","text":"<ul> <li>Validate incoming payloads with Pydantic models; never trust raw JSON.</li> <li>Enforce authentication and authorisation at the edge or through service mesh policies.</li> <li>Keep secrets and connection strings in environment variables or secret stores.</li> <li>Use TLS for inter-service communication in production environments.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit test repositories and domain adapters with mocks/stubs.</li> <li>Integration test endpoints with real databases via Testcontainers.</li> <li>Contract test HTTP interactions between business and data services to detect breaking changes early.</li> </ul>"},{"location":"atomic/architecture/data-access-architecture/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/postgres-service-setup.md</code></li> <li><code>docs/atomic/services/data-services/mongo-service-setup.md</code></li> <li><code>docs/atomic/integrations/http-communication/http-client-patterns.md</code></li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/","title":"DDD and Hexagonal Principles","text":"<p>The Improved Hybrid Approach relies on Domain-Driven Design (DDD) and Hexagonal Architecture to keep services modular and testable. This document summarises how those concepts map to the project structure.</p>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#layering-model","title":"Layering Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Interfaces \u2502  (FastAPI routers, bot handlers, CLI)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Application  \u2502  (Use cases, orchestrators, service classes)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Domain    \u2502  (Entities, value objects, domain services)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Infrastructure \u2502 (Repositories, HTTP clients, messaging adapters)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Interfaces convert transport-specific payloads to domain requests/responses.</li> <li>Application layer coordinates domain operations; it contains minimal logic, delegating to domain services.</li> <li>Domain layer models business rules and invariants. It has no dependencies on frameworks.</li> <li>Infrastructure layer provides implementations for persistence, messaging, and external systems.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#implementation-guidelines","title":"Implementation Guidelines","text":"<ul> <li>Keep routers thin: no direct database calls or complex branching logic.</li> <li>Domain services enforce invariants; repositories must not \u201cfix\u201d invalid states.</li> <li>Use interfaces or protocols for repositories and external gateways to enable mocking in tests.</li> <li>Name modules after domain contexts (<code>users</code>, <code>orders</code>), not technical layers.</li> <li>Keep each domain type in its own file to respect the \u201cminimum atomic file size\u201d requirement.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#dto-and-mapping-strategy","title":"DTO and Mapping Strategy","text":"<ul> <li>Define DTOs in <code>schemas/</code> with descriptive suffixes (<code>UserCreate</code>, <code>OrderPublic</code>).</li> <li>Implement mapping functions or classes in the application layer to convert between DTOs and domain types.</li> <li>Avoid leaking ORM models outside infrastructure; domain objects are plain Python classes or Pydantic models that represent intent, not persistence.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#ports-and-adapters","title":"Ports and Adapters","text":"<ul> <li>Ports are abstract interfaces defined by the domain/application layers (e.g., <code>UserRepository</code>, <code>PaymentGateway</code>).</li> <li>Adapters live in infrastructure and implement those ports (e.g., <code>SqlAlchemyUserRepository</code>).</li> <li>Use dependency injection to wire adapters at runtime.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#testing-implications","title":"Testing Implications","text":"<ul> <li>Unit tests focus on the domain/application layers by mocking ports.</li> <li>Integration tests exercise adapters against real dependencies (DB, message brokers).</li> <li>Contract tests verify that adapters honour expectations published by external systems.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#anti-corruption-layer-acl","title":"Anti-Corruption Layer (ACL)","text":"<ul> <li>Introduce ACLs where legacy systems or third-party APIs supply inconsistent payloads.</li> <li>ACLs translate external DTOs into domain types, ensuring the domain remains clean.</li> </ul>"},{"location":"atomic/architecture/ddd-hexagonal-principles/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/project-structure-patterns.md</code></li> <li><code>docs/atomic/services/fastapi/application-factory.md</code></li> <li><code>docs/atomic/services/data-services/repository-patterns.md</code></li> </ul>"},{"location":"atomic/architecture/event-loop-management/","title":"Event Loop Management","text":"<p>All services in the platform rely on Python's asynchronous runtimes. Mismanaging event loops leads to deadlocks, duplicate tasks, and hard-to-diagnose outages. This document defines how to own, share, and monitor event loops across service types.</p>"},{"location":"atomic/architecture/event-loop-management/#core-principles","title":"Core Principles","text":"<ul> <li>Single loop per process. Every container runs exactly one event loop. Do not create ad-hoc loops with <code>asyncio.new_event_loop()</code> unless you run fully isolated worker pools.</li> <li>Async all the way down. Mixing blocking I/O with the event loop stalls the entire service. Prefer async clients (<code>asyncpg</code>, <code>httpx</code>, <code>aio-pika</code>, <code>redis.asyncio</code>).</li> <li>Explicit lifecycle management. Startup and shutdown hooks manage background tasks, connection pools, and signal handlers.</li> <li>Graceful degradation. On fatal errors, cancel running tasks, close connections, and exit cleanly so orchestrators can restart the service.</li> </ul>"},{"location":"atomic/architecture/event-loop-management/#service-type-guidelines","title":"Service Type Guidelines","text":""},{"location":"atomic/architecture/event-loop-management/#fastapi-services","title":"FastAPI Services","text":"<ul> <li>Use the lifespan protocol (see lifespan-management.md).</li> <li>Register background tasks through dependency injection rather than <code>asyncio.create_task</code> in route handlers.</li> <li>Shield startup tasks with timeouts to prevent hanging containers (<code>asyncio.wait_for(init(), timeout=30)</code>).</li> </ul>"},{"location":"atomic/architecture/event-loop-management/#aiogram-bots","title":"Aiogram Bots","text":"<ul> <li>Instantiate the Dispatcher once and reuse it; rely on Aiogram's polling/webhook loop.</li> <li>Handle shutdown signals to cancel pending updates and close HTTP sessions.</li> <li>Keep long-running business logic in dedicated services; the bot should remain responsive.</li> </ul>"},{"location":"atomic/architecture/event-loop-management/#asyncio-workers","title":"AsyncIO Workers","text":"<ul> <li>Wrap <code>asyncio.run(main())</code> in <code>if __name__ == \"__main__\"</code> blocks.</li> <li>Use <code>asyncio.TaskGroup</code> (Python 3.12+) or <code>asyncio.gather</code> with graceful cancellation to coordinate jobs.</li> <li>Ensure signal handlers (<code>SIGTERM</code>, <code>SIGINT</code>) set shutdown flags and await task completion before closing.</li> </ul>"},{"location":"atomic/architecture/event-loop-management/#patterns-and-anti-patterns","title":"Patterns and Anti-Patterns","text":"Do Avoid Create connection pools during startup and reuse them. Creating new connections on each handler invocation. Use <code>asyncio.create_task</code> only inside supervised contexts (TaskGroup, background workers). Fire-and-forget tasks without cancellation or exception handling. Wrap long CPU-bound operations in <code>run_in_executor</code>. Blocking the loop with synchronous heavy computations. Propagate cancellation (use <code>asyncio.current_task().cancel()</code>). Swallowing <code>CancelledError</code>, which prevents clean shutdown."},{"location":"atomic/architecture/event-loop-management/#observability","title":"Observability","text":"<ul> <li>Emit metrics for event loop lag (<code>uvloop.loop.time() - asyncio.get_running_loop().time()</code> samples) to detect blocking calls.</li> <li>Use structured logging for lifecycle events (startup, shutdown, signal received, task cancelled).</li> <li>Trace background tasks with manual spans when they are long-lived jobs.</li> </ul>"},{"location":"atomic/architecture/event-loop-management/#troubleshooting-checklist","title":"Troubleshooting Checklist","text":"<ol> <li>Check for blocking stack traces in logs (<code>BlockingIOError</code>, warnings from <code>asyncio</code>).</li> <li>Confirm only one loop is running (<code>asyncio.get_running_loop()</code> from debug endpoints).</li> <li>Verify connection pools are closed on shutdown (use <code>atexit</code> or lifespan hooks).</li> <li>In workers, assert that <code>TaskGroup</code> exits cleanly and no tasks remain pending in debug logs.</li> </ol>"},{"location":"atomic/architecture/event-loop-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> <li><code>docs/atomic/services/asyncio-workers/signal-handling.md</code></li> <li><code>docs/atomic/integrations/rabbitmq/asyncio-integration.md</code></li> </ul>"},{"location":"atomic/architecture/improved-hybrid-overview/","title":"Improved Hybrid Approach Overview","text":"<p>The Improved Hybrid Approach combines strict service boundaries with shared tooling to keep delivery fast while ensuring architectural discipline. Business capabilities live in independently deployable services, data is exposed through dedicated data services, and cross-cutting concerns (observability, queues, caches) are delivered as platform components.</p>"},{"location":"atomic/architecture/improved-hybrid-overview/#goals","title":"Goals","text":"<ul> <li>Preserve clear separation between business, data, and supporting services.</li> <li>Provide a consistent developer experience across REST APIs, bots, and background workers.</li> <li>Allow incremental adoption inside existing products without breaking production traffic.</li> <li>Ensure every service can be tested, deployed, and scaled independently.</li> </ul>"},{"location":"atomic/architecture/improved-hybrid-overview/#service-landscape","title":"Service Landscape","text":"Category Role Examples Business services Deliver user-facing or domain logic via HTTP or messaging interfaces. <code>template_business_api</code>, <code>template_business_bot</code>, <code>template_business_worker</code> Data services Own direct database access and expose domain-driven HTTP APIs. <code>template_data_postgres_api</code>, <code>template_data_mongo_api</code> Integration services Provide reusable interfaces to brokers, caches, third-party APIs. Redis, RabbitMQ bridges Platform components Observability, CI/CD, configuration, shared libraries. <code>docs/atomic/*</code>, <code>scripts/</code>"},{"location":"atomic/architecture/improved-hybrid-overview/#interaction-model","title":"Interaction Model","text":"<ol> <li>Business services call data services over HTTP (never direct DB connections).</li> <li>Integration services (Redis, RabbitMQ) are accessed through adapters published by the platform team.</li> <li>Shared DTOs live under <code>src/shared/</code> to avoid duplication while respecting domain boundaries.</li> <li>Observability context (request id, trace id) flows through every hop via headers and logging formatters.</li> </ol> <pre><code>Client \u2192 Business Service \u2192 HTTP \u2192 Data Service \u2192 Database\n           \u2502\n           \u2514\u2192 Messaging / Cache via dedicated adapters\n</code></pre>"},{"location":"atomic/architecture/improved-hybrid-overview/#architectural-tenets","title":"Architectural Tenets","text":"<ul> <li>Single Source of Truth \u2013 the <code>docs/atomic/</code> tree defines authoritative guidance for all service patterns and infrastructure setup.</li> <li>HTTP-only Data Access \u2013 business services rely on typed clients that wrap HTTP calls and hide retry logic. Contracts are versioned (<code>/api/v1</code>) and validated with Pydantic schemas.</li> <li>Async First \u2013 all services share a single event loop per process, using async drivers for databases, queues, and HTTP clients.</li> <li>Operational Transparency \u2013 each service exposes <code>/health</code> and <code>/ready</code>, publishes Prometheus metrics, and emits structured logs with request correlation.</li> <li>Quality Gates \u2013 CI enforces linting, typing, security scans, and full test coverage before deployment.</li> </ul>"},{"location":"atomic/architecture/improved-hybrid-overview/#when-to-use","title":"When to Use","text":"<ul> <li>Greenfield microservice deployments that require rapid iteration without losing governance.</li> <li>Brownfield monolith extractions where domain logic must be separated from data access.</li> <li>Teams that share the same platform primitives (FastAPI, Aiogram, AsyncIO workers) and want strongly guided defaults.</li> </ul>"},{"location":"atomic/architecture/improved-hybrid-overview/#migration-notes","title":"Migration Notes","text":"<ol> <li>Inventory current services and classify them as business, data, or integration components.</li> <li>Establish typed HTTP clients for every data-service dependency, using the patterns in <code>docs/atomic/services/*</code>.</li> <li>Update CI/CD to run the mandatory verification steps described in <code>docs/atomic/architecture/quality-standards.md</code>.</li> <li>Communicate the new documentation baseline to every squad following the patterns in <code>docs/atomic/</code>.</li> </ol>"},{"location":"atomic/architecture/improved-hybrid-overview/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/service-separation-principles.md</code> \u2014 Service boundary definitions and separation rules</li> <li><code>docs/atomic/architecture/project-structure-patterns.md</code> \u2014 Repository and module organization</li> <li><code>docs/atomic/architecture/naming/README.md</code> \u2014 Service and component naming standards</li> <li><code>docs/atomic/architecture/context-registry.md</code> \u2014 Authorized context names for services</li> <li><code>docs/atomic/architecture/data-access-architecture.md</code> \u2014 HTTP-only data access patterns</li> <li><code>docs/atomic/services/fastapi/basic-setup.md</code> \u2014 FastAPI service implementation</li> <li><code>docs/atomic/infrastructure/docker-compose.md</code> \u2014 Container orchestration setup</li> </ul>"},{"location":"atomic/architecture/naming-conventions/","title":"Naming Conventions","text":"<p>\ud83d\udce6 CONTENT MOVED: This document has been reorganized into specialized files for better maintainability.</p> <p>The naming conventions content has been split into focused, atomic documents following the hub-and-spoke pattern. Each document covers a specific aspect of naming in depth.</p>"},{"location":"atomic/architecture/naming-conventions/#new-location-naming-directory","title":"\ud83d\udccd New Location: naming/ Directory","text":"<p>Main Hub (start here): - naming/README.md \u2014 Complete naming guide with Quick Reference Table and AI Decision Tree</p> <p>Specialized Guides: - naming/naming-services.md \u2014 Service naming patterns (3-part vs 4-part formula) - naming/naming-4part-reasons.md \u2014 10 serious reasons for using 4-part naming - naming/naming-python.md \u2014 Python classes, functions, variables, and file naming - naming/naming-infrastructure.md \u2014 Docker Compose, Kubernetes, Nginx configuration - naming/naming-databases.md \u2014 PostgreSQL and MongoDB naming conventions - naming/naming-documentation.md \u2014 Documentation file naming (SCREAMING vs kebab-case) - naming/naming-conversion.md \u2014 Dev\u2192Prod name transformation utilities</p>"},{"location":"atomic/architecture/naming-conventions/#why-this-change","title":"Why This Change?","text":"<ol> <li>Atomic Documentation: Each file now has a single, clear purpose (&lt;600 lines)</li> <li>Better Navigation: Find exactly what you need without scrolling through 1830 lines</li> <li>Maintainability: Easier to update specific sections without affecting others</li> <li>Hub-and-Spoke Pattern: Central hub (naming/README.md) with links to all specialized content</li> </ol>"},{"location":"atomic/architecture/naming-conventions/#backward-compatibility","title":"Backward Compatibility","text":"<p>This file remains as a redirect for existing links and documentation. All original content is preserved and enhanced in the new structure.</p>"},{"location":"atomic/architecture/naming-conventions/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/context-registry.md</code> \u2014 Authorized context names for services</li> <li><code>docs/atomic/architecture/service-separation-principles.md</code> \u2014 Service boundary definitions</li> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code> \u2014 Overall architecture approach</li> <li><code>docs/guides/template-naming-guide.md</code> \u2014 Template service renaming instructions</li> <li><code>docs/checklists/service-naming-checklist.md</code> \u2014 Quick service naming decisions</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/","title":"Project Structure Patterns","text":"<p>This document details the canonical structure for repositories using the Improved Hybrid Approach. It covers both single-service and multi-service project layouts.</p>"},{"location":"atomic/architecture/project-structure-patterns/#single-service-repository-layout","title":"Single Service Repository Layout","text":"<p>Use this structure when developing an individual microservice in its own repository:</p> <pre><code>my_service/\n\u251c\u2500\u2500 docs/                   # Documentation (this framework when used directly)\n\u251c\u2500\u2500 scripts/                # Automation helpers\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/                # Transport adapters (FastAPI routers, webhooks)\n\u2502   \u251c\u2500\u2500 application/        # Use cases, orchestrators\n\u2502   \u251c\u2500\u2500 domain/             # Entities, value objects, domain services\n\u2502   \u251c\u2500\u2500 infrastructure/     # Repositories, HTTP clients, broker adapters\n\u2502   \u251c\u2500\u2500 schemas/            # Pydantic DTOs (request/response)\n\u2502   \u251c\u2500\u2500 core/               # Configuration, logging, settings\n\u2502   \u2514\u2500\u2500 tasks/              # Background jobs, celery-style workers\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 service/\n\u2502   \u2514\u2500\u2500 e2e/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"atomic/architecture/project-structure-patterns/#multi-service-project-layout","title":"Multi-Service Project Layout","text":"<p>Use this structure when managing multiple microservices in a single repository with the framework as a submodule:</p> <pre><code>my_awesome_app/\n\u251c\u2500\u2500 .ai-framework/                   # Git submodule (this repository)\n\u251c\u2500\u2500 services/                        # All microservices (independent deployable units)\n\u2502   \u251c\u2500\u2500 template_business_api/                # FastAPI REST API (port 8000)\n\u2502   \u2502   \u251c\u2500\u2500 src/                    # DDD/Hexagonal structure (same as single service)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 application/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 infrastructure/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u251c\u2500\u2500 template_business_bot/                # Aiogram Telegram bot\n\u2502   \u251c\u2500\u2500 template_business_worker/             # AsyncIO workers\n\u2502   \u251c\u2500\u2500 template_data_postgres_api/        # PostgreSQL data service (port 8001)\n\u2502   \u2514\u2500\u2500 template_data_mongo_api/           # MongoDB data service (port 8002)\n\u251c\u2500\u2500 shared/                          # Shared components across services\n\u2502   \u251c\u2500\u2500 dtos/\n\u2502   \u251c\u2500\u2500 events/\n\u2502   \u2514\u2500\u2500 utils/\n\u251c\u2500\u2500 nginx/                           # API Gateway\n\u2502   \u251c\u2500\u2500 nginx.conf\n\u2502   \u251c\u2500\u2500 conf.d/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 certs/\n\u251c\u2500\u2500 infrastructure/                  # Observability (optional)\n\u2502   \u251c\u2500\u2500 monitoring/\n\u2502   \u2514\u2500\u2500 logging/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 .env.example\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Key Differences: - Single Service: <code>src/</code> at root, standalone deployment - Multi-Service: <code>services/{service-name}/src/</code> structure, each service self-contained - Multi-Service: Adds <code>nginx/</code> for API Gateway, <code>shared/</code> for cross-service code - Multi-Service: Single <code>docker-compose.yml</code> orchestrates all services</p>"},{"location":"atomic/architecture/project-structure-patterns/#service-modules","title":"Service Modules","text":"<ul> <li>api/ \u2013 minimal routing logic; no business decisions.</li> <li>application/ \u2013 orchestrates domain operations and applies use-case logic.</li> <li>domain/ \u2013 pure business rules with no framework dependencies.</li> <li>infrastructure/ \u2013 concrete adapters (ORM, HTTP, messaging, caching).</li> <li>schemas/ \u2013 request/response models grouped by feature area.</li> <li>core/ \u2013 settings, logging setup, dependency injection container, typed configuration.</li> <li>tasks/ \u2013 background processing (cron workers, scheduled jobs).</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#shared-components","title":"Shared Components","text":""},{"location":"atomic/architecture/project-structure-patterns/#single-service","title":"Single Service","text":"<ul> <li>Typically no shared components needed (all code in <code>src/</code>)</li> <li>If service has multiple modules, use <code>src/shared/</code> for internal shared code</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#multi-service-project","title":"Multi-Service Project","text":"<ul> <li>Cross-service DTOs reside in <code>shared/dtos/</code> with clear ownership</li> <li>Shared events live in <code>shared/events/</code> to align messaging contracts</li> <li>Utilities under <code>shared/utils/</code> remain stateless and generic</li> <li>Important: Keep shared code minimal; prefer service-specific implementations</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#documentation-expectations","title":"Documentation Expectations","text":"<ul> <li>Each service ships a README with run/test/build instructions and links back to the relevant atomic files.</li> <li>Architecture decisions are captured via ADRs (see <code>docs/reference/architecture-decision-log-template.md</code>).</li> <li>When the framework is used as a submodule, treat <code>.ai-framework/docs/atomic/</code> as read-only source material.</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#environment-and-configuration","title":"Environment and Configuration","text":"<ul> <li>Manage settings through <code>pydantic.BaseSettings</code> under <code>src/core/config.py</code>.</li> <li>Store secrets in environment variables or secret managers; never commit secrets.</li> <li>Provide <code>.env.example</code> with non-sensitive defaults for developers.</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#testing-layout","title":"Testing Layout","text":"<ul> <li><code>tests/unit/</code> mirrors the <code>src/</code> structure.</li> <li><code>tests/integration/</code> houses Testcontainers-based scenarios.</li> <li><code>tests/service/</code> exercises full service stacks (HTTP, bots, or workers).</li> <li><code>tests/e2e/</code> cover cross-service journeys.</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#tooling","title":"Tooling","text":"<ul> <li>AI scaffolding anchors (e.g., <code># @cursor-include-router-anchor</code>) belong in infrastructure/application layers to support generators without polluting domain code.</li> <li>CI scripts live in <code>scripts/</code> and are referenced from the Makefile or task runner.</li> <li>Use <code>uv</code> or <code>pip</code> with lock files to guarantee repeatable environments.</li> </ul>"},{"location":"atomic/architecture/project-structure-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/naming/README.md</code></li> <li><code>docs/reference/project-structure.md</code></li> </ul>"},{"location":"atomic/architecture/quality-standards/","title":"Quality Standards","text":"<p>Quality is enforced through automated gates and manual reviews. This document summarises non-negotiable expectations for services built on the platform.</p>"},{"location":"atomic/architecture/quality-standards/#principles","title":"Principles","text":"<ul> <li>Shift left \u2013 write tests alongside implementation and run them locally before raising a merge request.</li> <li>Automation first \u2013 linting, type checking, security scans, and tests run automatically in CI.</li> <li>Observable outcomes \u2013 every release must provide health checks, metrics, and structured logs.</li> <li>Documentation parity \u2013 update relevant guides whenever behaviour changes.</li> </ul>"},{"location":"atomic/architecture/quality-standards/#mandatory-checks","title":"Mandatory Checks","text":"Category Tooling Requirement Linting <code>ruff</code> (python), <code>markdownlint</code> (docs) Zero lint errors. Typing <code>mypy</code> or <code>pyright</code> No type regressions; strict mode for new modules. Security <code>bandit</code>, dependency scanners No high/critical findings without mitigation. Tests <code>pytest</code> (unit/integration/e2e) 100% coverage for new/changed code; critical paths always covered. Docs Link checker, spell checker (optional) No broken links; follow <code>docs/STYLE_GUIDE.md</code>."},{"location":"atomic/architecture/quality-standards/#test-expectations","title":"Test Expectations","text":"<ul> <li>Unit tests validate domain logic and application services with mocked ports.</li> <li>Integration tests run against real dependencies via Testcontainers (PostgreSQL, MongoDB, Redis, RabbitMQ).</li> <li>Service tests cover HTTP and messaging interfaces end-to-end.</li> <li>E2E tests ensure critical user journeys remain functional.</li> <li>Mock external HTTP calls using <code>respx</code> or similar libraries to keep tests deterministic.</li> </ul>"},{"location":"atomic/architecture/quality-standards/#release-checklist","title":"Release Checklist","text":"<ol> <li>CI pipeline green with all mandatory jobs.</li> <li>Manual review performed by at least one domain expert.</li> <li>OpenAPI schema updated (FastAPI services) and published.</li> <li>Changelog or release notes summarise functional impact.</li> <li>Observability dashboards updated when metrics or logs change.</li> </ol>"},{"location":"atomic/architecture/quality-standards/#incident-prevention","title":"Incident Prevention","text":"<ul> <li>Use feature flags for risky changes and provide rollback instructions.</li> <li>Monitor release metrics (error rate, latency, saturation) for at least one hour after deployment.</li> <li>Capture post-release validation steps in the team runbook.</li> </ul>"},{"location":"atomic/architecture/quality-standards/#documentation-requirements","title":"Documentation Requirements","text":"<ul> <li>Reflect service changes in <code>docs/atomic/services/*</code> and <code>docs/INDEX.md</code>.</li> <li>Mark superseded documents with DEPRECATED notice and update replacement references.</li> <li>Keep README files concise but accurate: include run/test/build commands and links to relevant atomic documents.</li> </ul>"},{"location":"atomic/architecture/quality-standards/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/*</code></li> <li><code>docs/atomic/observability/*</code></li> <li><code>docs/atomic/architecture/service-separation-principles.md</code></li> </ul>"},{"location":"atomic/architecture/service-separation-principles/","title":"Service Separation Principles","text":"<p>This guide defines the boundaries between business, data, and platform services in the Improved Hybrid Approach. Keeping the separation strict prevents cascading failures, simplifies testing, and enables teams to ship independently.</p>"},{"location":"atomic/architecture/service-separation-principles/#guiding-rules","title":"Guiding Rules","text":"<ol> <li>Business logic stays in business services. These services expose HTTP APIs, bot handlers, or background jobs. They never talk to databases directly and never own schema migrations.</li> <li>Data services own persistence. Data services wrap PostgreSQL or MongoDB, enforce invariants close to the data, and expose domain-aware HTTP endpoints.</li> <li>Integration services provide shared infrastructure access. Reusable adapters for Redis, RabbitMQ, or external APIs live here and are consumed by business/data services through dependency injection.</li> <li>Shared components are deliberately minimal. Shared DTOs or utilities go to <code>shared/</code> only when multiple services depend on the same contract.</li> <li>Event loop ownership is explicit. Each process manages exactly one event loop; cross-service communication uses HTTP or messaging.</li> </ol>"},{"location":"atomic/architecture/service-separation-principles/#responsibility-matrix","title":"Responsibility Matrix","text":"Concern Business Service Data Service Platform / Integration Domain logic \u2705 \ud83d\udeab \ud83d\udeab Schema migrations \ud83d\udeab \u2705 \ud83d\udeab External HTTP calls \u2705 (domain-specific) \ud83d\udeab \u2705 (shared connectors) Broker interactions \u2705 via adapters \ud83d\udeab \u2705 (adapters, consumers) Cache usage \u2705 via adapters \u2705 (internal caching) \u2705 (infrastructure) Observability \u2705 (emit context) \u2705 (emit context) \u2705 (aggregate metrics/logs)"},{"location":"atomic/architecture/service-separation-principles/#boundary-checklist","title":"Boundary Checklist","text":"<ul> <li>Business services must not import ORM models or repositories from data services.</li> <li>Data services must not leak database drivers or sessions to clients.</li> <li>Shared DTOs use suffixes (<code>...Create</code>, <code>...Update</code>, <code>...Public</code>) to clarify purpose.</li> <li>Any shared helper must be stateless and free of transport- or storage-specific assumptions.</li> <li>Version all HTTP APIs and keep backward-compatible responses until consumers migrate.</li> </ul>"},{"location":"atomic/architecture/service-separation-principles/#integration-patterns","title":"Integration Patterns","text":"<ul> <li>HTTP \u2013 use typed clients built on <code>httpx.AsyncClient</code>; provide retries with exponential backoff and propagate <code>X-Request-ID</code>.</li> <li>Messaging \u2013 use RabbitMQ via application-level publishers/subscribers; keep message DTOs in <code>shared/events/</code>.</li> <li>Caching \u2013 access Redis through well-defined key namespaces owned by the calling service; never re-use keys across domains.</li> </ul>"},{"location":"atomic/architecture/service-separation-principles/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"<ul> <li>Fat \u201cshared\u201d modules that contain business logic used by multiple services. Duplicate logic instead if domain contexts differ.</li> <li>Passing raw database cursors, ORM sessions, or repository instances across service boundaries.</li> <li>Embedding business validation inside data services\u2014use domain-aware endpoints that validate inputs but keep core rules within business services.</li> <li>Starting multiple event loops inside the same container (see <code>event-loop-management.md</code>).</li> </ul>"},{"location":"atomic/architecture/service-separation-principles/#enforcement","title":"Enforcement","text":"<ul> <li>Code reviews block any direct DB access in business services (<code>rg \"asyncpg\" services/template_business_api</code> should return zero matches outside data services).</li> <li>CI runs static checks (import blocks, architecture tests) to detect illegal module dependencies.</li> <li>Deployment manifests isolate data services behind internal networks so only platform-approved clients can reach them.</li> </ul>"},{"location":"atomic/architecture/service-separation-principles/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code> \u2014 Overall architecture approach</li> <li><code>docs/atomic/architecture/event-loop-management.md</code> \u2014 Async event loop patterns</li> <li><code>docs/atomic/architecture/data-access-architecture.md</code> \u2014 HTTP-only data access patterns</li> <li><code>docs/atomic/architecture/naming/README.md</code> \u2014 Service naming standards</li> <li><code>docs/atomic/architecture/context-registry.md</code> \u2014 Authorized context names</li> <li><code>docs/atomic/services/fastapi/dependency-injection.md</code> \u2014 DI patterns for FastAPI</li> <li><code>docs/atomic/data-flow/http-communication.md</code> \u2014 Inter-service HTTP patterns</li> </ul>"},{"location":"atomic/architecture/naming/","title":"Naming Conventions","text":"<p>This guide provides comprehensive naming conventions for the doc4microservices framework, covering all technical layers from Python code to Kubernetes infrastructure. It establishes consistent, predictable naming patterns that enable AI-first development and seamless transitions between development and production environments.</p> <p>Philosophy: Use separators appropriate to each technical layer (underscores for code/data, hyphens for network/DNS). Default to 3-part service naming (<code>{context}_{domain}_{type}</code>), using 4-part only when domain is ambiguous.</p> <p>Quick Start: Use the Quick Reference Table and AI Decision Tree below for immediate lookup. For detailed explanations, see the specialized guides in this directory.</p>"},{"location":"atomic/architecture/naming/#ai-quick-reference","title":"AI Quick Reference","text":"<p>NAMING PHILOSOPHY: DEFAULT TO 3-PART \u2014 Use <code>{context}_{domain}_{type}</code>. Add <code>{function}</code> ONLY when domain is ambiguous (burden of proof required).</p> <p>Use semantic shortening: clear context + domain, omit redundant function words. Average length: 20-27 chars (no abbreviations needed).</p> <p>\u26a0\ufe0f CRITICAL: Maintain a Context Registry to prevent context name conflicts across your project. Never reuse context names for different business domains.</p> <p>Location: Create <code>docs/atomic/architecture/context-registry.md</code> in your project Structure: List each context with its business domain and example services Example entry: <code>finance</code> \u2192 Financial services (lending, payments, crypto) See: context-registry.md template for detailed format</p>"},{"location":"atomic/architecture/naming/#3-part-vs-4-part-service-naming-decision","title":"3-Part vs 4-Part Service Naming Decision","text":"<p>DEFAULT (80-90% of services): Use 3-part <code>{context}_{domain}_{type}</code> \u2014 function is implied by domain.</p> <p>EXCEPTION (10-20% of services): Use 4-part ONLY when domain is ambiguous (see 10 Serious Reasons below).</p> <p>BURDEN OF PROOF: Always start with 3-part. Justify adding 4<sup>th</sup> component.</p> <p>OBJECTIVE DECISION RULE:</p> <p>Ask: \"Can this domain word refer to 3+ different operations in this context?\"</p> <ul> <li>YES \u2192 Use 4-part: <code>{context}_{domain}_{function}_{type}</code></li> <li>NO \u2192 Use 3-part: <code>{context}_{domain}_{type}</code></li> </ul> <p>USE 4-PART ONLY WHEN domain is ambiguous: - <code>fleet</code> \u2192 Could mean: tracking, management, maintenance, scheduling (4+ operations) - <code>analytics</code> \u2192 Could mean: reporting, querying, processing, visualization (4+ operations) - <code>communication</code> \u2192 Could mean: email, SMS, push, in-app notifications (4+ channels)</p> <p>USE 3-PART WHEN domain is specific: - <code>lending</code> \u2192 Clearly means loan matching/approval (1 primary operation) - <code>payment</code> \u2192 Clearly means payment processing (1 primary operation) - <code>telemedicine</code> \u2192 Clearly means online consultation (1 primary operation)</p> <p>NOTE: The <code>{type}</code> component (api, worker, bot) indicates technical implementation, NOT business function. Don't use 4-part just because a service has multiple code features\u2014use it only when the DOMAIN word itself is ambiguous.</p>"},{"location":"atomic/architecture/naming/#when-to-use-4-part-the-10-serious-reasons","title":"When to Use 4-Part: The 10 Serious Reasons","text":"<p>PRINCIPLE: Default to 3-part. Use 4-part ONLY when one of these reasons applies:</p> <ol> <li>Domain Ambiguity \u2014 Domain implies 3+ operations (<code>fleet</code>, <code>analytics</code>, <code>communication</code>)</li> <li>Multiple Services per Domain \u2014 Need 2+ services in same <code>{context}_{domain}</code></li> <li>Cross-Context Collision \u2014 Same domain word in different contexts with different meanings</li> <li>Organizational Policy \u2014 Team/company requires explicit functions for certain contexts</li> <li>Technical Differentiation \u2014 Different technologies/providers (e.g., <code>payment_stripe_api</code>, <code>payment_paypal_api</code>)</li> <li>Functional Split (Migration) \u2014 Blue-green deployment with functional separation</li> <li>Legacy Terminology \u2014 Integration with existing system that uses established terms</li> <li>Regulatory Requirements \u2014 Compliance requires explicit separation of functions</li> <li>Different SLA/Resources \u2014 Radically different infrastructure requirements</li> <li>Onboarding Clarity \u2014 New team members regularly confused by 3-part names</li> </ol> <p>Burden of Proof: If NONE of these apply \u2192 use 3-part.</p> <p>Detailed explanations: See naming-4part-reasons.md</p> Element Type Pattern Example Separator <p>| | Microservice (default) | <code>{context}_{domain}_{type}</code> | <code>finance_lending_api</code> | <code>_</code> | | Microservice (ambiguous domain) | <code>{context}_{domain}_{function}_{type}</code> | <code>logistics_fleet_tracking_api</code> | <code>_</code> | | Python Class | <code>{Noun}{Suffix}</code> | <code>UserService</code>, <code>OrderRepository</code> | None (PascalCase) | | Python Function | <code>{verb}_{noun}[_qualifier]</code> | <code>get_user_by_id</code>, <code>create_order</code> | <code>_</code> | | Python Variable | <code>{noun}[_qualifier]</code> | <code>user_id</code>, <code>max_attempts</code> | <code>_</code> | | Python Parameter | <code>{noun}[_qualifier]</code> | <code>user_id: int</code>, <code>is_active: bool</code> | <code>_</code> | | Python Constant | <code>{NOUN}_{QUALIFIER}</code> | <code>DATABASE_URL</code>, <code>MAX_RETRIES</code> | <code>_</code> | | Python Module/File | <code>{class_name}.py</code> | <code>user_service.py</code>, <code>order_dto.py</code> | <code>_</code> | | Folder/Package | <code>{service_name}/</code> | <code>finance_lending_api/</code> | <code>_</code> | | Documentation (entry points) | <code>SCREAMING_SNAKE_CASE</code> | <code>README.md</code>, <code>AGENTS.md</code> | None | | Documentation (content) | <code>kebab-case</code> | <code>naming-conventions.md</code>, <code>architecture-guide.md</code> | <code>-</code> | | Docker Compose Service | <code>{service_name}</code> | <code>finance_lending_api</code> | <code>_</code> | | Kubernetes Service | <code>{service-name}</code> | <code>finance-lending-api</code> | <code>-</code> | | Database Table | <code>{plural_noun}[_{qualifier}]</code> | <code>users</code>, <code>order_items</code> | <code>_</code> | | Database Column | <code>{noun}[_qualifier]</code> | <code>created_at</code>, <code>user_id</code> | <code>_</code> | | Env Variable | <code>{NOUN}_{QUALIFIER}</code> | <code>DATABASE_URL</code>, <code>API_KEY</code> | <code>_</code> | | REST API Path | <code>/api/v{N}/{resource}[/{id}]</code> | <code>/api/v1/users/{id}</code> | <code>/</code> (segments), <code>-</code> (words) | | Git Branch | <code>{type}/{description}</code> | <code>feature/user-auth</code> | <code>-</code> |</p> <p>\u2705 Validation: After naming elements, verify compliance with the validation checklist in naming-conversion.md.</p>"},{"location":"atomic/architecture/naming/#ai-decision-tree-how-to-name-any-element","title":"AI Decision Tree: How to Name Any Element","text":""},{"location":"atomic/architecture/naming/#quick-navigation-by-element-type","title":"Quick Navigation by Element Type","text":"<pre><code>SERVICE (microservice/app)     \u2192 naming-services.md\nPYTHON CLASS                   \u2192 naming-python.md (Classes section)\nPYTHON FUNCTION                \u2192 naming-python.md (Functions section)\nPYTHON VARIABLE/PARAMETER      \u2192 naming-python.md (Variables section)\nFILE/FOLDER                    \u2192 naming-python.md (Files &amp; Folders section)\nDOCUMENTATION FILES (.md)      \u2192 naming-documentation.md\nDATABASE (table/column)        \u2192 naming-databases.md\nINFRASTRUCTURE (K8s/Docker)    \u2192 naming-infrastructure.md\n</code></pre> <p>Most Common: Naming a Service \u2192 See naming-services.md</p>"},{"location":"atomic/architecture/naming/#detailed-guides","title":"Detailed Guides","text":""},{"location":"atomic/architecture/naming/#microservices","title":"Microservices","text":"<ul> <li>naming-services.md \u2014 Service naming formula (3-part vs 4-part), domain-function mapping, context catalog</li> <li>naming-4part-reasons.md \u2014 10 serious reasons for 4-part naming (detailed analysis with examples)</li> </ul>"},{"location":"atomic/architecture/naming/#code-infrastructure","title":"Code &amp; Infrastructure","text":"<ul> <li>naming-python.md \u2014 Python classes, functions, variables, files/folders</li> <li>naming-infrastructure.md \u2014 Docker Compose, Kubernetes, Nginx, 3-layer separator strategy</li> <li>naming-databases.md \u2014 PostgreSQL/MongoDB tables, columns, indexes, migrations</li> </ul>"},{"location":"atomic/architecture/naming/#documentation-tools","title":"Documentation &amp; Tools","text":"<ul> <li>naming-documentation.md \u2014 Documentation file naming (entry points vs content, kebab-case vs SCREAMING)</li> <li>naming-conversion.md \u2014 Dev\u2192Prod transformation (service_to_k8s function, validation checklist)</li> </ul>"},{"location":"atomic/architecture/naming/#common-questions","title":"Common Questions","text":""},{"location":"atomic/architecture/naming/#q-when-do-i-use-3-part-vs-4-part-service-naming","title":"Q: When do I use 3-part vs 4-part service naming?","text":"<p>Default (80-90%): Use 3-part <code>{context}_{domain}_{type}</code></p> <p>Function is implied by the domain: - <code>finance_lending_api</code> \u2014 lending implies matching/approval - <code>healthcare_telemedicine_api</code> \u2014 telemedicine implies consultation - <code>construction_house_bot</code> \u2014 house implies project management</p> <p>Exception (10-20%): Use 4-part <code>{context}_{domain}_{function}_{type}</code></p> <p>Only when domain is ambiguous (refers to 3+ different operations): - <code>logistics_fleet_tracking_api</code> \u2014 fleet could mean tracking, management, or maintenance - <code>analytics_reporting_api</code> \u2014 analytics could mean reporting, querying, or processing - <code>communication_notification_worker</code> \u2014 communication could mean email, SMS, or notifications</p> <p>Decision Rule: Ask \"Can this domain word refer to 3+ different operations?\" If yes \u2192 4-part. If no \u2192 3-part.</p> <p>See naming-services.md for complete decision tree and examples.</p>"},{"location":"atomic/architecture/naming/#q-which-separator-for-which-layer","title":"Q: Which separator for which layer?","text":"<p>Code/Data Layer (underscore <code>_</code>): - Python: <code>finance_lending_api.py</code>, <code>get_user_by_id()</code> - SQL: <code>users</code>, <code>created_at</code> - MongoDB: <code>user_sessions</code> - Environment variables: <code>DATABASE_URL</code></p> <p>Container Layer (Development) (underscore <code>_</code>): - Docker Compose: <code>finance_lending_api</code> - Internal dev environment</p> <p>Container Layer (Production) (hyphen <code>-</code>): - Kubernetes: <code>finance-lending-api</code> - DNS-compliant (RFC 1035)</p> <p>Network/DNS Layer (hyphen <code>-</code>): - DNS hostnames: <code>api.example.com</code> - REST API paths: <code>/api/v1/lending</code> - Git branches: <code>feature/user-auth</code></p> <p>Rationale: Each layer has technical requirements. Python/SQL require underscores, Kubernetes/DNS require hyphens.</p> <p>See naming-infrastructure.md for detailed layer breakdown.</p>"},{"location":"atomic/architecture/naming/#q-how-to-convert-service-names-for-kubernetes","title":"Q: How to convert service names for Kubernetes?","text":"<p>Use the <code>service_to_k8s()</code> function to convert Docker Compose names (underscores) to Kubernetes names (hyphens):</p> <pre><code>def service_to_k8s(service_name: str) -&gt; str:\n    \"\"\"Convert Docker Compose service name to Kubernetes DNS-compliant name.\n\n    Example:\n        &gt;&gt;&gt; service_to_k8s(\"finance_lending_api\")\n        \"finance-lending-api\"\n    \"\"\"\n    name = service_name.lower().replace('_', '-').strip('-')\n    return re.sub(r'-+', '-', name)\n</code></pre> <p>Mapping Example: - Code: <code>finance_lending_api/</code> (folder) - Docker Compose: <code>finance_lending_api</code> (service) - Kubernetes: <code>finance-lending-api</code> (service) - DNS: <code>lending-api.finance.example.com</code> (hostname)</p> <p>See naming-conversion.md for complete function code with validation.</p>"},{"location":"atomic/architecture/naming/#q-how-to-name-documentation-files","title":"Q: How to name documentation files?","text":"<p>Two-tier strategy:</p> <p>Entry Points (SCREAMING_SNAKE_CASE): - <code>README.md</code> \u2014 Project/directory entry point - <code>AGENTS.md</code> \u2014 AI agent entry point - <code>LICENSE</code> \u2014 Legal entry point - <code>CONTRIBUTING.md</code> \u2014 Contributor entry point (optional)</p> <p>Content Files (kebab-case): - <code>naming-conventions.md</code> \u2014 Guide document - <code>architecture-guide.md</code> \u2014 Reference document - <code>tech-stack.md</code> \u2014 Technical reference - <code>agent-verification-checklist.md</code> \u2014 Checklist</p> <p>Decision Rule: Ask \"Is this the FIRST file a human/AI reads when discovering this project/section?\" - YES \u2192 Entry point \u2192 <code>SCREAMING_SNAKE_CASE</code> - NO \u2192 Content \u2192 <code>kebab-case</code></p> <p>Rationale: - Entry points: SCREAMING emphasizes importance, industry convention - Content: kebab-case is URL-friendly, SEO-optimized, web publishing standard</p> <p>See naming-documentation.md for complete guide with examples.</p>"},{"location":"atomic/architecture/naming/#summary","title":"Summary","text":"<p>The Golden Rule: Use the separator appropriate for your technical layer.</p> Layer Separator Why Code &amp; Data Underscore <code>_</code> Python, SQL, MongoDB require it Container (Dev) Underscore <code>_</code> Matches code layer, internal dev environment Container (Prod) Hyphen <code>-</code> Kubernetes, DNS require it Network &amp; DNS Hyphen <code>-</code> RFC standards require it <p>Conversion: Automate <code>underscore_to_hyphen</code> transformation at deployment boundary (Docker Compose \u2192 Kubernetes).</p> <p>Consistency: Maintain 1:1 mapping across all layers: - Code: <code>finance_lending_api/</code> - Docker Compose: <code>finance_lending_api</code> - Kubernetes: <code>finance-lending-api</code> - DNS: <code>lending-api.finance.example.com</code></p> <p>All names refer to the same logical service, just using layer-appropriate separators.</p> <p>Service Naming: - DEFAULT (80-90%): <code>{context}_{domain}_{type}</code> (3-part) \u2014 function implied - EXCEPTION (10-20%): <code>{context}_{domain}_{function}_{type}</code> (4-part) \u2014 only when one of 10 reasons applies - BURDEN OF PROOF: Always start with 3-part, justify 4-part addition - See: naming-services.md and naming-4part-reasons.md</p> <p>Element Naming: Use appropriate suffixes for classes (Service, Repository, DTO, Handler, Router), verbs for functions (get_, create_, validate_), and descriptive patterns for variables.</p> <p>Name Length: Average 20-27 characters with 3-part formula (no abbreviations needed). 95%+ compatibility with Kubernetes DNS limits (253 chars).</p>"},{"location":"atomic/architecture/naming/#related-documents","title":"Related Documents","text":"<ul> <li><code>../context-registry.md</code> \u2014 Context name registry (prevent conflicts)</li> <li><code>../../../guides/semantic-shortening-guide.md</code> \u2014 3-part vs 4-part decision guide</li> <li><code>../../../checklists/service-naming-checklist.md</code> \u2014 Quick naming decision checklist</li> <li><code>../../../guides/architecture-guide.md</code> \u2014 Framework architecture overview</li> </ul>"},{"location":"atomic/architecture/naming/naming-4part-reasons/","title":"4-Part Service Naming: 10 Serious Reasons (Detailed)","text":"<p>This guide provides comprehensive analysis of when to use 4-part service naming in the doc4microservices framework. It presents 10 objective reasons that justify adding a <code>{function}</code> component to the standard 3-part naming pattern.</p> <p>PRINCIPLE: Default to 3-part. Use 4-part ONLY when one of these 10 reasons applies. If NONE apply, use 3-part naming.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#guiding-rules","title":"Guiding Rules","text":"<p>BURDEN OF PROOF: Always start with 3-part naming (<code>{context}_{domain}_{type}</code>). The burden of proof is on justifying the 4<sup>th</sup> component.</p> <p>OBJECTIVE TEST: Can this domain word refer to 3+ different operations in this context? If yes, consider 4-part. If no, use 3-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-1-domain-ambiguity-primary-reason","title":"Reason 1: Domain Ambiguity \u2b50 PRIMARY REASON","text":"<p>Criterion: The domain word can mean 3 or more different operations in the given context.</p> <p>Test: If you tell a colleague \"We have a <code>fleet</code> service\", and they ask \"What does it do with the fleet?\" \u2014 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#examples-of-ambiguous-domains","title":"Examples of Ambiguous Domains","text":"Domain Possible Operations Required 4-Part Names <code>fleet</code> tracking, management, maintenance, scheduling, optimization <code>logistics_fleet_tracking_api</code>, <code>logistics_fleet_management_api</code> <code>analytics</code> reporting, querying, processing, visualization, aggregation <code>analytics_reporting_api</code>, <code>analytics_querying_api</code> <code>data</code> collection, storage, transformation, aggregation, export <code>analytics_data_aggregation_worker</code> <code>communication</code> notification, email, sms, push, webhook, chat <code>communication_notification_worker</code> <code>warehouse</code> inventory, fulfillment, shipping, receiving, storage <code>logistics_warehouse_inventory_api</code> <code>delivery</code> routing, tracking, scheduling, optimization <code>logistics_delivery_routing_api</code> <code>content</code> creation, moderation, publishing, archiving <code>media_content_moderation_api</code> <code>user</code> (broad context) authentication, profile, preferences, activity, analytics <code>platform_user_authentication_api</code> <code>document</code> creation, storage, processing, conversion, signing <code>legal_document_signing_api</code> <code>event</code> creation, tracking, processing, notification, analytics <code>platform_event_processing_worker</code> <code>monitoring</code> collection, alerting, visualization, reporting <code>infrastructure_monitoring_alerting_api</code> <code>network</code> routing, monitoring, configuration, security <code>infrastructure_network_monitoring_api</code> <code>asset</code> tracking, valuation, maintenance, disposal <code>finance_asset_valuation_api</code> <code>inventory</code> tracking, management, optimization, forecasting <code>retail_inventory_optimization_api</code> <code>customer</code> acquisition, retention, support, analytics <code>sales_customer_acquisition_api</code>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#counter-examples-clear-domains-use-3-part","title":"Counter-examples (Clear Domains - Use 3-Part)","text":"<ul> <li><code>lending</code> \u2192 clearly means loan matching/approval</li> <li><code>payment</code> \u2192 clearly means payment processing</li> <li><code>telemedicine</code> \u2192 clearly means online consultation</li> <li><code>house</code> (in construction context) \u2192 clearly means project management</li> </ul>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-2-multiple-services-per-domain","title":"Reason 2: Multiple Services per Domain","text":"<p>Criterion: You need 2 or more separate services within the same <code>{context}_{domain}</code>, each handling different functions.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-logistics-fleet-management","title":"Example: Logistics Fleet Management","text":"<pre><code>logistics_fleet_tracking_api      \u2190 GPS tracking in real-time\nlogistics_fleet_management_api    \u2190 Driver/vehicle management\nlogistics_fleet_maintenance_api   \u2190 Maintenance scheduling\nlogistics_fleet_optimization_api  \u2190 Route optimization\n</code></pre> <p>Without 4-part: Impossible to create multiple services in same domain without name collision.</p> <p>Test: If you need to split domain into multiple independent services \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-3-cross-context-name-collision","title":"Reason 3: Cross-Context Name Collision","text":"<p>Criterion: The same domain word is used in different contexts with different meanings, requiring disambiguation.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-notification-in-different-contexts","title":"Example: <code>notification</code> in Different Contexts","text":"<pre><code># Context: communication (user-facing notifications)\ncommunication_push_notification_worker  \u2190 Push to users\n\n# Context: system (internal system alerts)\nsystem_alert_notification_api           \u2190 Internal alerts for admins\n\n# Context: analytics (metric threshold alerts)\nanalytics_threshold_notification_api    \u2190 Business metric alerts\n</code></pre> <p>Problem without 4-part: All three would be <code>{context}_notification_api</code>, but they serve completely different purposes.</p> <p>Test: If domain is used in 2+ contexts with different semantics \u2192 consider 4-part or rename domain.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-4-organizational-policy","title":"Reason 4: Organizational Policy","text":"<p>Criterion: Your team/organization has an established policy requiring explicit functions for certain contexts.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-policy","title":"Example Policy","text":"<p>\"All services in <code>analytics</code> context must explicitly state their function\"</p> <pre><code># Policy enforced:\nanalytics_reporting_api          \u2190 explicit function required\nanalytics_querying_api           \u2190 explicit function required\nanalytics_aggregation_worker     \u2190 explicit function required\n</code></pre> <p>Test: Check your Context Registry (<code>docs/atomic/architecture/context-registry.md</code>) for context-specific policies.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-5-technical-differentiation","title":"Reason 5: Technical Differentiation","text":"<p>Criterion: The domain has multiple technical implementations (different technologies/providers) requiring separate services.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-payment-processing-with-multiple-providers","title":"Example: Payment Processing with Multiple Providers","text":"<pre><code># Problem: one domain, multiple providers\nfinance_payment_api  \u2190 Which provider? Stripe? PayPal? Crypto?\n\n# Solution: explicit provider as function\nfinance_payment_stripe_api    \u2190 Stripe gateway\nfinance_payment_paypal_api    \u2190 PayPal gateway\nfinance_payment_crypto_api    \u2190 Cryptocurrency processing\n</code></pre>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-data-storage-with-different-engines","title":"Example: Data Storage with Different Engines","text":"<pre><code>storage_data_postgres_api     \u2190 PostgreSQL wrapper\nstorage_data_mongo_api        \u2190 MongoDB wrapper\nstorage_data_s3_api           \u2190 S3 file storage\n</code></pre> <p>Test: If domain needs multiple services for different technologies/providers \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-6-functional-split-during-migration","title":"Reason 6: Functional Split During Migration","text":"<p>Criterion: Blue-green deployment or migration requires functional decomposition of a monolith.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-monolith-to-microservices-migration","title":"Example: Monolith to Microservices Migration","text":"<pre><code># Legacy monolith\nfinance_lending_api              \u2190 old monolithic service\n\n# New microservices (functional split)\nfinance_lending_matching_api     \u2190 borrower-lender matching\nfinance_lending_approval_api     \u2190 credit approval workflow\nfinance_lending_servicing_api    \u2190 loan servicing\n</code></pre> <p>Note: Use 4-part ONLY if migration requires functional split. Not for simple v1/v2 versioning (versions belong in API paths, not service names).</p> <p>Test: If migration requires splitting ONE domain into multiple functional areas \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-7-legacy-system-integration","title":"Reason 7: Legacy System Integration","text":"<p>Criterion: Integration with existing system where terminology is already established and changing it would cause confusion.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-migrating-from-erp-system","title":"Example: Migrating from ERP System","text":"<pre><code># Old ERP modules (established terminology)\nOldERP.FleetTrackingModule     \u2190 legacy name\nOldERP.FleetManagementModule   \u2190 legacy name\n\n# New architecture (preserve terminology)\nlogistics_fleet_tracking_api      \u2190 matches FleetTrackingModule\nlogistics_fleet_management_api    \u2190 matches FleetManagementModule\n</code></pre> <p>Rationale: Team is familiar with \"tracking\" vs \"management\" distinction \u2014 don't change terminology unnecessarily.</p> <p>Test: If legacy system has established functional names \u2192 preserve them via 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-8-regulatorycompliance-requirements","title":"Reason 8: Regulatory/Compliance Requirements","text":"<p>Criterion: Regulations or audits require explicit functional separation at the service level.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-financial-services-with-regulatory-separation","title":"Example: Financial Services with Regulatory Separation","text":"<pre><code># Regulation: \"Payment processing and payment data storage must be separate systems\"\n\nfinance_payment_processing_api   \u2190 explicit: processing\nfinance_payment_storage_api      \u2190 explicit: storage (GDPR/PCI)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-healthcare-hipaagdpr-compliance","title":"Example: Healthcare (HIPAA/GDPR Compliance)","text":"<pre><code># Requirement: \"Patient data storage and processing must be separate\"\n\nhealthcare_patient_storage_api      \u2190 HIPAA-compliant storage\nhealthcare_patient_processing_api   \u2190 Data processing/analytics\n</code></pre> <p>Test: If regulator requires explicit separation \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-9-different-slaresource-requirements","title":"Reason 9: Different SLA/Resource Requirements","text":"<p>Criterion: Functions within a domain require radically different SLA or infrastructure resources, dictating separate services.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-analytics-with-different-performance-profiles","title":"Example: Analytics with Different Performance Profiles","text":"<pre><code>analytics_querying_api           \u2190 high load, low latency (ms), horizontal scaling\nanalytics_aggregation_worker     \u2190 low load, high latency (min/hours), vertical scaling\n</code></pre> <p>Characteristics comparison: - <code>querying</code>: 1000 req/sec, response &lt; 100ms, 10+ replicas - <code>aggregation</code>: 10 jobs/hour, response 10-60 min, 2 large workers</p> <p>Test: If functions need different infrastructure strategies \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#reason-10-onboarding-clarity","title":"Reason 10: Onboarding Clarity","text":"<p>Criterion: Large team (10+ developers) where newcomers regularly struggle to understand service purpose from 3-part names.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#example-platform-with-50-microservices","title":"Example: Platform with 50+ Microservices","text":"<pre><code># Problem: newcomer confusion\ncommunication_api  \u2190 What does it do? Send? Receive? Both?\ncommunication_bot  \u2190 What's the difference?\n\n# Solution: explicit functions for self-documentation\ncommunication_notification_worker   \u2190 clear: sends notifications\ncommunication_telegram_bot          \u2190 clear: Telegram interface\ncommunication_webhook_api           \u2190 clear: receives webhooks\n</code></pre> <p>Test: If new developers can't understand service purpose from 3-part name \u2192 use 4-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#decision-checklist-3-part-vs-4-part","title":"Decision Checklist: 3-Part vs 4-Part","text":"<p>Before adding <code>{function}</code>, verify at least ONE reason applies:</p> <ul> <li> Reason 1: Domain implies 3+ operations?</li> <li> Reason 2: Need 2+ services in same domain?</li> <li> Reason 3: Cross-context name collision?</li> <li> Reason 4: Organizational policy requires it?</li> <li> Reason 5: Different technologies/providers?</li> <li> Reason 6: Functional split during migration?</li> <li> Reason 7: Legacy system has established terms?</li> <li> Reason 8: Regulatory requirement for separation?</li> <li> Reason 9: Radically different SLA/resources?</li> <li> Reason 10: Onboarding clarity issue?</li> </ul> <p>If ALL unchecked \u2192 \u2705 Use 3-part (function is implied)</p> <p>If AT LEAST ONE checked \u2192 \u2705 Use 4-part with explicit <code>{function}</code></p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#anti-patterns-do-not-use-4-part-for","title":"Anti-Patterns: DO NOT Use 4-Part For","text":""},{"location":"atomic/architecture/naming/naming-4part-reasons/#anti-pattern-1-service-has-many-features","title":"\u274c Anti-Pattern 1: Service Has Many Features","text":"<p>Bad reasoning: \"Service has multiple code features (CRUD, search, export) \u2192 need 4-part\"</p> <pre><code># WRONG\nconstruction_house_management_bot  \u2190 redundant\n</code></pre> <p>Correct: <pre><code># RIGHT\nconstruction_house_bot  \u2190 management implied by context\n</code></pre></p> <p>Rule: Multiple code features \u2260 ambiguous domain. Use 3-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#anti-pattern-2-service-has-many-endpoints","title":"\u274c Anti-Pattern 2: Service Has Many Endpoints","text":"<p>Bad reasoning: \"API has many endpoints (/create, /update, /delete) \u2192 need 4-part\"</p> <pre><code># WRONG\nfinance_lending_operations_api  \u2190 redundant\n</code></pre> <p>Correct: <pre><code># RIGHT\nfinance_lending_api  \u2190 CRUD operations implied for API\n</code></pre></p> <p>Rule: Multiple REST endpoints \u2260 ambiguous domain. Use 3-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#anti-pattern-3-name-seems-too-short","title":"\u274c Anti-Pattern 3: Name Seems Too Short","text":"<p>Bad reasoning: \"19 chars seems short \u2192 add generic word for length\"</p> <pre><code># WRONG\nfinance_lending_platform_api  \u2190 adding \"platform\" for length\n</code></pre> <p>Correct: <pre><code># RIGHT\nfinance_lending_api  \u2190 brevity is good\n</code></pre></p> <p>Rule: Brevity is a virtue, not a problem. Use 3-part.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#anti-pattern-4-symmetry-with-other-services","title":"\u274c Anti-Pattern 4: Symmetry with Other Services","text":"<p>Bad reasoning: \"Other service uses 4-part \u2192 use 4-part for symmetry\"</p> <pre><code># WRONG (forced symmetry)\nfinance_lending_processing_api    \u2190 has 4-part cause\nfinance_payment_processing_api    \u2190 forced to match (bad!)\n</code></pre> <p>Correct: <pre><code># RIGHT (independent evaluation)\nfinance_lending_api               \u2190 processing implied\nfinance_payment_api               \u2190 processing implied\n</code></pre></p> <p>Rule: Evaluate each service independently. Don't force symmetry.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#expected-distribution","title":"Expected Distribution","text":"<p>In a well-designed architecture: - 80-90% of services: 3-part (most domains are specific) - 10-20% of services: 4-part (only truly ambiguous domains)</p> <p>Warning: If your project has &gt; 30% services using 4-part \u2192 domains are probably too generic. Consider refactoring domain decomposition.</p>"},{"location":"atomic/architecture/naming/naming-4part-reasons/#related-documents","title":"Related Documents","text":"<ul> <li><code>naming-services.md</code> \u2014 Service naming patterns guide</li> <li><code>../../../guides/semantic-shortening-guide.md</code> \u2014 Decision tree for 3-part vs 4-part</li> <li><code>../../../checklists/service-naming-checklist.md</code> \u2014 Quick checklist for naming decisions</li> <li><code>../context-registry.md</code> \u2014 Context name registry to prevent conflicts</li> </ul>"},{"location":"atomic/architecture/naming/naming-conversion/","title":"Naming Conversion Utilities","text":"<p>This guide provides utilities and patterns for converting service names between development (Docker Compose) and production (Kubernetes) environments. It ensures consistent name transformation across deployment boundaries.</p> <p>Key Principle: Automate underscore-to-hyphen conversion at deployment. Maintain 1:1 mapping between environments.</p>"},{"location":"atomic/architecture/naming/naming-conversion/#conversion-functions","title":"Conversion Functions","text":""},{"location":"atomic/architecture/naming/naming-conversion/#python-implementation","title":"Python Implementation","text":"<pre><code>import re\nfrom typing import Dict, List\n\ndef service_to_k8s(service_name: str) -&gt; str:\n    \"\"\"Convert Docker Compose service name to Kubernetes DNS-compliant name.\n\n    Args:\n        service_name: Docker Compose service name with underscores\n\n    Returns:\n        Kubernetes-compatible name with hyphens\n\n    Example:\n        &gt;&gt;&gt; service_to_k8s(\"finance_lending_api\")\n        \"finance-lending-api\"\n    \"\"\"\n    # Convert to lowercase and replace underscores\n    name = service_name.lower().replace('_', '-').strip('-')\n\n    # Remove any duplicate hyphens\n    name = re.sub(r'-+', '-', name)\n\n    # Ensure DNS compliance (alphanumeric and hyphens only)\n    name = re.sub(r'[^a-z0-9-]', '', name)\n\n    # Kubernetes names must not start/end with hyphen\n    name = name.strip('-')\n\n    # Enforce max length (253 chars for DNS)\n    if len(name) &gt; 253:\n        # Truncate and ensure no trailing hyphen\n        name = name[:253].rstrip('-')\n\n    return name\n\n\ndef k8s_to_service(k8s_name: str) -&gt; str:\n    \"\"\"Convert Kubernetes name back to Docker Compose format.\n\n    Args:\n        k8s_name: Kubernetes service name with hyphens\n\n    Returns:\n        Docker Compose service name with underscores\n\n    Example:\n        &gt;&gt;&gt; k8s_to_service(\"finance-lending-api\")\n        \"finance_lending_api\"\n    \"\"\"\n    return k8s_name.replace('-', '_')\n\n\ndef validate_service_name(name: str, environment: str = \"docker\") -&gt; bool:\n    \"\"\"Validate service name for target environment.\n\n    Args:\n        name: Service name to validate\n        environment: Target environment ('docker' or 'k8s')\n\n    Returns:\n        True if valid, False otherwise\n    \"\"\"\n    if environment == \"docker\":\n        # Docker Compose: letters, numbers, underscores\n        pattern = r'^[a-z][a-z0-9_]*$'\n    elif environment == \"k8s\":\n        # Kubernetes: DNS-compliant (lowercase, numbers, hyphens)\n        pattern = r'^[a-z][a-z0-9-]*[a-z0-9]$'\n        if len(name) &gt; 253:\n            return False\n    else:\n        raise ValueError(f\"Unknown environment: {environment}\")\n\n    return bool(re.match(pattern, name))\n\n\ndef batch_convert_services(services: List[str],\n                          target: str = \"k8s\") -&gt; Dict[str, str]:\n    \"\"\"Convert multiple service names.\n\n    Args:\n        services: List of service names\n        target: Target format ('k8s' or 'docker')\n\n    Returns:\n        Dictionary mapping original names to converted names\n    \"\"\"\n    result = {}\n    for service in services:\n        if target == \"k8s\":\n            result[service] = service_to_k8s(service)\n        elif target == \"docker\":\n            result[service] = k8s_to_service(service)\n        else:\n            raise ValueError(f\"Unknown target: {target}\")\n\n    return result\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#bash-implementation","title":"Bash Implementation","text":"<pre><code>#!/bin/bash\n\n# Convert Docker Compose name to Kubernetes\nservice_to_k8s() {\n    echo \"$1\" | tr '[:upper:]' '[:lower:]' | tr '_' '-' | sed 's/^-*//' | sed 's/-*$//'\n}\n\n# Convert Kubernetes name to Docker Compose\nk8s_to_service() {\n    echo \"$1\" | tr '-' '_'\n}\n\n# Validate Kubernetes name\nvalidate_k8s_name() {\n    local name=\"$1\"\n    if [[ \"$name\" =~ ^[a-z][a-z0-9-]*[a-z0-9]$ ]] &amp;&amp; [ ${#name} -le 253 ]; then\n        return 0\n    else\n        return 1\n    fi\n}\n\n# Example usage\nSERVICE=\"finance_lending_api\"\nK8S_NAME=$(service_to_k8s \"$SERVICE\")\necho \"Docker Compose: $SERVICE\"\necho \"Kubernetes: $K8S_NAME\"\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"atomic/architecture/naming/naming-conversion/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code># .github/workflows/deploy.yml\nname: Deploy to Kubernetes\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Convert service names\n        run: |\n          # Convert all service names for deployment\n          export K8S_LENDING_API=$(echo \"finance_lending_api\" | tr '_' '-')\n          export K8S_PAYMENT_WORKER=$(echo \"finance_payment_worker\" | tr '_' '-')\n\n          echo \"Deploying $K8S_LENDING_API to Kubernetes...\"\n\n      - name: Update Kubernetes manifests\n        run: |\n          sed -i \"s/{{SERVICE_NAME}}/$K8S_LENDING_API/g\" k8s/deployment.yaml\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#helm-values-transformation","title":"Helm Values Transformation","text":"<pre><code># values.yaml (Docker Compose names)\nservices:\n  finance_lending_api:\n    image: finance_lending_api:latest\n    replicas: 3\n\n# values-k8s.yaml (transformed)\nservices:\n  finance-lending-api:\n    image: finance-lending-api:latest\n    replicas: 3\n</code></pre> <p>Transform with script:</p> <pre><code># transform_values.py\nimport yaml\n\ndef transform_helm_values(input_file, output_file):\n    with open(input_file) as f:\n        values = yaml.safe_load(f)\n\n    # Transform service names\n    transformed = {}\n    for key, value in values.get('services', {}).items():\n        k8s_name = service_to_k8s(key)\n        value['name'] = k8s_name\n        transformed[k8s_name] = value\n\n    values['services'] = transformed\n\n    with open(output_file, 'w') as f:\n        yaml.dump(values, f)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#validation-checklist","title":"Validation Checklist","text":""},{"location":"atomic/architecture/naming/naming-conversion/#pre-deployment-validation","title":"Pre-Deployment Validation","text":"<pre><code># validate_names.py\ndef validate_deployment_names(compose_file: str, k8s_dir: str):\n    \"\"\"Validate name consistency between Docker Compose and Kubernetes.\"\"\"\n    errors = []\n\n    # Load Docker Compose services\n    with open(compose_file) as f:\n        compose = yaml.safe_load(f)\n\n    compose_services = set(compose.get('services', {}).keys())\n\n    # Check Kubernetes manifests\n    for k8s_file in Path(k8s_dir).glob('*.yaml'):\n        with open(k8s_file) as f:\n            manifest = yaml.safe_load(f)\n\n        # Extract service name from metadata\n        if manifest.get('kind') in ['Service', 'Deployment']:\n            k8s_name = manifest['metadata']['name']\n            expected_compose = k8s_to_service(k8s_name)\n\n            if expected_compose not in compose_services:\n                errors.append(f\"K8s service '{k8s_name}' has no matching \"\n                            f\"Docker Compose service '{expected_compose}'\")\n\n    return errors\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#common-mappings","title":"Common Mappings","text":""},{"location":"atomic/architecture/naming/naming-conversion/#service-name-mappings","title":"Service Name Mappings","text":"Docker Compose Kubernetes DNS Entry <code>finance_lending_api</code> <code>finance-lending-api</code> <code>finance-lending-api.finance.svc</code> <code>healthcare_telemedicine_api</code> <code>healthcare-telemedicine-api</code> <code>healthcare-telemedicine-api.healthcare.svc</code> <code>logistics_fleet_tracking_api</code> <code>logistics-fleet-tracking-api</code> <code>logistics-fleet-tracking-api.logistics.svc</code> <code>postgres_db</code> <code>postgres-db</code> <code>postgres-db.default.svc</code> <code>redis_cache</code> <code>redis-cache</code> <code>redis-cache.default.svc</code>"},{"location":"atomic/architecture/naming/naming-conversion/#environment-variable-mappings","title":"Environment Variable Mappings","text":"<pre><code># Docker Compose\nLENDING_API_URL=http://finance_lending_api:8000\nPAYMENT_API_URL=http://finance_payment_worker:8000\n\n# Kubernetes\nLENDING_API_URL=http://finance-lending-api.finance.svc:80\nPAYMENT_API_URL=http://finance-payment-worker.finance.svc:80\n</code></pre>"},{"location":"atomic/architecture/naming/naming-conversion/#troubleshooting","title":"Troubleshooting","text":""},{"location":"atomic/architecture/naming/naming-conversion/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Name too long for Kubernetes <pre><code>def truncate_k8s_name(name: str, max_length: int = 63) -&gt; str:\n    \"\"\"Truncate name for Kubernetes labels (63 char limit).\"\"\"\n    if len(name) &lt;= max_length:\n        return name\n    # Keep prefix and suffix, add hash in middle\n    import hashlib\n    hash_str = hashlib.md5(name.encode()).hexdigest()[:6]\n    keep_chars = max_length - 7  # 6 for hash + 1 for hyphen\n    prefix_len = keep_chars // 2\n    suffix_len = keep_chars - prefix_len\n    return f\"{name[:prefix_len]}-{hash_str}-{name[-suffix_len:]}\"\n</code></pre></p> </li> <li> <p>Special characters in names <pre><code>def sanitize_name(name: str) -&gt; str:\n    \"\"\"Remove special characters for Kubernetes.\"\"\"\n    # Replace common special chars\n    name = name.replace('/', '-')\n    name = name.replace('.', '-')\n    name = name.replace('@', 'at')\n    # Remove any remaining special chars\n    return re.sub(r'[^a-z0-9-]', '', name.lower())\n</code></pre></p> </li> </ol>"},{"location":"atomic/architecture/naming/naming-conversion/#related-documents","title":"Related Documents","text":"<ul> <li><code>./README.md</code> \u2014 Main naming conventions hub</li> <li><code>naming-infrastructure.md</code> \u2014 Infrastructure naming patterns</li> <li><code>naming-services.md</code> \u2014 Service naming patterns</li> </ul>"},{"location":"atomic/architecture/naming/naming-databases/","title":"Database Naming Conventions","text":"<p>This guide covers database naming patterns for PostgreSQL and MongoDB in the doc4microservices framework. It ensures consistent, self-documenting database schemas that align with the service architecture.</p> <p>Key Principle: Use snake_case for all database objects. Tables/collections use plural nouns. Follow service boundaries for database separation.</p>"},{"location":"atomic/architecture/naming/naming-databases/#postgresql","title":"PostgreSQL","text":""},{"location":"atomic/architecture/naming/naming-databases/#database-naming","title":"Database Naming","text":"<p>Each service context gets its own database:</p> <pre><code>-- Database per context\nCREATE DATABASE finance_db;\nCREATE DATABASE healthcare_db;\nCREATE DATABASE logistics_db;\n\n-- Or database per service for complete isolation\nCREATE DATABASE lending_service_db;\nCREATE DATABASE telemedicine_service_db;\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#table-naming","title":"Table Naming","text":"<p>Tables use plural nouns in snake_case:</p> <pre><code>-- Good table names\nCREATE TABLE users (...);\nCREATE TABLE loan_applications (...);\nCREATE TABLE payment_transactions (...);\nCREATE TABLE user_sessions (...);\n\n-- Bad table names (avoid)\nCREATE TABLE User (...);           -- No PascalCase\nCREATE TABLE user (...);           -- Use plural\nCREATE TABLE tbl_users (...);      -- No prefixes\nCREATE TABLE UsersTable (...);     -- No suffixes\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#column-naming","title":"Column Naming","text":"<p>Columns use snake_case with descriptive names:</p> <pre><code>CREATE TABLE users (\n    -- Primary key\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n\n    -- Basic fields\n    email VARCHAR(255) NOT NULL,\n    phone_number VARCHAR(20),\n    first_name VARCHAR(100),\n    last_name VARCHAR(100),\n\n    -- Boolean flags\n    is_active BOOLEAN DEFAULT true,\n    is_verified BOOLEAN DEFAULT false,\n    has_premium BOOLEAN DEFAULT false,\n\n    -- Timestamps\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    deleted_at TIMESTAMP WITH TIME ZONE,\n    last_login_at TIMESTAMP WITH TIME ZONE,\n\n    -- JSON fields\n    metadata JSONB DEFAULT '{}',\n    preferences JSONB DEFAULT '{}'\n);\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#foreign-key-naming","title":"Foreign Key Naming","text":"<pre><code>-- Pattern: {table}_{column}_fkey\nALTER TABLE loan_applications\n    ADD CONSTRAINT loan_applications_user_id_fkey\n    FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE payment_transactions\n    ADD CONSTRAINT payment_transactions_loan_id_fkey\n    FOREIGN KEY (loan_id) REFERENCES loan_applications(id);\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#index-naming","title":"Index Naming","text":"<pre><code>-- Pattern: idx_{table}_{column(s)}\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_created_at ON users(created_at);\nCREATE INDEX idx_loan_applications_user_id ON loan_applications(user_id);\nCREATE INDEX idx_loan_applications_status_created_at\n    ON loan_applications(status, created_at);\n\n-- Unique index: uniq_{table}_{column(s)}\nCREATE UNIQUE INDEX uniq_users_email ON users(email);\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#view-naming","title":"View Naming","text":"<pre><code>-- Pattern: v_{description} or {table}_view\nCREATE VIEW v_active_loans AS\n    SELECT * FROM loan_applications\n    WHERE status = 'active';\n\nCREATE VIEW user_statistics_view AS\n    SELECT user_id, COUNT(*) as loan_count\n    FROM loan_applications\n    GROUP BY user_id;\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#functionprocedure-naming","title":"Function/Procedure Naming","text":"<pre><code>-- Pattern: {verb}_{noun}\nCREATE FUNCTION calculate_interest(\n    principal DECIMAL,\n    rate DECIMAL,\n    months INT\n) RETURNS DECIMAL AS $$\nBEGIN\n    RETURN principal * rate * months / 12;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE PROCEDURE process_expired_loans() AS $$\nBEGIN\n    UPDATE loan_applications\n    SET status = 'expired'\n    WHERE expires_at &lt; NOW()\n    AND status = 'pending';\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#mongodb","title":"MongoDB","text":""},{"location":"atomic/architecture/naming/naming-databases/#database-naming_1","title":"Database Naming","text":"<pre><code>// Database per context\nuse finance_db\nuse healthcare_db\nuse logistics_db\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#collection-naming","title":"Collection Naming","text":"<p>Collections use plural nouns in snake_case:</p> <pre><code>// Good collection names\ndb.users\ndb.loan_applications\ndb.payment_transactions\ndb.audit_logs\n\n// Bad collection names (avoid)\ndb.User              // No PascalCase\ndb.user              // Use plural\ndb.usersCollection   // No suffixes\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#field-naming","title":"Field Naming","text":"<p>Fields use snake_case (not camelCase):</p> <pre><code>// Good document structure\n{\n  _id: ObjectId(),\n  user_id: \"usr_123\",\n  email: \"user@example.com\",\n  first_name: \"John\",\n  last_name: \"Doe\",\n  is_active: true,\n  is_verified: false,\n  created_at: ISODate(),\n  updated_at: ISODate(),\n\n  // Nested objects\n  address: {\n    street_address: \"123 Main St\",\n    city: \"Boston\",\n    state_code: \"MA\",\n    postal_code: \"02101\"\n  },\n\n  // Arrays\n  phone_numbers: [\n    {\n      type: \"mobile\",\n      number: \"+1-555-0123\",\n      is_primary: true\n    }\n  ]\n}\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#index-naming_1","title":"Index Naming","text":"<pre><code>// Single field index\ndb.users.createIndex(\n  { email: 1 },\n  { name: \"idx_users_email\" }\n)\n\n// Compound index\ndb.loan_applications.createIndex(\n  { user_id: 1, created_at: -1 },\n  { name: \"idx_loan_applications_user_id_created_at\" }\n)\n\n// Unique index\ndb.users.createIndex(\n  { email: 1 },\n  {\n    name: \"uniq_users_email\",\n    unique: true\n  }\n)\n\n// Text index\ndb.products.createIndex(\n  { name: \"text\", description: \"text\" },\n  { name: \"idx_products_text_search\" }\n)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#aggregation-pipeline-naming","title":"Aggregation Pipeline Naming","text":"<pre><code>// Name pipeline stages clearly\ndb.loan_applications.aggregate([\n  { $match: { status: \"approved\" } },           // filter_approved\n  { $group: {                                   // group_by_user\n      _id: \"$user_id\",\n      total_amount: { $sum: \"$amount\" }\n    }\n  },\n  { $sort: { total_amount: -1 } },              // sort_by_amount\n  { $limit: 10 }                                // limit_top_10\n])\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#migration-file-naming","title":"Migration File Naming","text":""},{"location":"atomic/architecture/naming/naming-databases/#sql-migrations-alembicflyway","title":"SQL Migrations (Alembic/Flyway)","text":"<pre><code>migrations/\n\u251c\u2500\u2500 V001__create_users_table.sql\n\u251c\u2500\u2500 V002__create_loan_applications_table.sql\n\u251c\u2500\u2500 V003__add_email_index_to_users.sql\n\u251c\u2500\u2500 V004__add_status_column_to_loans.sql\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#mongodb-migrations","title":"MongoDB Migrations","text":"<pre><code>migrations/\n\u251c\u2500\u2500 001_create_users_collection.js\n\u251c\u2500\u2500 002_create_loan_applications_collection.js\n\u251c\u2500\u2500 003_add_users_email_index.js\n\u251c\u2500\u2500 004_add_status_field_to_loans.js\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#common-patterns","title":"Common Patterns","text":""},{"location":"atomic/architecture/naming/naming-databases/#timestamp-columns","title":"Timestamp Columns","text":"<p>Always include these columns in PostgreSQL: <pre><code>created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\nupdated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n</code></pre></p> <p>MongoDB equivalent: <pre><code>{\n  created_at: ISODate(),\n  updated_at: ISODate()\n}\n</code></pre></p>"},{"location":"atomic/architecture/naming/naming-databases/#soft-delete-pattern","title":"Soft Delete Pattern","text":"<p>PostgreSQL: <pre><code>deleted_at TIMESTAMP WITH TIME ZONE DEFAULT NULL\n</code></pre></p> <p>MongoDB: <pre><code>{\n  deleted_at: null,  // or ISODate() when deleted\n  is_deleted: false  // boolean alternative\n}\n</code></pre></p>"},{"location":"atomic/architecture/naming/naming-databases/#status-fields","title":"Status Fields","text":"<pre><code>-- PostgreSQL enum\nCREATE TYPE loan_status AS ENUM ('pending', 'approved', 'rejected', 'expired');\nstatus loan_status NOT NULL DEFAULT 'pending'\n\n-- Or simple varchar\nstatus VARCHAR(20) NOT NULL DEFAULT 'pending'\n</code></pre> <pre><code>// MongoDB\n{\n  status: \"pending\"  // one of: pending, approved, rejected, expired\n}\n</code></pre>"},{"location":"atomic/architecture/naming/naming-databases/#checklist","title":"Checklist","text":"<ul> <li> Databases named per context or service</li> <li> Tables/collections use plural nouns</li> <li> All names use snake_case (no camelCase)</li> <li> Foreign keys follow {table}_{column}_fkey pattern</li> <li> Indexes follow idx_{table}_{columns} pattern</li> <li> Include created_at/updated_at timestamps</li> <li> No type prefixes (tbl_, col_, etc.)</li> <li> Migration files numbered sequentially</li> </ul>"},{"location":"atomic/architecture/naming/naming-databases/#related-documents","title":"Related Documents","text":"<ul> <li><code>./README.md</code> \u2014 Main naming conventions hub</li> <li><code>naming-python.md</code> \u2014 Python model naming</li> <li><code>naming-services.md</code> \u2014 Service naming patterns</li> </ul>"},{"location":"atomic/architecture/naming/naming-documentation/","title":"Documentation File Naming Conventions","text":"<p>This guide covers naming patterns for documentation files in the doc4microservices framework. It implements a two-tier strategy distinguishing entry points from content files.</p> <p>Key Principle: Use SCREAMING_SNAKE_CASE for entry points, kebab-case for content. This maximizes visibility of critical files while maintaining web-friendly URLs for content.</p>"},{"location":"atomic/architecture/naming/naming-documentation/#two-tier-naming-strategy","title":"Two-Tier Naming Strategy","text":"<p>Documentation files fall into two categories with different naming conventions:</p> Category Pattern Example Purpose Entry Points SCREAMING_SNAKE_CASE <code>README.md</code>, <code>AGENTS.md</code> First files humans/AI read Content Files kebab-case <code>naming-conventions.md</code> Reference and guide documents"},{"location":"atomic/architecture/naming/naming-documentation/#decision-rule","title":"Decision Rule","text":"<p>Ask: \"Is this the FIRST file someone reads when discovering this project/directory?\" - YES \u2192 Entry point \u2192 <code>SCREAMING_SNAKE_CASE.md</code> - NO \u2192 Content \u2192 <code>kebab-case.md</code></p>"},{"location":"atomic/architecture/naming/naming-documentation/#entry-point-files","title":"Entry Point Files","text":""},{"location":"atomic/architecture/naming/naming-documentation/#standard-entry-points","title":"Standard Entry Points","text":"<pre><code>README.md            # Project/directory main entry\nAGENTS.md           # AI agent instructions\nLICENSE             # Legal terms\nCONTRIBUTING.md     # Contribution guidelines\nCHANGELOG.md        # Version history\nSECURITY.md         # Security policies\nCODE_OF_CONDUCT.md  # Community standards\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#why-screaming_snake_case","title":"Why SCREAMING_SNAKE_CASE?","text":"<ol> <li>Industry Convention: GitHub, npm, PyPI expect README.md</li> <li>Maximum Visibility: Stands out in file listings</li> <li>Special Treatment: Tools recognize and prioritize these files</li> <li>Historical Standard: Unix tradition (LICENSE, INSTALL, AUTHORS)</li> </ol>"},{"location":"atomic/architecture/naming/naming-documentation/#entry-point-hierarchy","title":"Entry Point Hierarchy","text":"<pre><code>project/\n\u251c\u2500\u2500 README.md              # Project entry point\n\u251c\u2500\u2500 AGENTS.md             # AI entry point\n\u251c\u2500\u2500 LICENSE               # Legal entry point\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 README.md         # Docs entry point\n\u2502   \u251c\u2500\u2500 atomic/\n\u2502   \u2502   \u251c\u2500\u2500 README.md     # Atomic docs entry\n\u2502   \u2502   \u2514\u2500\u2500 architecture/\n\u2502   \u2502       \u251c\u2500\u2500 README.md # Architecture entry\n\u2502   \u2502       \u2514\u2500\u2500 naming-guide.md  # Content file\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#content-files","title":"Content Files","text":""},{"location":"atomic/architecture/naming/naming-documentation/#content-file-patterns","title":"Content File Patterns","text":"<pre><code># Guides and references\nnaming-conventions.md\narchitecture-guide.md\npython-style-guide.md\ndeployment-checklist.md\n\n# Technical documentation\napi-reference.md\ndatabase-schema.md\nintegration-guide.md\n\n# Process documentation\ncode-review-process.md\nrelease-notes-v1.md\nmigration-guide.md\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#why-kebab-case","title":"Why kebab-case?","text":"<ol> <li>URL-Friendly: Direct mapping to web URLs</li> <li>SEO-Optimized: Search engines prefer hyphens</li> <li>GitHub Pages: Clean URLs without encoding</li> <li>Readability: Natural word separation</li> <li>Tool Compatibility: Static site generators expect it</li> </ol>"},{"location":"atomic/architecture/naming/naming-documentation/#kebab-case-rules","title":"kebab-case Rules","text":"<pre><code># Good examples\nuser-authentication-guide.md    \u2705\napi-v2-migration.md            \u2705\n2024-01-release-notes.md       \u2705\nfaq.md                          \u2705\n\n# Bad examples\nuser_authentication_guide.md    \u274c (underscores)\nuserAuthenticationGuide.md      \u274c (camelCase)\nUSER-AUTHENTICATION-GUIDE.md    \u274c (unless entry point)\nuser-authentication-guide.MD    \u274c (uppercase extension)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#special-cases","title":"Special Cases","text":""},{"location":"atomic/architecture/naming/naming-documentation/#index-files","title":"Index Files","text":"<pre><code>INDEX.md            # Directory index (entry point)\nindex.md            # Web root index (content)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#configuration-documentation","title":"Configuration Documentation","text":"<pre><code>.env.example        # Example config (dot file)\nconfig-guide.md     # Config documentation\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#template-files","title":"Template Files","text":"<pre><code>TEMPLATE_README.md           # Template entry point\ntemplate-service.md          # Template content\npull-request-template.md    # GitHub template\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#directory-organization","title":"Directory Organization","text":""},{"location":"atomic/architecture/naming/naming-documentation/#atomic-documentation-structure","title":"Atomic Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 README.md                    # Entry point\n\u251c\u2500\u2500 INDEX.md                     # Documentation index\n\u251c\u2500\u2500 atomic/\n\u2502   \u251c\u2500\u2500 README.md               # Atomic entry\n\u2502   \u251c\u2500\u2500 architecture/\n\u2502   \u2502   \u251c\u2500\u2500 README.md           # Architecture entry\n\u2502   \u2502   \u251c\u2500\u2500 naming/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 README.md       # Naming hub\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 naming-services.md\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 naming-python.md\n\u2502   \u2502   \u2514\u2500\u2500 service-patterns.md\n\u2502   \u2514\u2500\u2500 testing/\n\u2502       \u251c\u2500\u2500 README.md           # Testing entry\n\u2502       \u251c\u2500\u2500 unit-testing.md\n\u2502       \u2514\u2500\u2500 integration-testing.md\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#content-grouping","title":"Content Grouping","text":"<p>Group related content with consistent naming:</p> <pre><code>docs/guides/\n\u251c\u2500\u2500 getting-started.md\n\u251c\u2500\u2500 quick-start.md\n\u251c\u2500\u2500 installation-guide.md\n\u251c\u2500\u2500 configuration-guide.md\n\u251c\u2500\u2500 deployment-guide.md\n\u2514\u2500\u2500 troubleshooting-guide.md\n\ndocs/reference/\n\u251c\u2500\u2500 api-reference.md\n\u251c\u2500\u2500 cli-reference.md\n\u251c\u2500\u2500 configuration-reference.md\n\u2514\u2500\u2500 error-reference.md\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#file-extensions","title":"File Extensions","text":""},{"location":"atomic/architecture/naming/naming-documentation/#markdown-files","title":"Markdown Files","text":"<p>Always use lowercase <code>.md</code>:</p> <pre><code>README.md     \u2705\nreadme.MD     \u274c\nREADME.markdown  \u274c\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#other-documentation-formats","title":"Other Documentation Formats","text":"<pre><code>architecture.puml    # PlantUML\nschema.json         # JSON Schema\nopenapi.yaml        # OpenAPI spec\ndiagram.drawio      # Draw.io diagram\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#versioned-documentation","title":"Versioned Documentation","text":""},{"location":"atomic/architecture/naming/naming-documentation/#version-in-filename","title":"Version in Filename","text":"<pre><code>migration-guide-v2.md\napi-reference-v1.md\nchangelog-2024.md\nrelease-notes-1.0.0.md\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#version-directories","title":"Version Directories","text":"<pre><code>docs/\n\u251c\u2500\u2500 v1/\n\u2502   \u2514\u2500\u2500 api-reference.md\n\u251c\u2500\u2500 v2/\n\u2502   \u2514\u2500\u2500 api-reference.md\n\u2514\u2500\u2500 latest/\n    \u2514\u2500\u2500 api-reference.md\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#language-specific-docs","title":"Language-Specific Docs","text":"<p>Use ISO 639-1 codes:</p> <pre><code>README.md           # Default (English)\nREADME.ru.md        # Russian\nREADME.zh-cn.md     # Simplified Chinese\nREADME.es.md        # Spanish\n</code></pre>"},{"location":"atomic/architecture/naming/naming-documentation/#checklist","title":"Checklist","text":"<ul> <li> Entry points use SCREAMING_SNAKE_CASE</li> <li> Content files use kebab-case</li> <li> File extensions are lowercase <code>.md</code></li> <li> No spaces in filenames</li> <li> Version numbers follow pattern</li> <li> Language codes use ISO 639-1</li> <li> README.md exists at each major directory</li> <li> Consistent naming within directories</li> </ul>"},{"location":"atomic/architecture/naming/naming-documentation/#common-patterns-reference","title":"Common Patterns Reference","text":"File Type Example Pattern Project entry <code>README.md</code> SCREAMING AI instructions <code>AGENTS.md</code> SCREAMING Legal <code>LICENSE</code> SCREAMING Guide <code>setup-guide.md</code> kebab-case Reference <code>api-reference.md</code> kebab-case Checklist <code>deployment-checklist.md</code> kebab-case Template <code>template-service.md</code> kebab-case Notes <code>release-notes-v1.md</code> kebab-case"},{"location":"atomic/architecture/naming/naming-documentation/#related-documents","title":"Related Documents","text":"<ul> <li><code>./README.md</code> \u2014 Main naming conventions hub</li> <li><code>../../../STYLE_GUIDE.md</code> \u2014 Documentation writing style</li> </ul>"},{"location":"atomic/architecture/naming/naming-infrastructure/","title":"Infrastructure Naming Conventions","text":"<p>This guide covers naming patterns for Docker Compose, Kubernetes, Nginx, and other infrastructure components in the doc4microservices framework. It implements a 3-layer separator strategy for smooth development-to-production transitions.</p> <p>Key Principle: Use underscores for development (Docker Compose), hyphens for production (Kubernetes/DNS). Automate conversion at deployment boundary.</p>"},{"location":"atomic/architecture/naming/naming-infrastructure/#3-layer-separator-strategy","title":"3-Layer Separator Strategy","text":"<p>Different infrastructure layers have different technical requirements for separators:</p> Layer Separator Reason Example Code &amp; Data Underscore <code>_</code> Python/SQL requirement <code>finance_lending_api</code> Container (Dev) Underscore <code>_</code> Docker Compose, internal <code>finance_lending_api</code> Container (Prod) Hyphen <code>-</code> Kubernetes DNS requirement <code>finance-lending-api</code> Network &amp; DNS Hyphen <code>-</code> RFC 1035 compliance <code>lending-api.finance.svc</code>"},{"location":"atomic/architecture/naming/naming-infrastructure/#layer-transitions","title":"Layer Transitions","text":"<pre><code>Development              Production\n-----------              ----------\nfinance_lending_api  \u2192   finance-lending-api\n(Docker Compose)         (Kubernetes)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#docker-compose","title":"Docker Compose","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#service-naming","title":"Service Naming","text":"<p>Docker Compose services use underscores matching the code layer:</p> <pre><code># docker-compose.yml\nservices:\n  finance_lending_api:\n    build: ./services/finance_lending_api\n    container_name: finance_lending_api\n    hostname: finance_lending_api\n    networks:\n      - finance_network\n\n  finance_payment_worker:\n    build: ./services/finance_payment_worker\n    container_name: finance_payment_worker\n    depends_on:\n      - finance_lending_api\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#network-naming","title":"Network Naming","text":"<pre><code>networks:\n  finance_network:\n    name: finance_network\n    driver: bridge\n\n  healthcare_network:\n    name: healthcare_network\n    driver: bridge\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#volume-naming","title":"Volume Naming","text":"<pre><code>volumes:\n  postgres_data:\n    name: postgres_data\n\n  redis_data:\n    name: redis_data\n\n  rabbitmq_data:\n    name: rabbitmq_data\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#complete-example","title":"Complete Example","text":"<pre><code>version: '3.8'\n\nservices:\n  # Business services\n  finance_lending_api:\n    build: ./services/finance_lending_api\n    container_name: finance_lending_api\n    environment:\n      DATABASE_URL: postgresql://user:pass@postgres_db:5432/lending\n      REDIS_URL: redis://redis_cache:6379\n    depends_on:\n      - postgres_db\n      - redis_cache\n    networks:\n      - finance_network\n\n  # Infrastructure services\n  postgres_db:\n    image: postgres:16\n    container_name: postgres_db\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    networks:\n      - finance_network\n\n  redis_cache:\n    image: redis:7-alpine\n    container_name: redis_cache\n    volumes:\n      - redis_data:/data\n    networks:\n      - finance_network\n\nnetworks:\n  finance_network:\n    name: finance_network\n\nvolumes:\n  postgres_data:\n  redis_data:\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#kubernetes","title":"Kubernetes","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#service-and-deployment-naming","title":"Service and Deployment Naming","text":"<p>Kubernetes resources use hyphens (DNS requirement):</p> <pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: finance-lending-api\n  namespace: finance\n  labels:\n    app: finance-lending-api\n    context: finance\n    domain: lending\n    type: api\nspec:\n  selector:\n    matchLabels:\n      app: finance-lending-api\n  template:\n    metadata:\n      labels:\n        app: finance-lending-api\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#service-definition","title":"Service Definition","text":"<pre><code># service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: finance-lending-api\n  namespace: finance\nspec:\n  selector:\n    app: finance-lending-api\n  ports:\n    - port: 80\n      targetPort: 8000\n      protocol: TCP\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#configmap-and-secret-naming","title":"ConfigMap and Secret Naming","text":"<pre><code># ConfigMap\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: finance-lending-config\n  namespace: finance\n\n# Secret\napiVersion: v1\nkind: Secret\nmetadata:\n  name: finance-lending-secret\n  namespace: finance\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#namespace-organization","title":"Namespace Organization","text":"<pre><code># namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: finance\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: healthcare\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: logistics\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#label-conventions","title":"Label Conventions","text":"<pre><code>metadata:\n  labels:\n    app: finance-lending-api           # Application name\n    version: v1.0.0                    # Version\n    context: finance                   # Business context\n    domain: lending                    # Business domain\n    type: api                         # Service type\n    environment: production           # Environment\n    managed-by: helm                  # Management tool\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#nginx-configuration","title":"Nginx Configuration","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#upstream-naming","title":"Upstream Naming","text":"<pre><code># nginx.conf\nupstream finance_lending_api {\n    server finance_lending_api:8000;\n}\n\nupstream healthcare_telemedicine_api {\n    server healthcare_telemedicine_api:8000;\n}\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#server-block-naming","title":"Server Block Naming","text":"<pre><code>server {\n    server_name lending-api.finance.example.com;\n\n    location / {\n        proxy_pass http://finance_lending_api;\n        proxy_set_header X-Service-Name \"finance-lending-api\";\n    }\n}\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#log-file-naming","title":"Log File Naming","text":"<pre><code>access_log /var/log/nginx/finance-lending-api-access.log;\nerror_log /var/log/nginx/finance-lending-api-error.log;\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#dns-naming","title":"DNS Naming","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#internal-service-discovery","title":"Internal Service Discovery","text":"<pre><code># Kubernetes internal DNS\nfinance-lending-api.finance.svc.cluster.local\nhealthcare-telemedicine-api.healthcare.svc.cluster.local\n\n# Docker Compose internal DNS\nfinance_lending_api\nhealthcare_telemedicine_api\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#external-domain-mapping","title":"External Domain Mapping","text":"<pre><code># Production domains\nlending-api.finance.example.com      \u2192 finance-lending-api\ntelemedicine-api.healthcare.example.com \u2192 healthcare-telemedicine-api\n\n# Staging domains\nlending-api.staging.finance.example.com\ntelemedicine-api.staging.healthcare.example.com\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#environment-variables","title":"Environment Variables","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#naming-pattern","title":"Naming Pattern","text":"<p>Environment variables use SCREAMING_SNAKE_CASE:</p> <pre><code># Database connections\nDATABASE_URL=postgresql://user:pass@localhost/db\nREDIS_URL=redis://localhost:6379\n\n# Service URLs (internal)\nLENDING_API_URL=http://finance_lending_api:8000\nPAYMENT_API_URL=http://finance_payment_api:8000\n\n# Service URLs (Kubernetes)\nLENDING_API_URL=http://finance-lending-api.finance.svc:80\nPAYMENT_API_URL=http://finance-payment-api.finance.svc:80\n\n# Configuration\nMAX_CONNECTIONS=100\nREQUEST_TIMEOUT=30\nENABLE_DEBUG=false\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#cicd-pipeline-naming","title":"CI/CD Pipeline Naming","text":""},{"location":"atomic/architecture/naming/naming-infrastructure/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/finance-lending-api.yml\nname: Finance Lending API CI/CD\n\njobs:\n  test-finance-lending-api:\n    name: Test Finance Lending API\n\n  build-finance-lending-api:\n    name: Build Finance Lending API\n\n  deploy-finance-lending-api:\n    name: Deploy Finance Lending API\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#docker-image-tags","title":"Docker Image Tags","text":"<pre><code># Pattern: {registry}/{namespace}/{service}:{tag}\nmyregistry.com/finance/lending-api:latest\nmyregistry.com/finance/lending-api:v1.0.0\nmyregistry.com/finance/lending-api:main-abc123\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#terraform-resource-naming","title":"Terraform Resource Naming","text":"<pre><code># Terraform resources use underscores\nresource \"aws_ecs_service\" \"finance_lending_api\" {\n  name = \"finance-lending-api\"  # AWS requires hyphens\n  # ...\n}\n\nresource \"aws_rds_instance\" \"postgres_lending\" {\n  identifier = \"finance-lending-postgres\"\n  # ...\n}\n</code></pre>"},{"location":"atomic/architecture/naming/naming-infrastructure/#checklist","title":"Checklist","text":"<ul> <li> Docker Compose uses underscores (matches code layer)</li> <li> Kubernetes uses hyphens (DNS compliance)</li> <li> Nginx upstreams use underscores (internal)</li> <li> DNS names use hyphens (RFC compliance)</li> <li> Environment variables use SCREAMING_SNAKE_CASE</li> <li> Labels follow Kubernetes conventions</li> <li> Image tags include namespace and version</li> <li> Terraform resources use appropriate separators</li> </ul>"},{"location":"atomic/architecture/naming/naming-infrastructure/#related-documents","title":"Related Documents","text":"<ul> <li><code>./README.md</code> \u2014 Main naming conventions hub</li> <li><code>naming-conversion.md</code> \u2014 Dev\u2192Prod conversion utilities</li> <li><code>naming-services.md</code> \u2014 Service naming patterns</li> </ul>"},{"location":"atomic/architecture/naming/naming-python/","title":"Python Naming Conventions","text":"<p>This guide covers Python naming patterns for classes, functions, variables, and file organization in the doc4microservices framework. It follows PEP 8 with specific adaptations for microservices architecture.</p> <p>Key Principle: Use snake_case for all Python elements except classes (PascalCase). File names match their primary class in snake_case.</p>"},{"location":"atomic/architecture/naming/naming-python/#classes","title":"Classes","text":""},{"location":"atomic/architecture/naming/naming-python/#naming-pattern","title":"Naming Pattern","text":"<p><code>{Noun}{Suffix}</code></p> <p>Classes use PascalCase with descriptive suffixes indicating their architectural role.</p>"},{"location":"atomic/architecture/naming/naming-python/#standard-suffixes","title":"Standard Suffixes","text":"Suffix Purpose Example <code>Service</code> Business logic layer <code>UserService</code>, <code>LendingService</code> <code>Repository</code> Data access layer <code>UserRepository</code>, <code>OrderRepository</code> <code>DTO</code> Data Transfer Object <code>UserDTO</code>, <code>LoanApplicationDTO</code> <code>Handler</code> Event/message handler <code>PaymentEventHandler</code>, <code>NotificationHandler</code> <code>Router</code> FastAPI route controller <code>UserRouter</code>, <code>HealthRouter</code> <code>Client</code> External service client <code>DataServiceClient</code>, <code>PaymentGatewayClient</code> <code>Manager</code> Resource/lifecycle manager <code>ConnectionManager</code>, <code>SessionManager</code> <code>Factory</code> Object creation <code>ServiceFactory</code>, <code>ClientFactory</code> <code>Validator</code> Input validation <code>UserValidator</code>, <code>LoanValidator</code> <code>Mapper</code> Data transformation <code>DTOMapper</code>, <code>EntityMapper</code>"},{"location":"atomic/architecture/naming/naming-python/#examples","title":"Examples","text":"<pre><code># Business logic\nclass LendingService:\n    \"\"\"Handles lending business logic.\"\"\"\n    pass\n\n# Data access\nclass UserRepository:\n    \"\"\"Manages user data persistence.\"\"\"\n    pass\n\n# Data transfer\nclass LoanApplicationDTO:\n    \"\"\"Loan application data structure.\"\"\"\n    user_id: str\n    amount: Decimal\n    term_months: int\n\n# External integration\nclass PaymentGatewayClient:\n    \"\"\"Client for payment processing service.\"\"\"\n    pass\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#functions","title":"Functions","text":""},{"location":"atomic/architecture/naming/naming-python/#naming-pattern_1","title":"Naming Pattern","text":"<p><code>{verb}_{noun}[_qualifier]</code></p> <p>Functions use snake_case starting with a verb, describing the action performed.</p>"},{"location":"atomic/architecture/naming/naming-python/#common-verbs","title":"Common Verbs","text":"Verb Usage Example <code>get</code> Retrieve single item <code>get_user_by_id()</code> <code>list</code> Retrieve multiple items <code>list_active_loans()</code> <code>create</code> Create new item <code>create_loan_application()</code> <code>update</code> Modify existing item <code>update_user_profile()</code> <code>delete</code> Remove item <code>delete_expired_sessions()</code> <code>validate</code> Check validity <code>validate_loan_eligibility()</code> <code>process</code> Handle/transform <code>process_payment()</code> <code>send</code> Dispatch message/request <code>send_notification()</code> <code>fetch</code> Get from external source <code>fetch_credit_score()</code> <code>calculate</code> Compute value <code>calculate_interest_rate()</code>"},{"location":"atomic/architecture/naming/naming-python/#examples_1","title":"Examples","text":"<pre><code>async def get_user_by_id(user_id: str) -&gt; UserDTO:\n    \"\"\"Retrieve user by ID.\"\"\"\n    pass\n\nasync def list_pending_applications(limit: int = 100) -&gt; List[ApplicationDTO]:\n    \"\"\"List pending loan applications.\"\"\"\n    pass\n\ndef validate_loan_amount(amount: Decimal, user_profile: UserDTO) -&gt; bool:\n    \"\"\"Validate loan amount against user profile.\"\"\"\n    pass\n\nasync def process_loan_approval(application_id: str) -&gt; ApprovalResult:\n    \"\"\"Process loan approval workflow.\"\"\"\n    pass\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#async-functions","title":"Async Functions","text":"<p>Prefix with <code>async</code> keyword, no special naming:</p> <pre><code>async def fetch_external_data() -&gt; dict:  # \u2705 Correct\n    pass\n\nasync def async_fetch_data() -&gt; dict:  # \u274c Don't prefix with async_\n    pass\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#variables-and-parameters","title":"Variables and Parameters","text":""},{"location":"atomic/architecture/naming/naming-python/#naming-pattern_2","title":"Naming Pattern","text":"<p><code>{noun}[_qualifier]</code></p> <p>Variables use snake_case, descriptive nouns without type prefixes.</p>"},{"location":"atomic/architecture/naming/naming-python/#common-patterns","title":"Common Patterns","text":"Pattern Example Usage Simple noun <code>user</code>, <code>loan</code>, <code>payment</code> Single entities Qualified noun <code>user_id</code>, <code>loan_amount</code> Specific attributes Boolean flag <code>is_active</code>, <code>has_permission</code> Boolean states Collection <code>users</code>, <code>pending_loans</code> Multiple items Configuration <code>max_retries</code>, <code>timeout_seconds</code> Config values"},{"location":"atomic/architecture/naming/naming-python/#examples_2","title":"Examples","text":"<pre><code># Good variable names\nuser_id: str = \"usr_123\"\nis_verified: bool = True\npending_applications: List[ApplicationDTO] = []\nmax_loan_amount: Decimal = Decimal(\"50000.00\")\n\n# Bad variable names (avoid)\nu = \"usr_123\"  # Too short\nuserIdentifier = \"usr_123\"  # camelCase\nstr_user_id = \"usr_123\"  # Type prefix\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#function-parameters","title":"Function Parameters","text":"<pre><code>async def create_loan(\n    user_id: str,\n    amount: Decimal,\n    term_months: int,\n    is_urgent: bool = False,\n    metadata: Optional[dict] = None\n) -&gt; LoanDTO:\n    \"\"\"Create new loan application.\"\"\"\n    pass\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#constants","title":"Constants","text":""},{"location":"atomic/architecture/naming/naming-python/#naming-pattern_3","title":"Naming Pattern","text":"<p><code>{NOUN}_{QUALIFIER}</code></p> <p>Constants use SCREAMING_SNAKE_CASE for module-level constants.</p> <pre><code># Configuration constants\nDATABASE_URL = \"postgresql://localhost/db\"\nREDIS_URL = \"redis://localhost:6379\"\nMAX_CONNECTIONS = 100\nDEFAULT_TIMEOUT = 30\n\n# Business constants\nMIN_LOAN_AMOUNT = Decimal(\"1000.00\")\nMAX_LOAN_TERM_MONTHS = 60\nINTEREST_RATE_ANNUAL = Decimal(\"0.12\")\n\n# Status codes\nSTATUS_PENDING = \"pending\"\nSTATUS_APPROVED = \"approved\"\nSTATUS_REJECTED = \"rejected\"\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#files-and-modules","title":"Files and Modules","text":""},{"location":"atomic/architecture/naming/naming-python/#file-naming","title":"File Naming","text":"<p>Files use snake_case matching their primary class:</p> Class File <code>UserService</code> <code>user_service.py</code> <code>LoanRepository</code> <code>loan_repository.py</code> <code>PaymentDTO</code> <code>payment_dto.py</code> <code>EventHandler</code> <code>event_handler.py</code>"},{"location":"atomic/architecture/naming/naming-python/#module-structure","title":"Module Structure","text":"<pre><code>finance_lending_api/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 config.py         # Configuration class\n\u2502   \u2502   \u2514\u2500\u2500 dependencies.py   # Dependency injection\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 lending_service.py    # LendingService class\n\u2502   \u2502   \u2514\u2500\u2500 user_service.py       # UserService class\n\u2502   \u251c\u2500\u2500 repositories/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 loan_repository.py    # LoanRepository class\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 user_dto.py          # UserDTO class\n\u2502   \u2502   \u2514\u2500\u2500 loan_dto.py          # LoanDTO class\n\u2502   \u2514\u2500\u2500 routers/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 lending_router.py    # LendingRouter class\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#private-elements","title":"Private Elements","text":"<p>Use single underscore prefix for internal elements:</p> <pre><code>class UserService:\n    def __init__(self):\n        self._cache = {}  # Private attribute\n\n    def _validate_user(self, user_id: str) -&gt; bool:\n        \"\"\"Private method for internal validation.\"\"\"\n        pass\n\n    def get_user(self, user_id: str) -&gt; UserDTO:\n        \"\"\"Public method.\"\"\"\n        if not self._validate_user(user_id):\n            raise ValueError(\"Invalid user\")\n        return self._fetch_from_cache(user_id)\n</code></pre>"},{"location":"atomic/architecture/naming/naming-python/#checklist","title":"Checklist","text":"<ul> <li> Classes use PascalCase with appropriate suffix</li> <li> Functions start with verb in snake_case</li> <li> Variables use descriptive snake_case</li> <li> Constants use SCREAMING_SNAKE_CASE</li> <li> Files match primary class in snake_case</li> <li> No type prefixes in variable names</li> <li> Boolean flags start with <code>is_</code> or <code>has_</code></li> <li> Private elements use <code>_</code> prefix</li> <li> Async functions not prefixed with <code>async_</code></li> </ul>"},{"location":"atomic/architecture/naming/naming-python/#related-documents","title":"Related Documents","text":"<ul> <li><code>./README.md</code> \u2014 Main naming conventions hub</li> <li><code>naming-services.md</code> \u2014 Service naming patterns</li> <li><code>naming-databases.md</code> \u2014 Database naming conventions</li> </ul>"},{"location":"atomic/architecture/naming/naming-services/","title":"Service Naming Patterns","text":"<p>This guide covers microservice naming patterns in the doc4microservices framework. It establishes the primary 3-part naming formula (<code>{context}_{domain}_{type}</code>) as the default, with 4-part naming reserved for ambiguous domains.</p> <p>Key Principle: DEFAULT TO 3-PART naming. Function is implied by the domain in most cases. Use 4-part only when the domain word can refer to 3+ different operations.</p>"},{"location":"atomic/architecture/naming/naming-services/#guiding-rules","title":"Guiding Rules","text":"<ol> <li>DEFAULT TO 3-PART naming (<code>{context}_{domain}_{type}</code>)</li> <li>Use 4-part ONLY when domain is ambiguous (burden of proof required)</li> <li>Semantic shortening: Clear context + domain, omit redundant function words</li> <li>Average length: 20-27 characters (no abbreviations needed)</li> <li>Context uniqueness: Never reuse context names for different business domains</li> </ol>"},{"location":"atomic/architecture/naming/naming-services/#service-naming-formula","title":"Service Naming Formula","text":""},{"location":"atomic/architecture/naming/naming-services/#primary-pattern-3-part","title":"Primary Pattern (3-part)","text":"<p><code>{context}_{domain}_{type}</code></p> <p>This hierarchical formula creates self-documenting service names where function is implied: - {context}: Business area (finance, healthcare, construction...) - {domain}: Subdomain within context (lending, telemedicine, house...) - {type}: Technical service type (api, worker, bot...)</p> <p>Philosophy: Function words are often redundant when context+domain already imply the action: - <code>lending</code> domain \u2192 matching/approval implied - <code>payment</code> domain \u2192 processing implied - <code>telemedicine</code> domain \u2192 consultation implied - <code>worker</code> type \u2192 background processing implied</p> <p>Examples (3-part): - <code>finance_lending_api</code> \u2014 Lending platform (19 chars, matching implied) - <code>healthcare_telemedicine_api</code> \u2014 Telemedicine service (27 chars, consultation implied) - <code>construction_house_bot</code> \u2014 House management bot (22 chars, management implied)</p>"},{"location":"atomic/architecture/naming/naming-services/#extended-pattern-4-part","title":"Extended Pattern (4-part)","text":"<p><code>{context}_{domain}_{function}_{type}</code></p> <p>Use when domain has multiple possible functions (ambiguous):</p> <p>Examples (4-part): - <code>logistics_fleet_tracking_api</code> \u2014 Fleet needs clarification (vs management, maintenance) - <code>analytics_reporting_api</code> \u2014 Analytics needs clarification (vs querying, processing) - <code>communication_notification_worker</code> \u2014 Communication needs clarification (vs email, SMS)</p>"},{"location":"atomic/architecture/naming/naming-services/#when-to-use-3-part-vs-4-part","title":"When to Use 3-Part vs 4-Part","text":"<p>TL;DR: Ask \"Can this domain word refer to 3+ different operations?\" If yes, use 4-part. If no, use 3-part.</p> <p>Common Patterns:</p> Domain Example Clear (3-part) Ambiguous (4-part) <code>lending</code> \u2705 <code>finance_lending_api</code> - <code>payment</code> \u2705 <code>finance_payment_worker</code> - <code>telemedicine</code> \u2705 <code>healthcare_telemedicine_api</code> - <code>fleet</code> - \u274c <code>logistics_fleet_tracking_api</code> (vs management, maintenance, scheduling) <code>analytics</code> - \u274c <code>analytics_reporting_api</code> (vs querying, processing, visualization) <code>communication</code> - \u274c <code>communication_notification_worker</code> (vs email, SMS, push) <p>Important: Don't confuse \"multiple code features\" with \"ambiguous domain\" - \u2705 <code>construction_house_bot</code> (3-part) \u2014 Multiple features (calc, upload, track) serving ONE domain (house projects) - \u274c DON'T use 4-part just because service has many features</p>"},{"location":"atomic/architecture/naming/naming-services/#domain-function-mapping-implied-functions","title":"Domain-Function Mapping (Implied Functions)","text":""},{"location":"atomic/architecture/naming/naming-services/#finance-context-mostly-3-part","title":"Finance Context (mostly 3-part)","text":"Domain Implied Function 3-Part Name Chars <code>lending</code> matching, approval <code>finance_lending_api</code> 19 <code>payment</code> processing <code>finance_payment_api</code> 19 <code>crypto</code> portfolio management <code>finance_crypto_api</code> 18 <code>billing</code> invoicing, cycles <code>finance_billing_api</code> 19 <code>trading</code> algorithmic trading <code>finance_trading_api</code> 19"},{"location":"atomic/architecture/naming/naming-services/#healthcare-context-mostly-3-part","title":"Healthcare Context (mostly 3-part)","text":"Domain Implied Function 3-Part Name Chars <code>telemedicine</code> consultation <code>healthcare_telemedicine_api</code> 27 <code>appointment</code> booking <code>healthcare_appointment_api</code> 26 <code>pharmacy</code> medication management <code>healthcare_pharmacy_api</code> 23 <code>mental_health</code> therapy, counseling <code>healthcare_mental_health_api</code> 28"},{"location":"atomic/architecture/naming/naming-services/#construction-context-mostly-3-part","title":"Construction Context (mostly 3-part)","text":"Domain Implied Function 3-Part Name Chars <code>house</code> project management <code>construction_house_bot</code> 22 <code>material</code> calculation, inventory <code>construction_material_api</code> 25 <code>renovation</code> planning <code>construction_renovation_api</code> 27 <code>commercial</code> project management <code>construction_commercial_api</code> 27"},{"location":"atomic/architecture/naming/naming-services/#logistics-context-needs-4-part-often","title":"Logistics Context (needs 4-part often)","text":"Domain Multiple Functions 4-Part Name (explicit) Chars <code>fleet</code> tracking OR management OR maintenance <code>logistics_fleet_tracking_api</code> 28 <code>delivery</code> routing OR tracking <code>logistics_delivery_tracking_api</code> 31 <code>warehouse</code> inventory OR fulfillment <code>logistics_warehouse_inventory_api</code> 34"},{"location":"atomic/architecture/naming/naming-services/#analytics-context-needs-4-part-often","title":"Analytics Context (needs 4-part often)","text":"Domain Multiple Functions 4-Part Name (explicit) Chars <code>reporting</code> generation (not querying) <code>analytics_reporting_api</code> 23 <code>data</code> aggregation OR transformation <code>analytics_data_aggregation_worker</code> 34 <code>dashboard</code> visualization (clear) <code>analytics_dashboard_api</code> 23"},{"location":"atomic/architecture/naming/naming-services/#extended-context-catalog","title":"Extended Context Catalog","text":"Context (Full) Business Domain Example Services (3-part) <code>finance</code> Financial services <code>finance_lending_api</code>, <code>finance_crypto_api</code> <code>healthcare</code> Medical &amp; health <code>healthcare_telemedicine_api</code>, <code>healthcare_appointment_api</code> <code>construction</code> Building &amp; construction <code>construction_house_bot</code>, <code>construction_material_api</code> <code>education</code> Learning &amp; training <code>education_lms_api</code>, <code>education_courses_api</code> <code>logistics</code> Transport &amp; delivery <code>logistics_fleet_tracking_api</code>, <code>logistics_delivery_tracking_api</code> <code>ecommerce</code> Online commerce <code>ecommerce_marketplace_api</code>, <code>ecommerce_dropship_api</code> <code>corporate</code> Enterprise tools <code>corporate_crm_api</code>, <code>corporate_hr_api</code> <code>property_management</code> Real estate <code>property_house_api</code>, <code>property_tenant_api</code> <code>communication</code> Messaging &amp; notifications <code>communication_notification_worker</code>, <code>communication_telegram_bot</code> <code>analytics</code> Data &amp; reporting <code>analytics_reporting_api</code>, <code>analytics_dashboard_api</code> <code>user_management</code> Auth &amp; profiles <code>user_auth_api</code>, <code>user_profile_api</code> <code>integration</code> Third-party APIs <code>integration_stripe_api</code>, <code>integration_google_api</code> <code>environment</code> Ecology &amp; monitoring <code>environment_emission_api</code>, <code>environment_recycling_api</code> <p>Naming Strategy: - \u2705 Use 3-part formula by default (context + domain + type) - \u2705 Add explicit function (4-part) only when domain is ambiguous - \u2705 Average name length: 20-27 characters (no abbreviations needed)</p>"},{"location":"atomic/architecture/naming/naming-services/#domain-examples-per-context","title":"Domain Examples per Context","text":""},{"location":"atomic/architecture/naming/naming-services/#finance-context","title":"Finance Context","text":"<ul> <li><code>lending</code> - P2P loans, microloans</li> <li><code>crypto</code> - Cryptocurrency portfolio, trading</li> <li><code>payments</code> - Payment processing</li> <li><code>billing</code> - Subscription billing</li> <li><code>trading</code> - Algorithmic trading</li> </ul>"},{"location":"atomic/architecture/naming/naming-services/#healthcare-context","title":"Healthcare Context","text":"<ul> <li><code>telemedicine</code> - Online consultations</li> <li><code>appointment</code> - Doctor booking</li> <li><code>mental_health</code> - Psychological support</li> <li><code>pharmacy</code> - Medication management</li> </ul>"},{"location":"atomic/architecture/naming/naming-services/#construction-context","title":"Construction Context","text":"<ul> <li><code>house</code> - Residential building</li> <li><code>commercial</code> - Commercial projects</li> <li><code>renovation</code> - Remodeling projects</li> <li><code>material</code> - Materials management</li> </ul>"},{"location":"atomic/architecture/naming/naming-services/#education-context","title":"Education Context","text":"<ul> <li><code>lms</code> - Learning management</li> <li><code>courses</code> - Online courses</li> <li><code>webinar</code> - Webinar platform</li> <li><code>assessment</code> - Testing &amp; grading</li> </ul>"},{"location":"atomic/architecture/naming/naming-services/#function-naming-patterns-4-part-only","title":"Function Naming Patterns (4-Part Only)","text":"<p>Use explicit function words only when domain is ambiguous. Most services use 3-part (function implied).</p> Function Use When (Domain Ambiguous) 4-Part Example <code>tracking</code> Fleet/delivery could be tracking OR routing OR management <code>logistics_fleet_tracking_api</code>, <code>logistics_delivery_tracking_api</code> <code>notification</code> Communication could be notification OR email OR SMS <code>communication_notification_worker</code> <code>reporting</code> Analytics could be reporting OR querying OR processing <code>analytics_reporting_api</code> <code>aggregation</code> Data could be aggregation OR transformation OR storage <code>analytics_data_aggregation_worker</code> <code>inventory</code> Warehouse could be inventory OR fulfillment OR shipping <code>logistics_warehouse_inventory_api</code> <p>Note: For clear domains, use 3-part: - <code>finance_lending_api</code> (matching implied) - <code>healthcare_telemedicine_api</code> (consultation implied) - <code>construction_house_bot</code> (management implied) - <code>finance_payment_worker</code> (processing implied)</p>"},{"location":"atomic/architecture/naming/naming-services/#service-type-catalog","title":"Service Type Catalog","text":"Type Description Technology Example (3-part) <code>api</code> REST API service FastAPI, Flask <code>finance_lending_api</code> <code>worker</code> Background job processor Celery, RQ <code>finance_payment_worker</code> <code>bot</code> Chat bot interface Aiogram, Telegram Bot API <code>construction_house_bot</code> <code>gateway</code> API Gateway / proxy Kong, Nginx <code>ecommerce_gateway</code> <code>stream</code> Stream processor Kafka Streams, Flink <code>logistics_tracking_stream</code> <code>scheduler</code> Task scheduler APScheduler, Celery Beat <code>analytics_scheduler</code> <code>cli</code> Command-line tool Click, Typer <code>database_migration_cli</code> <code>webhook</code> Webhook receiver FastAPI <code>integration_stripe_webhook</code>"},{"location":"atomic/architecture/naming/naming-services/#related-documents","title":"Related Documents","text":"<ul> <li><code>naming-4part-reasons.md</code> \u2014 10 serious reasons for 4-part naming</li> <li><code>../context-registry.md</code> \u2014 Context name registry (prevent conflicts)</li> <li><code>../../../guides/semantic-shortening-guide.md</code> \u2014 Complete shortening guide</li> <li><code>../../../checklists/service-naming-checklist.md</code> \u2014 Quick naming decision checklist</li> </ul>"},{"location":"atomic/databases/postgresql/basic-setup/","title":"PostgreSQL Basic Setup","text":"<p>Foundational guide for PostgreSQL installation, configuration, and initial setup in microservices architecture.</p>"},{"location":"atomic/databases/postgresql/basic-setup/#prerequisites","title":"Prerequisites","text":"<pre><code># Required versions\nPostgreSQL: 15.x or 16.x\nPython: 3.12+\nDocker: 24.0+\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#docker-based-postgresql-setup","title":"Docker-based PostgreSQL Setup","text":""},{"location":"atomic/databases/postgresql/basic-setup/#development-configuration","title":"Development Configuration","text":"<pre><code># docker-compose.yml (PostgreSQL service)\nversion: '3.8'\n\nservices:\n  postgres:\n    image: postgres:16-alpine\n    container_name: ${PROJECT_NAME:-myapp}-postgres\n    restart: unless-stopped\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB:-microservices_db}\n      POSTGRES_USER: ${POSTGRES_USER:-postgres}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF8 --locale=en_US.UTF-8\"\n      PGDATA: /var/lib/postgresql/data/pgdata\n    ports:\n      - \"${POSTGRES_PORT:-5432}:5432\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./scripts/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-microservices_db}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 10s\n    networks:\n      - backend\n\nvolumes:\n  postgres_data:\n    driver: local\n\nnetworks:\n  backend:\n    driver: bridge\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#production-configuration","title":"Production Configuration","text":"<pre><code># docker-compose.prod.yml (PostgreSQL optimizations)\nservices:\n  postgres:\n    image: postgres:16-alpine\n    restart: always\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB}\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      # Performance tuning\n      POSTGRES_SHARED_BUFFERS: 256MB\n      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB\n      POSTGRES_MAINTENANCE_WORK_MEM: 64MB\n      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9\n      POSTGRES_WAL_BUFFERS: 16MB\n      POSTGRES_DEFAULT_STATISTICS_TARGET: 100\n      POSTGRES_RANDOM_PAGE_COST: 1.1\n      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200\n      POSTGRES_WORK_MEM: 4MB\n      POSTGRES_MIN_WAL_SIZE: 1GB\n      POSTGRES_MAX_WAL_SIZE: 4GB\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./config/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#database-initialization-script","title":"Database Initialization Script","text":"<pre><code>#!/bin/bash\n# scripts/init-db.sh\n\nset -e\n\npsql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"$POSTGRES_DB\" &lt;&lt;-EOSQL\n    -- Enable required extensions\n    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n    CREATE EXTENSION IF NOT EXISTS \"pg_trgm\";\n    CREATE EXTENSION IF NOT EXISTS \"btree_gin\";\n    CREATE EXTENSION IF NOT EXISTS \"btree_gist\";\n\n    -- Create application user (if different from POSTGRES_USER)\n    DO \\$\\$\n    BEGIN\n        IF NOT EXISTS (SELECT FROM pg_catalog.pg_user WHERE usename = 'app_user') THEN\n            CREATE USER app_user WITH PASSWORD '${APP_USER_PASSWORD:-changeme}';\n        END IF;\n    END\n    \\$\\$;\n\n    -- Grant privileges\n    GRANT CONNECT ON DATABASE ${POSTGRES_DB} TO app_user;\n    GRANT USAGE ON SCHEMA public TO app_user;\n    GRANT CREATE ON SCHEMA public TO app_user;\n\n    -- Set default privileges for future tables\n    ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO app_user;\n    ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO app_user;\n\n    -- Create schemas for microservices\n    CREATE SCHEMA IF NOT EXISTS users AUTHORIZATION app_user;\n    CREATE SCHEMA IF NOT EXISTS orders AUTHORIZATION app_user;\n    CREATE SCHEMA IF NOT EXISTS products AUTHORIZATION app_user;\n\n    GRANT ALL ON SCHEMA users TO app_user;\n    GRANT ALL ON SCHEMA orders TO app_user;\n    GRANT ALL ON SCHEMA products TO app_user;\nEOSQL\n\necho \"PostgreSQL initialization completed successfully\"\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#environment-configuration","title":"Environment Configuration","text":"<pre><code># .env (PostgreSQL configuration)\n\n# PostgreSQL connection\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_DB=microservices_db\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=changeme_in_production\n\n# Application user\nAPP_USER_PASSWORD=changeme_in_production\n\n# Connection pool settings\nPOSTGRES_POOL_SIZE=20\nPOSTGRES_MAX_OVERFLOW=10\nPOSTGRES_POOL_TIMEOUT=30\nPOSTGRES_POOL_RECYCLE=3600\n\n# Database URL (for SQLAlchemy)\nDATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#python-dependencies","title":"Python Dependencies","text":"<pre><code># requirements.txt (PostgreSQL dependencies)\n\n# Async PostgreSQL driver\nasyncpg==0.29.0\n\n# SQLAlchemy ORM\nsqlalchemy[asyncio]==2.0.23\nalembic==1.13.1\n\n# Connection pooling\nsqlalchemy-utils==0.41.1\n\n# Type stubs\ntypes-asyncpg==0.27.0\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#basic-connection-configuration","title":"Basic Connection Configuration","text":"<pre><code># src/core/database.py\n\nfrom typing import AsyncGenerator\nimport asyncpg\nfrom sqlalchemy.ext.asyncio import (\n    AsyncEngine,\n    AsyncSession,\n    create_async_engine,\n    async_sessionmaker,\n)\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.pool import NullPool, AsyncAdaptedQueuePool\nimport os\n\nclass Base(DeclarativeBase):\n    \"\"\"Base class for SQLAlchemy models\"\"\"\n    pass\n\n\nclass DatabaseConfig:\n    \"\"\"PostgreSQL configuration\"\"\"\n\n    def __init__(self):\n        self.host = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n        self.port = int(os.getenv(\"POSTGRES_PORT\", \"5432\"))\n        self.database = os.getenv(\"POSTGRES_DB\", \"microservices_db\")\n        self.user = os.getenv(\"POSTGRES_USER\", \"postgres\")\n        self.password = os.getenv(\"POSTGRES_PASSWORD\", \"\")\n\n        # Pool settings\n        self.pool_size = int(os.getenv(\"POSTGRES_POOL_SIZE\", \"20\"))\n        self.max_overflow = int(os.getenv(\"POSTGRES_MAX_OVERFLOW\", \"10\"))\n        self.pool_timeout = int(os.getenv(\"POSTGRES_POOL_TIMEOUT\", \"30\"))\n        self.pool_recycle = int(os.getenv(\"POSTGRES_POOL_RECYCLE\", \"3600\"))\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"Build database URL\"\"\"\n        return f\"postgresql+asyncpg://{self.user}:{self.password}@{self.host}:{self.port}/{self.database}\"\n\n\n# Global engine and session factory\n_engine: AsyncEngine | None = None\n_session_factory: async_sessionmaker[AsyncSession] | None = None\n\n\ndef create_engine(config: DatabaseConfig) -&gt; AsyncEngine:\n    \"\"\"Create async SQLAlchemy engine\"\"\"\n    return create_async_engine(\n        config.url,\n        echo=False,\n        poolclass=AsyncAdaptedQueuePool,\n        pool_size=config.pool_size,\n        max_overflow=config.max_overflow,\n        pool_timeout=config.pool_timeout,\n        pool_recycle=config.pool_recycle,\n        pool_pre_ping=True,\n    )\n\n\ndef init_database(config: DatabaseConfig) -&gt; None:\n    \"\"\"Initialize database engine and session factory\"\"\"\n    global _engine, _session_factory\n\n    _engine = create_engine(config)\n    _session_factory = async_sessionmaker(\n        _engine,\n        class_=AsyncSession,\n        expire_on_commit=False,\n        autocommit=False,\n        autoflush=False,\n    )\n\n\nasync def get_session() -&gt; AsyncGenerator[AsyncSession, None]:\n    \"\"\"Dependency for FastAPI to get database session\"\"\"\n    if _session_factory is None:\n        raise RuntimeError(\"Database not initialized. Call init_database() first.\")\n\n    async with _session_factory() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n\nasync def close_database() -&gt; None:\n    \"\"\"Close database connections\"\"\"\n    global _engine\n    if _engine:\n        await _engine.dispose()\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#health-check-endpoint","title":"Health Check Endpoint","text":"<pre><code># src/api/health.py\n\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import text\n\nfrom src.core.database import get_session\n\nrouter = APIRouter(tags=[\"health\"])\n\n\n@router.get(\"/health/db\")\nasync def database_health(\n    session: AsyncSession = Depends(get_session)\n) -&gt; dict[str, str]:\n    \"\"\"Check PostgreSQL database health\"\"\"\n    try:\n        result = await session.execute(text(\"SELECT 1\"))\n        result.scalar_one()\n\n        # Check current connections\n        conn_result = await session.execute(text(\"\"\"\n            SELECT count(*)\n            FROM pg_stat_activity\n            WHERE datname = current_database()\n        \"\"\"))\n        active_connections = conn_result.scalar_one()\n\n        return {\n            \"status\": \"healthy\",\n            \"database\": \"postgresql\",\n            \"active_connections\": str(active_connections),\n        }\n    except Exception as e:\n        raise HTTPException(\n            status_code=503,\n            detail=f\"Database unhealthy: {str(e)}\"\n        )\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#application-lifecycle-integration","title":"Application Lifecycle Integration","text":"<pre><code># src/main.py\n\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\n\nfrom src.core.database import init_database, close_database, DatabaseConfig\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan manager\"\"\"\n    # Startup\n    config = DatabaseConfig()\n    init_database(config)\n    print(\"\u2713 PostgreSQL connection initialized\")\n\n    yield\n\n    # Shutdown\n    await close_database()\n    print(\"\u2713 PostgreSQL connection closed\")\n\n\napp = FastAPI(lifespan=lifespan)\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#verification-commands","title":"Verification Commands","text":"<pre><code># Check PostgreSQL is running\ndocker-compose ps postgres\n\n# View PostgreSQL logs\ndocker-compose logs -f postgres\n\n# Connect to PostgreSQL CLI\ndocker-compose exec postgres psql -U postgres -d microservices_db\n\n# Check database size\ndocker-compose exec postgres psql -U postgres -d microservices_db -c \"\\l+\"\n\n# Check active connections\ndocker-compose exec postgres psql -U postgres -d microservices_db -c \"SELECT * FROM pg_stat_activity;\"\n\n# Run migrations (Alembic)\nalembic upgrade head\n\n# Test database connection from Python\npython -c \"import asyncio; from src.core.database import *; config = DatabaseConfig(); asyncio.run(test_connection())\"\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#security-best-practices","title":"Security Best Practices","text":"<ol> <li> <p>Never commit credentials <pre><code># .gitignore\n.env\n.env.local\n.env.production\n</code></pre></p> </li> <li> <p>Use secrets management in production <pre><code># Use AWS Secrets Manager, HashiCorp Vault, etc.\nimport boto3\n\ndef get_db_password():\n    client = boto3.client('secretsmanager')\n    secret = client.get_secret_value(SecretId='prod/postgres/password')\n    return secret['SecretString']\n</code></pre></p> </li> <li> <p>Restrict network access <pre><code># docker-compose.yml - Remove exposed ports in production\nservices:\n  postgres:\n    # ports:  # &lt;-- Comment out for production\n    #   - \"5432:5432\"\n    networks:\n      - backend  # Internal network only\n</code></pre></p> </li> <li> <p>Enable SSL/TLS <pre><code># For production connections\nDATABASE_URL = f\"postgresql+asyncpg://{user}:{password}@{host}:{port}/{db}?ssl=require\"\n</code></pre></p> </li> </ol>"},{"location":"atomic/databases/postgresql/basic-setup/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"atomic/databases/postgresql/basic-setup/#issue-connection-refused","title":"Issue: Connection Refused","text":"<pre><code># Check if PostgreSQL is running\ndocker-compose ps postgres\n\n# Check logs\ndocker-compose logs postgres\n\n# Restart service\ndocker-compose restart postgres\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#issue-too-many-connections","title":"Issue: Too Many Connections","text":"<pre><code>-- Check current connections\nSELECT count(*) FROM pg_stat_activity;\n\n-- Increase max_connections (postgresql.conf)\nmax_connections = 200\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#issue-slow-queries","title":"Issue: Slow Queries","text":"<pre><code>-- Enable query logging\nALTER SYSTEM SET log_min_duration_statement = 1000;  -- Log queries &gt; 1s\nSELECT pg_reload_conf();\n\n-- Check slow queries\nSELECT query, calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\nLIMIT 10;\n</code></pre>"},{"location":"atomic/databases/postgresql/basic-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>SQLAlchemy Integration - ORM patterns and best practices</li> <li>Complex Relationship Modeling - Advanced entity relationships</li> <li>Performance Optimization - Query optimization and indexing</li> <li>Production Migrations - Safe migration strategies</li> <li>Database Service Setup - HTTP data service wrapper</li> </ul>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/","title":"SQLAlchemy Integration","text":"<p>Comprehensive guide for SQLAlchemy 2.0+ async patterns, model definitions, repository pattern, and best practices for microservices.</p>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#sqlalchemy-20-setup","title":"SQLAlchemy 2.0 Setup","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#core-dependencies","title":"Core Dependencies","text":"<pre><code># requirements.txt\n\nsqlalchemy[asyncio]==2.0.23\nasyncpg==0.29.0\nalembic==1.13.1\npydantic==2.5.0\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#base-model-configuration","title":"Base Model Configuration","text":"<pre><code># src/domain/base.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom sqlalchemy import MetaData, DateTime, func\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\n\n# Naming conventions for constraints\nconvention = {\n    \"ix\": \"ix_%(column_0_label)s\",\n    \"uq\": \"uq_%(table_name)s_%(column_0_name)s\",\n    \"ck\": \"ck_%(table_name)s_%(constraint_name)s\",\n    \"fk\": \"fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s\",\n    \"pk\": \"pk_%(table_name)s\"\n}\n\nmetadata = MetaData(naming_convention=convention)\n\n\nclass Base(DeclarativeBase):\n    \"\"\"Base class for all SQLAlchemy models\"\"\"\n\n    metadata = metadata\n\n    # Type annotation for better IDE support\n    __tablename__: str\n    __table_args__: dict[str, Any] = {}\n\n\nclass TimestampMixin:\n    \"\"\"Mixin for created_at and updated_at timestamps\"\"\"\n\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True),\n        server_default=func.now(),\n        nullable=False,\n        index=True,\n    )\n\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True),\n        server_default=func.now(),\n        onupdate=func.now(),\n        nullable=False,\n    )\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#domain-models","title":"Domain Models","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#simple-entity-example","title":"Simple Entity Example","text":"<pre><code># src/domain/user.py\n\nfrom typing import Optional\nfrom uuid import UUID, uuid4\nfrom sqlalchemy import String, Boolean\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom src.domain.base import Base, TimestampMixin\n\n\nclass User(Base, TimestampMixin):\n    \"\"\"User entity\"\"\"\n\n    __tablename__ = \"users\"\n    __table_args__ = {\"schema\": \"public\"}\n\n    # Primary key\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True,\n        default=uuid4,\n        index=True,\n    )\n\n    # Required fields\n    email: Mapped[str] = mapped_column(\n        String(255),\n        unique=True,\n        nullable=False,\n        index=True,\n    )\n\n    username: Mapped[str] = mapped_column(\n        String(50),\n        unique=True,\n        nullable=False,\n        index=True,\n    )\n\n    hashed_password: Mapped[str] = mapped_column(\n        String(255),\n        nullable=False,\n    )\n\n    # Optional fields\n    full_name: Mapped[Optional[str]] = mapped_column(\n        String(255),\n        nullable=True,\n    )\n\n    # Boolean flags\n    is_active: Mapped[bool] = mapped_column(\n        Boolean,\n        default=True,\n        nullable=False,\n        index=True,\n    )\n\n    is_superuser: Mapped[bool] = mapped_column(\n        Boolean,\n        default=False,\n        nullable=False,\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;User(id={self.id}, email={self.email})&gt;\"\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#entity-with-relationships","title":"Entity with Relationships","text":"<pre><code># src/domain/order.py\n\nfrom typing import Optional, List\nfrom uuid import UUID, uuid4\nfrom decimal import Decimal\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom sqlalchemy import (\n    String, Numeric, ForeignKey, Enum as SQLEnum\n)\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom src.domain.base import Base, TimestampMixin\n\n\nclass OrderStatus(str, Enum):\n    \"\"\"Order status enum\"\"\"\n    PENDING = \"pending\"\n    CONFIRMED = \"confirmed\"\n    PROCESSING = \"processing\"\n    SHIPPED = \"shipped\"\n    DELIVERED = \"delivered\"\n    CANCELLED = \"cancelled\"\n\n\nclass Order(Base, TimestampMixin):\n    \"\"\"Order entity\"\"\"\n\n    __tablename__ = \"orders\"\n    __table_args__ = {\"schema\": \"public\"}\n\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True,\n        default=uuid4,\n    )\n\n    # Foreign keys\n    user_id: Mapped[UUID] = mapped_column(\n        ForeignKey(\"public.users.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n\n    # Order details\n    order_number: Mapped[str] = mapped_column(\n        String(50),\n        unique=True,\n        nullable=False,\n        index=True,\n    )\n\n    status: Mapped[OrderStatus] = mapped_column(\n        SQLEnum(OrderStatus, name=\"order_status\"),\n        default=OrderStatus.PENDING,\n        nullable=False,\n        index=True,\n    )\n\n    total_amount: Mapped[Decimal] = mapped_column(\n        Numeric(10, 2),\n        nullable=False,\n    )\n\n    # Relationships\n    items: Mapped[List[\"OrderItem\"]] = relationship(\n        \"OrderItem\",\n        back_populates=\"order\",\n        cascade=\"all, delete-orphan\",\n        lazy=\"selectin\",\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Order(id={self.id}, number={self.order_number}, status={self.status})&gt;\"\n\n\nclass OrderItem(Base, TimestampMixin):\n    \"\"\"Order item entity\"\"\"\n\n    __tablename__ = \"order_items\"\n    __table_args__ = {\"schema\": \"public\"}\n\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True,\n        default=uuid4,\n    )\n\n    # Foreign keys\n    order_id: Mapped[UUID] = mapped_column(\n        ForeignKey(\"public.orders.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n\n    product_id: Mapped[UUID] = mapped_column(\n        nullable=False,\n        index=True,\n    )\n\n    # Item details\n    quantity: Mapped[int] = mapped_column(\n        nullable=False,\n    )\n\n    unit_price: Mapped[Decimal] = mapped_column(\n        Numeric(10, 2),\n        nullable=False,\n    )\n\n    subtotal: Mapped[Decimal] = mapped_column(\n        Numeric(10, 2),\n        nullable=False,\n    )\n\n    # Relationships\n    order: Mapped[\"Order\"] = relationship(\n        \"Order\",\n        back_populates=\"items\",\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;OrderItem(id={self.id}, product_id={self.product_id}, quantity={self.quantity})&gt;\"\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#repository-pattern","title":"Repository Pattern","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#base-repository","title":"Base Repository","text":"<pre><code># src/infrastructure/repositories/base.py\n\nfrom typing import Generic, TypeVar, Type, Optional, List, Any\nfrom uuid import UUID\n\nfrom sqlalchemy import select, func, delete, update\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.domain.base import Base\n\nModelType = TypeVar(\"ModelType\", bound=Base)\n\n\nclass BaseRepository(Generic[ModelType]):\n    \"\"\"Base repository with common CRUD operations\"\"\"\n\n    def __init__(self, model: Type[ModelType], session: AsyncSession):\n        self.model = model\n        self.session = session\n\n    async def get_by_id(self, id: UUID) -&gt; Optional[ModelType]:\n        \"\"\"Get entity by ID\"\"\"\n        result = await self.session.execute(\n            select(self.model).where(self.model.id == id)\n        )\n        return result.scalar_one_or_none()\n\n    async def get_all(\n        self,\n        skip: int = 0,\n        limit: int = 100,\n    ) -&gt; List[ModelType]:\n        \"\"\"Get all entities with pagination\"\"\"\n        result = await self.session.execute(\n            select(self.model)\n            .offset(skip)\n            .limit(limit)\n        )\n        return list(result.scalars().all())\n\n    async def count(self) -&gt; int:\n        \"\"\"Count total entities\"\"\"\n        result = await self.session.execute(\n            select(func.count()).select_from(self.model)\n        )\n        return result.scalar_one()\n\n    async def create(self, entity: ModelType) -&gt; ModelType:\n        \"\"\"Create new entity\"\"\"\n        self.session.add(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def update(self, entity: ModelType) -&gt; ModelType:\n        \"\"\"Update existing entity\"\"\"\n        await self.session.merge(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def delete(self, id: UUID) -&gt; bool:\n        \"\"\"Delete entity by ID\"\"\"\n        result = await self.session.execute(\n            delete(self.model).where(self.model.id == id)\n        )\n        return result.rowcount &gt; 0\n\n    async def exists(self, id: UUID) -&gt; bool:\n        \"\"\"Check if entity exists\"\"\"\n        result = await self.session.execute(\n            select(func.count())\n            .select_from(self.model)\n            .where(self.model.id == id)\n        )\n        return result.scalar_one() &gt; 0\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#specific-repository-example","title":"Specific Repository Example","text":"<pre><code># src/infrastructure/repositories/user_repository.py\n\nfrom typing import Optional\nfrom uuid import UUID\n\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.domain.user import User\nfrom src.infrastructure.repositories.base import BaseRepository\n\n\nclass UserRepository(BaseRepository[User]):\n    \"\"\"User repository with specific queries\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        super().__init__(User, session)\n\n    async def get_by_email(self, email: str) -&gt; Optional[User]:\n        \"\"\"Get user by email\"\"\"\n        result = await self.session.execute(\n            select(User).where(User.email == email)\n        )\n        return result.scalar_one_or_none()\n\n    async def get_by_username(self, username: str) -&gt; Optional[User]:\n        \"\"\"Get user by username\"\"\"\n        result = await self.session.execute(\n            select(User).where(User.username == username)\n        )\n        return result.scalar_one_or_none()\n\n    async def get_active_users(\n        self,\n        skip: int = 0,\n        limit: int = 100,\n    ) -&gt; list[User]:\n        \"\"\"Get all active users\"\"\"\n        result = await self.session.execute(\n            select(User)\n            .where(User.is_active == True)\n            .offset(skip)\n            .limit(limit)\n        )\n        return list(result.scalars().all())\n\n    async def email_exists(self, email: str) -&gt; bool:\n        \"\"\"Check if email already exists\"\"\"\n        result = await self.session.execute(\n            select(User.id).where(User.email == email)\n        )\n        return result.scalar_one_or_none() is not None\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#use-case-integration","title":"Use Case Integration","text":"<pre><code># src/application/use_cases/create_user.py\n\nfrom uuid import UUID\nfrom dataclasses import dataclass\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.domain.user import User\nfrom src.infrastructure.repositories.user_repository import UserRepository\n\n\n@dataclass\nclass CreateUserCommand:\n    \"\"\"Command to create new user\"\"\"\n    email: str\n    username: str\n    password: str\n    full_name: str | None = None\n\n\nclass CreateUserUseCase:\n    \"\"\"Use case for creating new user\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        self.repository = UserRepository(session)\n\n    async def execute(self, command: CreateUserCommand) -&gt; User:\n        \"\"\"Execute use case\"\"\"\n        # Check if email exists\n        if await self.repository.email_exists(command.email):\n            raise ValueError(f\"Email {command.email} already registered\")\n\n        # Check if username exists\n        if await self.repository.get_by_username(command.username):\n            raise ValueError(f\"Username {command.username} already taken\")\n\n        # Hash password (use proper hashing library)\n        from passlib.context import CryptContext\n        pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n        hashed_password = pwd_context.hash(command.password)\n\n        # Create user entity\n        user = User(\n            email=command.email,\n            username=command.username,\n            hashed_password=hashed_password,\n            full_name=command.full_name,\n        )\n\n        # Persist to database\n        user = await self.repository.create(user)\n\n        return user\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#transaction-management","title":"Transaction Management","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#manual-transaction-control","title":"Manual Transaction Control","text":"<pre><code># src/application/use_cases/transfer_funds.py\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.exc import SQLAlchemyError\n\n\nasync def transfer_funds(\n    session: AsyncSession,\n    from_account_id: UUID,\n    to_account_id: UUID,\n    amount: Decimal,\n) -&gt; bool:\n    \"\"\"Transfer funds between accounts with explicit transaction control\"\"\"\n\n    try:\n        # Start transaction (implicit with session)\n\n        # Debit from source account\n        await session.execute(\n            update(Account)\n            .where(Account.id == from_account_id)\n            .values(balance=Account.balance - amount)\n        )\n\n        # Credit to destination account\n        await session.execute(\n            update(Account)\n            .where(Account.id == to_account_id)\n            .values(balance=Account.balance + amount)\n        )\n\n        # Commit transaction\n        await session.commit()\n        return True\n\n    except SQLAlchemyError as e:\n        # Rollback on error\n        await session.rollback()\n        raise RuntimeError(f\"Transfer failed: {str(e)}\")\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#savepoint-pattern","title":"Savepoint Pattern","text":"<pre><code>async def complex_operation(session: AsyncSession):\n    \"\"\"Use savepoints for nested transactions\"\"\"\n\n    # Main transaction\n    user = await create_user(session, email=\"test@example.com\")\n\n    # Nested savepoint\n    async with session.begin_nested():\n        try:\n            await send_welcome_email(user.email)\n        except EmailError:\n            # Rollback only the email part\n            await session.rollback()\n            # Continue with user creation\n\n    await session.commit()\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#query-optimization-patterns","title":"Query Optimization Patterns","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#eager-loading","title":"Eager Loading","text":"<pre><code># src/infrastructure/repositories/order_repository.py\n\nfrom sqlalchemy.orm import selectinload, joinedload\n\nclass OrderRepository(BaseRepository[Order]):\n\n    async def get_with_items(self, order_id: UUID) -&gt; Optional[Order]:\n        \"\"\"Get order with all items eagerly loaded\"\"\"\n        result = await self.session.execute(\n            select(Order)\n            .options(selectinload(Order.items))\n            .where(Order.id == order_id)\n        )\n        return result.scalar_one_or_none()\n\n    async def get_user_orders(self, user_id: UUID) -&gt; list[Order]:\n        \"\"\"Get all user orders with items\"\"\"\n        result = await self.session.execute(\n            select(Order)\n            .options(selectinload(Order.items))\n            .where(Order.user_id == user_id)\n            .order_by(Order.created_at.desc())\n        )\n        return list(result.scalars().all())\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#pagination-with-total-count","title":"Pagination with Total Count","text":"<pre><code>async def get_paginated_users(\n    session: AsyncSession,\n    page: int = 1,\n    page_size: int = 20,\n) -&gt; tuple[list[User], int]:\n    \"\"\"Get paginated users with total count\"\"\"\n\n    # Count query\n    count_result = await session.execute(\n        select(func.count()).select_from(User)\n    )\n    total = count_result.scalar_one()\n\n    # Data query\n    offset = (page - 1) * page_size\n    result = await session.execute(\n        select(User)\n        .offset(offset)\n        .limit(page_size)\n        .order_by(User.created_at.desc())\n    )\n    users = list(result.scalars().all())\n\n    return users, total\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#alembic-migrations","title":"Alembic Migrations","text":""},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#configuration","title":"Configuration","text":"<pre><code># alembic/env.py\n\nimport asyncio\nfrom logging.config import fileConfig\n\nfrom sqlalchemy import pool\nfrom sqlalchemy.engine import Connection\nfrom sqlalchemy.ext.asyncio import async_engine_from_config\n\nfrom alembic import context\n\n# Import all models\nfrom src.domain.base import Base\nfrom src.domain.user import User\nfrom src.domain.order import Order, OrderItem\n\n# Alembic Config object\nconfig = context.config\n\n# Interpret the config file for Python logging\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# Target metadata\ntarget_metadata = Base.metadata\n\n\ndef run_migrations_offline() -&gt; None:\n    \"\"\"Run migrations in 'offline' mode\"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection: Connection) -&gt; None:\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\nasync def run_async_migrations() -&gt; None:\n    \"\"\"Run migrations in 'online' mode\"\"\"\n    configuration = config.get_section(config.config_ini_section)\n    configuration[\"sqlalchemy.url\"] = config.get_main_option(\"sqlalchemy.url\")\n\n    connectable = async_engine_from_config(\n        configuration,\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\ndef run_migrations_online() -&gt; None:\n    \"\"\"Run migrations in 'online' mode\"\"\"\n    asyncio.run(run_async_migrations())\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#creating-migrations","title":"Creating Migrations","text":"<pre><code># Generate migration from model changes\nalembic revision --autogenerate -m \"Add user and order tables\"\n\n# Apply migrations\nalembic upgrade head\n\n# Rollback one migration\nalembic downgrade -1\n\n# View current version\nalembic current\n\n# View migration history\nalembic history\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#testing-with-sqlalchemy","title":"Testing with SQLAlchemy","text":"<pre><code># tests/conftest.py\n\nimport pytest\nimport pytest_asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker\n\nfrom src.domain.base import Base\n\n\n@pytest_asyncio.fixture\nasync def db_engine():\n    \"\"\"Create test database engine\"\"\"\n    engine = create_async_engine(\n        \"postgresql+asyncpg://postgres:test@localhost:5432/test_db\",\n        echo=False,\n    )\n\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield engine\n\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.drop_all)\n\n    await engine.dispose()\n\n\n@pytest_asyncio.fixture\nasync def db_session(db_engine):\n    \"\"\"Create test database session\"\"\"\n    session_factory = async_sessionmaker(\n        db_engine,\n        class_=AsyncSession,\n        expire_on_commit=False,\n    )\n\n    async with session_factory() as session:\n        yield session\n        await session.rollback()\n</code></pre>"},{"location":"atomic/databases/postgresql/sqlalchemy-integration/#related-documentation","title":"Related Documentation","text":"<ul> <li>PostgreSQL Basic Setup - Initial PostgreSQL configuration</li> <li>Complex Relationship Modeling - Advanced relationships</li> <li>Performance Optimization - Query optimization</li> <li>Production Migrations - Safe migration strategies</li> <li>Repository Patterns - Data access patterns</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/","title":"Complex Relationship Modeling in PostgreSQL","text":"<p>Advanced patterns for modeling complex relationships, inheritance, polymorphism, and domain-driven design with PostgreSQL.</p>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL Basic Setup</li> <li>SQLAlchemy Integration</li> <li>Understanding of database normalization principles</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#polymorphic-associations","title":"Polymorphic Associations","text":""},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#single-table-inheritance-sti","title":"Single Table Inheritance (STI)","text":"<pre><code>from sqlalchemy import Column, Integer, String, ForeignKey, Float, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship, backref\n\nBase = declarative_base()\n\nclass Content(Base):\n    __tablename__ = 'contents'\n\n    id = Column(Integer, primary_key=True)\n    type = Column(String(50), nullable=False)  # Discriminator column\n    title = Column(String(255), nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    author_id = Column(Integer, ForeignKey('users.id'))\n\n    # Polymorphic configuration\n    __mapper_args__ = {\n        'polymorphic_identity': 'content',\n        'polymorphic_on': type\n    }\n\nclass Article(Content):\n    __tablename__ = 'contents'  # Same table\n\n    content = Column(Text)\n    word_count = Column(Integer)\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'article'\n    }\n\nclass Video(Content):\n    __tablename__ = 'contents'  # Same table\n\n    duration = Column(Integer)  # in seconds\n    video_url = Column(String(500))\n    thumbnail_url = Column(String(500))\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'video'\n    }\n\nclass Product(Content):\n    __tablename__ = 'contents'  # Same table\n\n    price = Column(Float)\n    sku = Column(String(100))\n    inventory_count = Column(Integer, default=0)\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'product'\n    }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#class-table-inheritance-cti","title":"Class Table Inheritance (CTI)","text":"<pre><code>class BaseContent(Base):\n    __tablename__ = 'base_contents'\n\n    id = Column(Integer, primary_key=True)\n    type = Column(String(50), nullable=False)\n    title = Column(String(255), nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    author_id = Column(Integer, ForeignKey('users.id'))\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'base_content',\n        'polymorphic_on': type\n    }\n\nclass Article(BaseContent):\n    __tablename__ = 'articles'\n\n    id = Column(Integer, ForeignKey('base_contents.id'), primary_key=True)\n    content = Column(Text, nullable=False)\n    word_count = Column(Integer)\n    reading_time = Column(Integer)  # in minutes\n    tags = relationship(\"Tag\", secondary=\"article_tags\", back_populates=\"articles\")\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'article'\n    }\n\nclass Video(BaseContent):\n    __tablename__ = 'videos'\n\n    id = Column(Integer, ForeignKey('base_contents.id'), primary_key=True)\n    duration = Column(Integer)\n    video_url = Column(String(500))\n    thumbnail_url = Column(String(500))\n    resolution = Column(String(20))  # 1080p, 720p, etc.\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'video'\n    }\n\nclass Product(BaseContent):\n    __tablename__ = 'products'\n\n    id = Column(Integer, ForeignKey('base_contents.id'), primary_key=True)\n    price = Column(Numeric(10, 2))\n    sku = Column(String(100), unique=True)\n    inventory_count = Column(Integer, default=0)\n    category_id = Column(Integer, ForeignKey('categories.id'))\n    variants = relationship(\"ProductVariant\", back_populates=\"product\")\n\n    __mapper_args__ = {\n        'polymorphic_identity': 'product'\n    }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#advanced-relationship-patterns","title":"Advanced Relationship Patterns","text":""},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#self-referencing-hierarchies","title":"Self-Referencing Hierarchies","text":"<pre><code>class Category(Base):\n    __tablename__ = 'categories'\n\n    id = Column(Integer, primary_key=True)\n    name = Column(String(100), nullable=False)\n    slug = Column(String(100), unique=True)\n    parent_id = Column(Integer, ForeignKey('categories.id'))\n    level = Column(Integer, default=0)\n    path = Column(String(500))  # Materialized path: /electronics/computers/laptops/\n    left_boundary = Column(Integer)  # For nested set model\n    right_boundary = Column(Integer)\n\n    # Self-referencing relationship\n    parent = relationship(\"Category\", remote_side=[id], backref=\"children\")\n    products = relationship(\"Product\", back_populates=\"category\")\n\n    def get_ancestors(self) -&gt; List['Category']:\n        \"\"\"Get all parent categories\"\"\"\n        ancestors = []\n        current = self.parent\n        while current:\n            ancestors.append(current)\n            current = current.parent\n        return ancestors[::-1]  # Root first\n\n    def get_descendants(self, session) -&gt; List['Category']:\n        \"\"\"Get all child categories using nested set model\"\"\"\n        if self.left_boundary and self.right_boundary:\n            return session.query(Category).filter(\n                Category.left_boundary &gt; self.left_boundary,\n                Category.right_boundary &lt; self.right_boundary\n            ).all()\n        return []\n\nclass CategoryClosure(Base):\n    \"\"\"Closure table for efficient hierarchy queries\"\"\"\n    __tablename__ = 'category_closures'\n\n    ancestor_id = Column(Integer, ForeignKey('categories.id'), primary_key=True)\n    descendant_id = Column(Integer, ForeignKey('categories.id'), primary_key=True)\n    depth = Column(Integer, nullable=False)\n\n    ancestor = relationship(\"Category\", foreign_keys=[ancestor_id])\n    descendant = relationship(\"Category\", foreign_keys=[descendant_id])\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#many-to-many-with-attributes","title":"Many-to-Many with Attributes","text":"<pre><code>class UserRole(Base):\n    \"\"\"Association object with additional attributes\"\"\"\n    __tablename__ = 'user_roles'\n\n    user_id = Column(Integer, ForeignKey('users.id'), primary_key=True)\n    role_id = Column(Integer, ForeignKey('roles.id'), primary_key=True)\n    granted_at = Column(DateTime, default=datetime.utcnow)\n    granted_by_id = Column(Integer, ForeignKey('users.id'))\n    expires_at = Column(DateTime)\n    scope = Column(String(100))  # 'global', 'project:123', etc.\n\n    user = relationship(\"User\", foreign_keys=[user_id], back_populates=\"user_roles\")\n    role = relationship(\"Role\", back_populates=\"user_roles\")\n    granted_by = relationship(\"User\", foreign_keys=[granted_by_id])\n\nclass User(Base):\n    __tablename__ = 'users'\n\n    id = Column(Integer, primary_key=True)\n    username = Column(String(50), unique=True)\n    email = Column(String(100), unique=True)\n\n    user_roles = relationship(\"UserRole\", foreign_keys=[UserRole.user_id], back_populates=\"user\")\n\n    def has_role(self, role_name: str, scope: str = 'global') -&gt; bool:\n        \"\"\"Check if user has specific role in scope\"\"\"\n        return any(\n            ur.role.name == role_name and ur.scope == scope\n            for ur in self.user_roles\n            if ur.expires_at is None or ur.expires_at &gt; datetime.utcnow()\n        )\n\nclass Role(Base):\n    __tablename__ = 'roles'\n\n    id = Column(Integer, primary_key=True)\n    name = Column(String(50), unique=True)\n    description = Column(Text)\n    permissions = relationship(\"Permission\", secondary=\"role_permissions\")\n    user_roles = relationship(\"UserRole\", back_populates=\"role\")\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#generic-foreign-keys-polymorphic-associations","title":"Generic Foreign Keys (Polymorphic Associations)","text":"<pre><code>class Comment(Base):\n    \"\"\"Comments that can be attached to any entity\"\"\"\n    __tablename__ = 'comments'\n\n    id = Column(Integer, primary_key=True)\n    content = Column(Text, nullable=False)\n    author_id = Column(Integer, ForeignKey('users.id'))\n\n    # Generic foreign key\n    commentable_type = Column(String(50), nullable=False)  # 'article', 'product', etc.\n    commentable_id = Column(Integer, nullable=False)\n\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n    author = relationship(\"User\")\n\n    @property\n    def commentable(self):\n        \"\"\"Get the commented object\"\"\"\n        if self.commentable_type == 'article':\n            return session.query(Article).get(self.commentable_id)\n        elif self.commentable_type == 'product':\n            return session.query(Product).get(self.commentable_id)\n        # Add more types as needed\n        return None\n\n# Mixin for commentable entities\nclass CommentableMixin:\n    @property\n    def comments(self):\n        return session.query(Comment).filter(\n            Comment.commentable_type == self.__class__.__name__.lower(),\n            Comment.commentable_id == self.id\n        ).all()\n\n    def add_comment(self, content: str, author_id: int) -&gt; Comment:\n        comment = Comment(\n            content=content,\n            author_id=author_id,\n            commentable_type=self.__class__.__name__.lower(),\n            commentable_id=self.id\n        )\n        session.add(comment)\n        return comment\n\nclass Article(Content, CommentableMixin):\n    # ... existing fields ...\n    pass\n\nclass Product(Content, CommentableMixin):\n    # ... existing fields ...\n    pass\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#advanced-querying-patterns","title":"Advanced Querying Patterns","text":""},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#dynamic-relationships-with-hybrid-properties","title":"Dynamic Relationships with Hybrid Properties","text":"<pre><code>from sqlalchemy.ext.hybrid import hybrid_property\nfrom sqlalchemy import select, func, case\n\nclass Order(Base):\n    __tablename__ = 'orders'\n\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey('users.id'))\n    status = Column(String(20), default='pending')\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    items = relationship(\"OrderItem\", back_populates=\"order\")\n\n    @hybrid_property\n    def total_amount(self):\n        \"\"\"Calculate total order amount\"\"\"\n        return sum(item.quantity * item.unit_price for item in self.items)\n\n    @total_amount.expression\n    def total_amount(cls):\n        \"\"\"SQL expression for total amount\"\"\"\n        return (\n            select([func.sum(OrderItem.quantity * OrderItem.unit_price)])\n            .where(OrderItem.order_id == cls.id)\n            .label('total_amount')\n        )\n\n    @hybrid_property\n    def item_count(self):\n        return len(self.items)\n\n    @item_count.expression\n    def item_count(cls):\n        return (\n            select([func.count(OrderItem.id)])\n            .where(OrderItem.order_id == cls.id)\n            .label('item_count')\n        )\n\nclass OrderItem(Base):\n    __tablename__ = 'order_items'\n\n    id = Column(Integer, primary_key=True)\n    order_id = Column(Integer, ForeignKey('orders.id'))\n    product_id = Column(Integer, ForeignKey('products.id'))\n    quantity = Column(Integer, nullable=False)\n    unit_price = Column(Numeric(10, 2), nullable=False)\n\n    order = relationship(\"Order\", back_populates=\"items\")\n    product = relationship(\"Product\")\n\n# Usage examples\ndef get_high_value_orders(session, min_amount: float):\n    \"\"\"Get orders above certain amount using hybrid property\"\"\"\n    return session.query(Order).filter(Order.total_amount &gt;= min_amount).all()\n\ndef get_order_statistics(session):\n    \"\"\"Get aggregated order statistics\"\"\"\n    return session.query(\n        func.count(Order.id).label('total_orders'),\n        func.avg(Order.total_amount).label('avg_order_value'),\n        func.sum(Order.total_amount).label('total_revenue'),\n        func.max(Order.total_amount).label('largest_order')\n    ).first()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#complex-join-patterns","title":"Complex Join Patterns","text":"<pre><code>class OrderAnalytics:\n    \"\"\"Complex analytical queries for orders\"\"\"\n\n    @staticmethod\n    def get_customer_lifetime_value(session, user_id: int):\n        \"\"\"Calculate customer lifetime value with detailed breakdown\"\"\"\n        return session.query(\n            User.id,\n            User.username,\n            func.count(Order.id).label('total_orders'),\n            func.sum(Order.total_amount).label('lifetime_value'),\n            func.avg(Order.total_amount).label('avg_order_value'),\n            func.min(Order.created_at).label('first_order_date'),\n            func.max(Order.created_at).label('last_order_date'),\n            func.extract('days', func.max(Order.created_at) - func.min(Order.created_at)).label('customer_lifespan_days')\n        ).join(Order).filter(User.id == user_id).group_by(User.id, User.username).first()\n\n    @staticmethod\n    def get_product_performance(session, start_date: datetime, end_date: datetime):\n        \"\"\"Analyze product performance with category breakdown\"\"\"\n        return session.query(\n            Product.id,\n            Product.title,\n            Category.name.label('category_name'),\n            func.sum(OrderItem.quantity).label('total_sold'),\n            func.sum(OrderItem.quantity * OrderItem.unit_price).label('total_revenue'),\n            func.count(func.distinct(OrderItem.order_id)).label('unique_orders'),\n            func.avg(OrderItem.unit_price).label('avg_selling_price')\n        ).join(OrderItem).join(Order).join(Category).filter(\n            Order.created_at.between(start_date, end_date),\n            Order.status == 'completed'\n        ).group_by(Product.id, Product.title, Category.name).order_by(\n            func.sum(OrderItem.quantity * OrderItem.unit_price).desc()\n        ).all()\n\n    @staticmethod\n    def get_cohort_analysis(session):\n        \"\"\"Customer cohort analysis by month\"\"\"\n        # First order month for each user\n        first_order_subquery = session.query(\n            Order.user_id,\n            func.date_trunc('month', func.min(Order.created_at)).label('cohort_month')\n        ).group_by(Order.user_id).subquery()\n\n        # Cohort analysis\n        return session.query(\n            first_order_subquery.c.cohort_month,\n            func.extract('month', Order.created_at - first_order_subquery.c.cohort_month).label('period_number'),\n            func.count(func.distinct(Order.user_id)).label('customers'),\n            func.sum(Order.total_amount).label('revenue')\n        ).join(\n            first_order_subquery, Order.user_id == first_order_subquery.c.user_id\n        ).group_by(\n            first_order_subquery.c.cohort_month,\n            func.extract('month', Order.created_at - first_order_subquery.c.cohort_month)\n        ).order_by(\n            first_order_subquery.c.cohort_month,\n            func.extract('month', Order.created_at - first_order_subquery.c.cohort_month)\n        ).all()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#event-sourcing-pattern","title":"Event Sourcing Pattern","text":"<pre><code>class EventStore(Base):\n    \"\"\"Event store for domain events\"\"\"\n    __tablename__ = 'event_store'\n\n    id = Column(Integer, primary_key=True)\n    aggregate_id = Column(String(100), nullable=False, index=True)\n    aggregate_type = Column(String(50), nullable=False)\n    event_type = Column(String(100), nullable=False)\n    event_data = Column(JSON, nullable=False)\n    event_version = Column(Integer, nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    correlation_id = Column(String(100))\n    causation_id = Column(String(100))\n\n    __table_args__ = (\n        Index('ix_aggregate_id_version', 'aggregate_id', 'event_version'),\n        UniqueConstraint('aggregate_id', 'event_version', name='uq_aggregate_version')\n    )\n\nclass OrderAggregate:\n    \"\"\"Order aggregate for event sourcing\"\"\"\n\n    def __init__(self, order_id: str):\n        self.id = order_id\n        self.version = 0\n        self.status = 'pending'\n        self.items = []\n        self.total_amount = 0\n        self.events = []\n\n    @classmethod\n    def from_events(cls, order_id: str, events: List[EventStore]) -&gt; 'OrderAggregate':\n        \"\"\"Reconstruct aggregate from events\"\"\"\n        order = cls(order_id)\n        for event in sorted(events, key=lambda e: e.event_version):\n            order.apply_event(event.event_type, event.event_data)\n            order.version = event.event_version\n        return order\n\n    def add_item(self, product_id: int, quantity: int, unit_price: float):\n        \"\"\"Add item to order\"\"\"\n        event_data = {\n            'product_id': product_id,\n            'quantity': quantity,\n            'unit_price': unit_price\n        }\n        self.add_event('ItemAdded', event_data)\n\n    def remove_item(self, product_id: int):\n        \"\"\"Remove item from order\"\"\"\n        event_data = {'product_id': product_id}\n        self.add_event('ItemRemoved', event_data)\n\n    def confirm_order(self):\n        \"\"\"Confirm the order\"\"\"\n        if self.status != 'pending':\n            raise ValueError(\"Order can only be confirmed from pending status\")\n        self.add_event('OrderConfirmed', {})\n\n    def add_event(self, event_type: str, event_data: dict):\n        \"\"\"Add new event to aggregate\"\"\"\n        self.version += 1\n        event = {\n            'aggregate_id': self.id,\n            'aggregate_type': 'Order',\n            'event_type': event_type,\n            'event_data': event_data,\n            'event_version': self.version\n        }\n        self.events.append(event)\n        self.apply_event(event_type, event_data)\n\n    def apply_event(self, event_type: str, event_data: dict):\n        \"\"\"Apply event to update aggregate state\"\"\"\n        if event_type == 'ItemAdded':\n            self.items.append({\n                'product_id': event_data['product_id'],\n                'quantity': event_data['quantity'],\n                'unit_price': event_data['unit_price']\n            })\n            self.total_amount += event_data['quantity'] * event_data['unit_price']\n\n        elif event_type == 'ItemRemoved':\n            self.items = [\n                item for item in self.items\n                if item['product_id'] != event_data['product_id']\n            ]\n            self.recalculate_total()\n\n        elif event_type == 'OrderConfirmed':\n            self.status = 'confirmed'\n\n    def recalculate_total(self):\n        \"\"\"Recalculate total amount\"\"\"\n        self.total_amount = sum(\n            item['quantity'] * item['unit_price']\n            for item in self.items\n        )\n\nclass EventRepository:\n    \"\"\"Repository for managing events\"\"\"\n\n    def __init__(self, session):\n        self.session = session\n\n    def save_events(self, events: List[dict]) -&gt; None:\n        \"\"\"Save events to event store\"\"\"\n        for event_data in events:\n            event = EventStore(**event_data)\n            self.session.add(event)\n        self.session.commit()\n\n    def get_events(self, aggregate_id: str, from_version: int = 0) -&gt; List[EventStore]:\n        \"\"\"Get events for aggregate\"\"\"\n        return self.session.query(EventStore).filter(\n            EventStore.aggregate_id == aggregate_id,\n            EventStore.event_version &gt; from_version\n        ).order_by(EventStore.event_version).all()\n\n    def get_aggregate(self, aggregate_id: str) -&gt; OrderAggregate:\n        \"\"\"Reconstruct aggregate from events\"\"\"\n        events = self.get_events(aggregate_id)\n        return OrderAggregate.from_events(aggregate_id, events)\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#jsonb-and-advanced-data-types","title":"JSONB and Advanced Data Types","text":"<pre><code>from sqlalchemy.dialects.postgresql import JSONB, ARRAY, UUID\nfrom sqlalchemy import text\n\nclass ProductCatalog(Base):\n    \"\"\"Product with flexible attributes using JSONB\"\"\"\n    __tablename__ = 'product_catalog'\n\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    name = Column(String(200), nullable=False)\n    category = Column(String(100))\n\n    # Flexible attributes stored as JSONB\n    attributes = Column(JSONB)\n    specifications = Column(JSONB)\n    pricing = Column(JSONB)\n\n    # Array fields\n    tags = Column(ARRAY(String))\n    image_urls = Column(ARRAY(String))\n\n    # Full-text search\n    search_vector = Column(String)  # Will be populated by trigger\n\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n    def set_attribute(self, key: str, value: Any):\n        \"\"\"Set flexible attribute\"\"\"\n        if self.attributes is None:\n            self.attributes = {}\n        self.attributes[key] = value\n\n    def get_attribute(self, key: str, default=None):\n        \"\"\"Get flexible attribute\"\"\"\n        if self.attributes is None:\n            return default\n        return self.attributes.get(key, default)\n\nclass ProductQuery:\n    \"\"\"Advanced querying for JSONB data\"\"\"\n\n    @staticmethod\n    def find_by_attribute(session, key: str, value: Any):\n        \"\"\"Find products by JSONB attribute\"\"\"\n        return session.query(ProductCatalog).filter(\n            ProductCatalog.attributes[key].astext == str(value)\n        ).all()\n\n    @staticmethod\n    def find_by_price_range(session, min_price: float, max_price: float):\n        \"\"\"Find products by price range in JSONB\"\"\"\n        return session.query(ProductCatalog).filter(\n            ProductCatalog.pricing['base_price'].astext.cast(Float) &gt;= min_price,\n            ProductCatalog.pricing['base_price'].astext.cast(Float) &lt;= max_price\n        ).all()\n\n    @staticmethod\n    def find_by_tags(session, tags: List[str]):\n        \"\"\"Find products containing any of the specified tags\"\"\"\n        return session.query(ProductCatalog).filter(\n            ProductCatalog.tags.overlap(tags)\n        ).all()\n\n    @staticmethod\n    def search_specifications(session, spec_criteria: dict):\n        \"\"\"Search by complex specification criteria\"\"\"\n        filters = []\n        for key, value in spec_criteria.items():\n            filters.append(\n                ProductCatalog.specifications[key].astext == str(value)\n            )\n\n        return session.query(ProductCatalog).filter(*filters).all()\n\n    @staticmethod\n    def full_text_search(session, search_term: str):\n        \"\"\"Full-text search across product data\"\"\"\n        return session.query(ProductCatalog).filter(\n            text(\"search_vector @@ plainto_tsquery(:search)\")\n        ).params(search=search_term).all()\n\n# SQL for setting up full-text search trigger\nFULLTEXT_SEARCH_SETUP = \"\"\"\n-- Add tsvector column for full-text search\nALTER TABLE product_catalog ADD COLUMN search_vector tsvector;\n\n-- Create index for fast text search\nCREATE INDEX idx_product_search ON product_catalog USING gin(search_vector);\n\n-- Function to update search vector\nCREATE OR REPLACE FUNCTION update_product_search_vector()\nRETURNS trigger AS $$\nBEGIN\n    NEW.search_vector :=\n        setweight(to_tsvector('english', coalesce(NEW.name, '')), 'A') ||\n        setweight(to_tsvector('english', coalesce(NEW.category, '')), 'B') ||\n        setweight(to_tsvector('english', coalesce(NEW.attributes::text, '')), 'C') ||\n        setweight(to_tsvector('english', coalesce(NEW.specifications::text, '')), 'D');\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Trigger to automatically update search vector\nCREATE TRIGGER update_product_search_trigger\n    BEFORE INSERT OR UPDATE ON product_catalog\n    FOR EACH ROW EXECUTE FUNCTION update_product_search_vector();\n\"\"\"\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#related-documentation","title":"Related Documentation","text":"<ul> <li>PostgreSQL Performance Optimization</li> <li>Production Migrations</li> <li>Multi-tenant Patterns</li> <li>SQLAlchemy Integration</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/complex-relationship-modeling/#best-practices","title":"Best Practices","text":"<ol> <li>Relationship Design:</li> <li>Choose inheritance pattern based on query patterns</li> <li>Use closure tables for deep hierarchies</li> <li> <p>Consider performance implications of joins</p> </li> <li> <p>JSONB Usage:</p> </li> <li>Index frequently queried JSON paths</li> <li>Use appropriate data types for better performance</li> <li> <p>Implement proper validation for flexible schemas</p> </li> <li> <p>Event Sourcing:</p> </li> <li>Keep events immutable and append-only</li> <li>Use correlation IDs for tracking related events</li> <li> <p>Implement snapshots for large aggregates</p> </li> <li> <p>Query Optimization:</p> </li> <li>Use hybrid properties for computed fields</li> <li>Implement proper indexing strategies</li> <li> <p>Consider materialized views for complex analytics</p> </li> <li> <p>Data Integrity:</p> </li> <li>Use database constraints where possible</li> <li>Implement domain validation in application layer</li> <li>Use transactions for multi-table operations</li> </ol>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/","title":"Multi-tenant Patterns in PostgreSQL","text":"<p>Comprehensive guide for implementing multi-tenancy patterns including database-per-tenant, schema-per-tenant, and row-level security approaches.</p>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#prerequisites","title":"Prerequisites","text":"<ul> <li>Complex Relationship Modeling</li> <li>Performance Optimization</li> <li>Production Migrations</li> <li>Understanding of PostgreSQL security and permissions</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#multi-tenancy-strategy-overview","title":"Multi-tenancy Strategy Overview","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#tenancy-models-comparison","title":"Tenancy Models Comparison","text":"<pre><code>from enum import Enum\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass\n\nclass TenancyModel(Enum):\n    DATABASE_PER_TENANT = \"database_per_tenant\"\n    SCHEMA_PER_TENANT = \"schema_per_tenant\"\n    ROW_LEVEL_SECURITY = \"row_level_security\"\n    HYBRID = \"hybrid\"\n\n@dataclass\nclass TenancyRequirements:\n    tenant_count: int\n    data_isolation_level: str  # \"strict\", \"moderate\", \"basic\"\n    customization_needs: str   # \"high\", \"medium\", \"low\"\n    scaling_requirements: str  # \"horizontal\", \"vertical\", \"both\"\n    compliance_requirements: List[str]  # [\"GDPR\", \"HIPAA\", \"SOX\", etc.]\n    budget_constraints: str    # \"cost_optimized\", \"balanced\", \"performance_first\"\n\nclass TenancyModelSelector:\n    \"\"\"Helper to select appropriate tenancy model\"\"\"\n\n    @staticmethod\n    def recommend_model(requirements: TenancyRequirements) -&gt; TenancyModel:\n        \"\"\"Recommend tenancy model based on requirements\"\"\"\n\n        # High isolation requirements -&gt; Database per tenant\n        if (requirements.data_isolation_level == \"strict\" or\n            \"HIPAA\" in requirements.compliance_requirements or\n            requirements.customization_needs == \"high\"):\n            return TenancyModel.DATABASE_PER_TENANT\n\n        # Medium isolation with cost constraints -&gt; Schema per tenant\n        elif (requirements.data_isolation_level == \"moderate\" and\n              requirements.tenant_count &lt; 1000):\n            return TenancyModel.SCHEMA_PER_TENANT\n\n        # Large scale with basic isolation -&gt; Row-level security\n        elif (requirements.tenant_count &gt; 1000 or\n              requirements.budget_constraints == \"cost_optimized\"):\n            return TenancyModel.ROW_LEVEL_SECURITY\n\n        # Mixed requirements -&gt; Hybrid approach\n        else:\n            return TenancyModel.HYBRID\n\n    @staticmethod\n    def get_model_characteristics(model: TenancyModel) -&gt; Dict[str, str]:\n        \"\"\"Get characteristics of tenancy model\"\"\"\n        characteristics = {\n            TenancyModel.DATABASE_PER_TENANT: {\n                \"isolation\": \"Maximum\",\n                \"scalability\": \"Good\",\n                \"cost\": \"High\",\n                \"complexity\": \"Medium\",\n                \"customization\": \"High\"\n            },\n            TenancyModel.SCHEMA_PER_TENANT: {\n                \"isolation\": \"Good\",\n                \"scalability\": \"Medium\",\n                \"cost\": \"Medium\",\n                \"complexity\": \"Medium\",\n                \"customization\": \"Medium\"\n            },\n            TenancyModel.ROW_LEVEL_SECURITY: {\n                \"isolation\": \"Basic\",\n                \"scalability\": \"Excellent\",\n                \"cost\": \"Low\",\n                \"complexity\": \"High\",\n                \"customization\": \"Low\"\n            },\n            TenancyModel.HYBRID: {\n                \"isolation\": \"Variable\",\n                \"scalability\": \"Good\",\n                \"cost\": \"Medium\",\n                \"complexity\": \"High\",\n                \"customization\": \"High\"\n            }\n        }\n        return characteristics.get(model, {})\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#database-per-tenant-pattern","title":"Database-per-Tenant Pattern","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#database-management-service","title":"Database Management Service","text":"<pre><code>import asyncio\nimport asyncpg\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\n\nclass DatabasePerTenantManager:\n    \"\"\"Manage separate databases for each tenant\"\"\"\n\n    def __init__(self, master_db_url: str, db_template: str = \"template_app\"):\n        self.master_db_url = master_db_url\n        self.db_template = db_template\n        self.tenant_databases = {}\n        self.connection_pools = {}\n\n    async def create_tenant_database(self, tenant_id: str, tenant_config: Dict[str, Any] = None) -&gt; str:\n        \"\"\"Create new database for tenant\"\"\"\n        db_name = f\"tenant_{tenant_id}\"\n\n        # Connect to master database\n        master_conn = await asyncpg.connect(self.master_db_url)\n\n        try:\n            # Create database from template\n            await master_conn.execute(f\"\"\"\n                CREATE DATABASE {db_name}\n                WITH TEMPLATE {self.db_template}\n                OWNER tenant_owner\n                ENCODING 'UTF8'\n                LC_COLLATE 'en_US.UTF-8'\n                LC_CTYPE 'en_US.UTF-8'\n            \"\"\")\n\n            # Create tenant-specific connection pool\n            tenant_db_url = self.master_db_url.rsplit('/', 1)[0] + f'/{db_name}'\n            self.tenant_databases[tenant_id] = {\n                'db_name': db_name,\n                'db_url': tenant_db_url,\n                'created_at': datetime.utcnow(),\n                'config': tenant_config or {}\n            }\n\n            # Initialize connection pool\n            await self._create_connection_pool(tenant_id, tenant_db_url)\n\n            # Run tenant-specific initialization\n            await self._initialize_tenant_database(tenant_id, tenant_config)\n\n            return tenant_db_url\n\n        finally:\n            await master_conn.close()\n\n    async def _create_connection_pool(self, tenant_id: str, db_url: str):\n        \"\"\"Create optimized connection pool for tenant\"\"\"\n        engine = create_engine(\n            db_url,\n            pool_size=10,\n            max_overflow=20,\n            pool_pre_ping=True,\n            pool_recycle=3600\n        )\n        self.connection_pools[tenant_id] = sessionmaker(bind=engine)\n\n    async def _initialize_tenant_database(self, tenant_id: str, config: Dict[str, Any]):\n        \"\"\"Initialize tenant-specific configuration\"\"\"\n        session_maker = self.connection_pools[tenant_id]\n\n        with session_maker() as session:\n            # Set tenant-specific configuration\n            if config:\n                # Create tenant settings table\n                session.execute(text(\"\"\"\n                    CREATE TABLE IF NOT EXISTS tenant_settings (\n                        key VARCHAR(100) PRIMARY KEY,\n                        value JSONB NOT NULL,\n                        created_at TIMESTAMP DEFAULT NOW(),\n                        updated_at TIMESTAMP DEFAULT NOW()\n                    )\n                \"\"\"))\n\n                # Insert tenant configuration\n                for key, value in config.items():\n                    session.execute(text(\"\"\"\n                        INSERT INTO tenant_settings (key, value)\n                        VALUES (:key, :value)\n                        ON CONFLICT (key) DO UPDATE\n                        SET value = EXCLUDED.value, updated_at = NOW()\n                    \"\"\"), {'key': key, 'value': json.dumps(value)})\n\n            # Create tenant-specific indexes or customizations\n            await self._apply_tenant_customizations(session, tenant_id, config)\n\n            session.commit()\n\n    async def _apply_tenant_customizations(self, session, tenant_id: str, config: Dict[str, Any]):\n        \"\"\"Apply tenant-specific database customizations\"\"\"\n        customizations = config.get('database_customizations', {})\n\n        # Custom indexes\n        for index_config in customizations.get('indexes', []):\n            session.execute(text(index_config['sql']))\n\n        # Custom stored procedures\n        for proc_config in customizations.get('procedures', []):\n            session.execute(text(proc_config['sql']))\n\n        # Tenant-specific data seeding\n        seed_data = customizations.get('seed_data', {})\n        for table, records in seed_data.items():\n            for record in records:\n                columns = ', '.join(record.keys())\n                placeholders = ', '.join(f':{k}' for k in record.keys())\n                session.execute(\n                    text(f\"INSERT INTO {table} ({columns}) VALUES ({placeholders})\"),\n                    record\n                )\n\n    def get_tenant_session(self, tenant_id: str):\n        \"\"\"Get database session for specific tenant\"\"\"\n        if tenant_id not in self.connection_pools:\n            raise ValueError(f\"Tenant {tenant_id} database not found\")\n\n        return self.connection_pools[tenant_id]()\n\n    async def backup_tenant_database(self, tenant_id: str, backup_location: str) -&gt; str:\n        \"\"\"Create backup of tenant database\"\"\"\n        tenant_info = self.tenant_databases.get(tenant_id)\n        if not tenant_info:\n            raise ValueError(f\"Tenant {tenant_id} not found\")\n\n        db_name = tenant_info['db_name']\n        backup_filename = f\"{backup_location}/{db_name}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.dump\"\n\n        # Use pg_dump for backup\n        backup_command = [\n            'pg_dump',\n            '--host', self._extract_host(self.master_db_url),\n            '--port', str(self._extract_port(self.master_db_url)),\n            '--username', self._extract_username(self.master_db_url),\n            '--format=custom',\n            '--no-owner',\n            '--no-privileges',\n            '--file', backup_filename,\n            db_name\n        ]\n\n        # Execute backup (implementation depends on environment)\n        # subprocess.run(backup_command, check=True)\n\n        return backup_filename\n\n    async def restore_tenant_database(self, tenant_id: str, backup_file: str) -&gt; bool:\n        \"\"\"Restore tenant database from backup\"\"\"\n        tenant_info = self.tenant_databases.get(tenant_id)\n        if not tenant_info:\n            raise ValueError(f\"Tenant {tenant_id} not found\")\n\n        # Implementation for restore operation\n        # This would use pg_restore\n        return True\n\n    async def migrate_tenant(self, tenant_id: str, migration_scripts: List[str]) -&gt; Dict[str, Any]:\n        \"\"\"Run migrations on specific tenant database\"\"\"\n        session_maker = self.connection_pools[tenant_id]\n        results = []\n\n        with session_maker() as session:\n            for script in migration_scripts:\n                try:\n                    session.execute(text(script))\n                    results.append({'script': script[:50], 'success': True})\n                except Exception as e:\n                    session.rollback()\n                    results.append({'script': script[:50], 'success': False, 'error': str(e)})\n                    break\n\n            session.commit()\n\n        return {\n            'tenant_id': tenant_id,\n            'migration_results': results,\n            'success': all(r['success'] for r in results)\n        }\n\n    def _extract_host(self, db_url: str) -&gt; str:\n        \"\"\"Extract host from database URL\"\"\"\n        from urllib.parse import urlparse\n        return urlparse(db_url).hostname\n\n    def _extract_port(self, db_url: str) -&gt; int:\n        \"\"\"Extract port from database URL\"\"\"\n        from urllib.parse import urlparse\n        return urlparse(db_url).port or 5432\n\n    def _extract_username(self, db_url: str) -&gt; str:\n        \"\"\"Extract username from database URL\"\"\"\n        from urllib.parse import urlparse\n        return urlparse(db_url).username\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#schema-per-tenant-pattern","title":"Schema-per-Tenant Pattern","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#schema-based-multi-tenancy","title":"Schema-based Multi-tenancy","text":"<pre><code>class SchemaPerTenantManager:\n    \"\"\"Manage separate schemas for each tenant\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n        self.tenant_schemas = {}\n\n    async def create_tenant_schema(self, tenant_id: str, schema_config: Dict[str, Any] = None) -&gt; str:\n        \"\"\"Create schema for tenant\"\"\"\n        schema_name = f\"tenant_{tenant_id}\"\n\n        # Create schema\n        await self.session.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\"))\n\n        # Create tenant-specific role\n        role_name = f\"tenant_{tenant_id}_role\"\n        await self.session.execute(text(f\"\"\"\n            CREATE ROLE {role_name} WITH\n            LOGIN\n            NOSUPERUSER\n            NOCREATEDB\n            NOCREATEROLE\n            NOINHERIT\n            NOREPLICATION\n            CONNECTION LIMIT 20\n        \"\"\"))\n\n        # Grant schema permissions\n        await self.session.execute(text(f\"\"\"\n            GRANT USAGE ON SCHEMA {schema_name} TO {role_name};\n            GRANT CREATE ON SCHEMA {schema_name} TO {role_name};\n            ALTER DEFAULT PRIVILEGES IN SCHEMA {schema_name}\n            GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO {role_name};\n        \"\"\"))\n\n        # Create tables in tenant schema\n        await self._create_tenant_tables(schema_name)\n\n        # Apply schema-specific configuration\n        if schema_config:\n            await self._apply_schema_configuration(schema_name, schema_config)\n\n        self.tenant_schemas[tenant_id] = {\n            'schema_name': schema_name,\n            'role_name': role_name,\n            'created_at': datetime.utcnow(),\n            'config': schema_config or {}\n        }\n\n        self.session.commit()\n        return schema_name\n\n    async def _create_tenant_tables(self, schema_name: str):\n        \"\"\"Create standard tables in tenant schema\"\"\"\n        table_definitions = [\n            f\"\"\"\n            CREATE TABLE {schema_name}.users (\n                id SERIAL PRIMARY KEY,\n                username VARCHAR(100) UNIQUE NOT NULL,\n                email VARCHAR(255) UNIQUE NOT NULL,\n                password_hash VARCHAR(255) NOT NULL,\n                created_at TIMESTAMP DEFAULT NOW(),\n                updated_at TIMESTAMP DEFAULT NOW()\n            )\n            \"\"\",\n            f\"\"\"\n            CREATE TABLE {schema_name}.orders (\n                id SERIAL PRIMARY KEY,\n                user_id INTEGER REFERENCES {schema_name}.users(id),\n                total_amount DECIMAL(10,2) NOT NULL,\n                status VARCHAR(20) DEFAULT 'pending',\n                created_at TIMESTAMP DEFAULT NOW(),\n                updated_at TIMESTAMP DEFAULT NOW()\n            )\n            \"\"\",\n            f\"\"\"\n            CREATE TABLE {schema_name}.order_items (\n                id SERIAL PRIMARY KEY,\n                order_id INTEGER REFERENCES {schema_name}.orders(id),\n                product_name VARCHAR(255) NOT NULL,\n                quantity INTEGER NOT NULL,\n                unit_price DECIMAL(10,2) NOT NULL,\n                created_at TIMESTAMP DEFAULT NOW()\n            )\n            \"\"\"\n        ]\n\n        for table_sql in table_definitions:\n            await self.session.execute(text(table_sql))\n\n    async def _apply_schema_configuration(self, schema_name: str, config: Dict[str, Any]):\n        \"\"\"Apply tenant-specific schema configuration\"\"\"\n\n        # Custom indexes\n        for index_config in config.get('indexes', []):\n            index_sql = index_config['sql'].replace('{schema}', schema_name)\n            await self.session.execute(text(index_sql))\n\n        # Custom views\n        for view_config in config.get('views', []):\n            view_sql = view_config['sql'].replace('{schema}', schema_name)\n            await self.session.execute(text(view_sql))\n\n        # Tenant-specific functions\n        for function_config in config.get('functions', []):\n            function_sql = function_config['sql'].replace('{schema}', schema_name)\n            await self.session.execute(text(function_sql))\n\nclass SchemaContextManager:\n    \"\"\"Manage schema context for queries\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n        self.current_schema = None\n\n    async def set_tenant_context(self, tenant_id: str):\n        \"\"\"Set current tenant schema context\"\"\"\n        schema_name = f\"tenant_{tenant_id}\"\n        await self.session.execute(text(f\"SET search_path = {schema_name}, public\"))\n        self.current_schema = schema_name\n\n    async def reset_context(self):\n        \"\"\"Reset to default schema context\"\"\"\n        await self.session.execute(text(\"SET search_path = public\"))\n        self.current_schema = None\n\n    def __enter__(self):\n        return self\n\n    async def __aenter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self.current_schema:\n            asyncio.create_task(self.reset_context())\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if self.current_schema:\n            await self.reset_context()\n\n# SQLAlchemy integration with schema context\nfrom sqlalchemy.orm import declarative_base\nfrom sqlalchemy import event\n\nclass TenantAwareBase:\n    \"\"\"Base class for tenant-aware models\"\"\"\n\n    @classmethod\n    def set_schema(cls, schema_name: str):\n        \"\"\"Dynamically set schema for model\"\"\"\n        cls.__table__.schema = schema_name\n\ndef create_tenant_models(schema_name: str):\n    \"\"\"Create models bound to specific schema\"\"\"\n    Base = declarative_base(cls=TenantAwareBase)\n\n    class TenantUser(Base):\n        __tablename__ = 'users'\n        __table_args__ = {'schema': schema_name}\n\n        id = Column(Integer, primary_key=True)\n        username = Column(String(100), unique=True, nullable=False)\n        email = Column(String(255), unique=True, nullable=False)\n        password_hash = Column(String(255), nullable=False)\n        created_at = Column(DateTime, default=datetime.utcnow)\n\n        orders = relationship(\"TenantOrder\", back_populates=\"user\")\n\n    class TenantOrder(Base):\n        __tablename__ = 'orders'\n        __table_args__ = {'schema': schema_name}\n\n        id = Column(Integer, primary_key=True)\n        user_id = Column(Integer, ForeignKey(f'{schema_name}.users.id'))\n        total_amount = Column(Numeric(10, 2), nullable=False)\n        status = Column(String(20), default='pending')\n        created_at = Column(DateTime, default=datetime.utcnow)\n\n        user = relationship(\"TenantUser\", back_populates=\"orders\")\n        items = relationship(\"TenantOrderItem\", back_populates=\"order\")\n\n    class TenantOrderItem(Base):\n        __tablename__ = 'order_items'\n        __table_args__ = {'schema': schema_name}\n\n        id = Column(Integer, primary_key=True)\n        order_id = Column(Integer, ForeignKey(f'{schema_name}.orders.id'))\n        product_name = Column(String(255), nullable=False)\n        quantity = Column(Integer, nullable=False)\n        unit_price = Column(Numeric(10, 2), nullable=False)\n\n        order = relationship(\"TenantOrder\", back_populates=\"items\")\n\n    return {\n        'User': TenantUser,\n        'Order': TenantOrder,\n        'OrderItem': TenantOrderItem\n    }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#row-level-security-rls-pattern","title":"Row-Level Security (RLS) Pattern","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#rls-implementation","title":"RLS Implementation","text":"<pre><code>class RowLevelSecurityManager:\n    \"\"\"Implement row-level security for multi-tenancy\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n\n    async def setup_rls_tables(self):\n        \"\"\"Setup tables with RLS policies\"\"\"\n\n        # Enable RLS on tables\n        rls_tables = ['users', 'orders', 'order_items', 'products']\n\n        for table in rls_tables:\n            await self.session.execute(text(f\"ALTER TABLE {table} ENABLE ROW LEVEL SECURITY\"))\n\n        # Create RLS policies\n        await self._create_rls_policies()\n\n        self.session.commit()\n\n    async def _create_rls_policies(self):\n        \"\"\"Create row-level security policies\"\"\"\n\n        # Policy for users table\n        await self.session.execute(text(\"\"\"\n            CREATE POLICY tenant_isolation_users ON users\n            FOR ALL\n            TO tenant_role\n            USING (tenant_id = current_setting('app.current_tenant')::INTEGER)\n            WITH CHECK (tenant_id = current_setting('app.current_tenant')::INTEGER)\n        \"\"\"))\n\n        # Policy for orders table\n        await self.session.execute(text(\"\"\"\n            CREATE POLICY tenant_isolation_orders ON orders\n            FOR ALL\n            TO tenant_role\n            USING (tenant_id = current_setting('app.current_tenant')::INTEGER)\n            WITH CHECK (tenant_id = current_setting('app.current_tenant')::INTEGER)\n        \"\"\"))\n\n        # Policy for order_items table with JOIN\n        await self.session.execute(text(\"\"\"\n            CREATE POLICY tenant_isolation_order_items ON order_items\n            FOR ALL\n            TO tenant_role\n            USING (EXISTS (\n                SELECT 1 FROM orders\n                WHERE orders.id = order_items.order_id\n                AND orders.tenant_id = current_setting('app.current_tenant')::INTEGER\n            ))\n            WITH CHECK (EXISTS (\n                SELECT 1 FROM orders\n                WHERE orders.id = order_items.order_id\n                AND orders.tenant_id = current_setting('app.current_tenant')::INTEGER\n            ))\n        \"\"\"))\n\n        # Bypass policy for superusers/admin\n        await self.session.execute(text(\"\"\"\n            CREATE POLICY bypass_rls_for_admin ON users\n            FOR ALL\n            TO admin_role\n            USING (true)\n        \"\"\"))\n\n    async def set_tenant_context(self, tenant_id: int):\n        \"\"\"Set tenant context for RLS\"\"\"\n        await self.session.execute(text(f\"SELECT set_config('app.current_tenant', '{tenant_id}', false)\"))\n\n    async def create_tenant_user(self, tenant_id: int, username: str) -&gt; str:\n        \"\"\"Create database user for tenant with appropriate permissions\"\"\"\n        role_name = f\"tenant_{tenant_id}_user\"\n\n        # Create role\n        await self.session.execute(text(f\"\"\"\n            CREATE ROLE {role_name} WITH\n            LOGIN\n            NOSUPERUSER\n            NOCREATEDB\n            NOCREATEROLE\n            INHERIT\n            NOREPLICATION\n            CONNECTION LIMIT 10\n            IN ROLE tenant_role\n        \"\"\"))\n\n        # Set default tenant context for this user\n        await self.session.execute(text(f\"\"\"\n            ALTER ROLE {role_name}\n            SET app.current_tenant = '{tenant_id}'\n        \"\"\"))\n\n        self.session.commit()\n        return role_name\n\n# SQLAlchemy models with RLS support\nclass RLSBase(Base):\n    \"\"\"Base class for RLS-enabled models\"\"\"\n\n    tenant_id = Column(Integer, nullable=False, index=True)\n\n    @classmethod\n    def for_tenant(cls, session, tenant_id: int):\n        \"\"\"Query scoped to specific tenant\"\"\"\n        return session.query(cls).filter(cls.tenant_id == tenant_id)\n\nclass User(RLSBase):\n    __tablename__ = 'users'\n\n    id = Column(Integer, primary_key=True)\n    tenant_id = Column(Integer, nullable=False, index=True)\n    username = Column(String(100), nullable=False)\n    email = Column(String(255), nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    orders = relationship(\"Order\", back_populates=\"user\")\n\n    __table_args__ = (\n        Index('idx_users_tenant_email', 'tenant_id', 'email', unique=True),\n        Index('idx_users_tenant_username', 'tenant_id', 'username', unique=True),\n    )\n\nclass Order(RLSBase):\n    __tablename__ = 'orders'\n\n    id = Column(Integer, primary_key=True)\n    tenant_id = Column(Integer, nullable=False, index=True)\n    user_id = Column(Integer, ForeignKey('users.id'))\n    total_amount = Column(Numeric(10, 2), nullable=False)\n    status = Column(String(20), default='pending')\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    user = relationship(\"User\", back_populates=\"orders\")\n    items = relationship(\"OrderItem\", back_populates=\"order\")\n\n    __table_args__ = (\n        Index('idx_orders_tenant_user', 'tenant_id', 'user_id'),\n        Index('idx_orders_tenant_status', 'tenant_id', 'status'),\n    )\n\nclass RLSQueryHelper:\n    \"\"\"Helper for RLS queries\"\"\"\n\n    @staticmethod\n    def ensure_tenant_context(session, tenant_id: int):\n        \"\"\"Ensure tenant context is set\"\"\"\n        session.execute(text(f\"SELECT set_config('app.current_tenant', '{tenant_id}', true)\"))\n\n    @staticmethod\n    def get_tenant_stats(session, tenant_id: int) -&gt; Dict[str, Any]:\n        \"\"\"Get statistics for specific tenant\"\"\"\n        RLSQueryHelper.ensure_tenant_context(session, tenant_id)\n\n        stats = session.execute(text(\"\"\"\n            SELECT\n                (SELECT COUNT(*) FROM users) as user_count,\n                (SELECT COUNT(*) FROM orders) as order_count,\n                (SELECT COALESCE(SUM(total_amount), 0) FROM orders WHERE status = 'completed') as total_revenue\n        \"\"\")).fetchone()\n\n        return {\n            'tenant_id': tenant_id,\n            'user_count': stats.user_count,\n            'order_count': stats.order_count,\n            'total_revenue': float(stats.total_revenue)\n        }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#hybrid-multi-tenancy-pattern","title":"Hybrid Multi-tenancy Pattern","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#flexible-multi-tenancy-architecture","title":"Flexible Multi-tenancy Architecture","text":"<pre><code>class HybridTenancyManager:\n    \"\"\"Manage hybrid multi-tenancy approach\"\"\"\n\n    def __init__(self, master_db_session):\n        self.master_session = master_db_session\n        self.tenant_configs = {}\n        self.tenant_managers = {}\n\n    async def setup_tenant(self, tenant_id: str, tenancy_config: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Setup tenant using appropriate tenancy model\"\"\"\n\n        tenant_tier = tenancy_config.get('tier', 'standard')\n        data_sensitivity = tenancy_config.get('data_sensitivity', 'normal')\n        expected_scale = tenancy_config.get('expected_scale', 'medium')\n\n        # Determine tenancy model based on requirements\n        if tenant_tier == 'enterprise' or data_sensitivity == 'high':\n            tenancy_model = TenancyModel.DATABASE_PER_TENANT\n            manager = DatabasePerTenantManager(self.master_db_url)\n            connection_info = await manager.create_tenant_database(tenant_id, tenancy_config)\n\n        elif tenant_tier == 'business' or expected_scale == 'medium':\n            tenancy_model = TenancyModel.SCHEMA_PER_TENANT\n            manager = SchemaPerTenantManager(self.master_session)\n            connection_info = await manager.create_tenant_schema(tenant_id, tenancy_config)\n\n        else:\n            tenancy_model = TenancyModel.ROW_LEVEL_SECURITY\n            manager = RowLevelSecurityManager(self.master_session)\n            await manager.setup_rls_tables()\n            connection_info = await manager.create_tenant_user(int(tenant_id), f\"tenant_{tenant_id}\")\n\n        # Store tenant configuration\n        self.tenant_configs[tenant_id] = {\n            'tenancy_model': tenancy_model,\n            'tier': tenant_tier,\n            'connection_info': connection_info,\n            'created_at': datetime.utcnow(),\n            'config': tenancy_config\n        }\n\n        self.tenant_managers[tenant_id] = manager\n\n        return {\n            'tenant_id': tenant_id,\n            'tenancy_model': tenancy_model.value,\n            'connection_info': connection_info,\n            'setup_completed': True\n        }\n\n    def get_tenant_session(self, tenant_id: str):\n        \"\"\"Get appropriate session for tenant\"\"\"\n        tenant_config = self.tenant_configs.get(tenant_id)\n        if not tenant_config:\n            raise ValueError(f\"Tenant {tenant_id} not configured\")\n\n        tenancy_model = tenant_config['tenancy_model']\n\n        if tenancy_model == TenancyModel.DATABASE_PER_TENANT:\n            manager = self.tenant_managers[tenant_id]\n            return manager.get_tenant_session(tenant_id)\n\n        elif tenancy_model == TenancyModel.SCHEMA_PER_TENANT:\n            # Return session with schema context\n            session = self.master_session\n            schema_context = SchemaContextManager(session)\n            asyncio.create_task(schema_context.set_tenant_context(tenant_id))\n            return session\n\n        else:  # RLS\n            # Return session with RLS context\n            session = self.master_session\n            rls_manager = self.tenant_managers[tenant_id]\n            asyncio.create_task(rls_manager.set_tenant_context(int(tenant_id)))\n            return session\n\n    async def migrate_tenant(self, tenant_id: str, new_tenancy_model: TenancyModel) -&gt; Dict[str, Any]:\n        \"\"\"Migrate tenant to different tenancy model\"\"\"\n        current_config = self.tenant_configs.get(tenant_id)\n        if not current_config:\n            raise ValueError(f\"Tenant {tenant_id} not found\")\n\n        current_model = current_config['tenancy_model']\n        if current_model == new_tenancy_model:\n            return {'message': 'Tenant already using target tenancy model'}\n\n        # Export current data\n        export_data = await self._export_tenant_data(tenant_id)\n\n        # Setup new tenancy model\n        migration_config = {\n            **current_config['config'],\n            'migration_source': current_model.value,\n            'migration_data': export_data\n        }\n\n        # Create tenant with new model\n        new_setup = await self.setup_tenant(tenant_id, migration_config)\n\n        # Import data to new tenant setup\n        await self._import_tenant_data(tenant_id, export_data)\n\n        # Archive old tenant setup\n        await self._archive_old_tenant_setup(tenant_id, current_model)\n\n        return {\n            'tenant_id': tenant_id,\n            'migration_from': current_model.value,\n            'migration_to': new_tenancy_model.value,\n            'completed_at': datetime.utcnow(),\n            'data_migrated': True\n        }\n\n    async def _export_tenant_data(self, tenant_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Export all tenant data for migration\"\"\"\n        session = self.get_tenant_session(tenant_id)\n\n        # Export all tables\n        tables_data = {}\n\n        # This would export data from all tenant tables\n        # Implementation depends on tenancy model\n        return tables_data\n\n    async def _import_tenant_data(self, tenant_id: str, data: Dict[str, Any]):\n        \"\"\"Import data to new tenant setup\"\"\"\n        session = self.get_tenant_session(tenant_id)\n\n        # Import data to all tables\n        # Implementation depends on tenancy model and data structure\n        pass\n\nclass TenantMetricsCollector:\n    \"\"\"Collect metrics across different tenancy models\"\"\"\n\n    def __init__(self, hybrid_manager: HybridTenancyManager):\n        self.hybrid_manager = hybrid_manager\n\n    async def collect_tenant_metrics(self, tenant_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Collect metrics for specific tenant\"\"\"\n        tenant_config = self.hybrid_manager.tenant_configs.get(tenant_id)\n        if not tenant_config:\n            return {}\n\n        tenancy_model = tenant_config['tenancy_model']\n        session = self.hybrid_manager.get_tenant_session(tenant_id)\n\n        # Base metrics common to all models\n        base_metrics = await self._collect_base_metrics(session, tenancy_model)\n\n        # Model-specific metrics\n        if tenancy_model == TenancyModel.DATABASE_PER_TENANT:\n            specific_metrics = await self._collect_database_metrics(session, tenant_id)\n        elif tenancy_model == TenancyModel.SCHEMA_PER_TENANT:\n            specific_metrics = await self._collect_schema_metrics(session, tenant_id)\n        else:  # RLS\n            specific_metrics = await self._collect_rls_metrics(session, tenant_id)\n\n        return {\n            'tenant_id': tenant_id,\n            'tenancy_model': tenancy_model.value,\n            'collection_time': datetime.utcnow(),\n            **base_metrics,\n            **specific_metrics\n        }\n\n    async def _collect_base_metrics(self, session, tenancy_model: TenancyModel) -&gt; Dict[str, Any]:\n        \"\"\"Collect base metrics\"\"\"\n        # Common metrics like row counts, activity, etc.\n        return {\n            'tenancy_model': tenancy_model.value,\n            'active_connections': 0,  # Implementation specific\n            'query_performance': {},   # Implementation specific\n        }\n\n    async def _collect_database_metrics(self, session, tenant_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Collect database-specific metrics\"\"\"\n        return {\n            'database_size': 0,        # pg_database_size\n            'connection_limit': 0,     # Database-specific limits\n            'backup_status': 'current' # Backup information\n        }\n\n    async def _collect_schema_metrics(self, session, tenant_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Collect schema-specific metrics\"\"\"\n        return {\n            'schema_size': 0,          # Schema size calculation\n            'shared_resources': {},    # Shared resource usage\n        }\n\n    async def _collect_rls_metrics(self, session, tenant_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Collect RLS-specific metrics\"\"\"\n        return {\n            'rls_policy_performance': {},  # RLS policy efficiency\n            'tenant_data_distribution': {} # Data distribution analysis\n        }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#security-and-compliance","title":"Security and Compliance","text":""},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#security-implementation","title":"Security Implementation","text":"<pre><code>class TenantSecurityManager:\n    \"\"\"Manage security across tenancy models\"\"\"\n\n    def __init__(self):\n        self.audit_log = []\n        self.security_policies = {}\n\n    async def setup_tenant_security(self, tenant_id: str, security_config: Dict[str, Any]):\n        \"\"\"Setup security for tenant\"\"\"\n\n        # Encryption at rest\n        if security_config.get('encryption_required'):\n            await self._setup_encryption(tenant_id, security_config)\n\n        # Audit logging\n        if security_config.get('audit_logging'):\n            await self._setup_audit_logging(tenant_id)\n\n        # Access controls\n        await self._setup_access_controls(tenant_id, security_config)\n\n        # Compliance controls\n        compliance_requirements = security_config.get('compliance', [])\n        for requirement in compliance_requirements:\n            await self._apply_compliance_controls(tenant_id, requirement)\n\n    async def _setup_encryption(self, tenant_id: str, config: Dict[str, Any]):\n        \"\"\"Setup encryption for tenant data\"\"\"\n        encryption_config = {\n            'algorithm': config.get('encryption_algorithm', 'AES-256'),\n            'key_rotation_days': config.get('key_rotation_days', 90),\n            'encrypted_fields': config.get('encrypted_fields', [])\n        }\n\n        # Implementation would setup column-level encryption\n        # or database-level encryption depending on requirements\n\n    async def _setup_audit_logging(self, tenant_id: str):\n        \"\"\"Setup comprehensive audit logging\"\"\"\n\n        # Create audit table for tenant\n        audit_table_sql = f\"\"\"\n            CREATE TABLE IF NOT EXISTS tenant_{tenant_id}_audit_log (\n                id SERIAL PRIMARY KEY,\n                table_name VARCHAR(100) NOT NULL,\n                operation VARCHAR(10) NOT NULL,\n                old_values JSONB,\n                new_values JSONB,\n                user_id INTEGER,\n                timestamp TIMESTAMP DEFAULT NOW(),\n                ip_address INET,\n                user_agent TEXT\n            )\n        \"\"\"\n\n        # Create audit triggers\n        audit_trigger_function = f\"\"\"\n            CREATE OR REPLACE FUNCTION tenant_{tenant_id}_audit_trigger()\n            RETURNS TRIGGER AS $$\n            BEGIN\n                INSERT INTO tenant_{tenant_id}_audit_log (\n                    table_name, operation, old_values, new_values, user_id, timestamp\n                ) VALUES (\n                    TG_TABLE_NAME,\n                    TG_OP,\n                    CASE WHEN TG_OP = 'DELETE' THEN to_jsonb(OLD) ELSE NULL END,\n                    CASE WHEN TG_OP != 'DELETE' THEN to_jsonb(NEW) ELSE NULL END,\n                    COALESCE(current_setting('app.current_user_id', true)::INTEGER, 0),\n                    NOW()\n                );\n                RETURN COALESCE(NEW, OLD);\n            END;\n            $$ LANGUAGE plpgsql;\n        \"\"\"\n\n        # Apply to all tenant tables\n        # Implementation would create triggers on all relevant tables\n\n    async def _apply_compliance_controls(self, tenant_id: str, requirement: str):\n        \"\"\"Apply compliance-specific controls\"\"\"\n\n        if requirement == 'GDPR':\n            await self._apply_gdpr_controls(tenant_id)\n        elif requirement == 'HIPAA':\n            await self._apply_hipaa_controls(tenant_id)\n        elif requirement == 'SOX':\n            await self._apply_sox_controls(tenant_id)\n\n    async def _apply_gdpr_controls(self, tenant_id: str):\n        \"\"\"Apply GDPR compliance controls\"\"\"\n        # Right to be forgotten\n        # Data portability\n        # Consent management\n        # Data retention policies\n        pass\n\n    async def get_tenant_audit_trail(self, tenant_id: str, start_date: datetime, end_date: datetime) -&gt; List[Dict]:\n        \"\"\"Get audit trail for tenant\"\"\"\n        # Implementation would query audit logs\n        return []\n\nclass DataResidencyManager:\n    \"\"\"Manage data residency requirements\"\"\"\n\n    def __init__(self):\n        self.regional_databases = {}\n\n    async def setup_regional_tenant(self, tenant_id: str, region: str, compliance_requirements: List[str]):\n        \"\"\"Setup tenant in specific geographic region\"\"\"\n\n        # Select appropriate regional database\n        regional_db_config = self.regional_databases.get(region)\n        if not regional_db_config:\n            raise ValueError(f\"Region {region} not supported\")\n\n        # Create tenant in regional database\n        regional_manager = DatabasePerTenantManager(regional_db_config['db_url'])\n        await regional_manager.create_tenant_database(tenant_id, {\n            'region': region,\n            'compliance': compliance_requirements,\n            'data_residency': True\n        })\n\n        return {\n            'tenant_id': tenant_id,\n            'region': region,\n            'database_location': regional_db_config['location'],\n            'compliance_met': compliance_requirements\n        }\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Complex Relationship Modeling</li> <li>Performance Optimization</li> <li>Production Migrations</li> <li>PostgreSQL Basic Setup</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/multi-tenant-patterns/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Model Selection:</li> <li>Choose tenancy model based on isolation, scale, and cost requirements</li> <li>Consider compliance and regulatory requirements</li> <li> <p>Plan for future migration between models</p> </li> <li> <p>Security:</p> </li> <li>Implement proper access controls and authentication</li> <li>Use encryption for sensitive data</li> <li>Maintain comprehensive audit logs</li> <li> <p>Regular security reviews and updates</p> </li> <li> <p>Performance:</p> </li> <li>Optimize for your specific tenancy model</li> <li>Monitor per-tenant performance metrics</li> <li>Plan for tenant-specific scaling needs</li> <li> <p>Use appropriate indexing strategies</p> </li> <li> <p>Operations:</p> </li> <li>Automate tenant provisioning and management</li> <li>Implement proper backup and disaster recovery</li> <li>Plan for tenant migration strategies</li> <li> <p>Monitor tenant health and resource usage</p> </li> <li> <p>Compliance:</p> </li> <li>Understand regulatory requirements for your industry</li> <li>Implement data residency controls where needed</li> <li>Maintain audit trails for compliance reporting</li> <li>Regular compliance assessments and updates</li> </ol>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/","title":"PostgreSQL Performance Optimization","text":"<p>Comprehensive guide for optimizing PostgreSQL performance including query optimization, indexing strategies, connection pooling, and monitoring.</p>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL Basic Setup</li> <li>Complex Relationship Modeling</li> <li>Understanding of SQL and database concepts</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#query-optimization-fundamentals","title":"Query Optimization Fundamentals","text":""},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#query-analysis-with-explain","title":"Query Analysis with EXPLAIN","text":"<pre><code>-- Basic EXPLAIN to see execution plan\nEXPLAIN SELECT * FROM orders WHERE user_id = 123;\n\n-- EXPLAIN ANALYZE for actual execution statistics\nEXPLAIN (ANALYZE, BUFFERS, VERBOSE)\nSELECT o.id, o.total_amount, u.username\nFROM orders o\nJOIN users u ON o.user_id = u.id\nWHERE o.created_at &gt;= '2023-01-01'\nAND o.status = 'completed';\n\n-- EXPLAIN with different output formats\nEXPLAIN (FORMAT JSON, ANALYZE)\nSELECT product_id, SUM(quantity * unit_price) as revenue\nFROM order_items\nGROUP BY product_id\nORDER BY revenue DESC\nLIMIT 10;\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#query-optimization-patterns","title":"Query Optimization Patterns","text":"<pre><code>from sqlalchemy import text, func, Index\nfrom sqlalchemy.orm import load_only, joinedload, selectinload\n\nclass OptimizedQueries:\n    \"\"\"Examples of optimized query patterns\"\"\"\n\n    @staticmethod\n    def efficient_pagination(session, page: int, per_page: int = 20):\n        \"\"\"Cursor-based pagination for better performance\"\"\"\n        offset = (page - 1) * per_page\n\n        # Use LIMIT/OFFSET for small offsets\n        if offset &lt; 1000:\n            return session.query(Order).order_by(Order.id).offset(offset).limit(per_page).all()\n\n        # Use cursor-based pagination for large offsets\n        cursor_query = session.query(Order).order_by(Order.id)\n        if page &gt; 1:\n            # Get the last ID from previous page\n            last_id = session.query(Order.id).order_by(Order.id).offset(offset - 1).limit(1).scalar()\n            cursor_query = cursor_query.filter(Order.id &gt; last_id)\n\n        return cursor_query.limit(per_page).all()\n\n    @staticmethod\n    def optimized_aggregations(session, start_date, end_date):\n        \"\"\"Efficient aggregation queries\"\"\"\n        # Use indexes on date columns\n        return session.query(\n            func.date_trunc('day', Order.created_at).label('date'),\n            func.count(Order.id).label('order_count'),\n            func.sum(Order.total_amount).label('revenue'),\n            func.avg(Order.total_amount).label('avg_order_value')\n        ).filter(\n            Order.created_at.between(start_date, end_date),\n            Order.status == 'completed'\n        ).group_by(\n            func.date_trunc('day', Order.created_at)\n        ).order_by('date').all()\n\n    @staticmethod\n    def bulk_operations(session, order_ids: List[int]):\n        \"\"\"Efficient bulk updates\"\"\"\n        # Use bulk update instead of individual updates\n        session.query(Order).filter(\n            Order.id.in_(order_ids)\n        ).update(\n            {Order.status: 'cancelled'},\n            synchronize_session=False\n        )\n\n        # For complex bulk operations, use raw SQL\n        session.execute(\n            text(\"\"\"\n                UPDATE orders\n                SET status = 'shipped',\n                    shipped_at = NOW()\n                WHERE id = ANY(:order_ids)\n                AND status = 'confirmed'\n            \"\"\"),\n            {'order_ids': order_ids}\n        )\n\n    @staticmethod\n    def selective_loading(session, user_id: int):\n        \"\"\"Load only needed columns and relationships\"\"\"\n        # Load only specific columns\n        orders = session.query(Order).options(\n            load_only(Order.id, Order.total_amount, Order.created_at)\n        ).filter(Order.user_id == user_id).all()\n\n        # Eager load relationships to avoid N+1 queries\n        orders_with_items = session.query(Order).options(\n            joinedload(Order.items).joinedload(OrderItem.product)\n        ).filter(Order.user_id == user_id).all()\n\n        # Use selectinload for one-to-many relationships\n        orders_with_select = session.query(Order).options(\n            selectinload(Order.items)\n        ).filter(Order.user_id == user_id).all()\n\n        return orders_with_select\n\n    @staticmethod\n    def window_functions(session):\n        \"\"\"Use window functions for analytics\"\"\"\n        from sqlalchemy import func\n\n        return session.query(\n            Order.id,\n            Order.total_amount,\n            Order.created_at,\n            # Running total\n            func.sum(Order.total_amount).over(\n                order_by=Order.created_at,\n                rows=(None, 0)\n            ).label('running_total'),\n            # Rank by amount\n            func.row_number().over(\n                order_by=Order.total_amount.desc()\n            ).label('amount_rank'),\n            # Previous order amount\n            func.lag(Order.total_amount, 1).over(\n                order_by=Order.created_at\n            ).label('prev_amount')\n        ).order_by(Order.created_at).all()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#indexing-strategies","title":"Indexing Strategies","text":""},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#index-creation-and-management","title":"Index Creation and Management","text":"<pre><code>-- B-tree indexes (default)\nCREATE INDEX idx_orders_user_id ON orders(user_id);\nCREATE INDEX idx_orders_created_at ON orders(created_at);\n\n-- Composite indexes (order matters!)\nCREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_at);\n\n-- Partial indexes for conditional queries\nCREATE INDEX idx_orders_active_user ON orders(user_id)\nWHERE status IN ('pending', 'confirmed');\n\n-- Expression indexes for computed values\nCREATE INDEX idx_orders_year ON orders(EXTRACT(YEAR FROM created_at));\n\n-- Unique indexes for constraints\nCREATE UNIQUE INDEX idx_users_email_unique ON users(email)\nWHERE deleted_at IS NULL;\n\n-- GIN indexes for JSONB and arrays\nCREATE INDEX idx_product_attributes ON products USING gin(attributes);\nCREATE INDEX idx_product_tags ON products USING gin(tags);\n\n-- Full-text search indexes\nCREATE INDEX idx_product_search ON products USING gin(to_tsvector('english', name || ' ' || description));\n\n-- Hash indexes for equality comparisons (PostgreSQL 10+, framework uses 16)\nCREATE INDEX idx_orders_status_hash ON orders USING hash(status);\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#sqlalchemy-index-definitions","title":"SQLAlchemy Index Definitions","text":"<pre><code>from sqlalchemy import Index, text\n\nclass OptimizedModels(Base):\n    __tablename__ = 'orders'\n\n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)\n    status = Column(String(20), nullable=False, default='pending')\n    total_amount = Column(Numeric(10, 2), nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    metadata_json = Column(JSONB)\n\n    # Define indexes in model\n    __table_args__ = (\n        # Composite index\n        Index('idx_orders_user_status', 'user_id', 'status'),\n\n        # Partial index\n        Index('idx_orders_user_active', 'user_id',\n              postgresql_where=text(\"status IN ('pending', 'confirmed')\")),\n\n        # Expression index\n        Index('idx_orders_date_part', text('EXTRACT(YEAR FROM created_at)')),\n\n        # GIN index for JSONB\n        Index('idx_orders_metadata', 'metadata_json', postgresql_using='gin'),\n\n        # Unique constraint with condition\n        Index('idx_orders_unique_user_pending', 'user_id', unique=True,\n              postgresql_where=text(\"status = 'pending'\"))\n    )\n\nclass IndexAnalyzer:\n    \"\"\"Tools for analyzing index usage\"\"\"\n\n    @staticmethod\n    def get_unused_indexes(session):\n        \"\"\"Find unused indexes\"\"\"\n        return session.execute(text(\"\"\"\n            SELECT schemaname, tablename, indexname, idx_tup_read, idx_tup_fetch\n            FROM pg_stat_user_indexes\n            WHERE idx_tup_read = 0 AND idx_tup_fetch = 0\n            AND indexname NOT LIKE '%_pkey'\n        \"\"\")).fetchall()\n\n    @staticmethod\n    def get_index_sizes(session):\n        \"\"\"Get index sizes\"\"\"\n        return session.execute(text(\"\"\"\n            SELECT schemaname, tablename, indexname,\n                   pg_size_pretty(pg_relation_size(indexrelid)) as size\n            FROM pg_stat_user_indexes\n            ORDER BY pg_relation_size(indexrelid) DESC\n        \"\"\")).fetchall()\n\n    @staticmethod\n    def get_duplicate_indexes(session):\n        \"\"\"Find potentially duplicate indexes\"\"\"\n        return session.execute(text(\"\"\"\n            SELECT table_name, column_names, index_names\n            FROM (\n                SELECT\n                    schemaname||'.'||tablename as table_name,\n                    array_to_string(array_agg(attname), ',') as column_names,\n                    array_to_string(array_agg(indexname), ',') as index_names,\n                    count(*) as index_count\n                FROM pg_index i\n                JOIN pg_class t ON t.oid = i.indrelid\n                JOIN pg_namespace n ON n.oid = t.relnamespace\n                JOIN pg_class idx ON idx.oid = i.indexrelid\n                JOIN pg_attribute a ON a.attrelid = t.oid AND a.attnum = ANY(i.indkey)\n                WHERE n.nspname NOT IN ('pg_catalog', 'information_schema')\n                GROUP BY schemaname, tablename, i.indkey\n            ) dup_idx\n            WHERE index_count &gt; 1\n        \"\"\")).fetchall()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#connection-pooling-and-configuration","title":"Connection Pooling and Configuration","text":""},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#connection-pool-configuration","title":"Connection Pool Configuration","text":"<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool, NullPool\nimport redis.asyncio as redis\n\nclass DatabaseConfig:\n    \"\"\"Optimized database configuration\"\"\"\n\n    @staticmethod\n    def create_optimized_engine(database_url: str, is_production: bool = False):\n        \"\"\"Create properly configured engine\"\"\"\n\n        pool_config = {\n            'poolclass': QueuePool,\n            'pool_size': 20,          # Core connections\n            'max_overflow': 30,       # Additional connections\n            'pool_pre_ping': True,    # Validate connections\n            'pool_recycle': 3600,     # Recycle after 1 hour\n            'pool_timeout': 30,       # Timeout for getting connection\n        }\n\n        if is_production:\n            # Production optimizations\n            pool_config.update({\n                'pool_size': 50,\n                'max_overflow': 100,\n                'echo': False,\n                'echo_pool': False,\n            })\n        else:\n            # Development settings\n            pool_config.update({\n                'echo': True,\n                'echo_pool': True,\n            })\n\n        return create_engine(\n            database_url,\n            **pool_config,\n            connect_args={\n                \"application_name\": \"microservice\",\n                \"options\": \"-c timezone=UTC\"\n            }\n        )\n\nclass ConnectionMonitor:\n    \"\"\"Monitor database connections\"\"\"\n\n    def __init__(self, engine):\n        self.engine = engine\n\n    def get_pool_status(self):\n        \"\"\"Get connection pool status\"\"\"\n        pool = self.engine.pool\n        return {\n            'size': pool.size(),\n            'checked_in': pool.checkedin(),\n            'checked_out': pool.checkedout(),\n            'overflow': pool.overflow(),\n            'invalid': pool.invalidated()\n        }\n\n    def health_check(self):\n        \"\"\"Basic database health check\"\"\"\n        try:\n            with self.engine.connect() as conn:\n                result = conn.execute(text(\"SELECT 1\")).scalar()\n                return result == 1\n        except Exception:\n            return False\n\n# Redis for caching frequently accessed data\nclass CacheConfig:\n    \"\"\"Redis caching configuration\"\"\"\n\n    def __init__(self, redis_url: str):\n        self.redis = redis.from_url(redis_url)\n\n    async def cache_query_result(self, cache_key: str, data, expiry: int = 300):\n        \"\"\"Cache query results\"\"\"\n        import json\n        await self.redis.setex(\n            cache_key,\n            expiry,\n            json.dumps(data, default=str)\n        )\n\n    async def get_cached_result(self, cache_key: str):\n        \"\"\"Get cached query results\"\"\"\n        import json\n        cached = await self.redis.get(cache_key)\n        if cached:\n            return json.loads(cached)\n        return None\n\n    async def invalidate_cache_pattern(self, pattern: str):\n        \"\"\"Invalidate cache keys matching pattern\"\"\"\n        keys = await self.redis.keys(pattern)\n        if keys:\n            await self.redis.delete(*keys)\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#postgresql-configuration-tuning","title":"PostgreSQL Configuration Tuning","text":"<pre><code>-- postgresql.conf optimizations\n\n-- Memory settings\nshared_buffers = '256MB'              -- 25% of RAM for small instances\nwork_mem = '4MB'                      -- Per operation memory\nmaintenance_work_mem = '64MB'         -- For maintenance operations\neffective_cache_size = '1GB'          -- OS cache estimate\n\n-- Checkpoint settings\ncheckpoint_completion_target = 0.7\nwal_buffers = '16MB'\ncheckpoint_timeout = '10min'\n\n-- Connection settings\nmax_connections = 200\nsuperuser_reserved_connections = 3\n\n-- Query planner settings\nrandom_page_cost = 1.1               -- For SSD storage\neffective_io_concurrency = 200       -- For SSD storage\ndefault_statistics_target = 100\n\n-- Logging for monitoring\nlog_statement = 'mod'                -- Log modifications\nlog_min_duration_statement = 1000    -- Log slow queries (1s+)\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\n\n-- Auto-vacuum settings\nautovacuum = on\nautovacuum_naptime = '1min'\nautovacuum_vacuum_threshold = 50\nautovacuum_analyze_threshold = 50\nautovacuum_vacuum_scale_factor = 0.1\nautovacuum_analyze_scale_factor = 0.05\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#monitoring-and-performance-analysis","title":"Monitoring and Performance Analysis","text":""},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#query-performance-monitoring","title":"Query Performance Monitoring","text":"<pre><code>import time\nfrom contextlib import contextmanager\nfrom sqlalchemy import event\nfrom sqlalchemy.engine import Engine\n\nclass QueryProfiler:\n    \"\"\"Profile database queries\"\"\"\n\n    def __init__(self):\n        self.queries = []\n\n    @contextmanager\n    def profile_queries(self):\n        \"\"\"Context manager for profiling queries\"\"\"\n        self.queries.clear()\n\n        @event.listens_for(Engine, \"before_cursor_execute\")\n        def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n            context._query_start_time = time.time()\n\n        @event.listens_for(Engine, \"after_cursor_execute\")\n        def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n            total = time.time() - context._query_start_time\n            self.queries.append({\n                'statement': statement,\n                'parameters': parameters,\n                'duration': total,\n                'timestamp': time.time()\n            })\n\n        try:\n            yield self\n        finally:\n            event.remove(Engine, \"before_cursor_execute\", receive_before_cursor_execute)\n            event.remove(Engine, \"after_cursor_execute\", receive_after_cursor_execute)\n\n    def get_slow_queries(self, threshold: float = 1.0):\n        \"\"\"Get queries slower than threshold\"\"\"\n        return [q for q in self.queries if q['duration'] &gt; threshold]\n\n    def get_query_stats(self):\n        \"\"\"Get query statistics\"\"\"\n        if not self.queries:\n            return {}\n\n        durations = [q['duration'] for q in self.queries]\n        return {\n            'total_queries': len(self.queries),\n            'total_time': sum(durations),\n            'avg_time': sum(durations) / len(durations),\n            'max_time': max(durations),\n            'min_time': min(durations)\n        }\n\nclass DatabaseMonitor:\n    \"\"\"Monitor database performance metrics\"\"\"\n\n    def __init__(self, session):\n        self.session = session\n\n    def get_active_connections(self):\n        \"\"\"Get active connection count\"\"\"\n        return self.session.execute(text(\"\"\"\n            SELECT count(*) as active_connections\n            FROM pg_stat_activity\n            WHERE state = 'active'\n        \"\"\")).scalar()\n\n    def get_long_running_queries(self, threshold_minutes: int = 5):\n        \"\"\"Get long-running queries\"\"\"\n        return self.session.execute(text(\"\"\"\n            SELECT\n                pid,\n                now() - pg_stat_activity.query_start AS duration,\n                query,\n                state,\n                usename,\n                application_name\n            FROM pg_stat_activity\n            WHERE (now() - pg_stat_activity.query_start) &gt; interval :threshold\n            AND state != 'idle'\n        \"\"\"), {'threshold': f'{threshold_minutes} minutes'}).fetchall()\n\n    def get_table_stats(self, table_name: str = None):\n        \"\"\"Get table statistics\"\"\"\n        query = \"\"\"\n            SELECT\n                schemaname,\n                tablename,\n                n_tup_ins as inserts,\n                n_tup_upd as updates,\n                n_tup_del as deletes,\n                n_live_tup as live_rows,\n                n_dead_tup as dead_rows,\n                last_vacuum,\n                last_autovacuum,\n                last_analyze,\n                last_autoanalyze\n            FROM pg_stat_user_tables\n        \"\"\"\n\n        if table_name:\n            query += \" WHERE tablename = :table_name\"\n            return self.session.execute(text(query), {'table_name': table_name}).fetchall()\n        else:\n            return self.session.execute(text(query)).fetchall()\n\n    def get_index_usage(self, table_name: str = None):\n        \"\"\"Get index usage statistics\"\"\"\n        query = \"\"\"\n            SELECT\n                schemaname,\n                tablename,\n                indexname,\n                idx_tup_read as reads,\n                idx_tup_fetch as fetches,\n                pg_size_pretty(pg_relation_size(indexrelid)) as size\n            FROM pg_stat_user_indexes\n        \"\"\"\n\n        if table_name:\n            query += \" WHERE tablename = :table_name\"\n            return self.session.execute(text(query), {'table_name': table_name}).fetchall()\n        else:\n            return self.session.execute(text(query)).fetchall()\n\n    def get_database_size(self):\n        \"\"\"Get database size information\"\"\"\n        return self.session.execute(text(\"\"\"\n            SELECT\n                pg_database.datname as database_name,\n                pg_size_pretty(pg_database_size(pg_database.datname)) as size\n            FROM pg_database\n            WHERE pg_database.datname = current_database()\n        \"\"\")).fetchone()\n\n    def get_blocking_queries(self):\n        \"\"\"Get queries that are blocking others\"\"\"\n        return self.session.execute(text(\"\"\"\n            SELECT\n                blocked_locks.pid AS blocked_pid,\n                blocked_activity.usename AS blocked_user,\n                blocking_locks.pid AS blocking_pid,\n                blocking_activity.usename AS blocking_user,\n                blocked_activity.query AS blocked_statement,\n                blocking_activity.query AS blocking_statement\n            FROM pg_catalog.pg_locks blocked_locks\n            JOIN pg_catalog.pg_stat_activity blocked_activity\n                ON blocked_activity.pid = blocked_locks.pid\n            JOIN pg_catalog.pg_locks blocking_locks\n                ON blocking_locks.locktype = blocked_locks.locktype\n                AND blocking_locks.DATABASE IS NOT DISTINCT FROM blocked_locks.DATABASE\n                AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n                AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n                AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n                AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n                AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n                AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n                AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n                AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n                AND blocking_locks.pid != blocked_locks.pid\n            JOIN pg_catalog.pg_stat_activity blocking_activity\n                ON blocking_activity.pid = blocking_locks.pid\n            WHERE NOT blocked_locks.GRANTED\n        \"\"\")).fetchall()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#maintenance-and-optimization-tasks","title":"Maintenance and Optimization Tasks","text":""},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#automated-maintenance","title":"Automated Maintenance","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\n\nclass DatabaseMaintenance:\n    \"\"\"Automated database maintenance tasks\"\"\"\n\n    def __init__(self, session):\n        self.session = session\n\n    async def analyze_tables(self, table_names: List[str] = None):\n        \"\"\"Update table statistics\"\"\"\n        if table_names:\n            for table in table_names:\n                self.session.execute(text(f\"ANALYZE {table}\"))\n        else:\n            self.session.execute(text(\"ANALYZE\"))\n        self.session.commit()\n\n    async def vacuum_tables(self, table_names: List[str] = None, full: bool = False):\n        \"\"\"Vacuum tables to reclaim space\"\"\"\n        vacuum_cmd = \"VACUUM FULL\" if full else \"VACUUM\"\n\n        if table_names:\n            for table in table_names:\n                self.session.execute(text(f\"{vacuum_cmd} {table}\"))\n        else:\n            self.session.execute(text(vacuum_cmd))\n        self.session.commit()\n\n    async def reindex_tables(self, table_names: List[str]):\n        \"\"\"Rebuild indexes for better performance\"\"\"\n        for table in table_names:\n            self.session.execute(text(f\"REINDEX TABLE {table}\"))\n        self.session.commit()\n\n    async def cleanup_old_data(self, retention_days: int = 90):\n        \"\"\"Clean up old data based on retention policy\"\"\"\n        cutoff_date = datetime.utcnow() - timedelta(days=retention_days)\n\n        # Example: Clean up old audit logs\n        deleted_count = self.session.execute(text(\"\"\"\n            DELETE FROM audit_logs\n            WHERE created_at &lt; :cutoff_date\n        \"\"\"), {'cutoff_date': cutoff_date}).rowcount\n\n        self.session.commit()\n        return deleted_count\n\nclass PerformanceOptimizer:\n    \"\"\"Automatic performance optimization\"\"\"\n\n    def __init__(self, session):\n        self.session = session\n\n    def suggest_indexes(self, slow_query_threshold: float = 1.0):\n        \"\"\"Suggest indexes based on slow queries\"\"\"\n        # This would analyze query logs and suggest indexes\n        # Implementation would require log analysis\n        suggestions = []\n\n        # Example suggestions based on common patterns\n        missing_indexes = self.session.execute(text(\"\"\"\n            SELECT schemaname, tablename, attname, n_distinct, correlation\n            FROM pg_stats\n            WHERE schemaname NOT IN ('information_schema', 'pg_catalog')\n            AND n_distinct &gt; 100\n            AND correlation &lt; 0.1\n        \"\"\")).fetchall()\n\n        for row in missing_indexes:\n            suggestions.append({\n                'table': f\"{row.schemaname}.{row.tablename}\",\n                'column': row.attname,\n                'reason': 'High cardinality, low correlation',\n                'suggested_index': f\"CREATE INDEX idx_{row.tablename}_{row.attname} ON {row.schemaname}.{row.tablename}({row.attname})\"\n            })\n\n        return suggestions\n\n    def check_table_bloat(self):\n        \"\"\"Check for table bloat\"\"\"\n        return self.session.execute(text(\"\"\"\n            SELECT\n                schemaname,\n                tablename,\n                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,\n                pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,\n                round(\n                    100 * (pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename))::numeric\n                    / pg_total_relation_size(schemaname||'.'||tablename), 2\n                ) as index_ratio\n            FROM pg_tables\n            WHERE schemaname NOT IN ('information_schema', 'pg_catalog')\n            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC\n        \"\"\")).fetchall()\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#related-documentation","title":"Related Documentation","text":"<ul> <li>Complex Relationship Modeling</li> <li>Production Migrations</li> <li>Multi-tenant Patterns</li> <li>PostgreSQL Basic Setup</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/performance-optimization/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Query Optimization:</li> <li>Use EXPLAIN ANALYZE for query analysis</li> <li>Implement proper pagination strategies</li> <li>Avoid N+1 queries with eager loading</li> <li> <p>Use bulk operations for data modifications</p> </li> <li> <p>Indexing:</p> </li> <li>Create indexes based on query patterns</li> <li>Use composite indexes wisely</li> <li>Monitor index usage and remove unused ones</li> <li> <p>Consider partial indexes for filtered queries</p> </li> <li> <p>Connection Management:</p> </li> <li>Configure connection pooling appropriately</li> <li>Monitor connection pool status</li> <li> <p>Use connection health checks</p> </li> <li> <p>Monitoring:</p> </li> <li>Track slow queries and performance metrics</li> <li>Monitor database size and growth</li> <li>Set up alerts for performance issues</li> <li> <p>Regular maintenance schedule</p> </li> <li> <p>Configuration:</p> </li> <li>Tune PostgreSQL settings for workload</li> <li>Optimize memory and checkpoint settings</li> <li>Configure appropriate logging</li> <li>Regular database maintenance</li> </ol>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/","title":"Production Migrations","text":"<p>Comprehensive guide for safe database migrations in production environments with zero-downtime strategies, rollback procedures, and validation.</p>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL Performance Optimization</li> <li>Complex Relationship Modeling</li> <li>Understanding of database locking and transactions</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#migration-strategy-overview","title":"Migration Strategy Overview","text":""},{"location":"atomic/databases/postgresql-advanced/production-migrations/#zero-downtime-migration-principles","title":"Zero-Downtime Migration Principles","text":"<pre><code>from enum import Enum\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Dict, Any\nfrom datetime import datetime\nimport asyncio\n\nclass MigrationType(Enum):\n    SCHEMA_CHANGE = \"schema_change\"\n    DATA_MIGRATION = \"data_migration\"\n    INDEX_CREATION = \"index_creation\"\n    CONSTRAINT_ADDITION = \"constraint_addition\"\n    ROLLBACK = \"rollback\"\n\nclass MigrationRisk(Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n@dataclass\nclass MigrationStep:\n    id: str\n    description: str\n    sql_up: str\n    sql_down: str\n    migration_type: MigrationType\n    risk_level: MigrationRisk\n    estimated_duration: int  # seconds\n    requires_downtime: bool = False\n    validation_query: Optional[str] = None\n    rollback_validation: Optional[str] = None\n\n@dataclass\nclass MigrationPlan:\n    version: str\n    description: str\n    steps: List[MigrationStep]\n    total_estimated_duration: int\n    requires_maintenance_window: bool\n    rollback_strategy: str\n    validation_checklist: List[str]\n\nclass ProductionMigrationRunner:\n    \"\"\"Safe migration execution for production\"\"\"\n\n    def __init__(self, db_session, dry_run: bool = False):\n        self.session = db_session\n        self.dry_run = dry_run\n        self.migration_log = []\n\n    async def execute_migration_plan(self, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Execute migration plan with safety checks\"\"\"\n\n        # Pre-migration validation\n        await self._pre_migration_checks(plan)\n\n        # Execute steps\n        results = []\n        for step in plan.steps:\n            try:\n                result = await self._execute_step(step)\n                results.append(result)\n\n                # Stop on first failure for critical operations\n                if not result['success'] and step.risk_level == MigrationRisk.CRITICAL:\n                    await self._emergency_rollback(results)\n                    break\n\n            except Exception as e:\n                self._log_error(f\"Step {step.id} failed: {str(e)}\")\n                await self._emergency_rollback(results)\n                raise\n\n        return {\n            'migration_version': plan.version,\n            'completed_steps': len([r for r in results if r['success']]),\n            'total_steps': len(plan.steps),\n            'duration': sum(r['duration'] for r in results),\n            'success': all(r['success'] for r in results)\n        }\n\n    async def _pre_migration_checks(self, plan: MigrationPlan):\n        \"\"\"Perform pre-migration safety checks\"\"\"\n\n        # Check database connectivity\n        await self._check_database_health()\n\n        # Verify backup completion\n        await self._verify_recent_backup()\n\n        # Check replication lag\n        await self._check_replication_lag()\n\n        # Validate migration scripts\n        await self._validate_migration_syntax(plan)\n\n        # Check disk space\n        await self._check_disk_space()\n\n    async def _execute_step(self, step: MigrationStep) -&gt; Dict[str, Any]:\n        \"\"\"Execute individual migration step\"\"\"\n        start_time = datetime.utcnow()\n\n        self._log_info(f\"Executing step {step.id}: {step.description}\")\n\n        try:\n            if self.dry_run:\n                self._log_info(f\"DRY RUN - Would execute: {step.sql_up}\")\n                success = True\n            else:\n                # Execute the migration\n                await self._execute_sql_with_timeout(step.sql_up, timeout=step.estimated_duration * 2)\n\n                # Validate if validation query provided\n                if step.validation_query:\n                    validation_result = await self._validate_step(step.validation_query)\n                    success = validation_result\n                else:\n                    success = True\n\n            duration = (datetime.utcnow() - start_time).total_seconds()\n\n            return {\n                'step_id': step.id,\n                'success': success,\n                'duration': duration,\n                'description': step.description\n            }\n\n        except Exception as e:\n            duration = (datetime.utcnow() - start_time).total_seconds()\n            self._log_error(f\"Step {step.id} failed after {duration}s: {str(e)}\")\n\n            return {\n                'step_id': step.id,\n                'success': False,\n                'duration': duration,\n                'error': str(e)\n            }\n\n    async def _execute_sql_with_timeout(self, sql: str, timeout: int):\n        \"\"\"Execute SQL with timeout protection\"\"\"\n        from sqlalchemy import text\n\n        try:\n            # Set statement timeout\n            await self.session.execute(text(f\"SET statement_timeout = '{timeout}s'\"))\n\n            # Execute the migration SQL\n            await self.session.execute(text(sql))\n            self.session.commit()\n\n        except Exception as e:\n            self.session.rollback()\n            raise e\n        finally:\n            # Reset timeout\n            await self.session.execute(text(\"SET statement_timeout = 0\"))\n\n    def _log_info(self, message: str):\n        \"\"\"Log info message\"\"\"\n        log_entry = {\n            'timestamp': datetime.utcnow(),\n            'level': 'INFO',\n            'message': message\n        }\n        self.migration_log.append(log_entry)\n        print(f\"[INFO] {message}\")\n\n    def _log_error(self, message: str):\n        \"\"\"Log error message\"\"\"\n        log_entry = {\n            'timestamp': datetime.utcnow(),\n            'level': 'ERROR',\n            'message': message\n        }\n        self.migration_log.append(log_entry)\n        print(f\"[ERROR] {message}\")\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#common-migration-patterns","title":"Common Migration Patterns","text":""},{"location":"atomic/databases/postgresql-advanced/production-migrations/#safe-schema-changes","title":"Safe Schema Changes","text":"<pre><code>class SafeSchemaChanges:\n    \"\"\"Patterns for safe schema modifications\"\"\"\n\n    @staticmethod\n    def add_nullable_column() -&gt; MigrationStep:\n        \"\"\"Add nullable column (safe operation)\"\"\"\n        return MigrationStep(\n            id=\"add_nullable_column\",\n            description=\"Add nullable email_verified column to users table\",\n            sql_up=\"\"\"\n                ALTER TABLE users\n                ADD COLUMN email_verified BOOLEAN DEFAULT NULL;\n            \"\"\",\n            sql_down=\"\"\"\n                ALTER TABLE users\n                DROP COLUMN email_verified;\n            \"\"\",\n            migration_type=MigrationType.SCHEMA_CHANGE,\n            risk_level=MigrationRisk.LOW,\n            estimated_duration=5,\n            requires_downtime=False,\n            validation_query=\"\"\"\n                SELECT COUNT(*) FROM information_schema.columns\n                WHERE table_name = 'users' AND column_name = 'email_verified'\n            \"\"\"\n        )\n\n    @staticmethod\n    def add_column_with_default() -&gt; List[MigrationStep]:\n        \"\"\"Add column with default value (multi-step for large tables)\"\"\"\n        return [\n            MigrationStep(\n                id=\"add_column_nullable\",\n                description=\"Add status column as nullable first\",\n                sql_up=\"ALTER TABLE orders ADD COLUMN status VARCHAR(20) DEFAULT NULL;\",\n                sql_down=\"ALTER TABLE orders DROP COLUMN status;\",\n                migration_type=MigrationType.SCHEMA_CHANGE,\n                risk_level=MigrationRisk.LOW,\n                estimated_duration=10\n            ),\n            MigrationStep(\n                id=\"backfill_status_column\",\n                description=\"Backfill status column with default values\",\n                sql_up=\"\"\"\n                    UPDATE orders\n                    SET status = 'pending'\n                    WHERE status IS NULL;\n                \"\"\",\n                sql_down=\"-- No rollback needed for data\",\n                migration_type=MigrationType.DATA_MIGRATION,\n                risk_level=MigrationRisk.MEDIUM,\n                estimated_duration=300,  # 5 minutes for large table\n                validation_query=\"SELECT COUNT(*) FROM orders WHERE status IS NULL\"\n            ),\n            MigrationStep(\n                id=\"add_not_null_constraint\",\n                description=\"Add NOT NULL constraint to status column\",\n                sql_up=\"ALTER TABLE orders ALTER COLUMN status SET NOT NULL;\",\n                sql_down=\"ALTER TABLE orders ALTER COLUMN status DROP NOT NULL;\",\n                migration_type=MigrationType.CONSTRAINT_ADDITION,\n                risk_level=MigrationRisk.MEDIUM,\n                estimated_duration=30\n            ),\n            MigrationStep(\n                id=\"set_default_value\",\n                description=\"Set default value for future records\",\n                sql_up=\"ALTER TABLE orders ALTER COLUMN status SET DEFAULT 'pending';\",\n                sql_down=\"ALTER TABLE orders ALTER COLUMN status DROP DEFAULT;\",\n                migration_type=MigrationType.SCHEMA_CHANGE,\n                risk_level=MigrationRisk.LOW,\n                estimated_duration=5\n            )\n        ]\n\n    @staticmethod\n    def rename_column() -&gt; List[MigrationStep]:\n        \"\"\"Rename column safely using dual-write approach\"\"\"\n        return [\n            MigrationStep(\n                id=\"add_new_column\",\n                description=\"Add new column with correct name\",\n                sql_up=\"ALTER TABLE users ADD COLUMN username VARCHAR(100);\",\n                sql_down=\"ALTER TABLE users DROP COLUMN username;\",\n                migration_type=MigrationType.SCHEMA_CHANGE,\n                risk_level=MigrationRisk.LOW,\n                estimated_duration=10\n            ),\n            MigrationStep(\n                id=\"copy_data_to_new_column\",\n                description=\"Copy data from old column to new column\",\n                sql_up=\"UPDATE users SET username = user_name WHERE username IS NULL;\",\n                sql_down=\"-- Data rollback handled by dropping column\",\n                migration_type=MigrationType.DATA_MIGRATION,\n                risk_level=MigrationRisk.MEDIUM,\n                estimated_duration=120\n            ),\n            MigrationStep(\n                id=\"add_triggers_for_dual_write\",\n                description=\"Add triggers to keep columns in sync\",\n                sql_up=\"\"\"\n                    CREATE OR REPLACE FUNCTION sync_username()\n                    RETURNS TRIGGER AS $$\n                    BEGIN\n                        IF TG_OP = 'INSERT' OR TG_OP = 'UPDATE' THEN\n                            NEW.username = NEW.user_name;\n                            NEW.user_name = NEW.username;\n                            RETURN NEW;\n                        END IF;\n                        RETURN NULL;\n                    END;\n                    $$ LANGUAGE plpgsql;\n\n                    CREATE TRIGGER sync_username_trigger\n                        BEFORE INSERT OR UPDATE ON users\n                        FOR EACH ROW EXECUTE FUNCTION sync_username();\n                \"\"\",\n                sql_down=\"\"\"\n                    DROP TRIGGER IF EXISTS sync_username_trigger ON users;\n                    DROP FUNCTION IF EXISTS sync_username();\n                \"\"\",\n                migration_type=MigrationType.SCHEMA_CHANGE,\n                risk_level=MigrationRisk.MEDIUM,\n                estimated_duration=10\n            )\n            # Note: Later migration would remove old column and triggers\n        ]\n\n    @staticmethod\n    def create_index_concurrently() -&gt; MigrationStep:\n        \"\"\"Create index without blocking writes\"\"\"\n        return MigrationStep(\n            id=\"create_index_concurrent\",\n            description=\"Create index on users.email concurrently\",\n            sql_up=\"CREATE INDEX CONCURRENTLY idx_users_email ON users(email);\",\n            sql_down=\"DROP INDEX IF EXISTS idx_users_email;\",\n            migration_type=MigrationType.INDEX_CREATION,\n            risk_level=MigrationRisk.MEDIUM,\n            estimated_duration=600,  # 10 minutes for large table\n            requires_downtime=False,\n            validation_query=\"\"\"\n                SELECT COUNT(*) FROM pg_indexes\n                WHERE tablename = 'users' AND indexname = 'idx_users_email'\n            \"\"\"\n        )\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#data-migrations","title":"Data Migrations","text":"<pre><code>class DataMigrationPatterns:\n    \"\"\"Safe patterns for data migrations\"\"\"\n\n    @staticmethod\n    def batch_data_migration() -&gt; MigrationStep:\n        \"\"\"Migrate data in batches to avoid long locks\"\"\"\n        return MigrationStep(\n            id=\"batch_migrate_user_preferences\",\n            description=\"Migrate user preferences to JSONB format in batches\",\n            sql_up=\"\"\"\n                DO $$\n                DECLARE\n                    batch_size INTEGER := 1000;\n                    total_processed INTEGER := 0;\n                    batch_count INTEGER;\n                BEGIN\n                    LOOP\n                        -- Process batch\n                        UPDATE users\n                        SET preferences_json = jsonb_build_object(\n                            'theme', COALESCE(theme_preference, 'light'),\n                            'language', COALESCE(language_preference, 'en'),\n                            'notifications', COALESCE(email_notifications, true)\n                        )\n                        WHERE id IN (\n                            SELECT id FROM users\n                            WHERE preferences_json IS NULL\n                            ORDER BY id\n                            LIMIT batch_size\n                        );\n\n                        GET DIAGNOSTICS batch_count = ROW_COUNT;\n                        total_processed := total_processed + batch_count;\n\n                        -- Log progress\n                        RAISE NOTICE 'Processed % users total', total_processed;\n\n                        -- Exit if no more rows to process\n                        EXIT WHEN batch_count = 0;\n\n                        -- Small delay between batches\n                        PERFORM pg_sleep(0.1);\n                    END LOOP;\n\n                    RAISE NOTICE 'Migration completed. Total users processed: %', total_processed;\n                END $$;\n            \"\"\",\n            sql_down=\"\"\"\n                UPDATE users SET preferences_json = NULL\n                WHERE preferences_json IS NOT NULL;\n            \"\"\",\n            migration_type=MigrationType.DATA_MIGRATION,\n            risk_level=MigrationRisk.MEDIUM,\n            estimated_duration=1800,  # 30 minutes\n            validation_query=\"\"\"\n                SELECT COUNT(*) FROM users WHERE preferences_json IS NULL\n            \"\"\"\n        )\n\n    @staticmethod\n    def conditional_data_update() -&gt; MigrationStep:\n        \"\"\"Update data conditionally with validation\"\"\"\n        return MigrationStep(\n            id=\"normalize_email_addresses\",\n            description=\"Normalize email addresses to lowercase\",\n            sql_up=\"\"\"\n                UPDATE users\n                SET email = LOWER(TRIM(email))\n                WHERE email != LOWER(TRIM(email))\n                AND email ~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$';\n            \"\"\",\n            sql_down=\"\"\"\n                -- Cannot reliably rollback email normalization\n                -- Original case information is lost\n            \"\"\",\n            migration_type=MigrationType.DATA_MIGRATION,\n            risk_level=MigrationRisk.HIGH,\n            estimated_duration=300,\n            validation_query=\"\"\"\n                SELECT COUNT(*) FROM users\n                WHERE email != LOWER(TRIM(email))\n            \"\"\"\n        )\n\nclass LargeTableMigration:\n    \"\"\"Strategies for migrating large tables\"\"\"\n\n    @staticmethod\n    def partition_table_migration() -&gt; List[MigrationStep]:\n        \"\"\"Convert table to partitioned table\"\"\"\n        return [\n            MigrationStep(\n                id=\"create_partitioned_table\",\n                description=\"Create new partitioned orders table\",\n                sql_up=\"\"\"\n                    CREATE TABLE orders_partitioned (\n                        LIKE orders INCLUDING ALL\n                    ) PARTITION BY RANGE (created_at);\n\n                    -- Create partitions for current and future months\n                    CREATE TABLE orders_2023_01 PARTITION OF orders_partitioned\n                        FOR VALUES FROM ('2023-01-01') TO ('2023-02-01');\n                    CREATE TABLE orders_2023_02 PARTITION OF orders_partitioned\n                        FOR VALUES FROM ('2023-02-01') TO ('2023-03-01');\n                    -- Add more partitions as needed\n                \"\"\",\n                sql_down=\"DROP TABLE IF EXISTS orders_partitioned CASCADE;\",\n                migration_type=MigrationType.SCHEMA_CHANGE,\n                risk_level=MigrationRisk.MEDIUM,\n                estimated_duration=60\n            ),\n            MigrationStep(\n                id=\"migrate_data_to_partitioned\",\n                description=\"Migrate data to partitioned table in chunks\",\n                sql_up=\"\"\"\n                    DO $$\n                    DECLARE\n                        start_date DATE := '2023-01-01';\n                        end_date DATE := '2023-01-02';\n                        chunk_size INTEGER := 10000;\n                    BEGIN\n                        WHILE start_date &lt; CURRENT_DATE LOOP\n                            INSERT INTO orders_partitioned\n                            SELECT * FROM orders\n                            WHERE created_at &gt;= start_date\n                            AND created_at &lt; end_date\n                            ORDER BY id\n                            LIMIT chunk_size;\n\n                            start_date := start_date + INTERVAL '1 day';\n                            end_date := end_date + INTERVAL '1 day';\n\n                            -- Progress tracking\n                            RAISE NOTICE 'Migrated data for %', start_date - INTERVAL '1 day';\n\n                            -- Prevent overwhelming the system\n                            PERFORM pg_sleep(1);\n                        END LOOP;\n                    END $$;\n                \"\"\",\n                sql_down=\"TRUNCATE orders_partitioned;\",\n                migration_type=MigrationType.DATA_MIGRATION,\n                risk_level=MigrationRisk.HIGH,\n                estimated_duration=7200  # 2 hours\n            )\n        ]\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#rollback-strategies","title":"Rollback Strategies","text":""},{"location":"atomic/databases/postgresql-advanced/production-migrations/#automated-rollback-system","title":"Automated Rollback System","text":"<pre><code>class MigrationRollback:\n    \"\"\"Automated rollback capabilities\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n\n    async def create_rollback_plan(self, executed_steps: List[Dict]) -&gt; List[MigrationStep]:\n        \"\"\"Create rollback plan from executed steps\"\"\"\n        rollback_steps = []\n\n        # Reverse the order of executed steps\n        for step_result in reversed(executed_steps):\n            if step_result['success']:\n                # Find original step and create rollback\n                rollback_step = MigrationStep(\n                    id=f\"rollback_{step_result['step_id']}\",\n                    description=f\"Rollback: {step_result['description']}\",\n                    sql_up=step_result.get('sql_down', '-- No rollback defined'),\n                    sql_down=step_result.get('sql_up', '-- Original operation'),\n                    migration_type=MigrationType.ROLLBACK,\n                    risk_level=MigrationRisk.HIGH,\n                    estimated_duration=step_result['duration']\n                )\n                rollback_steps.append(rollback_step)\n\n        return rollback_steps\n\n    async def validate_rollback_safety(self, rollback_steps: List[MigrationStep]) -&gt; Dict[str, Any]:\n        \"\"\"Validate that rollback is safe to execute\"\"\"\n        safety_checks = {\n            'data_loss_risk': False,\n            'dependency_issues': [],\n            'validation_failures': [],\n            'safe_to_rollback': True\n        }\n\n        for step in rollback_steps:\n            # Check for potential data loss\n            if 'DROP COLUMN' in step.sql_up.upper():\n                safety_checks['data_loss_risk'] = True\n                safety_checks['safe_to_rollback'] = False\n\n            # Check for dependency issues\n            if 'DROP TABLE' in step.sql_up.upper():\n                table_name = self._extract_table_name(step.sql_up)\n                dependencies = await self._check_table_dependencies(table_name)\n                if dependencies:\n                    safety_checks['dependency_issues'].append({\n                        'table': table_name,\n                        'dependencies': dependencies\n                    })\n\n        return safety_checks\n\n    async def _check_table_dependencies(self, table_name: str) -&gt; List[str]:\n        \"\"\"Check for foreign key dependencies\"\"\"\n        from sqlalchemy import text\n\n        result = await self.session.execute(text(\"\"\"\n            SELECT\n                tc.table_name,\n                kcu.column_name\n            FROM information_schema.table_constraints tc\n            JOIN information_schema.key_column_usage kcu\n                ON tc.constraint_name = kcu.constraint_name\n            JOIN information_schema.constraint_column_usage ccu\n                ON ccu.constraint_name = tc.constraint_name\n            WHERE tc.constraint_type = 'FOREIGN KEY'\n            AND ccu.table_name = :table_name\n        \"\"\"), {'table_name': table_name})\n\n        return [f\"{row.table_name}.{row.column_name}\" for row in result]\n\nclass BackupIntegration:\n    \"\"\"Integration with backup systems for safe migrations\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n\n    async def create_pre_migration_backup(self, migration_version: str) -&gt; str:\n        \"\"\"Create backup before migration\"\"\"\n        backup_name = f\"pre_migration_{migration_version}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n\n        # This would integrate with your backup system\n        # Example using pg_dump\n        backup_command = f\"\"\"\n            pg_dump --verbose --format=custom --no-owner --no-privileges\n            --file=/backups/{backup_name}.dump\n            {self._get_database_url()}\n        \"\"\"\n\n        # Execute backup (implementation depends on your environment)\n        # await self._execute_backup_command(backup_command)\n\n        return backup_name\n\n    async def verify_backup_integrity(self, backup_name: str) -&gt; bool:\n        \"\"\"Verify backup integrity\"\"\"\n        # Implementation would verify backup file\n        # and optionally test restore to staging environment\n        return True\n\n    async def restore_from_backup(self, backup_name: str, target_db: str = None) -&gt; bool:\n        \"\"\"Restore database from backup\"\"\"\n        restore_command = f\"\"\"\n            pg_restore --verbose --clean --no-owner --no-privileges\n            --dbname={target_db or self._get_database_url()}\n            /backups/{backup_name}.dump\n        \"\"\"\n\n        # Execute restore (implementation depends on your environment)\n        # return await self._execute_restore_command(restore_command)\n        return True\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#migration-testing-and-validation","title":"Migration Testing and Validation","text":""},{"location":"atomic/databases/postgresql-advanced/production-migrations/#migration-testing-framework","title":"Migration Testing Framework","text":"<pre><code>class MigrationTester:\n    \"\"\"Framework for testing migrations\"\"\"\n\n    def __init__(self, test_db_session):\n        self.session = test_db_session\n\n    async def test_migration_plan(self, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Test complete migration plan\"\"\"\n        test_results = {\n            'plan_version': plan.version,\n            'test_passed': True,\n            'step_results': [],\n            'performance_metrics': {},\n            'validation_results': []\n        }\n\n        # Create test data\n        await self._create_test_data()\n\n        try:\n            # Test forward migration\n            runner = ProductionMigrationRunner(self.session, dry_run=False)\n            migration_result = await runner.execute_migration_plan(plan)\n\n            test_results['step_results'] = migration_result\n\n            # Validate data integrity\n            integrity_check = await self._validate_data_integrity()\n            test_results['validation_results'].append(integrity_check)\n\n            # Test rollback\n            if migration_result['success']:\n                rollback_tester = MigrationRollback(self.session)\n                rollback_steps = await rollback_tester.create_rollback_plan(\n                    migration_result.get('completed_steps', [])\n                )\n\n                # Execute rollback\n                rollback_plan = MigrationPlan(\n                    version=f\"{plan.version}_rollback\",\n                    description=f\"Rollback for {plan.version}\",\n                    steps=rollback_steps,\n                    total_estimated_duration=sum(s.estimated_duration for s in rollback_steps),\n                    requires_maintenance_window=False,\n                    rollback_strategy=\"automated\",\n                    validation_checklist=[]\n                )\n\n                rollback_result = await runner.execute_migration_plan(rollback_plan)\n                test_results['rollback_results'] = rollback_result\n\n        except Exception as e:\n            test_results['test_passed'] = False\n            test_results['error'] = str(e)\n\n        return test_results\n\n    async def _create_test_data(self):\n        \"\"\"Create realistic test data\"\"\"\n        # Implementation would create representative test data\n        # that exercises the migration paths\n        pass\n\n    async def _validate_data_integrity(self) -&gt; Dict[str, Any]:\n        \"\"\"Validate data integrity after migration\"\"\"\n        from sqlalchemy import text\n\n        checks = {\n            'foreign_key_violations': 0,\n            'null_constraint_violations': 0,\n            'unique_constraint_violations': 0,\n            'data_consistency_issues': []\n        }\n\n        # Check foreign key constraints\n        fk_violations = await self.session.execute(text(\"\"\"\n            SELECT conname, conrelid::regclass, confrelid::regclass\n            FROM pg_constraint\n            WHERE contype = 'f'\n            AND NOT EXISTS (\n                SELECT 1 FROM pg_trigger\n                WHERE tgconstraint = pg_constraint.oid\n                AND tgenabled = 'O'\n            )\n        \"\"\"))\n\n        checks['foreign_key_violations'] = len(list(fk_violations))\n\n        return checks\n\nclass PerformanceImpactAnalyzer:\n    \"\"\"Analyze performance impact of migrations\"\"\"\n\n    def __init__(self, db_session):\n        self.session = db_session\n\n    async def analyze_migration_impact(self, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Analyze potential performance impact\"\"\"\n        impact_analysis = {\n            'estimated_duration': plan.total_estimated_duration,\n            'lock_impact': [],\n            'index_impact': [],\n            'storage_impact': 0,\n            'read_performance_impact': 'none',\n            'write_performance_impact': 'none'\n        }\n\n        for step in plan.steps:\n            # Analyze locking impact\n            if 'ALTER TABLE' in step.sql_up.upper():\n                impact_analysis['lock_impact'].append({\n                    'step': step.id,\n                    'lock_type': 'ACCESS EXCLUSIVE',\n                    'duration': step.estimated_duration,\n                    'affected_table': self._extract_table_name(step.sql_up)\n                })\n\n            # Analyze index impact\n            if 'CREATE INDEX' in step.sql_up.upper():\n                if 'CONCURRENTLY' not in step.sql_up.upper():\n                    impact_analysis['write_performance_impact'] = 'high'\n                else:\n                    impact_analysis['write_performance_impact'] = 'low'\n\n        return impact_analysis\n\n    def _extract_table_name(self, sql: str) -&gt; str:\n        \"\"\"Extract table name from SQL statement\"\"\"\n        # Simple regex to extract table name\n        import re\n        match = re.search(r'(?:ALTER|DROP|CREATE)\\s+TABLE\\s+(\\w+)', sql, re.IGNORECASE)\n        return match.group(1) if match else 'unknown'\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#production-deployment-workflow","title":"Production Deployment Workflow","text":""},{"location":"atomic/databases/postgresql-advanced/production-migrations/#automated-deployment-pipeline","title":"Automated Deployment Pipeline","text":"<pre><code>class MigrationDeploymentPipeline:\n    \"\"\"Production deployment pipeline for migrations\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.environments = ['staging', 'production']\n\n    async def deploy_migration(self, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Deploy migration through all environments\"\"\"\n        deployment_results = {}\n\n        for env in self.environments:\n            env_result = await self._deploy_to_environment(plan, env)\n            deployment_results[env] = env_result\n\n            # Stop deployment if staging fails\n            if env == 'staging' and not env_result['success']:\n                break\n\n        return deployment_results\n\n    async def _deploy_to_environment(self, plan: MigrationPlan, environment: str) -&gt; Dict[str, Any]:\n        \"\"\"Deploy to specific environment\"\"\"\n        env_config = self.config[environment]\n\n        # Create database session for environment\n        db_session = self._create_db_session(env_config)\n\n        # Pre-deployment checks\n        pre_checks = await self._pre_deployment_checks(db_session, plan)\n        if not pre_checks['passed']:\n            return {\n                'environment': environment,\n                'success': False,\n                'stage': 'pre_checks',\n                'issues': pre_checks['issues']\n            }\n\n        # Create backup if production\n        backup_name = None\n        if environment == 'production':\n            backup_integration = BackupIntegration(db_session)\n            backup_name = await backup_integration.create_pre_migration_backup(plan.version)\n\n        try:\n            # Execute migration\n            runner = ProductionMigrationRunner(db_session)\n            result = await runner.execute_migration_plan(plan)\n\n            # Post-deployment validation\n            validation_result = await self._post_deployment_validation(db_session, plan)\n\n            return {\n                'environment': environment,\n                'success': result['success'] and validation_result['passed'],\n                'migration_result': result,\n                'validation_result': validation_result,\n                'backup_name': backup_name\n            }\n\n        except Exception as e:\n            # Automatic rollback on production failure\n            if environment == 'production' and backup_name:\n                await self._emergency_restore(db_session, backup_name)\n\n            return {\n                'environment': environment,\n                'success': False,\n                'error': str(e),\n                'backup_restored': backup_name is not None\n            }\n\n    async def _pre_deployment_checks(self, session, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Pre-deployment safety checks\"\"\"\n        checks = {\n            'passed': True,\n            'issues': []\n        }\n\n        # Check replication lag\n        replication_lag = await self._check_replication_lag(session)\n        if replication_lag &gt; 30:  # 30 seconds threshold\n            checks['passed'] = False\n            checks['issues'].append(f\"High replication lag: {replication_lag}s\")\n\n        # Check active connections\n        active_connections = await self._get_active_connections(session)\n        if active_connections &gt; 100:  # Connection threshold\n            checks['passed'] = False\n            checks['issues'].append(f\"Too many active connections: {active_connections}\")\n\n        # Validate migration syntax\n        syntax_check = await self._validate_migration_syntax(session, plan)\n        if not syntax_check['valid']:\n            checks['passed'] = False\n            checks['issues'].extend(syntax_check['errors'])\n\n        return checks\n\n    async def _post_deployment_validation(self, session, plan: MigrationPlan) -&gt; Dict[str, Any]:\n        \"\"\"Post-deployment validation\"\"\"\n        validation = {\n            'passed': True,\n            'checks': []\n        }\n\n        # Run validation queries from migration steps\n        for step in plan.steps:\n            if step.validation_query:\n                try:\n                    result = await session.execute(text(step.validation_query))\n                    validation['checks'].append({\n                        'step': step.id,\n                        'passed': True,\n                        'result': result.scalar()\n                    })\n                except Exception as e:\n                    validation['passed'] = False\n                    validation['checks'].append({\n                        'step': step.id,\n                        'passed': False,\n                        'error': str(e)\n                    })\n\n        return validation\n</code></pre>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#related-documentation","title":"Related Documentation","text":"<ul> <li>Performance Optimization</li> <li>Complex Relationship Modeling</li> <li>Multi-tenant Patterns</li> <li>PostgreSQL Basic Setup</li> </ul>"},{"location":"atomic/databases/postgresql-advanced/production-migrations/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Safety First:</li> <li>Always create backups before production migrations</li> <li>Test migrations thoroughly in staging environment</li> <li>Use concurrent operations where possible</li> <li> <p>Implement proper rollback strategies</p> </li> <li> <p>Zero-Downtime Strategies:</p> </li> <li>Add columns as nullable first, then populate and add constraints</li> <li>Use dual-write patterns for column renames</li> <li>Create indexes concurrently</li> <li> <p>Migrate data in batches</p> </li> <li> <p>Risk Management:</p> </li> <li>Classify migrations by risk level</li> <li>Have emergency rollback procedures</li> <li>Monitor performance impact</li> <li> <p>Validate data integrity</p> </li> <li> <p>Automation:</p> </li> <li>Use automated deployment pipelines</li> <li>Implement comprehensive testing</li> <li>Include performance impact analysis</li> <li> <p>Maintain detailed migration logs</p> </li> <li> <p>Monitoring:</p> </li> <li>Track migration progress and performance</li> <li>Monitor replication lag during migrations</li> <li>Set up alerts for migration failures</li> <li>Validate post-migration system health</li> </ol>"},{"location":"atomic/external-integrations/api-rate-limiting/","title":"API Rate Limiting Patterns","text":"<p>Comprehensive guide for implementing rate limiting in external API integrations with Redis-based storage, distributed algorithms, and graceful degradation.</p>"},{"location":"atomic/external-integrations/api-rate-limiting/#core-rate-limiting-service","title":"Core Rate Limiting Service","text":"<pre><code>from typing import Dict, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nimport asyncio\nimport redis.asyncio as redis\nfrom dataclasses import dataclass\nimport json\n\nclass RateLimitAlgorithm(Enum):\n    TOKEN_BUCKET = \"token_bucket\"\n    SLIDING_WINDOW = \"sliding_window\"\n    FIXED_WINDOW = \"fixed_window\"\n    LEAKY_BUCKET = \"leaky_bucket\"\n\n@dataclass\nclass RateLimitConfig:\n    requests_per_window: int\n    window_seconds: int\n    algorithm: RateLimitAlgorithm = RateLimitAlgorithm.SLIDING_WINDOW\n    burst_requests: Optional[int] = None  # For token bucket\n    recovery_seconds: Optional[int] = None  # For circuit breaker\n\nclass RateLimitService:\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n\n    async def check_rate_limit(\n        self,\n        identifier: str,\n        config: RateLimitConfig,\n        namespace: str = \"api\"\n    ) -&gt; Tuple[bool, Dict[str, any]]:\n        \"\"\"Check if request is within rate limits\"\"\"\n        key = f\"rate_limit:{namespace}:{identifier}\"\n\n        if config.algorithm == RateLimitAlgorithm.SLIDING_WINDOW:\n            return await self._sliding_window_check(key, config)\n        elif config.algorithm == RateLimitAlgorithm.TOKEN_BUCKET:\n            return await self._token_bucket_check(key, config)\n        elif config.algorithm == RateLimitAlgorithm.FIXED_WINDOW:\n            return await self._fixed_window_check(key, config)\n        else:\n            raise ValueError(f\"Unsupported algorithm: {config.algorithm}\")\n\n    async def _sliding_window_check(self, key: str, config: RateLimitConfig) -&gt; Tuple[bool, Dict]:\n        \"\"\"Sliding window rate limiting with Redis sorted sets\"\"\"\n        now = datetime.now().timestamp()\n        window_start = now - config.window_seconds\n\n        pipe = self.redis.pipeline()\n        # Remove old entries\n        pipe.zremrangebyscore(key, 0, window_start)\n        # Count current requests\n        pipe.zcard(key)\n        # Add current request\n        pipe.zadd(key, {str(now): now})\n        # Set expiration\n        pipe.expire(key, config.window_seconds + 10)\n\n        results = await pipe.execute()\n        current_count = results[1]\n\n        if current_count &lt; config.requests_per_window:\n            return True, {\n                \"allowed\": True,\n                \"current_count\": current_count + 1,\n                \"limit\": config.requests_per_window,\n                \"window_seconds\": config.window_seconds,\n                \"reset_time\": now + config.window_seconds\n            }\n        else:\n            # Remove the request we just added since it's not allowed\n            await self.redis.zrem(key, str(now))\n            return False, {\n                \"allowed\": False,\n                \"current_count\": current_count,\n                \"limit\": config.requests_per_window,\n                \"window_seconds\": config.window_seconds,\n                \"retry_after\": config.window_seconds\n            }\n\n    async def _token_bucket_check(self, key: str, config: RateLimitConfig) -&gt; Tuple[bool, Dict]:\n        \"\"\"Token bucket algorithm implementation\"\"\"\n        bucket_key = f\"{key}:bucket\"\n        now = datetime.now().timestamp()\n\n        # Get current bucket state\n        bucket_data = await self.redis.get(bucket_key)\n        if bucket_data:\n            bucket = json.loads(bucket_data)\n            last_refill = bucket[\"last_refill\"]\n            tokens = bucket[\"tokens\"]\n        else:\n            last_refill = now\n            tokens = config.burst_requests or config.requests_per_window\n\n        # Calculate tokens to add\n        time_passed = now - last_refill\n        tokens_to_add = (time_passed / config.window_seconds) * config.requests_per_window\n        tokens = min(\n            config.burst_requests or config.requests_per_window,\n            tokens + tokens_to_add\n        )\n\n        if tokens &gt;= 1:\n            tokens -= 1\n            bucket_data = json.dumps({\n                \"tokens\": tokens,\n                \"last_refill\": now\n            })\n            await self.redis.setex(bucket_key, config.window_seconds * 2, bucket_data)\n\n            return True, {\n                \"allowed\": True,\n                \"tokens_remaining\": int(tokens),\n                \"bucket_capacity\": config.burst_requests or config.requests_per_window\n            }\n        else:\n            return False, {\n                \"allowed\": False,\n                \"tokens_remaining\": 0,\n                \"retry_after\": (1 - tokens) * (config.window_seconds / config.requests_per_window)\n            }\n\nclass DistributedRateLimiter:\n    \"\"\"Rate limiter that works across multiple service instances\"\"\"\n\n    def __init__(self, redis_client: redis.Redis, service_id: str):\n        self.redis = redis_client\n        self.service_id = service_id\n        self.rate_limit_service = RateLimitService(redis_client)\n\n    async def limit_external_api(\n        self,\n        api_name: str,\n        endpoint: str,\n        config: RateLimitConfig,\n        user_id: Optional[str] = None\n    ) -&gt; Tuple[bool, Dict]:\n        \"\"\"Apply rate limiting for external API calls\"\"\"\n\n        # Create hierarchical identifiers\n        identifiers = [\n            f\"api:{api_name}\",  # Global API limit\n            f\"api:{api_name}:endpoint:{endpoint}\",  # Per-endpoint limit\n        ]\n\n        if user_id:\n            identifiers.extend([\n                f\"user:{user_id}:api:{api_name}\",  # Per-user API limit\n                f\"user:{user_id}:api:{api_name}:endpoint:{endpoint}\"  # Per-user endpoint limit\n            ])\n\n        # Check all limits - fail if any exceeded\n        for identifier in identifiers:\n            allowed, info = await self.rate_limit_service.check_rate_limit(\n                identifier, config, namespace=\"external_api\"\n            )\n            if not allowed:\n                info[\"failed_check\"] = identifier\n                return False, info\n\n        return True, {\"allowed\": True, \"checks_passed\": len(identifiers)}\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#api-client-with-rate-limiting","title":"API Client with Rate Limiting","text":"<pre><code>import aiohttp\nfrom typing import Optional, Dict, Any\nimport asyncio\nfrom datetime import datetime, timedelta\n\nclass RateLimitedAPIClient:\n    \"\"\"HTTP client with built-in rate limiting and retry logic\"\"\"\n\n    def __init__(\n        self,\n        base_url: str,\n        rate_limiter: DistributedRateLimiter,\n        default_config: RateLimitConfig,\n        timeout: int = 30\n    ):\n        self.base_url = base_url.rstrip('/')\n        self.rate_limiter = rate_limiter\n        self.default_config = default_config\n        self.timeout = aiohttp.ClientTimeout(total=timeout)\n        self.session: Optional[aiohttp.ClientSession] = None\n\n    async def __aenter__(self):\n        self.session = aiohttp.ClientSession(timeout=self.timeout)\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if self.session:\n            await self.session.close()\n\n    async def request(\n        self,\n        method: str,\n        endpoint: str,\n        user_id: Optional[str] = None,\n        config: Optional[RateLimitConfig] = None,\n        max_retries: int = 3,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Make rate-limited API request with retry logic\"\"\"\n\n        if not self.session:\n            raise RuntimeError(\"Client not initialized. Use 'async with' context manager.\")\n\n        config = config or self.default_config\n        api_name = self._extract_api_name(self.base_url)\n\n        for attempt in range(max_retries + 1):\n            # Check rate limit\n            allowed, limit_info = await self.rate_limiter.limit_external_api(\n                api_name, endpoint, config, user_id\n            )\n\n            if not allowed:\n                if attempt == max_retries:\n                    raise RateLimitExceeded(limit_info)\n\n                # Wait before retry\n                retry_after = limit_info.get(\"retry_after\", 1)\n                await asyncio.sleep(retry_after)\n                continue\n\n            try:\n                url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n                async with self.session.request(method, url, **kwargs) as response:\n\n                    # Handle API-specific rate limit headers\n                    await self._update_from_headers(response.headers, api_name)\n\n                    if response.status == 429:  # Too Many Requests\n                        retry_after = int(response.headers.get(\"Retry-After\", 60))\n                        if attempt &lt; max_retries:\n                            await asyncio.sleep(retry_after)\n                            continue\n                        raise RateLimitExceeded({\n                            \"status\": 429,\n                            \"retry_after\": retry_after,\n                            \"source\": \"api_response\"\n                        })\n\n                    response.raise_for_status()\n                    return {\n                        \"data\": await response.json(),\n                        \"status\": response.status,\n                        \"headers\": dict(response.headers),\n                        \"rate_limit_info\": limit_info\n                    }\n\n            except aiohttp.ClientError as e:\n                if attempt == max_retries:\n                    raise APIClientError(f\"Request failed after {max_retries} retries: {str(e)}\")\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n        raise APIClientError(\"Maximum retries exceeded\")\n\n    async def _update_from_headers(self, headers: Dict[str, str], api_name: str):\n        \"\"\"Update rate limit state from API response headers\"\"\"\n        # Common rate limit headers\n        remaining = headers.get(\"X-RateLimit-Remaining\") or headers.get(\"X-Rate-Limit-Remaining\")\n        reset_time = headers.get(\"X-RateLimit-Reset\") or headers.get(\"X-Rate-Limit-Reset\")\n\n        if remaining and reset_time:\n            # Store API's reported rate limit state\n            key = f\"api_reported:{api_name}:state\"\n            state = {\n                \"remaining\": int(remaining),\n                \"reset_time\": int(reset_time),\n                \"updated_at\": datetime.now().timestamp()\n            }\n            await self.rate_limiter.redis.setex(\n                key, 3600, json.dumps(state)\n            )\n\n    def _extract_api_name(self, url: str) -&gt; str:\n        \"\"\"Extract API name from base URL\"\"\"\n        from urllib.parse import urlparse\n        parsed = urlparse(url)\n        domain = parsed.netloc.lower()\n        # Remove common prefixes\n        if domain.startswith(\"api.\"):\n            domain = domain[4:]\n        return domain.split('.')[0]\n\nclass RateLimitExceeded(Exception):\n    def __init__(self, info: Dict[str, Any]):\n        self.info = info\n        super().__init__(f\"Rate limit exceeded: {info}\")\n\nclass APIClientError(Exception):\n    pass\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, Request, HTTPException, Depends\nfrom fastapi.responses import JSONResponse\nimport redis.asyncio as redis\n\napp = FastAPI()\n\n# Global rate limiter instance\nrate_limiter: Optional[DistributedRateLimiter] = None\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    global rate_limiter\n    redis_client = redis.Redis.from_url(\n        \"redis://localhost:6379\",\n        encoding=\"utf-8\",\n        decode_responses=True\n    )\n    rate_limiter = DistributedRateLimiter(redis_client, \"template_business_api\")\n\nasync def get_rate_limiter() -&gt; DistributedRateLimiter:\n    if not rate_limiter:\n        raise HTTPException(500, \"Rate limiter not initialized\")\n    return rate_limiter\n\nasync def rate_limit_middleware(\n    request: Request,\n    limiter: DistributedRateLimiter = Depends(get_rate_limiter)\n):\n    \"\"\"Apply rate limiting to incoming requests\"\"\"\n\n    # Extract client identifier\n    client_ip = request.client.host\n    user_id = request.headers.get(\"X-User-ID\")  # From auth middleware\n\n    # Configure rate limits based on endpoint\n    if request.url.path.startswith(\"/api/external/\"):\n        config = RateLimitConfig(\n            requests_per_window=100,\n            window_seconds=3600,  # 100 requests per hour\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n    else:\n        config = RateLimitConfig(\n            requests_per_window=1000,\n            window_seconds=3600,  # 1000 requests per hour\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n\n    # Check rate limit\n    identifier = user_id or client_ip\n    allowed, info = await limiter.rate_limit_service.check_rate_limit(\n        identifier, config, namespace=\"incoming\"\n    )\n\n    if not allowed:\n        raise HTTPException(\n            status_code=429,\n            detail=\"Rate limit exceeded\",\n            headers={\n                \"Retry-After\": str(int(info.get(\"retry_after\", 60))),\n                \"X-RateLimit-Limit\": str(info[\"limit\"]),\n                \"X-RateLimit-Remaining\": \"0\",\n                \"X-RateLimit-Reset\": str(int(info.get(\"reset_time\", 0)))\n            }\n        )\n\n    return info\n\n@app.middleware(\"http\")\nasync def add_rate_limit_headers(request: Request, call_next):\n    \"\"\"Add rate limit information to response headers\"\"\"\n\n    try:\n        # Get rate limit info if available\n        rate_info = getattr(request.state, \"rate_limit_info\", None)\n        response = await call_next(request)\n\n        if rate_info:\n            response.headers[\"X-RateLimit-Limit\"] = str(rate_info[\"limit\"])\n            response.headers[\"X-RateLimit-Remaining\"] = str(\n                rate_info[\"limit\"] - rate_info[\"current_count\"]\n            )\n            if \"reset_time\" in rate_info:\n                response.headers[\"X-RateLimit-Reset\"] = str(int(rate_info[\"reset_time\"]))\n\n        return response\n\n    except Exception as e:\n        # Don't let rate limiting break the application\n        return await call_next(request)\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#external-api-integration-examples","title":"External API Integration Examples","text":"<pre><code># Stripe API with rate limiting\nclass StripeRateLimitedClient(RateLimitedAPIClient):\n    def __init__(self, api_key: str, rate_limiter: DistributedRateLimiter):\n        config = RateLimitConfig(\n            requests_per_window=100,  # Stripe allows 100 req/sec\n            window_seconds=1,\n            algorithm=RateLimitAlgorithm.TOKEN_BUCKET,\n            burst_requests=25  # Allow bursts up to 25\n        )\n        super().__init__(\n            \"https://api.stripe.com/v1\",\n            rate_limiter,\n            config\n        )\n        self.headers = {\"Authorization\": f\"Bearer {api_key}\"}\n\n    async def create_payment_intent(self, amount: int, currency: str, user_id: str):\n        return await self.request(\n            \"POST\",\n            \"payment_intents\",\n            user_id=user_id,\n            json={\n                \"amount\": amount,\n                \"currency\": currency\n            },\n            headers=self.headers\n        )\n\n# SendGrid API with rate limiting\nclass SendGridRateLimitedClient(RateLimitedAPIClient):\n    def __init__(self, api_key: str, rate_limiter: DistributedRateLimiter):\n        config = RateLimitConfig(\n            requests_per_window=600,  # SendGrid free tier\n            window_seconds=60,\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n        super().__init__(\n            \"https://api.sendgrid.com/v3\",\n            rate_limiter,\n            config\n        )\n        self.headers = {\"Authorization\": f\"Bearer {api_key}\"}\n\n    async def send_email(self, to_email: str, subject: str, content: str, user_id: str):\n        return await self.request(\n            \"POST\",\n            \"mail/send\",\n            user_id=user_id,\n            json={\n                \"personalizations\": [{\"to\": [{\"email\": to_email}]}],\n                \"from\": {\"email\": \"noreply@example.com\"},\n                \"subject\": subject,\n                \"content\": [{\"type\": \"text/plain\", \"value\": content}]\n            },\n            headers=self.headers\n        )\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#circuit-breaker-integration","title":"Circuit Breaker Integration","text":"<pre><code>from enum import Enum\nfrom datetime import datetime, timedelta\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"\n    OPEN = \"open\"\n    HALF_OPEN = \"half_open\"\n\nclass CircuitBreakerRateLimiter:\n    \"\"\"Combines rate limiting with circuit breaker pattern\"\"\"\n\n    def __init__(self, rate_limiter: DistributedRateLimiter):\n        self.rate_limiter = rate_limiter\n\n    async def check_with_circuit_breaker(\n        self,\n        api_name: str,\n        endpoint: str,\n        config: RateLimitConfig,\n        user_id: Optional[str] = None,\n        failure_threshold: int = 5,\n        recovery_timeout: int = 60\n    ) -&gt; Tuple[bool, Dict[str, Any]]:\n        \"\"\"Check rate limit with circuit breaker protection\"\"\"\n\n        circuit_key = f\"circuit:{api_name}:{endpoint}\"\n\n        # Check circuit state\n        circuit_data = await self.rate_limiter.redis.get(circuit_key)\n        if circuit_data:\n            circuit = json.loads(circuit_data)\n            state = CircuitState(circuit[\"state\"])\n\n            if state == CircuitState.OPEN:\n                # Check if recovery period has passed\n                open_time = datetime.fromisoformat(circuit[\"open_time\"])\n                if datetime.now() - open_time &gt; timedelta(seconds=recovery_timeout):\n                    # Move to half-open\n                    circuit[\"state\"] = CircuitState.HALF_OPEN.value\n                    await self.rate_limiter.redis.setex(\n                        circuit_key, recovery_timeout * 2, json.dumps(circuit)\n                    )\n                else:\n                    return False, {\n                        \"allowed\": False,\n                        \"reason\": \"circuit_breaker_open\",\n                        \"retry_after\": recovery_timeout\n                    }\n\n        # Apply rate limiting\n        allowed, rate_info = await self.rate_limiter.limit_external_api(\n            api_name, endpoint, config, user_id\n        )\n\n        if not allowed:\n            # Increment failure count\n            await self._record_failure(circuit_key, failure_threshold)\n\n        return allowed, rate_info\n\n    async def _record_failure(self, circuit_key: str, failure_threshold: int):\n        \"\"\"Record API failure and potentially open circuit\"\"\"\n        failure_key = f\"{circuit_key}:failures\"\n\n        # Increment failure count\n        failures = await self.rate_limiter.redis.incr(failure_key)\n        await self.rate_limiter.redis.expire(failure_key, 300)  # 5 minute window\n\n        if failures &gt;= failure_threshold:\n            # Open circuit breaker\n            circuit_data = {\n                \"state\": CircuitState.OPEN.value,\n                \"open_time\": datetime.now().isoformat(),\n                \"failure_count\": failures\n            }\n            await self.rate_limiter.redis.setex(\n                circuit_key, 3600, json.dumps(circuit_data)\n            )\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#testing-rate-limiting","title":"Testing Rate Limiting","text":"<pre><code>import pytest\nimport redis.asyncio as redis\nfrom unittest.mock import AsyncMock\n\n@pytest.fixture\nasync def redis_client():\n    client = redis.Redis.from_url(\"redis://localhost:6379/15\")  # Test DB\n    yield client\n    await client.flushdb()  # Clean up\n    await client.close()\n\n@pytest.fixture\nasync def rate_limiter(redis_client):\n    return DistributedRateLimiter(redis_client, \"test-service\")\n\nclass TestRateLimiting:\n\n    async def test_sliding_window_allows_requests_within_limit(self, rate_limiter):\n        config = RateLimitConfig(\n            requests_per_window=5,\n            window_seconds=60,\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n\n        # Should allow first 5 requests\n        for i in range(5):\n            allowed, info = await rate_limiter.limit_external_api(\n                \"test-api\", \"test-endpoint\", config, \"user123\"\n            )\n            assert allowed\n            assert info[\"allowed\"]\n\n    async def test_sliding_window_blocks_requests_over_limit(self, rate_limiter):\n        config = RateLimitConfig(\n            requests_per_window=3,\n            window_seconds=60,\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n\n        # Allow first 3 requests\n        for i in range(3):\n            allowed, _ = await rate_limiter.limit_external_api(\n                \"test-api\", \"test-endpoint\", config, \"user123\"\n            )\n            assert allowed\n\n        # Block 4th request\n        allowed, info = await rate_limiter.limit_external_api(\n            \"test-api\", \"test-endpoint\", config, \"user123\"\n        )\n        assert not allowed\n        assert not info[\"allowed\"]\n        assert \"retry_after\" in info\n\n    async def test_token_bucket_allows_bursts(self, rate_limiter):\n        config = RateLimitConfig(\n            requests_per_window=5,\n            window_seconds=60,\n            algorithm=RateLimitAlgorithm.TOKEN_BUCKET,\n            burst_requests=10\n        )\n\n        # Should allow burst up to 10 requests\n        for i in range(10):\n            allowed, info = await rate_limiter.limit_external_api(\n                \"test-api\", \"test-endpoint\", config, \"user123\"\n            )\n            assert allowed\n\n        # 11th request should be blocked\n        allowed, info = await rate_limiter.limit_external_api(\n            \"test-api\", \"test-endpoint\", config, \"user123\"\n        )\n        assert not allowed\n\n    async def test_different_users_have_separate_limits(self, rate_limiter):\n        config = RateLimitConfig(\n            requests_per_window=2,\n            window_seconds=60,\n            algorithm=RateLimitAlgorithm.SLIDING_WINDOW\n        )\n\n        # User 1 uses up their limit\n        for i in range(2):\n            allowed, _ = await rate_limiter.limit_external_api(\n                \"test-api\", \"test-endpoint\", config, \"user1\"\n            )\n            assert allowed\n\n        # User 1's next request should be blocked\n        allowed, _ = await rate_limiter.limit_external_api(\n            \"test-api\", \"test-endpoint\", config, \"user1\"\n        )\n        assert not allowed\n\n        # User 2 should still be allowed\n        allowed, _ = await rate_limiter.limit_external_api(\n            \"test-api\", \"test-endpoint\", config, \"user2\"\n        )\n        assert allowed\n\n@pytest.mark.asyncio\nasync def test_rate_limited_client_retries_on_429():\n    # Mock session that returns 429 then 200\n    mock_session = AsyncMock()\n    mock_response_429 = AsyncMock()\n    mock_response_429.status = 429\n    mock_response_429.headers = {\"Retry-After\": \"1\"}\n\n    mock_response_200 = AsyncMock()\n    mock_response_200.status = 200\n    mock_response_200.json.return_value = {\"success\": True}\n    mock_response_200.headers = {}\n\n    mock_session.request.side_effect = [\n        AsyncMock(__aenter__=AsyncMock(return_value=mock_response_429)),\n        AsyncMock(__aenter__=AsyncMock(return_value=mock_response_200))\n    ]\n\n    redis_client = AsyncMock()\n    rate_limiter = DistributedRateLimiter(redis_client, \"test\")\n    rate_limiter.limit_external_api = AsyncMock(return_value=(True, {\"allowed\": True}))\n\n    client = RateLimitedAPIClient(\n        \"https://api.example.com\",\n        rate_limiter,\n        RateLimitConfig(10, 60)\n    )\n    client.session = mock_session\n\n    # Should retry and succeed\n    result = await client.request(\"GET\", \"test\", max_retries=2)\n    assert result[\"data\"][\"success\"]\n    assert mock_session.request.call_count == 2\n</code></pre>"},{"location":"atomic/external-integrations/api-rate-limiting/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication &amp; Authorization Guide - JWT tokens and user authentication</li> <li>Payment Gateway Integration - Rate-limited payment processing</li> <li>Communication APIs - Email/SMS rate limiting</li> <li>Webhook Handling - Webhook rate protection</li> </ul>"},{"location":"atomic/external-integrations/api-rate-limiting/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Redis Storage: All rate limiting state stored in Redis for distributed consistency</li> <li>Algorithm Selection: Choose based on API characteristics and traffic patterns</li> <li>Circuit Breaker: Prevents cascade failures when APIs are down</li> <li>Header Integration: Respects API-provided rate limit headers</li> <li>Testing: Comprehensive test coverage for all algorithms and edge cases</li> <li>Monitoring: Log rate limit violations for capacity planning</li> </ol>"},{"location":"atomic/external-integrations/api-rate-limiting/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/basic-setup.md</code> \u2014 FastAPI service configuration</li> <li><code>docs/atomic/infrastructure/redis.md</code> \u2014 Redis for rate limit counters</li> <li><code>docs/atomic/services/fastapi/middleware-configuration.md</code> \u2014 Middleware setup</li> <li><code>docs/atomic/observability/metrics/service-metrics.md</code> \u2014 Rate limit metrics</li> </ul>"},{"location":"atomic/external-integrations/communication-apis/","title":"Communication APIs","text":"<p>Comprehensive guide for integrating communication services (Email, SMS, Push Notifications) in microservices architecture following the Improved Hybrid Approach.</p>"},{"location":"atomic/external-integrations/communication-apis/#overview","title":"Overview","text":"<p>Communication services integration enables applications to send notifications, alerts, and messages to users through various channels. This guide covers integration patterns for email (SendGrid, AWS SES), SMS (Twilio, AWS SNS), and push notifications while maintaining service separation and reliability.</p>"},{"location":"atomic/external-integrations/communication-apis/#architecture-pattern","title":"Architecture Pattern","text":"<p>Communication services follow the dedicated service pattern with centralized message routing and template management.</p> <pre><code>graph TB\n    subgraph \"Business Services\"\n        API[FastAPI Service]\n        BOT[Aiogram Bot]\n        WORKER[AsyncIO Workers]\n    end\n\n    subgraph \"Communication APIs\"\n        COMM_SERVICE[Communication Service :8004]\n        TEMPLATE_SERVICE[Template Service]\n        DELIVERY_TRACKER[Delivery Tracker]\n    end\n\n    subgraph \"External Providers\"\n        SENDGRID[SendGrid]\n        TWILIO[Twilio SMS]\n        AWS_SES[AWS SES]\n        AWS_SNS[AWS SNS]\n        FCM[Firebase FCM]\n        APNS[Apple Push]\n    end\n\n    subgraph \"Infrastructure\"\n        POSTGRES[(PostgreSQL)]\n        REDIS[(Redis - Queue)]\n        RABBIT[RabbitMQ - Events]\n    end\n\n    API --&gt;|HTTP| COMM_SERVICE\n    BOT --&gt;|HTTP| COMM_SERVICE\n    WORKER --&gt;|HTTP| COMM_SERVICE\n\n    COMM_SERVICE --&gt; TEMPLATE_SERVICE\n    COMM_SERVICE --&gt; DELIVERY_TRACKER\n\n    COMM_SERVICE --&gt; SENDGRID\n    COMM_SERVICE --&gt; TWILIO\n    COMM_SERVICE --&gt; AWS_SES\n    COMM_SERVICE --&gt; AWS_SNS\n    COMM_SERVICE --&gt; FCM\n    COMM_SERVICE --&gt; APNS\n\n    COMM_SERVICE --&gt; POSTGRES\n    COMM_SERVICE --&gt; REDIS\n    COMM_SERVICE --&gt; RABBIT</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#email-integration","title":"Email Integration","text":""},{"location":"atomic/external-integrations/communication-apis/#1-sendgrid-integration","title":"1. SendGrid Integration","text":"<pre><code># src/services/communication/email/sendgrid_service.py\nimport sendgrid\nfrom sendgrid.helpers.mail import Mail, Email, To, Content, Attachment\nfrom typing import List, Dict, Any, Optional\nimport base64\nfrom datetime import datetime\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass SendGridService:\n    \"\"\"SendGrid email service implementation.\"\"\"\n\n    def __init__(self):\n        self.api_key = settings.sendgrid_api_key\n        self.client = sendgrid.SendGridAPIClient(api_key=self.api_key)\n        self.default_from_email = settings.default_from_email\n        self.default_from_name = settings.default_from_name or settings.app_name\n\n    async def send_email(\n        self,\n        to_emails: List[str],\n        subject: str,\n        html_content: str,\n        text_content: Optional[str] = None,\n        from_email: Optional[str] = None,\n        from_name: Optional[str] = None,\n        cc_emails: List[str] = None,\n        bcc_emails: List[str] = None,\n        attachments: List[Dict[str, Any]] = None,\n        template_id: Optional[str] = None,\n        template_data: Dict[str, Any] = None,\n        custom_args: Dict[str, str] = None,\n        categories: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send email via SendGrid.\"\"\"\n        try:\n            # Setup sender\n            from_email_obj = Email(\n                email=from_email or self.default_from_email,\n                name=from_name or self.default_from_name\n            )\n\n            # Setup recipients\n            to_list = [To(email=email) for email in to_emails]\n\n            # Create mail object\n            if template_id:\n                # Use template\n                mail = Mail(\n                    from_email=from_email_obj,\n                    to_emails=to_list,\n                    subject=subject\n                )\n                mail.template_id = template_id\n                if template_data:\n                    mail.dynamic_template_data = template_data\n            else:\n                # Use content\n                html_content_obj = Content(\"text/html\", html_content)\n                text_content_obj = Content(\"text/plain\", text_content) if text_content else None\n\n                mail = Mail(\n                    from_email=from_email_obj,\n                    to_emails=to_list,\n                    subject=subject,\n                    html_content=html_content_obj,\n                    plain_text_content=text_content_obj\n                )\n\n            # Add CC recipients\n            if cc_emails:\n                for email in cc_emails:\n                    mail.add_cc(Email(email))\n\n            # Add BCC recipients\n            if bcc_emails:\n                for email in bcc_emails:\n                    mail.add_bcc(Email(email))\n\n            # Add attachments\n            if attachments:\n                for attachment_data in attachments:\n                    attachment = Attachment()\n                    attachment.file_content = attachment_data.get(\"content\")\n                    attachment.file_type = attachment_data.get(\"type\")\n                    attachment.file_name = attachment_data.get(\"filename\")\n                    attachment.disposition = attachment_data.get(\"disposition\", \"attachment\")\n                    mail.add_attachment(attachment)\n\n            # Add custom arguments\n            if custom_args:\n                for key, value in custom_args.items():\n                    mail.add_custom_arg(key, value)\n\n            # Add categories\n            if categories:\n                for category in categories:\n                    mail.add_category(category)\n\n            # Send email\n            response = self.client.send(mail)\n\n            logger.info(f\"Email sent via SendGrid to {len(to_emails)} recipients\")\n\n            return {\n                \"message_id\": response.headers.get(\"X-Message-Id\"),\n                \"status_code\": response.status_code,\n                \"recipients\": to_emails,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"SendGrid email sending failed: {e}\")\n            raise CommunicationError(f\"Email sending failed: {str(e)}\")\n\n    async def send_template_email(\n        self,\n        to_emails: List[str],\n        template_id: str,\n        template_data: Dict[str, Any],\n        from_email: Optional[str] = None,\n        from_name: Optional[str] = None,\n        custom_args: Dict[str, str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send email using SendGrid template.\"\"\"\n        return await self.send_email(\n            to_emails=to_emails,\n            subject=\"\",  # Template defines subject\n            html_content=\"\",  # Template defines content\n            from_email=from_email,\n            from_name=from_name,\n            template_id=template_id,\n            template_data=template_data,\n            custom_args=custom_args\n        )\n\n    async def create_contact(\n        self,\n        email: str,\n        first_name: Optional[str] = None,\n        last_name: Optional[str] = None,\n        custom_fields: Dict[str, Any] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create contact in SendGrid.\"\"\"\n        try:\n            contact_data = {\n                \"email\": email\n            }\n\n            if first_name:\n                contact_data[\"first_name\"] = first_name\n            if last_name:\n                contact_data[\"last_name\"] = last_name\n            if custom_fields:\n                contact_data.update(custom_fields)\n\n            response = self.client.client.marketing.contacts.put(\n                request_body={\"contacts\": [contact_data]}\n            )\n\n            logger.info(f\"Contact created in SendGrid: {email}\")\n\n            return {\n                \"email\": email,\n                \"status_code\": response.status_code,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"SendGrid contact creation failed: {e}\")\n            raise CommunicationError(f\"Contact creation failed: {str(e)}\")\n\n    async def add_to_list(\n        self,\n        list_id: str,\n        contacts: List[Dict[str, Any]]\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Add contacts to SendGrid list.\"\"\"\n        try:\n            response = self.client.client.marketing.contacts.put(\n                request_body={\n                    \"list_ids\": [list_id],\n                    \"contacts\": contacts\n                }\n            )\n\n            logger.info(f\"Added {len(contacts)} contacts to SendGrid list {list_id}\")\n\n            return {\n                \"list_id\": list_id,\n                \"contacts_added\": len(contacts),\n                \"status_code\": response.status_code,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"SendGrid list addition failed: {e}\")\n            raise CommunicationError(f\"List addition failed: {str(e)}\")\n\n# Dependency injection\ndef get_sendgrid_service() -&gt; SendGridService:\n    return SendGridService()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#2-aws-ses-integration","title":"2. AWS SES Integration","text":"<pre><code># src/services/communication/email/aws_ses_service.py\nimport boto3\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nfrom botocore.exceptions import ClientError\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass AWSSESService:\n    \"\"\"AWS SES email service implementation.\"\"\"\n\n    def __init__(self):\n        self.client = boto3.client(\n            'ses',\n            region_name=settings.aws_region,\n            aws_access_key_id=settings.aws_access_key_id,\n            aws_secret_access_key=settings.aws_secret_access_key\n        )\n        self.default_from_email = settings.default_from_email\n        self.configuration_set = settings.aws_ses_configuration_set\n\n    async def send_email(\n        self,\n        to_emails: List[str],\n        subject: str,\n        html_content: str,\n        text_content: Optional[str] = None,\n        from_email: Optional[str] = None,\n        cc_emails: List[str] = None,\n        bcc_emails: List[str] = None,\n        reply_to_emails: List[str] = None,\n        tags: List[Dict[str, str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send email via AWS SES.\"\"\"\n        try:\n            # Build destination\n            destination = {\n                'ToAddresses': to_emails\n            }\n\n            if cc_emails:\n                destination['CcAddresses'] = cc_emails\n            if bcc_emails:\n                destination['BccAddresses'] = bcc_emails\n\n            # Build message\n            message = {\n                'Subject': {\n                    'Data': subject,\n                    'Charset': 'UTF-8'\n                },\n                'Body': {\n                    'Html': {\n                        'Data': html_content,\n                        'Charset': 'UTF-8'\n                    }\n                }\n            }\n\n            if text_content:\n                message['Body']['Text'] = {\n                    'Data': text_content,\n                    'Charset': 'UTF-8'\n                }\n\n            # Send email\n            send_params = {\n                'Source': from_email or self.default_from_email,\n                'Destination': destination,\n                'Message': message\n            }\n\n            if reply_to_emails:\n                send_params['ReplyToAddresses'] = reply_to_emails\n\n            if self.configuration_set:\n                send_params['ConfigurationSetName'] = self.configuration_set\n\n            if tags:\n                send_params['Tags'] = tags\n\n            response = self.client.send_email(**send_params)\n\n            logger.info(f\"Email sent via AWS SES to {len(to_emails)} recipients\")\n\n            return {\n                \"message_id\": response['MessageId'],\n                \"recipients\": to_emails,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SES email sending failed: {e}\")\n            raise CommunicationError(f\"Email sending failed: {e.response['Error']['Message']}\")\n\n    async def send_template_email(\n        self,\n        to_emails: List[str],\n        template_name: str,\n        template_data: Dict[str, Any],\n        from_email: Optional[str] = None,\n        tags: List[Dict[str, str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send email using AWS SES template.\"\"\"\n        try:\n            destinations = [\n                {\n                    'Destination': {\n                        'ToAddresses': [email]\n                    },\n                    'ReplacementTemplateData': str(template_data)\n                }\n                for email in to_emails\n            ]\n\n            send_params = {\n                'Source': from_email or self.default_from_email,\n                'Template': template_name,\n                'DefaultTemplateData': str(template_data),\n                'Destinations': destinations\n            }\n\n            if self.configuration_set:\n                send_params['ConfigurationSetName'] = self.configuration_set\n\n            if tags:\n                send_params['Tags'] = tags\n\n            response = self.client.send_bulk_templated_email(**send_params)\n\n            logger.info(f\"Template email sent via AWS SES to {len(to_emails)} recipients\")\n\n            return {\n                \"message_id\": response['MessageId'],\n                \"recipients\": to_emails,\n                \"template\": template_name,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SES template email sending failed: {e}\")\n            raise CommunicationError(f\"Template email sending failed: {e.response['Error']['Message']}\")\n\n    async def verify_email_identity(self, email: str) -&gt; Dict[str, Any]:\n        \"\"\"Verify email identity in AWS SES.\"\"\"\n        try:\n            response = self.client.verify_email_identity(EmailAddress=email)\n\n            logger.info(f\"Email identity verification initiated for: {email}\")\n\n            return {\n                \"email\": email,\n                \"verification_initiated\": True,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SES email verification failed: {e}\")\n            raise CommunicationError(f\"Email verification failed: {e.response['Error']['Message']}\")\n\n# Dependency injection\ndef get_aws_ses_service() -&gt; AWSSESService:\n    return AWSSESService()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#sms-integration","title":"SMS Integration","text":""},{"location":"atomic/external-integrations/communication-apis/#1-twilio-sms-service","title":"1. Twilio SMS Service","text":"<pre><code># src/services/communication/sms/twilio_service.py\nfrom twilio.rest import Client\nfrom typing import Dict, Any, Optional, List\nfrom datetime import datetime\nfrom twilio.base.exceptions import TwilioRestException\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass TwilioService:\n    \"\"\"Twilio SMS service implementation.\"\"\"\n\n    def __init__(self):\n        self.account_sid = settings.twilio_account_sid\n        self.auth_token = settings.twilio_auth_token\n        self.client = Client(self.account_sid, self.auth_token)\n        self.default_from_number = settings.twilio_from_number\n        self.messaging_service_sid = settings.twilio_messaging_service_sid\n\n    async def send_sms(\n        self,\n        to_number: str,\n        message: str,\n        from_number: Optional[str] = None,\n        media_urls: List[str] = None,\n        status_callback: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send SMS via Twilio.\"\"\"\n        try:\n            message_params = {\n                \"body\": message,\n                \"to\": to_number\n            }\n\n            # Use messaging service or from number\n            if self.messaging_service_sid:\n                message_params[\"messaging_service_sid\"] = self.messaging_service_sid\n            else:\n                message_params[\"from_\"] = from_number or self.default_from_number\n\n            if media_urls:\n                message_params[\"media_url\"] = media_urls\n\n            if status_callback:\n                message_params[\"status_callback\"] = status_callback\n\n            message_obj = self.client.messages.create(**message_params)\n\n            logger.info(f\"SMS sent via Twilio to {to_number}\")\n\n            return {\n                \"message_sid\": message_obj.sid,\n                \"to_number\": to_number,\n                \"from_number\": message_obj.from_,\n                \"status\": message_obj.status,\n                \"price\": message_obj.price,\n                \"price_unit\": message_obj.price_unit,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio SMS sending failed: {e}\")\n            raise CommunicationError(f\"SMS sending failed: {e.msg}\")\n\n    async def send_bulk_sms(\n        self,\n        messages: List[Dict[str, str]],\n        from_number: Optional[str] = None\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Send bulk SMS messages.\"\"\"\n        results = []\n\n        for message_data in messages:\n            try:\n                result = await self.send_sms(\n                    to_number=message_data[\"to_number\"],\n                    message=message_data[\"message\"],\n                    from_number=from_number,\n                    media_urls=message_data.get(\"media_urls\")\n                )\n                results.append(result)\n\n            except Exception as e:\n                logger.error(f\"Bulk SMS failed for {message_data['to_number']}: {e}\")\n                results.append({\n                    \"to_number\": message_data[\"to_number\"],\n                    \"error\": str(e),\n                    \"timestamp\": datetime.utcnow().isoformat()\n                })\n\n        return results\n\n    async def get_message_status(self, message_sid: str) -&gt; Dict[str, Any]:\n        \"\"\"Get SMS message status.\"\"\"\n        try:\n            message = self.client.messages(message_sid).fetch()\n\n            return {\n                \"message_sid\": message.sid,\n                \"status\": message.status,\n                \"error_code\": message.error_code,\n                \"error_message\": message.error_message,\n                \"price\": message.price,\n                \"price_unit\": message.price_unit,\n                \"date_sent\": message.date_sent.isoformat() if message.date_sent else None,\n                \"date_updated\": message.date_updated.isoformat() if message.date_updated else None\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio message status check failed: {e}\")\n            raise CommunicationError(f\"Message status check failed: {e.msg}\")\n\n    async def send_whatsapp_message(\n        self,\n        to_number: str,\n        message: str,\n        media_urls: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send WhatsApp message via Twilio.\"\"\"\n        try:\n            message_params = {\n                \"body\": message,\n                \"from_\": f\"whatsapp:{self.default_from_number}\",\n                \"to\": f\"whatsapp:{to_number}\"\n            }\n\n            if media_urls:\n                message_params[\"media_url\"] = media_urls\n\n            message_obj = self.client.messages.create(**message_params)\n\n            logger.info(f\"WhatsApp message sent via Twilio to {to_number}\")\n\n            return {\n                \"message_sid\": message_obj.sid,\n                \"to_number\": to_number,\n                \"status\": message_obj.status,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio WhatsApp sending failed: {e}\")\n            raise CommunicationError(f\"WhatsApp sending failed: {e.msg}\")\n\n    async def create_verify_service(\n        self,\n        friendly_name: str,\n        code_length: int = 6\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create Twilio Verify service for OTP.\"\"\"\n        try:\n            service = self.client.verify.services.create(\n                friendly_name=friendly_name,\n                code_length=code_length\n            )\n\n            logger.info(f\"Twilio Verify service created: {service.sid}\")\n\n            return {\n                \"service_sid\": service.sid,\n                \"friendly_name\": service.friendly_name,\n                \"code_length\": service.code_length\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio Verify service creation failed: {e}\")\n            raise CommunicationError(f\"Verify service creation failed: {e.msg}\")\n\n    async def send_verification_code(\n        self,\n        service_sid: str,\n        to_number: str,\n        channel: str = \"sms\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send verification code via Twilio Verify.\"\"\"\n        try:\n            verification = self.client.verify.services(service_sid).verifications.create(\n                to=to_number,\n                channel=channel\n            )\n\n            logger.info(f\"Verification code sent to {to_number}\")\n\n            return {\n                \"verification_sid\": verification.sid,\n                \"to_number\": to_number,\n                \"channel\": verification.channel,\n                \"status\": verification.status,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio verification sending failed: {e}\")\n            raise CommunicationError(f\"Verification sending failed: {e.msg}\")\n\n    async def check_verification_code(\n        self,\n        service_sid: str,\n        to_number: str,\n        code: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Check verification code via Twilio Verify.\"\"\"\n        try:\n            verification_check = self.client.verify.services(service_sid).verification_checks.create(\n                to=to_number,\n                code=code\n            )\n\n            logger.info(f\"Verification code checked for {to_number}\")\n\n            return {\n                \"to_number\": to_number,\n                \"status\": verification_check.status,\n                \"valid\": verification_check.status == \"approved\",\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except TwilioRestException as e:\n            logger.error(f\"Twilio verification check failed: {e}\")\n            raise CommunicationError(f\"Verification check failed: {e.msg}\")\n\n# Dependency injection\ndef get_twilio_service() -&gt; TwilioService:\n    return TwilioService()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#2-aws-sns-sms-service","title":"2. AWS SNS SMS Service","text":"<pre><code># src/services/communication/sms/aws_sns_service.py\nimport boto3\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nfrom botocore.exceptions import ClientError\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass AWSSNSService:\n    \"\"\"AWS SNS SMS service implementation.\"\"\"\n\n    def __init__(self):\n        self.client = boto3.client(\n            'sns',\n            region_name=settings.aws_region,\n            aws_access_key_id=settings.aws_access_key_id,\n            aws_secret_access_key=settings.aws_secret_access_key\n        )\n\n    async def send_sms(\n        self,\n        to_number: str,\n        message: str,\n        sender_id: Optional[str] = None,\n        sms_type: str = \"Transactional\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send SMS via AWS SNS.\"\"\"\n        try:\n            message_attributes = {\n                'AWS.SNS.SMS.SMSType': {\n                    'DataType': 'String',\n                    'StringValue': sms_type\n                }\n            }\n\n            if sender_id:\n                message_attributes['AWS.SNS.SMS.SenderID'] = {\n                    'DataType': 'String',\n                    'StringValue': sender_id\n                }\n\n            response = self.client.publish(\n                PhoneNumber=to_number,\n                Message=message,\n                MessageAttributes=message_attributes\n            )\n\n            logger.info(f\"SMS sent via AWS SNS to {to_number}\")\n\n            return {\n                \"message_id\": response['MessageId'],\n                \"to_number\": to_number,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SNS SMS sending failed: {e}\")\n            raise CommunicationError(f\"SMS sending failed: {e.response['Error']['Message']}\")\n\n    async def create_topic(\n        self,\n        topic_name: str,\n        display_name: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create SNS topic.\"\"\"\n        try:\n            response = self.client.create_topic(Name=topic_name)\n\n            if display_name:\n                self.client.set_topic_attributes(\n                    TopicArn=response['TopicArn'],\n                    AttributeName='DisplayName',\n                    AttributeValue=display_name\n                )\n\n            logger.info(f\"SNS topic created: {topic_name}\")\n\n            return {\n                \"topic_arn\": response['TopicArn'],\n                \"topic_name\": topic_name,\n                \"display_name\": display_name,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SNS topic creation failed: {e}\")\n            raise CommunicationError(f\"Topic creation failed: {e.response['Error']['Message']}\")\n\n    async def subscribe_to_topic(\n        self,\n        topic_arn: str,\n        protocol: str,\n        endpoint: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Subscribe to SNS topic.\"\"\"\n        try:\n            response = self.client.subscribe(\n                TopicArn=topic_arn,\n                Protocol=protocol,\n                Endpoint=endpoint\n            )\n\n            logger.info(f\"Subscribed {endpoint} to topic {topic_arn}\")\n\n            return {\n                \"subscription_arn\": response['SubscriptionArn'],\n                \"topic_arn\": topic_arn,\n                \"protocol\": protocol,\n                \"endpoint\": endpoint,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except ClientError as e:\n            logger.error(f\"AWS SNS subscription failed: {e}\")\n            raise CommunicationError(f\"Subscription failed: {e.response['Error']['Message']}\")\n\n# Dependency injection\ndef get_aws_sns_service() -&gt; AWSSNSService:\n    return AWSSNSService()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#push-notifications-integration","title":"Push Notifications Integration","text":""},{"location":"atomic/external-integrations/communication-apis/#1-firebase-cloud-messaging-fcm","title":"1. Firebase Cloud Messaging (FCM)","text":"<pre><code># src/services/communication/push/fcm_service.py\nfrom firebase_admin import messaging, credentials, initialize_app\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nimport json\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass FCMService:\n    \"\"\"Firebase Cloud Messaging service implementation.\"\"\"\n\n    def __init__(self):\n        # Initialize Firebase Admin SDK\n        if not settings.firebase_initialized:\n            cred = credentials.Certificate(settings.firebase_service_account_path)\n            initialize_app(cred)\n            settings.firebase_initialized = True\n\n    async def send_to_token(\n        self,\n        token: str,\n        title: str,\n        body: str,\n        data: Optional[Dict[str, str]] = None,\n        android_config: Optional[Dict] = None,\n        apns_config: Optional[Dict] = None,\n        image_url: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send push notification to specific device token.\"\"\"\n        try:\n            # Build notification\n            notification = messaging.Notification(\n                title=title,\n                body=body,\n                image=image_url\n            )\n\n            # Build message\n            message = messaging.Message(\n                notification=notification,\n                data=data,\n                token=token,\n                android=messaging.AndroidConfig(**android_config) if android_config else None,\n                apns=messaging.APNSConfig(**apns_config) if apns_config else None\n            )\n\n            # Send message\n            response = messaging.send(message)\n\n            logger.info(f\"Push notification sent to token: {token[:10]}...\")\n\n            return {\n                \"message_id\": response,\n                \"token\": token[:10] + \"...\",  # Partial token for logging\n                \"title\": title,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"FCM push notification failed: {e}\")\n            raise CommunicationError(f\"Push notification failed: {str(e)}\")\n\n    async def send_to_tokens(\n        self,\n        tokens: List[str],\n        title: str,\n        body: str,\n        data: Optional[Dict[str, str]] = None,\n        android_config: Optional[Dict] = None,\n        apns_config: Optional[Dict] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send push notification to multiple device tokens.\"\"\"\n        try:\n            # Build notification\n            notification = messaging.Notification(\n                title=title,\n                body=body\n            )\n\n            # Build multicast message\n            message = messaging.MulticastMessage(\n                notification=notification,\n                data=data,\n                tokens=tokens,\n                android=messaging.AndroidConfig(**android_config) if android_config else None,\n                apns=messaging.APNSConfig(**apns_config) if apns_config else None\n            )\n\n            # Send message\n            response = messaging.send_multicast(message)\n\n            logger.info(f\"Push notifications sent to {len(tokens)} tokens\")\n\n            return {\n                \"success_count\": response.success_count,\n                \"failure_count\": response.failure_count,\n                \"tokens_count\": len(tokens),\n                \"title\": title,\n                \"timestamp\": datetime.utcnow().isoformat(),\n                \"responses\": [\n                    {\n                        \"success\": resp.success,\n                        \"message_id\": resp.message_id if resp.success else None,\n                        \"error\": str(resp.exception) if not resp.success else None\n                    }\n                    for resp in response.responses\n                ]\n            }\n\n        except Exception as e:\n            logger.error(f\"FCM multicast push notification failed: {e}\")\n            raise CommunicationError(f\"Multicast push notification failed: {str(e)}\")\n\n    async def send_to_topic(\n        self,\n        topic: str,\n        title: str,\n        body: str,\n        data: Optional[Dict[str, str]] = None,\n        condition: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send push notification to topic subscribers.\"\"\"\n        try:\n            # Build notification\n            notification = messaging.Notification(\n                title=title,\n                body=body\n            )\n\n            # Build message\n            if condition:\n                message = messaging.Message(\n                    notification=notification,\n                    data=data,\n                    condition=condition\n                )\n            else:\n                message = messaging.Message(\n                    notification=notification,\n                    data=data,\n                    topic=topic\n                )\n\n            # Send message\n            response = messaging.send(message)\n\n            logger.info(f\"Push notification sent to topic: {topic}\")\n\n            return {\n                \"message_id\": response,\n                \"topic\": topic,\n                \"title\": title,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"FCM topic push notification failed: {e}\")\n            raise CommunicationError(f\"Topic push notification failed: {str(e)}\")\n\n    async def subscribe_to_topic(\n        self,\n        tokens: List[str],\n        topic: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Subscribe device tokens to topic.\"\"\"\n        try:\n            response = messaging.subscribe_to_topic(tokens, topic)\n\n            logger.info(f\"Subscribed {len(tokens)} tokens to topic: {topic}\")\n\n            return {\n                \"success_count\": response.success_count,\n                \"failure_count\": response.failure_count,\n                \"topic\": topic,\n                \"tokens_count\": len(tokens),\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"FCM topic subscription failed: {e}\")\n            raise CommunicationError(f\"Topic subscription failed: {str(e)}\")\n\n    async def unsubscribe_from_topic(\n        self,\n        tokens: List[str],\n        topic: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Unsubscribe device tokens from topic.\"\"\"\n        try:\n            response = messaging.unsubscribe_from_topic(tokens, topic)\n\n            logger.info(f\"Unsubscribed {len(tokens)} tokens from topic: {topic}\")\n\n            return {\n                \"success_count\": response.success_count,\n                \"failure_count\": response.failure_count,\n                \"topic\": topic,\n                \"tokens_count\": len(tokens),\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            logger.error(f\"FCM topic unsubscription failed: {e}\")\n            raise CommunicationError(f\"Topic unsubscription failed: {str(e)}\")\n\n# Dependency injection\ndef get_fcm_service() -&gt; FCMService:\n    return FCMService()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#communication-service-orchestration","title":"Communication Service Orchestration","text":""},{"location":"atomic/external-integrations/communication-apis/#1-communication-manager","title":"1. Communication Manager","text":"<pre><code># src/services/communication/communication_manager.py\nfrom typing import Dict, Any, Optional, List, Literal\nfrom enum import Enum\nfrom datetime import datetime\nfrom src.services.communication.email.sendgrid_service import SendGridService\nfrom src.services.communication.email.aws_ses_service import AWSSESService\nfrom src.services.communication.sms.twilio_service import TwilioService\nfrom src.services.communication.sms.aws_sns_service import AWSSNSService\nfrom src.services.communication.push.fcm_service import FCMService\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\nclass CommunicationChannel(str, Enum):\n    EMAIL = \"email\"\n    SMS = \"sms\"\n    PUSH = \"push\"\n    WHATSAPP = \"whatsapp\"\n\nclass CommunicationProvider(str, Enum):\n    SENDGRID = \"sendgrid\"\n    AWS_SES = \"aws_ses\"\n    TWILIO = \"twilio\"\n    AWS_SNS = \"aws_sns\"\n    FCM = \"fcm\"\n\nclass CommunicationManager:\n    \"\"\"Centralized communication management across multiple channels and providers.\"\"\"\n\n    def __init__(self):\n        # Initialize services based on configuration\n        self.email_services = {}\n        self.sms_services = {}\n        self.push_services = {}\n\n        # Email services\n        if settings.sendgrid_api_key:\n            self.email_services[CommunicationProvider.SENDGRID] = SendGridService()\n        if settings.aws_ses_enabled:\n            self.email_services[CommunicationProvider.AWS_SES] = AWSSESService()\n\n        # SMS services\n        if settings.twilio_account_sid:\n            self.sms_services[CommunicationProvider.TWILIO] = TwilioService()\n        if settings.aws_sns_enabled:\n            self.sms_services[CommunicationProvider.AWS_SNS] = AWSSNSService()\n\n        # Push services\n        if settings.firebase_service_account_path:\n            self.push_services[CommunicationProvider.FCM] = FCMService()\n\n        # Default providers\n        self.default_email_provider = settings.default_email_provider or CommunicationProvider.SENDGRID\n        self.default_sms_provider = settings.default_sms_provider or CommunicationProvider.TWILIO\n        self.default_push_provider = settings.default_push_provider or CommunicationProvider.FCM\n\n    async def send_email(\n        self,\n        to_emails: List[str],\n        subject: str,\n        html_content: str,\n        text_content: Optional[str] = None,\n        provider: Optional[CommunicationProvider] = None,\n        template_id: Optional[str] = None,\n        template_data: Optional[Dict[str, Any]] = None,\n        attachments: Optional[List[Dict]] = None,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send email using specified or default provider.\"\"\"\n        provider = provider or self.default_email_provider\n\n        if provider not in self.email_services:\n            raise CommunicationError(f\"Email provider {provider} not configured\")\n\n        service = self.email_services[provider]\n\n        try:\n            if template_id:\n                if hasattr(service, 'send_template_email'):\n                    result = await service.send_template_email(\n                        to_emails=to_emails,\n                        template_id=template_id,\n                        template_data=template_data or {},\n                        **kwargs\n                    )\n                else:\n                    raise CommunicationError(f\"Template emails not supported by {provider}\")\n            else:\n                result = await service.send_email(\n                    to_emails=to_emails,\n                    subject=subject,\n                    html_content=html_content,\n                    text_content=text_content,\n                    attachments=attachments,\n                    **kwargs\n                )\n\n            result[\"provider\"] = provider.value\n            result[\"channel\"] = CommunicationChannel.EMAIL.value\n\n            logger.info(f\"Email sent via {provider} to {len(to_emails)} recipients\")\n            return result\n\n        except Exception as e:\n            logger.error(f\"Email sending failed with {provider}: {e}\")\n            raise\n\n    async def send_sms(\n        self,\n        to_number: str,\n        message: str,\n        provider: Optional[CommunicationProvider] = None,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send SMS using specified or default provider.\"\"\"\n        provider = provider or self.default_sms_provider\n\n        if provider not in self.sms_services:\n            raise CommunicationError(f\"SMS provider {provider} not configured\")\n\n        service = self.sms_services[provider]\n\n        try:\n            result = await service.send_sms(\n                to_number=to_number,\n                message=message,\n                **kwargs\n            )\n\n            result[\"provider\"] = provider.value\n            result[\"channel\"] = CommunicationChannel.SMS.value\n\n            logger.info(f\"SMS sent via {provider} to {to_number}\")\n            return result\n\n        except Exception as e:\n            logger.error(f\"SMS sending failed with {provider}: {e}\")\n            raise\n\n    async def send_push_notification(\n        self,\n        tokens: List[str],\n        title: str,\n        body: str,\n        data: Optional[Dict[str, str]] = None,\n        provider: Optional[CommunicationProvider] = None,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send push notification using specified or default provider.\"\"\"\n        provider = provider or self.default_push_provider\n\n        if provider not in self.push_services:\n            raise CommunicationError(f\"Push provider {provider} not configured\")\n\n        service = self.push_services[provider]\n\n        try:\n            if len(tokens) == 1:\n                result = await service.send_to_token(\n                    token=tokens[0],\n                    title=title,\n                    body=body,\n                    data=data,\n                    **kwargs\n                )\n            else:\n                result = await service.send_to_tokens(\n                    tokens=tokens,\n                    title=title,\n                    body=body,\n                    data=data,\n                    **kwargs\n                )\n\n            result[\"provider\"] = provider.value\n            result[\"channel\"] = CommunicationChannel.PUSH.value\n\n            logger.info(f\"Push notification sent via {provider} to {len(tokens)} tokens\")\n            return result\n\n        except Exception as e:\n            logger.error(f\"Push notification sending failed with {provider}: {e}\")\n            raise\n\n    async def send_multi_channel_notification(\n        self,\n        user_id: str,\n        message_data: Dict[str, Any],\n        channels: List[CommunicationChannel],\n        user_preferences: Optional[Dict[str, Any]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send notification across multiple channels.\"\"\"\n        results = []\n\n        for channel in channels:\n            try:\n                # Check user preferences\n                if user_preferences and not user_preferences.get(f\"{channel}_enabled\", True):\n                    logger.info(f\"Skipping {channel} for user {user_id} - disabled in preferences\")\n                    continue\n\n                channel_data = message_data.get(channel.value, {})\n                if not channel_data:\n                    logger.warning(f\"No data provided for channel {channel}\")\n                    continue\n\n                if channel == CommunicationChannel.EMAIL:\n                    result = await self.send_email(**channel_data)\n                elif channel == CommunicationChannel.SMS:\n                    result = await self.send_sms(**channel_data)\n                elif channel == CommunicationChannel.PUSH:\n                    result = await self.send_push_notification(**channel_data)\n\n                results.append({\n                    \"channel\": channel.value,\n                    \"success\": True,\n                    \"result\": result\n                })\n\n            except Exception as e:\n                logger.error(f\"Multi-channel notification failed for {channel}: {e}\")\n                results.append({\n                    \"channel\": channel.value,\n                    \"success\": False,\n                    \"error\": str(e)\n                })\n\n        return {\n            \"user_id\": user_id,\n            \"channels\": [channel.value for channel in channels],\n            \"results\": results,\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n\n# Dependency injection\ndef get_communication_manager() -&gt; CommunicationManager:\n    return CommunicationManager()\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#2-communication-api-endpoints","title":"2. Communication API Endpoints","text":"<pre><code># src/api/communications.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom typing import List, Dict, Any, Optional\nfrom src.services.communication.communication_manager import (\n    CommunicationManager,\n    CommunicationChannel,\n    CommunicationProvider,\n    get_communication_manager\n)\nfrom src.core.auth import get_current_active_user\nfrom src.core.models import CurrentUser\nfrom src.core.schemas import (\n    EmailMessage,\n    SMSMessage,\n    PushNotification,\n    MultiChannelMessage,\n    CommunicationResponse\n)\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\nrouter = APIRouter(prefix=\"/communications\", tags=[\"communications\"])\n\n@router.post(\"/email\", response_model=CommunicationResponse)\nasync def send_email(\n    email_data: EmailMessage,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    comm_manager: CommunicationManager = Depends(get_communication_manager)\n):\n    \"\"\"Send email notification.\"\"\"\n    try:\n        result = await comm_manager.send_email(\n            to_emails=email_data.to_emails,\n            subject=email_data.subject,\n            html_content=email_data.html_content,\n            text_content=email_data.text_content,\n            provider=email_data.provider,\n            template_id=email_data.template_id,\n            template_data=email_data.template_data,\n            attachments=email_data.attachments\n        )\n\n        logger.info(f\"Email sent by user {current_user.id} to {len(email_data.to_emails)} recipients\")\n\n        return CommunicationResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Email sending failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/sms\", response_model=CommunicationResponse)\nasync def send_sms(\n    sms_data: SMSMessage,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    comm_manager: CommunicationManager = Depends(get_communication_manager)\n):\n    \"\"\"Send SMS notification.\"\"\"\n    try:\n        result = await comm_manager.send_sms(\n            to_number=sms_data.to_number,\n            message=sms_data.message,\n            provider=sms_data.provider,\n            from_number=sms_data.from_number\n        )\n\n        logger.info(f\"SMS sent by user {current_user.id} to {sms_data.to_number}\")\n\n        return CommunicationResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"SMS sending failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/push\", response_model=CommunicationResponse)\nasync def send_push_notification(\n    push_data: PushNotification,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    comm_manager: CommunicationManager = Depends(get_communication_manager)\n):\n    \"\"\"Send push notification.\"\"\"\n    try:\n        result = await comm_manager.send_push_notification(\n            tokens=push_data.tokens,\n            title=push_data.title,\n            body=push_data.body,\n            data=push_data.data,\n            provider=push_data.provider\n        )\n\n        logger.info(f\"Push notification sent by user {current_user.id} to {len(push_data.tokens)} devices\")\n\n        return CommunicationResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Push notification sending failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/multi-channel\", response_model=Dict[str, Any])\nasync def send_multi_channel_notification(\n    message_data: MultiChannelMessage,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    comm_manager: CommunicationManager = Depends(get_communication_manager)\n):\n    \"\"\"Send notification across multiple channels.\"\"\"\n    try:\n        result = await comm_manager.send_multi_channel_notification(\n            user_id=message_data.user_id,\n            message_data=message_data.messages,\n            channels=message_data.channels,\n            user_preferences=message_data.user_preferences\n        )\n\n        logger.info(f\"Multi-channel notification sent by user {current_user.id} for user {message_data.user_id}\")\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Multi-channel notification failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.get(\"/providers\")\nasync def get_available_providers(\n    current_user: CurrentUser = Depends(get_current_active_user),\n    comm_manager: CommunicationManager = Depends(get_communication_manager)\n):\n    \"\"\"Get available communication providers.\"\"\"\n    return {\n        \"email_providers\": list(comm_manager.email_services.keys()),\n        \"sms_providers\": list(comm_manager.sms_services.keys()),\n        \"push_providers\": list(comm_manager.push_services.keys()),\n        \"default_providers\": {\n            \"email\": comm_manager.default_email_provider,\n            \"sms\": comm_manager.default_sms_provider,\n            \"push\": comm_manager.default_push_provider\n        }\n    }\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#testing-communication-apis","title":"Testing Communication APIs","text":""},{"location":"atomic/external-integrations/communication-apis/#1-communication-service-tests","title":"1. Communication Service Tests","text":"<pre><code># tests/test_communication_services.py\nimport pytest\nfrom unittest.mock import Mock, patch, AsyncMock\nfrom src.services.communication.email.sendgrid_service import SendGridService\nfrom src.services.communication.sms.twilio_service import TwilioService\nfrom src.services.communication.push.fcm_service import FCMService\nfrom src.services.communication.communication_manager import CommunicationManager, CommunicationChannel\nfrom src.core.exceptions import CommunicationError\n\nclass TestSendGridService:\n    \"\"\"Test SendGrid email service.\"\"\"\n\n    @pytest.fixture\n    def sendgrid_service(self):\n        return SendGridService()\n\n    @pytest.mark.asyncio\n    async def test_send_email_success(self, sendgrid_service):\n        \"\"\"Test successful email sending.\"\"\"\n        with patch.object(sendgrid_service.client, 'send') as mock_send:\n            mock_response = Mock()\n            mock_response.status_code = 202\n            mock_response.headers = {\"X-Message-Id\": \"test_message_id\"}\n            mock_send.return_value = mock_response\n\n            result = await sendgrid_service.send_email(\n                to_emails=[\"test@example.com\"],\n                subject=\"Test Subject\",\n                html_content=\"&lt;h1&gt;Test&lt;/h1&gt;\"\n            )\n\n            assert result[\"message_id\"] == \"test_message_id\"\n            assert result[\"recipients\"] == [\"test@example.com\"]\n\n    @pytest.mark.asyncio\n    async def test_send_template_email(self, sendgrid_service):\n        \"\"\"Test template email sending.\"\"\"\n        with patch.object(sendgrid_service.client, 'send') as mock_send:\n            mock_response = Mock()\n            mock_response.status_code = 202\n            mock_response.headers = {\"X-Message-Id\": \"template_message_id\"}\n            mock_send.return_value = mock_response\n\n            result = await sendgrid_service.send_template_email(\n                to_emails=[\"test@example.com\"],\n                template_id=\"d-template123\",\n                template_data={\"name\": \"John\"}\n            )\n\n            assert result[\"message_id\"] == \"template_message_id\"\n\nclass TestTwilioService:\n    \"\"\"Test Twilio SMS service.\"\"\"\n\n    @pytest.fixture\n    def twilio_service(self):\n        return TwilioService()\n\n    @pytest.mark.asyncio\n    async def test_send_sms_success(self, twilio_service):\n        \"\"\"Test successful SMS sending.\"\"\"\n        with patch.object(twilio_service.client.messages, 'create') as mock_create:\n            mock_message = Mock()\n            mock_message.sid = \"SM123456789\"\n            mock_message.from_ = \"+1234567890\"\n            mock_message.status = \"sent\"\n            mock_message.price = \"-0.0075\"\n            mock_message.price_unit = \"USD\"\n            mock_create.return_value = mock_message\n\n            result = await twilio_service.send_sms(\n                to_number=\"+1987654321\",\n                message=\"Test SMS message\"\n            )\n\n            assert result[\"message_sid\"] == \"SM123456789\"\n            assert result[\"to_number\"] == \"+1987654321\"\n            assert result[\"status\"] == \"sent\"\n\n    @pytest.mark.asyncio\n    async def test_send_verification_code(self, twilio_service):\n        \"\"\"Test verification code sending.\"\"\"\n        with patch.object(twilio_service.client.verify.services, '__call__') as mock_service:\n            mock_verification = Mock()\n            mock_verification.sid = \"VE123456789\"\n            mock_verification.channel = \"sms\"\n            mock_verification.status = \"pending\"\n\n            mock_service.return_value.verifications.create.return_value = mock_verification\n\n            result = await twilio_service.send_verification_code(\n                service_sid=\"VA123456789\",\n                to_number=\"+1987654321\"\n            )\n\n            assert result[\"verification_sid\"] == \"VE123456789\"\n            assert result[\"status\"] == \"pending\"\n\nclass TestFCMService:\n    \"\"\"Test Firebase Cloud Messaging service.\"\"\"\n\n    @pytest.fixture\n    def fcm_service(self):\n        with patch('firebase_admin.initialize_app'):\n            return FCMService()\n\n    @pytest.mark.asyncio\n    async def test_send_to_token_success(self, fcm_service):\n        \"\"\"Test successful push notification to token.\"\"\"\n        with patch('firebase_admin.messaging.send') as mock_send:\n            mock_send.return_value = \"projects/test/messages/123456789\"\n\n            result = await fcm_service.send_to_token(\n                token=\"device_token_123\",\n                title=\"Test Notification\",\n                body=\"This is a test notification\"\n            )\n\n            assert result[\"message_id\"] == \"projects/test/messages/123456789\"\n            assert result[\"title\"] == \"Test Notification\"\n\n    @pytest.mark.asyncio\n    async def test_send_to_tokens_multicast(self, fcm_service):\n        \"\"\"Test multicast push notification.\"\"\"\n        with patch('firebase_admin.messaging.send_multicast') as mock_send:\n            mock_response = Mock()\n            mock_response.success_count = 2\n            mock_response.failure_count = 0\n            mock_response.responses = [\n                Mock(success=True, message_id=\"msg1\", exception=None),\n                Mock(success=True, message_id=\"msg2\", exception=None)\n            ]\n            mock_send.return_value = mock_response\n\n            result = await fcm_service.send_to_tokens(\n                tokens=[\"token1\", \"token2\"],\n                title=\"Test Notification\",\n                body=\"Multicast test\"\n            )\n\n            assert result[\"success_count\"] == 2\n            assert result[\"failure_count\"] == 0\n            assert len(result[\"responses\"]) == 2\n\nclass TestCommunicationManager:\n    \"\"\"Test communication manager orchestration.\"\"\"\n\n    @pytest.fixture\n    def communication_manager(self):\n        with patch.multiple(\n            'src.services.communication.communication_manager',\n            SendGridService=Mock,\n            TwilioService=Mock,\n            FCMService=Mock\n        ):\n            return CommunicationManager()\n\n    @pytest.mark.asyncio\n    async def test_send_email_with_provider(self, communication_manager):\n        \"\"\"Test email sending with specific provider.\"\"\"\n        mock_service = Mock()\n        mock_service.send_email = AsyncMock(return_value={\n            \"message_id\": \"test_id\",\n            \"recipients\": [\"test@example.com\"]\n        })\n        communication_manager.email_services[\"sendgrid\"] = mock_service\n\n        result = await communication_manager.send_email(\n            to_emails=[\"test@example.com\"],\n            subject=\"Test\",\n            html_content=\"&lt;h1&gt;Test&lt;/h1&gt;\",\n            provider=\"sendgrid\"\n        )\n\n        assert result[\"provider\"] == \"sendgrid\"\n        assert result[\"channel\"] == \"email\"\n\n    @pytest.mark.asyncio\n    async def test_multi_channel_notification(self, communication_manager):\n        \"\"\"Test multi-channel notification sending.\"\"\"\n        # Mock all services\n        email_service = Mock()\n        email_service.send_email = AsyncMock(return_value={\"message_id\": \"email_123\"})\n        communication_manager.email_services[\"sendgrid\"] = email_service\n\n        sms_service = Mock()\n        sms_service.send_sms = AsyncMock(return_value={\"message_sid\": \"sms_123\"})\n        communication_manager.sms_services[\"twilio\"] = sms_service\n\n        message_data = {\n            \"email\": {\n                \"to_emails\": [\"user@example.com\"],\n                \"subject\": \"Test\",\n                \"html_content\": \"&lt;h1&gt;Test&lt;/h1&gt;\"\n            },\n            \"sms\": {\n                \"to_number\": \"+1234567890\",\n                \"message\": \"Test SMS\"\n            }\n        }\n\n        result = await communication_manager.send_multi_channel_notification(\n            user_id=\"user123\",\n            message_data=message_data,\n            channels=[CommunicationChannel.EMAIL, CommunicationChannel.SMS]\n        )\n\n        assert len(result[\"results\"]) == 2\n        assert all(r[\"success\"] for r in result[\"results\"])\n\n    @pytest.mark.asyncio\n    async def test_unsupported_provider_error(self, communication_manager):\n        \"\"\"Test error handling for unsupported provider.\"\"\"\n        with pytest.raises(CommunicationError) as exc_info:\n            await communication_manager.send_email(\n                to_emails=[\"test@example.com\"],\n                subject=\"Test\",\n                html_content=\"&lt;h1&gt;Test&lt;/h1&gt;\",\n                provider=\"unsupported_provider\"\n            )\n\n        assert \"not configured\" in str(exc_info.value)\n</code></pre>"},{"location":"atomic/external-integrations/communication-apis/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/external-integrations/webhook-handling.md</code> - Webhook processing patterns</li> <li><code>docs/atomic/external-integrations/api-rate-limiting.md</code> - Rate limiting patterns</li> <li><code>docs/atomic/services/fastapi/error-handling.md</code> - Error handling patterns</li> <li><code>docs/atomic/testing/integration-testing/http-integration-testing.md</code> - HTTP testing</li> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> - Secure API integration</li> </ul>"},{"location":"atomic/external-integrations/communication-apis/#implementation-checklist","title":"Implementation Checklist","text":""},{"location":"atomic/external-integrations/communication-apis/#email-integration_1","title":"Email Integration","text":"<ul> <li> SendGrid API key configuration</li> <li> AWS SES credentials setup</li> <li> Template management system</li> <li> Attachment handling</li> <li> Email validation and verification</li> <li> Bounce and complaint handling</li> <li> Delivery tracking</li> <li> Rate limiting compliance</li> </ul>"},{"location":"atomic/external-integrations/communication-apis/#sms-integration_1","title":"SMS Integration","text":"<ul> <li> Twilio account setup</li> <li> AWS SNS configuration</li> <li> Phone number validation</li> <li> International SMS support</li> <li> Delivery receipts handling</li> <li> Opt-out management</li> <li> Cost optimization</li> <li> Verification codes (OTP)</li> </ul>"},{"location":"atomic/external-integrations/communication-apis/#push-notifications","title":"Push Notifications","text":"<ul> <li> Firebase project setup</li> <li> Apple Push Notification certificates</li> <li> Device token management</li> <li> Topic subscription management</li> <li> Rich media notifications</li> <li> Badge management</li> <li> Analytics integration</li> <li> A/B testing support</li> </ul>"},{"location":"atomic/external-integrations/communication-apis/#general-integration","title":"General Integration","text":"<ul> <li> Provider failover mechanisms</li> <li> Message templates system</li> <li> User preference management</li> <li> Delivery analytics</li> <li> Cost tracking</li> <li> Compliance with regulations</li> <li> Testing with test APIs</li> <li> Production deployment</li> </ul>"},{"location":"atomic/external-integrations/payment-gateways/","title":"Payment Gateway Integration","text":"<p>Comprehensive guide for integrating payment gateways (Stripe, PayPal, and others) in microservices architecture following the Improved Hybrid Approach.</p>"},{"location":"atomic/external-integrations/payment-gateways/#overview","title":"Overview","text":"<p>Payment integration requires secure handling of sensitive financial data, compliance with PCI standards, and reliable transaction processing. This guide covers integration patterns that maintain service separation while ensuring security and reliability.</p>"},{"location":"atomic/external-integrations/payment-gateways/#architecture-pattern","title":"Architecture Pattern","text":"<p>Payment processing follows the data service pattern where payment operations are centralized in dedicated services while business services handle the orchestration.</p> <pre><code>graph TB\n    subgraph \"Business Services\"\n        API[FastAPI Service]\n        BOT[Aiogram Bot]\n        WORKER[AsyncIO Workers]\n    end\n\n    subgraph \"Payment Services\"\n        PAY_SERVICE[Payment Service :8003]\n        WEBHOOK_HANDLER[Webhook Handler]\n    end\n\n    subgraph \"External Services\"\n        STRIPE[Stripe API]\n        PAYPAL[PayPal API]\n        BANK[Bank API]\n    end\n\n    subgraph \"Infrastructure\"\n        POSTGRES[(PostgreSQL)]\n        REDIS[(Redis - Idempotency)]\n        RABBIT[RabbitMQ - Events]\n    end\n\n    API --&gt;|HTTP| PAY_SERVICE\n    BOT --&gt;|HTTP| PAY_SERVICE\n    WORKER --&gt;|HTTP| PAY_SERVICE\n\n    PAY_SERVICE --&gt; STRIPE\n    PAY_SERVICE --&gt; PAYPAL\n    PAY_SERVICE --&gt; BANK\n\n    STRIPE -.-&gt;|Webhooks| WEBHOOK_HANDLER\n    PAYPAL -.-&gt;|Webhooks| WEBHOOK_HANDLER\n\n    PAY_SERVICE --&gt; POSTGRES\n    PAY_SERVICE --&gt; REDIS\n    WEBHOOK_HANDLER --&gt; RABBIT</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#stripe-integration","title":"Stripe Integration","text":""},{"location":"atomic/external-integrations/payment-gateways/#1-stripe-service-implementation","title":"1. Stripe Service Implementation","text":"<pre><code># src/services/payment/stripe_service.py\nimport stripe\nfrom typing import Dict, Any, Optional, List\nfrom decimal import Decimal\nfrom datetime import datetime\nimport httpx\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import PaymentError, PaymentValidationError\n\nlogger = get_logger(__name__)\n\nclass StripeService:\n    \"\"\"Stripe payment service implementation.\"\"\"\n\n    def __init__(self):\n        stripe.api_key = settings.stripe_secret_key\n        self.webhook_secret = settings.stripe_webhook_secret\n        self.currency = settings.default_currency or \"usd\"\n\n    async def create_payment_intent(\n        self,\n        amount: Decimal,\n        currency: str = None,\n        customer_id: Optional[str] = None,\n        metadata: Dict[str, Any] = None,\n        payment_method_types: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create Stripe Payment Intent.\"\"\"\n        try:\n            # Convert amount to cents (Stripe expects smallest currency unit)\n            amount_cents = int(amount * 100)\n\n            payment_intent_data = {\n                \"amount\": amount_cents,\n                \"currency\": currency or self.currency,\n                \"payment_method_types\": payment_method_types or [\"card\"],\n                \"metadata\": metadata or {}\n            }\n\n            if customer_id:\n                payment_intent_data[\"customer\"] = customer_id\n\n            payment_intent = stripe.PaymentIntent.create(**payment_intent_data)\n\n            logger.info(f\"Created Stripe Payment Intent: {payment_intent.id}\")\n\n            return {\n                \"payment_intent_id\": payment_intent.id,\n                \"client_secret\": payment_intent.client_secret,\n                \"amount\": amount,\n                \"currency\": payment_intent.currency,\n                \"status\": payment_intent.status,\n                \"payment_methods\": payment_intent.payment_method_types\n            }\n\n        except stripe.error.CardError as e:\n            logger.error(f\"Stripe card error: {e}\")\n            raise PaymentError(f\"Card error: {e.user_message}\")\n        except stripe.error.RateLimitError as e:\n            logger.error(f\"Stripe rate limit error: {e}\")\n            raise PaymentError(\"Payment service temporarily unavailable\")\n        except stripe.error.InvalidRequestError as e:\n            logger.error(f\"Stripe invalid request: {e}\")\n            raise PaymentValidationError(f\"Invalid payment request: {e.user_message}\")\n        except stripe.error.AuthenticationError as e:\n            logger.error(f\"Stripe authentication error: {e}\")\n            raise PaymentError(\"Payment service configuration error\")\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe error: {e}\")\n            raise PaymentError(\"Payment processing error\")\n\n    async def confirm_payment_intent(\n        self,\n        payment_intent_id: str,\n        payment_method_id: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Confirm Stripe Payment Intent.\"\"\"\n        try:\n            payment_intent = stripe.PaymentIntent.confirm(\n                payment_intent_id,\n                payment_method=payment_method_id\n            )\n\n            logger.info(f\"Confirmed Stripe Payment Intent: {payment_intent_id}\")\n\n            return {\n                \"payment_intent_id\": payment_intent.id,\n                \"status\": payment_intent.status,\n                \"amount\": Decimal(payment_intent.amount) / 100,\n                \"currency\": payment_intent.currency,\n                \"charges\": [self._format_charge(charge) for charge in payment_intent.charges.data]\n            }\n\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe confirmation error: {e}\")\n            raise PaymentError(f\"Payment confirmation failed: {e.user_message}\")\n\n    async def create_customer(\n        self,\n        email: str,\n        name: Optional[str] = None,\n        metadata: Dict[str, Any] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create Stripe customer.\"\"\"\n        try:\n            customer_data = {\n                \"email\": email,\n                \"metadata\": metadata or {}\n            }\n\n            if name:\n                customer_data[\"name\"] = name\n\n            customer = stripe.Customer.create(**customer_data)\n\n            logger.info(f\"Created Stripe customer: {customer.id}\")\n\n            return {\n                \"customer_id\": customer.id,\n                \"email\": customer.email,\n                \"name\": customer.name,\n                \"created\": datetime.fromtimestamp(customer.created)\n            }\n\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe customer creation error: {e}\")\n            raise PaymentError(f\"Customer creation failed: {e.user_message}\")\n\n    async def create_subscription(\n        self,\n        customer_id: str,\n        price_id: str,\n        metadata: Dict[str, Any] = None,\n        trial_period_days: Optional[int] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create Stripe subscription.\"\"\"\n        try:\n            subscription_data = {\n                \"customer\": customer_id,\n                \"items\": [{\"price\": price_id}],\n                \"metadata\": metadata or {}\n            }\n\n            if trial_period_days:\n                subscription_data[\"trial_period_days\"] = trial_period_days\n\n            subscription = stripe.Subscription.create(**subscription_data)\n\n            logger.info(f\"Created Stripe subscription: {subscription.id}\")\n\n            return {\n                \"subscription_id\": subscription.id,\n                \"customer_id\": subscription.customer,\n                \"status\": subscription.status,\n                \"current_period_start\": datetime.fromtimestamp(subscription.current_period_start),\n                \"current_period_end\": datetime.fromtimestamp(subscription.current_period_end),\n                \"trial_end\": datetime.fromtimestamp(subscription.trial_end) if subscription.trial_end else None\n            }\n\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe subscription creation error: {e}\")\n            raise PaymentError(f\"Subscription creation failed: {e.user_message}\")\n\n    async def cancel_subscription(\n        self,\n        subscription_id: str,\n        at_period_end: bool = True\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Cancel Stripe subscription.\"\"\"\n        try:\n            if at_period_end:\n                subscription = stripe.Subscription.modify(\n                    subscription_id,\n                    cancel_at_period_end=True\n                )\n            else:\n                subscription = stripe.Subscription.delete(subscription_id)\n\n            logger.info(f\"Cancelled Stripe subscription: {subscription_id}\")\n\n            return {\n                \"subscription_id\": subscription.id,\n                \"status\": subscription.status,\n                \"canceled_at\": datetime.fromtimestamp(subscription.canceled_at) if subscription.canceled_at else None,\n                \"cancel_at_period_end\": subscription.cancel_at_period_end\n            }\n\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe subscription cancellation error: {e}\")\n            raise PaymentError(f\"Subscription cancellation failed: {e.user_message}\")\n\n    async def refund_payment(\n        self,\n        payment_intent_id: str,\n        amount: Optional[Decimal] = None,\n        reason: str = \"requested_by_customer\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Refund Stripe payment.\"\"\"\n        try:\n            refund_data = {\n                \"payment_intent\": payment_intent_id,\n                \"reason\": reason\n            }\n\n            if amount:\n                refund_data[\"amount\"] = int(amount * 100)\n\n            refund = stripe.Refund.create(**refund_data)\n\n            logger.info(f\"Created Stripe refund: {refund.id}\")\n\n            return {\n                \"refund_id\": refund.id,\n                \"payment_intent_id\": refund.payment_intent,\n                \"amount\": Decimal(refund.amount) / 100,\n                \"currency\": refund.currency,\n                \"status\": refund.status,\n                \"reason\": refund.reason\n            }\n\n        except stripe.error.StripeError as e:\n            logger.error(f\"Stripe refund error: {e}\")\n            raise PaymentError(f\"Refund failed: {e.user_message}\")\n\n    def verify_webhook_signature(\n        self,\n        payload: bytes,\n        signature: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Verify Stripe webhook signature.\"\"\"\n        try:\n            event = stripe.Webhook.construct_event(\n                payload, signature, self.webhook_secret\n            )\n            return event\n        except ValueError as e:\n            logger.error(f\"Invalid Stripe webhook payload: {e}\")\n            raise PaymentError(\"Invalid webhook payload\")\n        except stripe.error.SignatureVerificationError as e:\n            logger.error(f\"Invalid Stripe webhook signature: {e}\")\n            raise PaymentError(\"Invalid webhook signature\")\n\n    def _format_charge(self, charge) -&gt; Dict[str, Any]:\n        \"\"\"Format Stripe charge data.\"\"\"\n        return {\n            \"charge_id\": charge.id,\n            \"amount\": Decimal(charge.amount) / 100,\n            \"currency\": charge.currency,\n            \"status\": charge.status,\n            \"payment_method\": charge.payment_method,\n            \"receipt_url\": charge.receipt_url,\n            \"created\": datetime.fromtimestamp(charge.created)\n        }\n\n# Dependency injection\ndef get_stripe_service() -&gt; StripeService:\n    return StripeService()\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#2-payment-api-endpoints","title":"2. Payment API Endpoints","text":"<pre><code># src/api/payments.py\nfrom fastapi import APIRouter, Depends, HTTPException, status, Request\nfrom decimal import Decimal\nfrom typing import Dict, Any, Optional\nfrom src.services.payment.stripe_service import StripeService, get_stripe_service\nfrom src.core.auth import get_current_active_user\nfrom src.core.models import CurrentUser\nfrom src.core.schemas import (\n    PaymentIntentCreate,\n    PaymentIntentResponse,\n    CustomerCreate,\n    CustomerResponse,\n    SubscriptionCreate,\n    SubscriptionResponse,\n    RefundCreate,\n    RefundResponse\n)\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\nrouter = APIRouter(prefix=\"/payments\", tags=[\"payments\"])\n\n@router.post(\"/intents\", response_model=PaymentIntentResponse)\nasync def create_payment_intent(\n    payment_data: PaymentIntentCreate,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Create a payment intent.\"\"\"\n    try:\n        # Add user ID to metadata for tracking\n        metadata = payment_data.metadata or {}\n        metadata[\"user_id\"] = current_user.id\n\n        result = await stripe_service.create_payment_intent(\n            amount=payment_data.amount,\n            currency=payment_data.currency,\n            customer_id=payment_data.customer_id,\n            metadata=metadata,\n            payment_method_types=payment_data.payment_method_types\n        )\n\n        logger.info(f\"Created payment intent for user {current_user.id}: {result['payment_intent_id']}\")\n\n        return PaymentIntentResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Payment intent creation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/intents/{payment_intent_id}/confirm\", response_model=PaymentIntentResponse)\nasync def confirm_payment_intent(\n    payment_intent_id: str,\n    payment_method_id: str,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Confirm a payment intent.\"\"\"\n    try:\n        result = await stripe_service.confirm_payment_intent(\n            payment_intent_id=payment_intent_id,\n            payment_method_id=payment_method_id\n        )\n\n        logger.info(f\"Confirmed payment intent for user {current_user.id}: {payment_intent_id}\")\n\n        return PaymentIntentResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Payment confirmation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/customers\", response_model=CustomerResponse)\nasync def create_customer(\n    customer_data: CustomerCreate,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Create a Stripe customer.\"\"\"\n    try:\n        metadata = customer_data.metadata or {}\n        metadata[\"user_id\"] = current_user.id\n\n        result = await stripe_service.create_customer(\n            email=customer_data.email,\n            name=customer_data.name,\n            metadata=metadata\n        )\n\n        logger.info(f\"Created Stripe customer for user {current_user.id}: {result['customer_id']}\")\n\n        return CustomerResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Customer creation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/subscriptions\", response_model=SubscriptionResponse)\nasync def create_subscription(\n    subscription_data: SubscriptionCreate,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Create a subscription.\"\"\"\n    try:\n        metadata = subscription_data.metadata or {}\n        metadata[\"user_id\"] = current_user.id\n\n        result = await stripe_service.create_subscription(\n            customer_id=subscription_data.customer_id,\n            price_id=subscription_data.price_id,\n            metadata=metadata,\n            trial_period_days=subscription_data.trial_period_days\n        )\n\n        logger.info(f\"Created subscription for user {current_user.id}: {result['subscription_id']}\")\n\n        return SubscriptionResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Subscription creation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.delete(\"/subscriptions/{subscription_id}\")\nasync def cancel_subscription(\n    subscription_id: str,\n    at_period_end: bool = True,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Cancel a subscription.\"\"\"\n    try:\n        result = await stripe_service.cancel_subscription(\n            subscription_id=subscription_id,\n            at_period_end=at_period_end\n        )\n\n        logger.info(f\"Cancelled subscription for user {current_user.id}: {subscription_id}\")\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Subscription cancellation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n\n@router.post(\"/refunds\", response_model=RefundResponse)\nasync def create_refund(\n    refund_data: RefundCreate,\n    current_user: CurrentUser = Depends(get_current_active_user),\n    stripe_service: StripeService = Depends(get_stripe_service)\n):\n    \"\"\"Create a refund.\"\"\"\n    try:\n        result = await stripe_service.refund_payment(\n            payment_intent_id=refund_data.payment_intent_id,\n            amount=refund_data.amount,\n            reason=refund_data.reason\n        )\n\n        logger.info(f\"Created refund for user {current_user.id}: {result['refund_id']}\")\n\n        return RefundResponse(**result)\n\n    except Exception as e:\n        logger.error(f\"Refund creation failed for user {current_user.id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#3-stripe-webhook-handler","title":"3. Stripe Webhook Handler","text":"<pre><code># src/api/webhooks/stripe.py\nfrom fastapi import APIRouter, Request, HTTPException, status, Depends\nfrom fastapi.responses import Response\nimport json\nfrom src.services.payment.stripe_service import StripeService, get_stripe_service\nfrom src.core.events import EventPublisher, get_event_publisher\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\nrouter = APIRouter(prefix=\"/webhooks/stripe\", tags=[\"stripe-webhooks\"])\n\n@router.post(\"/\")\nasync def stripe_webhook(\n    request: Request,\n    stripe_service: StripeService = Depends(get_stripe_service),\n    event_publisher: EventPublisher = Depends(get_event_publisher)\n):\n    \"\"\"Handle Stripe webhooks.\"\"\"\n    payload = await request.body()\n    signature = request.headers.get(\"stripe-signature\")\n\n    if not signature:\n        logger.error(\"Missing Stripe webhook signature\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Missing webhook signature\"\n        )\n\n    try:\n        # Verify webhook signature\n        event = stripe_service.verify_webhook_signature(payload, signature)\n\n        logger.info(f\"Received Stripe webhook: {event['type']} - {event['id']}\")\n\n        # Handle different event types\n        await handle_stripe_event(event, event_publisher)\n\n        return Response(status_code=200, content=\"OK\")\n\n    except Exception as e:\n        logger.error(f\"Stripe webhook processing failed: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Webhook processing failed\"\n        )\n\nasync def handle_stripe_event(event: dict, event_publisher: EventPublisher):\n    \"\"\"Handle specific Stripe event types.\"\"\"\n    event_type = event[\"type\"]\n    event_data = event[\"data\"][\"object\"]\n\n    handlers = {\n        \"payment_intent.succeeded\": handle_payment_succeeded,\n        \"payment_intent.payment_failed\": handle_payment_failed,\n        \"customer.subscription.created\": handle_subscription_created,\n        \"customer.subscription.updated\": handle_subscription_updated,\n        \"customer.subscription.deleted\": handle_subscription_deleted,\n        \"invoice.payment_succeeded\": handle_invoice_paid,\n        \"invoice.payment_failed\": handle_invoice_failed\n    }\n\n    handler = handlers.get(event_type)\n    if handler:\n        await handler(event_data, event_publisher)\n    else:\n        logger.warning(f\"Unhandled Stripe event type: {event_type}\")\n\nasync def handle_payment_succeeded(payment_data: dict, event_publisher: EventPublisher):\n    \"\"\"Handle successful payment.\"\"\"\n    payment_event = {\n        \"event_type\": \"payment.succeeded\",\n        \"payment_intent_id\": payment_data[\"id\"],\n        \"amount\": payment_data[\"amount\"] / 100,\n        \"currency\": payment_data[\"currency\"],\n        \"customer_id\": payment_data.get(\"customer\"),\n        \"metadata\": payment_data.get(\"metadata\", {}),\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n\n    await event_publisher.publish(\"payment.succeeded\", payment_event)\n    logger.info(f\"Published payment succeeded event: {payment_data['id']}\")\n\nasync def handle_payment_failed(payment_data: dict, event_publisher: EventPublisher):\n    \"\"\"Handle failed payment.\"\"\"\n    payment_event = {\n        \"event_type\": \"payment.failed\",\n        \"payment_intent_id\": payment_data[\"id\"],\n        \"amount\": payment_data[\"amount\"] / 100,\n        \"currency\": payment_data[\"currency\"],\n        \"customer_id\": payment_data.get(\"customer\"),\n        \"last_payment_error\": payment_data.get(\"last_payment_error\"),\n        \"metadata\": payment_data.get(\"metadata\", {}),\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n\n    await event_publisher.publish(\"payment.failed\", payment_event)\n    logger.info(f\"Published payment failed event: {payment_data['id']}\")\n\nasync def handle_subscription_created(subscription_data: dict, event_publisher: EventPublisher):\n    \"\"\"Handle subscription creation.\"\"\"\n    subscription_event = {\n        \"event_type\": \"subscription.created\",\n        \"subscription_id\": subscription_data[\"id\"],\n        \"customer_id\": subscription_data[\"customer\"],\n        \"status\": subscription_data[\"status\"],\n        \"current_period_start\": subscription_data[\"current_period_start\"],\n        \"current_period_end\": subscription_data[\"current_period_end\"],\n        \"metadata\": subscription_data.get(\"metadata\", {}),\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n\n    await event_publisher.publish(\"subscription.created\", subscription_event)\n    logger.info(f\"Published subscription created event: {subscription_data['id']}\")\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#paypal-integration","title":"PayPal Integration","text":""},{"location":"atomic/external-integrations/payment-gateways/#1-paypal-service-implementation","title":"1. PayPal Service Implementation","text":"<pre><code># src/services/payment/paypal_service.py\nimport httpx\nfrom typing import Dict, Any, Optional\nfrom decimal import Decimal\nfrom datetime import datetime, timedelta\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import PaymentError, PaymentValidationError\n\nlogger = get_logger(__name__)\n\nclass PayPalService:\n    \"\"\"PayPal payment service implementation.\"\"\"\n\n    def __init__(self):\n        self.client_id = settings.paypal_client_id\n        self.client_secret = settings.paypal_client_secret\n        self.base_url = settings.paypal_base_url  # sandbox or live\n        self.access_token = None\n        self.token_expires_at = None\n\n    async def _get_access_token(self) -&gt; str:\n        \"\"\"Get PayPal access token.\"\"\"\n        if self.access_token and self.token_expires_at &gt; datetime.utcnow():\n            return self.access_token\n\n        auth = httpx.BasicAuth(self.client_id, self.client_secret)\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Accept-Language\": \"en_US\",\n        }\n        data = {\"grant_type\": \"client_credentials\"}\n\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.post(\n                    f\"{self.base_url}/v1/oauth2/token\",\n                    auth=auth,\n                    headers=headers,\n                    data=data\n                )\n                response.raise_for_status()\n\n                token_data = response.json()\n                self.access_token = token_data[\"access_token\"]\n                expires_in = token_data[\"expires_in\"]\n                self.token_expires_at = datetime.utcnow() + timedelta(seconds=expires_in - 60)\n\n                logger.info(\"Retrieved PayPal access token\")\n                return self.access_token\n\n            except httpx.HTTPStatusError as e:\n                logger.error(f\"PayPal authentication failed: {e}\")\n                raise PaymentError(\"PayPal authentication failed\")\n\n    async def _make_request(\n        self,\n        method: str,\n        endpoint: str,\n        data: Optional[Dict] = None,\n        headers: Optional[Dict] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Make authenticated request to PayPal API.\"\"\"\n        access_token = await self._get_access_token()\n\n        request_headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {access_token}\",\n        }\n        if headers:\n            request_headers.update(headers)\n\n        async with httpx.AsyncClient() as client:\n            try:\n                response = await client.request(\n                    method=method,\n                    url=f\"{self.base_url}{endpoint}\",\n                    json=data,\n                    headers=request_headers\n                )\n                response.raise_for_status()\n                return response.json()\n\n            except httpx.HTTPStatusError as e:\n                logger.error(f\"PayPal API error: {e.response.text}\")\n                raise PaymentError(f\"PayPal API error: {e.response.status_code}\")\n\n    async def create_order(\n        self,\n        amount: Decimal,\n        currency: str = \"USD\",\n        description: str = \"Payment\",\n        return_url: str = None,\n        cancel_url: str = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create PayPal order.\"\"\"\n        order_data = {\n            \"intent\": \"CAPTURE\",\n            \"purchase_units\": [\n                {\n                    \"amount\": {\n                        \"currency_code\": currency,\n                        \"value\": str(amount)\n                    },\n                    \"description\": description\n                }\n            ],\n            \"payment_source\": {\n                \"paypal\": {\n                    \"experience_context\": {\n                        \"payment_method_preference\": \"IMMEDIATE_PAYMENT_REQUIRED\",\n                        \"brand_name\": settings.app_name,\n                        \"locale\": \"en-US\",\n                        \"landing_page\": \"LOGIN\",\n                        \"shipping_preference\": \"NO_SHIPPING\",\n                        \"user_action\": \"PAY_NOW\"\n                    }\n                }\n            }\n        }\n\n        if return_url and cancel_url:\n            order_data[\"payment_source\"][\"paypal\"][\"experience_context\"].update({\n                \"return_url\": return_url,\n                \"cancel_url\": cancel_url\n            })\n\n        try:\n            response = await self._make_request(\"POST\", \"/v2/checkout/orders\", order_data)\n\n            logger.info(f\"Created PayPal order: {response['id']}\")\n\n            return {\n                \"order_id\": response[\"id\"],\n                \"status\": response[\"status\"],\n                \"amount\": amount,\n                \"currency\": currency,\n                \"approval_url\": self._get_approval_url(response[\"links\"]),\n                \"capture_url\": self._get_capture_url(response[\"links\"])\n            }\n\n        except Exception as e:\n            logger.error(f\"PayPal order creation failed: {e}\")\n            raise PaymentError(f\"PayPal order creation failed: {str(e)}\")\n\n    async def capture_order(self, order_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Capture PayPal order.\"\"\"\n        try:\n            response = await self._make_request(\n                \"POST\",\n                f\"/v2/checkout/orders/{order_id}/capture\"\n            )\n\n            logger.info(f\"Captured PayPal order: {order_id}\")\n\n            capture_data = response[\"purchase_units\"][0][\"payments\"][\"captures\"][0]\n\n            return {\n                \"order_id\": response[\"id\"],\n                \"capture_id\": capture_data[\"id\"],\n                \"status\": capture_data[\"status\"],\n                \"amount\": Decimal(capture_data[\"amount\"][\"value\"]),\n                \"currency\": capture_data[\"amount\"][\"currency_code\"],\n                \"create_time\": capture_data[\"create_time\"],\n                \"update_time\": capture_data[\"update_time\"]\n            }\n\n        except Exception as e:\n            logger.error(f\"PayPal order capture failed: {e}\")\n            raise PaymentError(f\"PayPal order capture failed: {str(e)}\")\n\n    async def refund_capture(\n        self,\n        capture_id: str,\n        amount: Optional[Decimal] = None,\n        currency: str = \"USD\",\n        note: str = \"Refund\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Refund PayPal capture.\"\"\"\n        refund_data = {\n            \"note_to_payer\": note\n        }\n\n        if amount:\n            refund_data[\"amount\"] = {\n                \"value\": str(amount),\n                \"currency_code\": currency\n            }\n\n        try:\n            response = await self._make_request(\n                \"POST\",\n                f\"/v2/payments/captures/{capture_id}/refund\",\n                refund_data\n            )\n\n            logger.info(f\"Created PayPal refund: {response['id']}\")\n\n            return {\n                \"refund_id\": response[\"id\"],\n                \"capture_id\": capture_id,\n                \"status\": response[\"status\"],\n                \"amount\": Decimal(response[\"amount\"][\"value\"]),\n                \"currency\": response[\"amount\"][\"currency_code\"],\n                \"create_time\": response[\"create_time\"],\n                \"update_time\": response[\"update_time\"]\n            }\n\n        except Exception as e:\n            logger.error(f\"PayPal refund failed: {e}\")\n            raise PaymentError(f\"PayPal refund failed: {str(e)}\")\n\n    def _get_approval_url(self, links: list) -&gt; Optional[str]:\n        \"\"\"Extract approval URL from PayPal response links.\"\"\"\n        for link in links:\n            if link[\"rel\"] == \"approve\":\n                return link[\"href\"]\n        return None\n\n    def _get_capture_url(self, links: list) -&gt; Optional[str]:\n        \"\"\"Extract capture URL from PayPal response links.\"\"\"\n        for link in links:\n            if link[\"rel\"] == \"capture\":\n                return link[\"href\"]\n        return None\n\n# Dependency injection\ndef get_paypal_service() -&gt; PayPalService:\n    return PayPalService()\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#payment-service-orchestration","title":"Payment Service Orchestration","text":""},{"location":"atomic/external-integrations/payment-gateways/#1-payment-manager","title":"1. Payment Manager","text":"<pre><code># src/services/payment/payment_manager.py\nfrom typing import Dict, Any, Optional, Literal\nfrom decimal import Decimal\nfrom src.services.payment.stripe_service import StripeService\nfrom src.services.payment.paypal_service import PayPalService\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.core.exceptions import PaymentError\n\nlogger = get_logger(__name__)\n\nPaymentProvider = Literal[\"stripe\", \"paypal\"]\n\nclass PaymentManager:\n    \"\"\"Centralized payment management across multiple providers.\"\"\"\n\n    def __init__(self):\n        self.stripe = StripeService()\n        self.paypal = PayPalService()\n        self.default_provider = settings.default_payment_provider or \"stripe\"\n\n    async def create_payment(\n        self,\n        amount: Decimal,\n        currency: str = \"USD\",\n        provider: PaymentProvider = None,\n        customer_id: Optional[str] = None,\n        description: str = \"Payment\",\n        metadata: Dict[str, Any] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create payment with specified or default provider.\"\"\"\n        provider = provider or self.default_provider\n\n        try:\n            if provider == \"stripe\":\n                result = await self.stripe.create_payment_intent(\n                    amount=amount,\n                    currency=currency.lower(),\n                    customer_id=customer_id,\n                    metadata=metadata\n                )\n                result[\"provider\"] = \"stripe\"\n                return result\n\n            elif provider == \"paypal\":\n                result = await self.paypal.create_order(\n                    amount=amount,\n                    currency=currency.upper(),\n                    description=description\n                )\n                result[\"provider\"] = \"paypal\"\n                return result\n\n            else:\n                raise PaymentError(f\"Unsupported payment provider: {provider}\")\n\n        except Exception as e:\n            logger.error(f\"Payment creation failed with {provider}: {e}\")\n            raise\n\n    async def capture_payment(\n        self,\n        payment_id: str,\n        provider: PaymentProvider,\n        payment_method_id: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Capture payment with specified provider.\"\"\"\n        try:\n            if provider == \"stripe\":\n                if not payment_method_id:\n                    raise PaymentError(\"Payment method ID required for Stripe\")\n\n                result = await self.stripe.confirm_payment_intent(\n                    payment_intent_id=payment_id,\n                    payment_method_id=payment_method_id\n                )\n                result[\"provider\"] = \"stripe\"\n                return result\n\n            elif provider == \"paypal\":\n                result = await self.paypal.capture_order(order_id=payment_id)\n                result[\"provider\"] = \"paypal\"\n                return result\n\n            else:\n                raise PaymentError(f\"Unsupported payment provider: {provider}\")\n\n        except Exception as e:\n            logger.error(f\"Payment capture failed with {provider}: {e}\")\n            raise\n\n    async def refund_payment(\n        self,\n        payment_id: str,\n        provider: PaymentProvider,\n        amount: Optional[Decimal] = None,\n        reason: str = \"requested_by_customer\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Refund payment with specified provider.\"\"\"\n        try:\n            if provider == \"stripe\":\n                result = await self.stripe.refund_payment(\n                    payment_intent_id=payment_id,\n                    amount=amount,\n                    reason=reason\n                )\n                result[\"provider\"] = \"stripe\"\n                return result\n\n            elif provider == \"paypal\":\n                result = await self.paypal.refund_capture(\n                    capture_id=payment_id,\n                    amount=amount,\n                    note=reason\n                )\n                result[\"provider\"] = \"paypal\"\n                return result\n\n            else:\n                raise PaymentError(f\"Unsupported payment provider: {provider}\")\n\n        except Exception as e:\n            logger.error(f\"Payment refund failed with {provider}: {e}\")\n            raise\n\n# Dependency injection\ndef get_payment_manager() -&gt; PaymentManager:\n    return PaymentManager()\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#security-and-compliance","title":"Security and Compliance","text":""},{"location":"atomic/external-integrations/payment-gateways/#1-pci-compliance-patterns","title":"1. PCI Compliance Patterns","text":"<pre><code># src/core/pci_compliance.py\nfrom typing import Any, Dict\nimport re\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nclass PCIComplianceHelper:\n    \"\"\"Helper for PCI DSS compliance.\"\"\"\n\n    @staticmethod\n    def mask_card_number(card_number: str) -&gt; str:\n        \"\"\"Mask credit card number for logging/display.\"\"\"\n        # Remove non-digits\n        digits_only = re.sub(r'\\D', '', card_number)\n\n        if len(digits_only) &lt; 6:\n            return \"*\" * len(digits_only)\n\n        # Show first 4 and last 4 digits\n        return f\"{digits_only[:4]}{'*' * (len(digits_only) - 8)}{digits_only[-4:]}\"\n\n    @staticmethod\n    def sanitize_payment_data(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Remove sensitive payment data from logs/responses.\"\"\"\n        sensitive_fields = {\n            \"card_number\", \"cvv\", \"cvc\", \"card_code\", \"security_code\",\n            \"expiry_month\", \"expiry_year\", \"exp_month\", \"exp_year\",\n            \"account_number\", \"routing_number\", \"ssn\", \"tax_id\"\n        }\n\n        sanitized = data.copy()\n\n        for key, value in data.items():\n            if key.lower() in sensitive_fields:\n                if key.lower() == \"card_number\" and isinstance(value, str):\n                    sanitized[key] = PCIComplianceHelper.mask_card_number(value)\n                else:\n                    sanitized[key] = \"***REDACTED***\"\n\n        return sanitized\n\n    @staticmethod\n    def validate_card_number(card_number: str) -&gt; bool:\n        \"\"\"Validate credit card number using Luhn algorithm.\"\"\"\n        # Remove non-digits\n        digits = re.sub(r'\\D', '', card_number)\n\n        if not digits or len(digits) &lt; 13 or len(digits) &gt; 19:\n            return False\n\n        # Luhn algorithm\n        checksum = 0\n        even_position = False\n\n        for digit in reversed(digits):\n            n = int(digit)\n            if even_position:\n                n *= 2\n                if n &gt; 9:\n                    n = n // 10 + n % 10\n            checksum += n\n            even_position = not even_position\n\n        return checksum % 10 == 0\n\n    @staticmethod\n    def log_payment_event(event_type: str, data: Dict[str, Any]):\n        \"\"\"Log payment event with PCI compliance.\"\"\"\n        sanitized_data = PCIComplianceHelper.sanitize_payment_data(data)\n        logger.info(f\"Payment event: {event_type}\", extra={\"data\": sanitized_data})\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#testing-payment-integration","title":"Testing Payment Integration","text":""},{"location":"atomic/external-integrations/payment-gateways/#1-payment-service-tests","title":"1. Payment Service Tests","text":"<pre><code># tests/test_payment_integration.py\nimport pytest\nfrom decimal import Decimal\nfrom unittest.mock import Mock, patch, AsyncMock\nfrom src.services.payment.stripe_service import StripeService\nfrom src.services.payment.paypal_service import PayPalService\nfrom src.services.payment.payment_manager import PaymentManager\nfrom src.core.exceptions import PaymentError\n\nclass TestStripeIntegration:\n    \"\"\"Test Stripe payment integration.\"\"\"\n\n    @pytest.fixture\n    def stripe_service(self):\n        return StripeService()\n\n    @pytest.mark.asyncio\n    async def test_create_payment_intent_success(self, stripe_service):\n        \"\"\"Test successful payment intent creation.\"\"\"\n        with patch('stripe.PaymentIntent.create') as mock_create:\n            mock_create.return_value = Mock(\n                id=\"pi_test_123\",\n                client_secret=\"pi_test_123_secret_test\",\n                amount=2000,\n                currency=\"usd\",\n                status=\"requires_payment_method\",\n                payment_method_types=[\"card\"]\n            )\n\n            result = await stripe_service.create_payment_intent(\n                amount=Decimal(\"20.00\"),\n                currency=\"usd\"\n            )\n\n            assert result[\"payment_intent_id\"] == \"pi_test_123\"\n            assert result[\"amount\"] == Decimal(\"20.00\")\n            assert result[\"currency\"] == \"usd\"\n\n    @pytest.mark.asyncio\n    async def test_create_payment_intent_card_error(self, stripe_service):\n        \"\"\"Test payment intent creation with card error.\"\"\"\n        import stripe\n\n        with patch('stripe.PaymentIntent.create') as mock_create:\n            mock_create.side_effect = stripe.error.CardError(\n                message=\"Your card was declined.\",\n                param=\"card\",\n                code=\"card_declined\"\n            )\n\n            with pytest.raises(PaymentError) as exc_info:\n                await stripe_service.create_payment_intent(\n                    amount=Decimal(\"20.00\"),\n                    currency=\"usd\"\n                )\n\n            assert \"Card error\" in str(exc_info.value)\n\n    @pytest.mark.asyncio\n    async def test_webhook_signature_verification(self, stripe_service):\n        \"\"\"Test webhook signature verification.\"\"\"\n        payload = b'{\"test\": \"data\"}'\n        signature = \"test_signature\"\n\n        with patch('stripe.Webhook.construct_event') as mock_construct:\n            mock_construct.return_value = {\"type\": \"payment_intent.succeeded\"}\n\n            result = stripe_service.verify_webhook_signature(payload, signature)\n\n            assert result[\"type\"] == \"payment_intent.succeeded\"\n            mock_construct.assert_called_once_with(\n                payload, signature, stripe_service.webhook_secret\n            )\n\nclass TestPayPalIntegration:\n    \"\"\"Test PayPal payment integration.\"\"\"\n\n    @pytest.fixture\n    def paypal_service(self):\n        return PayPalService()\n\n    @pytest.mark.asyncio\n    async def test_get_access_token(self, paypal_service):\n        \"\"\"Test PayPal access token retrieval.\"\"\"\n        with patch('httpx.AsyncClient') as mock_client:\n            mock_response = Mock()\n            mock_response.json.return_value = {\n                \"access_token\": \"test_token\",\n                \"expires_in\": 3600\n            }\n            mock_response.raise_for_status.return_value = None\n\n            mock_client.return_value.__aenter__.return_value.post = AsyncMock(\n                return_value=mock_response\n            )\n\n            token = await paypal_service._get_access_token()\n\n            assert token == \"test_token\"\n            assert paypal_service.access_token == \"test_token\"\n\n    @pytest.mark.asyncio\n    async def test_create_order_success(self, paypal_service):\n        \"\"\"Test successful PayPal order creation.\"\"\"\n        with patch.object(paypal_service, '_make_request') as mock_request:\n            mock_request.return_value = {\n                \"id\": \"order_123\",\n                \"status\": \"CREATED\",\n                \"links\": [\n                    {\"rel\": \"approve\", \"href\": \"https://paypal.com/approve\"},\n                    {\"rel\": \"capture\", \"href\": \"https://api.paypal.com/capture\"}\n                ]\n            }\n\n            result = await paypal_service.create_order(\n                amount=Decimal(\"25.00\"),\n                currency=\"USD\"\n            )\n\n            assert result[\"order_id\"] == \"order_123\"\n            assert result[\"amount\"] == Decimal(\"25.00\")\n            assert \"paypal.com/approve\" in result[\"approval_url\"]\n\nclass TestPaymentManager:\n    \"\"\"Test payment manager orchestration.\"\"\"\n\n    @pytest.fixture\n    def payment_manager(self):\n        return PaymentManager()\n\n    @pytest.mark.asyncio\n    async def test_create_payment_stripe(self, payment_manager):\n        \"\"\"Test payment creation with Stripe.\"\"\"\n        with patch.object(payment_manager.stripe, 'create_payment_intent') as mock_create:\n            mock_create.return_value = {\n                \"payment_intent_id\": \"pi_test_123\",\n                \"amount\": Decimal(\"30.00\"),\n                \"currency\": \"usd\"\n            }\n\n            result = await payment_manager.create_payment(\n                amount=Decimal(\"30.00\"),\n                provider=\"stripe\"\n            )\n\n            assert result[\"provider\"] == \"stripe\"\n            assert result[\"payment_intent_id\"] == \"pi_test_123\"\n\n    @pytest.mark.asyncio\n    async def test_create_payment_paypal(self, payment_manager):\n        \"\"\"Test payment creation with PayPal.\"\"\"\n        with patch.object(payment_manager.paypal, 'create_order') as mock_create:\n            mock_create.return_value = {\n                \"order_id\": \"order_123\",\n                \"amount\": Decimal(\"30.00\"),\n                \"currency\": \"USD\"\n            }\n\n            result = await payment_manager.create_payment(\n                amount=Decimal(\"30.00\"),\n                provider=\"paypal\"\n            )\n\n            assert result[\"provider\"] == \"paypal\"\n            assert result[\"order_id\"] == \"order_123\"\n\n    @pytest.mark.asyncio\n    async def test_unsupported_provider(self, payment_manager):\n        \"\"\"Test error handling for unsupported provider.\"\"\"\n        with pytest.raises(PaymentError) as exc_info:\n            await payment_manager.create_payment(\n                amount=Decimal(\"30.00\"),\n                provider=\"unsupported\"\n            )\n\n        assert \"Unsupported payment provider\" in str(exc_info.value)\n\nclass TestPCICompliance:\n    \"\"\"Test PCI compliance helpers.\"\"\"\n\n    def test_mask_card_number(self):\n        \"\"\"Test credit card number masking.\"\"\"\n        from src.core.pci_compliance import PCIComplianceHelper\n\n        # Test full card number\n        masked = PCIComplianceHelper.mask_card_number(\"4111111111111111\")\n        assert masked == \"4111********1111\"\n\n        # Test short number\n        masked = PCIComplianceHelper.mask_card_number(\"4111\")\n        assert masked == \"****\"\n\n    def test_sanitize_payment_data(self):\n        \"\"\"Test payment data sanitization.\"\"\"\n        from src.core.pci_compliance import PCIComplianceHelper\n\n        data = {\n            \"amount\": \"100.00\",\n            \"card_number\": \"4111111111111111\",\n            \"cvv\": \"123\",\n            \"user_id\": \"user-123\"\n        }\n\n        sanitized = PCIComplianceHelper.sanitize_payment_data(data)\n\n        assert sanitized[\"amount\"] == \"100.00\"\n        assert sanitized[\"card_number\"] == \"4111********1111\"\n        assert sanitized[\"cvv\"] == \"***REDACTED***\"\n        assert sanitized[\"user_id\"] == \"user-123\"\n\n    def test_validate_card_number(self):\n        \"\"\"Test credit card number validation.\"\"\"\n        from src.core.pci_compliance import PCIComplianceHelper\n\n        # Valid Visa test number\n        assert PCIComplianceHelper.validate_card_number(\"4111111111111111\") is True\n\n        # Invalid number\n        assert PCIComplianceHelper.validate_card_number(\"4111111111111112\") is False\n\n        # Too short\n        assert PCIComplianceHelper.validate_card_number(\"411111\") is False\n</code></pre>"},{"location":"atomic/external-integrations/payment-gateways/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/external-integrations/webhook-handling.md</code> - Webhook processing</li> <li><code>docs/atomic/external-integrations/api-rate-limiting.md</code> - Rate limiting patterns</li> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> - Authentication for payments</li> <li><code>docs/atomic/services/fastapi/error-handling.md</code> - Error handling patterns</li> <li><code>docs/atomic/testing/integration-testing/http-integration-testing.md</code> - HTTP testing</li> </ul>"},{"location":"atomic/external-integrations/payment-gateways/#implementation-checklist","title":"Implementation Checklist","text":""},{"location":"atomic/external-integrations/payment-gateways/#stripe-integration_1","title":"Stripe Integration","text":"<ul> <li> API key configuration and security</li> <li> Payment Intent creation and confirmation</li> <li> Customer management</li> <li> Subscription handling</li> <li> Webhook signature verification</li> <li> Refund processing</li> <li> Error handling and logging</li> <li> Test mode configuration</li> </ul>"},{"location":"atomic/external-integrations/payment-gateways/#paypal-integration_1","title":"PayPal Integration","text":"<ul> <li> OAuth2 authentication</li> <li> Order creation and capture</li> <li> Refund processing</li> <li> Webhook handling</li> <li> Error handling and logging</li> <li> Sandbox/production configuration</li> </ul>"},{"location":"atomic/external-integrations/payment-gateways/#security-compliance","title":"Security &amp; Compliance","text":"<ul> <li> PCI DSS compliance measures</li> <li> Sensitive data sanitization</li> <li> Secure credential storage</li> <li> Card number validation</li> <li> Payment data encryption</li> <li> Audit logging</li> </ul>"},{"location":"atomic/external-integrations/payment-gateways/#testing","title":"Testing","text":"<ul> <li> Unit tests for payment services</li> <li> Integration tests with test APIs</li> <li> Webhook testing</li> <li> Error scenario testing</li> <li> Security testing</li> <li> PCI compliance validation</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/","title":"Webhook Handling","text":"<p>Comprehensive guide for handling webhooks from external services in microservices architecture following the Improved Hybrid Approach.</p>"},{"location":"atomic/external-integrations/webhook-handling/#overview","title":"Overview","text":"<p>Webhooks enable external services to notify your application about events in real-time. This guide covers secure webhook handling patterns, verification, processing, and error handling while maintaining service reliability and security.</p>"},{"location":"atomic/external-integrations/webhook-handling/#architecture-pattern","title":"Architecture Pattern","text":"<p>Webhook handling follows a dedicated service pattern with centralized processing, verification, and event distribution.</p> <pre><code>graph TB\n    subgraph \"External Services\"\n        STRIPE[Stripe Webhooks]\n        PAYPAL[PayPal Webhooks]\n        TWILIO[Twilio Webhooks]\n        GITHUB[GitHub Webhooks]\n        SHOPIFY[Shopify Webhooks]\n    end\n\n    subgraph \"Webhook Infrastructure\"\n        WEBHOOK_GATEWAY[Webhook Gateway :8005]\n        WEBHOOK_PROCESSOR[Webhook Processor]\n        WEBHOOK_RETRY[Retry Handler]\n    end\n\n    subgraph \"Business Services\"\n        API[FastAPI Service]\n        WORKER[AsyncIO Workers]\n    end\n\n    subgraph \"Infrastructure\"\n        POSTGRES[(PostgreSQL - Logs)]\n        REDIS[(Redis - Queue)]\n        RABBIT[RabbitMQ - Events]\n    end\n\n    STRIPE -.-&gt;|POST /webhooks/stripe| WEBHOOK_GATEWAY\n    PAYPAL -.-&gt;|POST /webhooks/paypal| WEBHOOK_GATEWAY\n    TWILIO -.-&gt;|POST /webhooks/twilio| WEBHOOK_GATEWAY\n    GITHUB -.-&gt;|POST /webhooks/github| WEBHOOK_GATEWAY\n    SHOPIFY -.-&gt;|POST /webhooks/shopify| WEBHOOK_GATEWAY\n\n    WEBHOOK_GATEWAY --&gt; WEBHOOK_PROCESSOR\n    WEBHOOK_PROCESSOR --&gt; WEBHOOK_RETRY\n    WEBHOOK_PROCESSOR --&gt; RABBIT\n    WEBHOOK_RETRY --&gt; REDIS\n\n    RABBIT --&gt; API\n    RABBIT --&gt; WORKER\n\n    WEBHOOK_GATEWAY --&gt; POSTGRES</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#core-webhook-infrastructure","title":"Core Webhook Infrastructure","text":""},{"location":"atomic/external-integrations/webhook-handling/#1-webhook-gateway-service","title":"1. Webhook Gateway Service","text":"<pre><code># src/services/webhooks/webhook_gateway.py\nfrom fastapi import FastAPI, Request, HTTPException, status, BackgroundTasks\nfrom fastapi.responses import Response\nfrom typing import Dict, Any, Optional\nimport hmac\nimport hashlib\nimport json\nfrom datetime import datetime\nimport uuid6\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\nfrom src.services.webhooks.webhook_processor import WebhookProcessor\nfrom src.services.webhooks.webhook_storage import WebhookStorage\nfrom src.core.exceptions import WebhookError\n\nlogger = get_logger(__name__)\n\nclass WebhookGateway:\n    \"\"\"Centralized webhook gateway for handling all external webhooks.\"\"\"\n\n    def __init__(self):\n        self.processor = WebhookProcessor()\n        self.storage = WebhookStorage()\n        self.app = FastAPI(title=\"Webhook Gateway\")\n        self.setup_routes()\n\n    def setup_routes(self):\n        \"\"\"Setup webhook routes for different providers.\"\"\"\n\n        @self.app.post(\"/webhooks/stripe\")\n        async def stripe_webhook(request: Request, background_tasks: BackgroundTasks):\n            return await self.handle_webhook(\n                request=request,\n                provider=\"stripe\",\n                background_tasks=background_tasks,\n                verification_method=self._verify_stripe_signature\n            )\n\n        @self.app.post(\"/webhooks/paypal\")\n        async def paypal_webhook(request: Request, background_tasks: BackgroundTasks):\n            return await self.handle_webhook(\n                request=request,\n                provider=\"paypal\",\n                background_tasks=background_tasks,\n                verification_method=self._verify_paypal_signature\n            )\n\n        @self.app.post(\"/webhooks/twilio\")\n        async def twilio_webhook(request: Request, background_tasks: BackgroundTasks):\n            return await self.handle_webhook(\n                request=request,\n                provider=\"twilio\",\n                background_tasks=background_tasks,\n                verification_method=self._verify_twilio_signature\n            )\n\n        @self.app.post(\"/webhooks/github\")\n        async def github_webhook(request: Request, background_tasks: BackgroundTasks):\n            return await self.handle_webhook(\n                request=request,\n                provider=\"github\",\n                background_tasks=background_tasks,\n                verification_method=self._verify_github_signature\n            )\n\n        @self.app.post(\"/webhooks/shopify\")\n        async def shopify_webhook(request: Request, background_tasks: BackgroundTasks):\n            return await self.handle_webhook(\n                request=request,\n                provider=\"shopify\",\n                background_tasks=background_tasks,\n                verification_method=self._verify_shopify_signature\n            )\n\n        @self.app.get(\"/health\")\n        async def health_check():\n            return {\"status\": \"healthy\", \"service\": \"webhook-gateway\"}\n\n    async def handle_webhook(\n        self,\n        request: Request,\n        provider: str,\n        background_tasks: BackgroundTasks,\n        verification_method: callable\n    ) -&gt; Response:\n        \"\"\"Generic webhook handler with verification and processing.\"\"\"\n        webhook_id = str(uuid6.uuid6())\n        start_time = datetime.utcnow()\n\n        try:\n            # Get request data\n            body = await request.body()\n            headers = dict(request.headers)\n\n            # Store raw webhook for audit\n            webhook_record = {\n                \"id\": webhook_id,\n                \"provider\": provider,\n                \"headers\": headers,\n                \"body\": body.decode('utf-8'),\n                \"received_at\": start_time.isoformat(),\n                \"client_ip\": request.client.host,\n                \"status\": \"received\"\n            }\n\n            # Verify webhook signature\n            if not verification_method(body, headers):\n                webhook_record[\"status\"] = \"verification_failed\"\n                await self.storage.store_webhook(webhook_record)\n\n                logger.warning(f\"Webhook verification failed for {provider} - {webhook_id}\")\n                raise HTTPException(\n                    status_code=status.HTTP_401_UNAUTHORIZED,\n                    detail=\"Webhook verification failed\"\n                )\n\n            # Parse JSON payload\n            try:\n                payload = json.loads(body.decode('utf-8'))\n            except json.JSONDecodeError as e:\n                webhook_record[\"status\"] = \"invalid_json\"\n                webhook_record[\"error\"] = str(e)\n                await self.storage.store_webhook(webhook_record)\n\n                logger.error(f\"Invalid JSON in webhook from {provider} - {webhook_id}: {e}\")\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=\"Invalid JSON payload\"\n                )\n\n            # Update webhook record with parsed data\n            webhook_record.update({\n                \"payload\": payload,\n                \"event_type\": self._extract_event_type(provider, payload),\n                \"status\": \"verified\"\n            })\n\n            # Store verified webhook\n            await self.storage.store_webhook(webhook_record)\n\n            # Process webhook in background\n            background_tasks.add_task(\n                self.processor.process_webhook,\n                webhook_id=webhook_id,\n                provider=provider,\n                payload=payload,\n                headers=headers\n            )\n\n            # Log successful receipt\n            processing_time = (datetime.utcnow() - start_time).total_seconds()\n            logger.info(\n                f\"Webhook received from {provider} - {webhook_id} \"\n                f\"({processing_time:.3f}s)\"\n            )\n\n            return Response(status_code=200, content=\"OK\")\n\n        except HTTPException:\n            raise\n        except Exception as e:\n            webhook_record[\"status\"] = \"error\"\n            webhook_record[\"error\"] = str(e)\n            await self.storage.store_webhook(webhook_record)\n\n            logger.error(f\"Webhook handling error for {provider} - {webhook_id}: {e}\")\n            raise HTTPException(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                detail=\"Internal server error\"\n            )\n\n    def _verify_stripe_signature(self, body: bytes, headers: Dict[str, str]) -&gt; bool:\n        \"\"\"Verify Stripe webhook signature.\"\"\"\n        signature = headers.get(\"stripe-signature\")\n        if not signature:\n            return False\n\n        try:\n            import stripe\n            stripe.Webhook.construct_event(\n                body, signature, settings.stripe_webhook_secret\n            )\n            return True\n        except Exception as e:\n            logger.error(f\"Stripe signature verification failed: {e}\")\n            return False\n\n    def _verify_paypal_signature(self, body: bytes, headers: Dict[str, str]) -&gt; bool:\n        \"\"\"Verify PayPal webhook signature.\"\"\"\n        # PayPal webhook verification implementation\n        auth_algo = headers.get(\"paypal-auth-algo\")\n        transmission_id = headers.get(\"paypal-transmission-id\")\n        cert_id = headers.get(\"paypal-cert-id\")\n        transmission_sig = headers.get(\"paypal-transmission-sig\")\n        transmission_time = headers.get(\"paypal-transmission-time\")\n\n        # Implement PayPal webhook verification logic\n        # This is a simplified version - implement actual verification\n        return all([auth_algo, transmission_id, cert_id, transmission_sig, transmission_time])\n\n    def _verify_twilio_signature(self, body: bytes, headers: Dict[str, str]) -&gt; bool:\n        \"\"\"Verify Twilio webhook signature.\"\"\"\n        signature = headers.get(\"x-twilio-signature\")\n        if not signature:\n            return False\n\n        try:\n            from twilio.request_validator import RequestValidator\n            validator = RequestValidator(settings.twilio_auth_token)\n\n            # Get full URL (implement based on your setup)\n            url = f\"{settings.webhook_base_url}/webhooks/twilio\"\n\n            return validator.validate(url, body.decode('utf-8'), signature)\n        except Exception as e:\n            logger.error(f\"Twilio signature verification failed: {e}\")\n            return False\n\n    def _verify_github_signature(self, body: bytes, headers: Dict[str, str]) -&gt; bool:\n        \"\"\"Verify GitHub webhook signature.\"\"\"\n        signature = headers.get(\"x-hub-signature-256\")\n        if not signature:\n            return False\n\n        try:\n            expected_signature = \"sha256=\" + hmac.new(\n                settings.github_webhook_secret.encode(),\n                body,\n                hashlib.sha256\n            ).hexdigest()\n\n            return hmac.compare_digest(signature, expected_signature)\n        except Exception as e:\n            logger.error(f\"GitHub signature verification failed: {e}\")\n            return False\n\n    def _verify_shopify_signature(self, body: bytes, headers: Dict[str, str]) -&gt; bool:\n        \"\"\"Verify Shopify webhook signature.\"\"\"\n        signature = headers.get(\"x-shopify-hmac-sha256\")\n        if not signature:\n            return False\n\n        try:\n            expected_signature = hmac.new(\n                settings.shopify_webhook_secret.encode(),\n                body,\n                hashlib.sha256\n            ).digest()\n\n            import base64\n            return hmac.compare_digest(\n                signature.encode(),\n                base64.b64encode(expected_signature)\n            )\n        except Exception as e:\n            logger.error(f\"Shopify signature verification failed: {e}\")\n            return False\n\n    def _extract_event_type(self, provider: str, payload: Dict[str, Any]) -&gt; Optional[str]:\n        \"\"\"Extract event type from webhook payload.\"\"\"\n        event_type_mappings = {\n            \"stripe\": lambda p: p.get(\"type\"),\n            \"paypal\": lambda p: p.get(\"event_type\"),\n            \"twilio\": lambda p: p.get(\"StatusCallbackEvent\") or p.get(\"EventType\"),\n            \"github\": lambda p: p.get(\"action\"),\n            \"shopify\": lambda p: headers.get(\"x-shopify-topic\")  # From headers\n        }\n\n        extractor = event_type_mappings.get(provider)\n        return extractor(payload) if extractor else None\n\n# Initialize webhook gateway\nwebhook_gateway = WebhookGateway()\napp = webhook_gateway.app\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#2-webhook-processor","title":"2. Webhook Processor","text":"<pre><code># src/services/webhooks/webhook_processor.py\nimport asyncio\nfrom typing import Dict, Any, Optional, List\nfrom datetime import datetime, timedelta\nimport json\nfrom src.core.logging import get_logger\nfrom src.core.events import EventPublisher\nfrom src.services.webhooks.webhook_storage import WebhookStorage\nfrom src.services.webhooks.webhook_handlers import WebhookHandlerRegistry\nfrom src.core.exceptions import WebhookError\n\nlogger = get_logger(__name__)\n\nclass WebhookProcessor:\n    \"\"\"Process verified webhooks and distribute events.\"\"\"\n\n    def __init__(self):\n        self.storage = WebhookStorage()\n        self.event_publisher = EventPublisher()\n        self.handler_registry = WebhookHandlerRegistry()\n        self.max_retries = 3\n        self.retry_delays = [5, 30, 300]  # seconds\n\n    async def process_webhook(\n        self,\n        webhook_id: str,\n        provider: str,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; None:\n        \"\"\"Process a verified webhook.\"\"\"\n        processing_start = datetime.utcnow()\n\n        try:\n            # Update webhook status to processing\n            await self.storage.update_webhook_status(\n                webhook_id, \"processing\", processing_start\n            )\n\n            # Extract event information\n            event_type = self._extract_event_type(provider, payload, headers)\n            if not event_type:\n                raise WebhookError(f\"Cannot determine event type for {provider} webhook\")\n\n            # Check for duplicate processing (idempotency)\n            if await self._is_duplicate_event(provider, payload):\n                logger.info(f\"Duplicate webhook detected: {webhook_id} - skipping\")\n                await self.storage.update_webhook_status(webhook_id, \"duplicate\")\n                return\n\n            # Get appropriate handler\n            handler = self.handler_registry.get_handler(provider, event_type)\n            if not handler:\n                logger.warning(f\"No handler found for {provider}.{event_type}\")\n                await self.storage.update_webhook_status(webhook_id, \"no_handler\")\n                return\n\n            # Process with handler\n            result = await handler.handle(payload, headers)\n\n            # Publish internal events if handler returns them\n            if result and result.get(\"events\"):\n                for event in result[\"events\"]:\n                    await self.event_publisher.publish(\n                        event[\"type\"],\n                        event[\"data\"],\n                        correlation_id=webhook_id\n                    )\n\n            # Update webhook status to completed\n            processing_end = datetime.utcnow()\n            processing_time = (processing_end - processing_start).total_seconds()\n\n            await self.storage.update_webhook_status(\n                webhook_id,\n                \"completed\",\n                processing_end,\n                {\"processing_time\": processing_time, \"result\": result}\n            )\n\n            logger.info(\n                f\"Webhook processed successfully: {webhook_id} \"\n                f\"({processing_time:.3f}s)\"\n            )\n\n        except Exception as e:\n            # Handle processing error\n            await self._handle_processing_error(webhook_id, e)\n\n    async def _is_duplicate_event(\n        self,\n        provider: str,\n        payload: Dict[str, Any]\n    ) -&gt; bool:\n        \"\"\"Check if this event has already been processed.\"\"\"\n        # Extract unique event identifier based on provider\n        event_id = self._extract_event_id(provider, payload)\n        if not event_id:\n            return False\n\n        # Check if we've seen this event before\n        return await self.storage.check_event_processed(provider, event_id)\n\n    def _extract_event_id(self, provider: str, payload: Dict[str, Any]) -&gt; Optional[str]:\n        \"\"\"Extract unique event ID from payload.\"\"\"\n        id_mappings = {\n            \"stripe\": lambda p: p.get(\"id\"),\n            \"paypal\": lambda p: p.get(\"id\"),\n            \"twilio\": lambda p: p.get(\"MessageSid\") or p.get(\"CallSid\"),\n            \"github\": lambda p: p.get(\"delivery\"),\n            \"shopify\": lambda p: p.get(\"id\")\n        }\n\n        extractor = id_mappings.get(provider)\n        return str(extractor(payload)) if extractor and extractor(payload) else None\n\n    def _extract_event_type(\n        self,\n        provider: str,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[str]:\n        \"\"\"Extract event type from webhook.\"\"\"\n        type_mappings = {\n            \"stripe\": lambda p, h: p.get(\"type\"),\n            \"paypal\": lambda p, h: p.get(\"event_type\"),\n            \"twilio\": lambda p, h: p.get(\"StatusCallbackEvent\") or p.get(\"EventType\"),\n            \"github\": lambda p, h: h.get(\"x-github-event\"),\n            \"shopify\": lambda p, h: h.get(\"x-shopify-topic\")\n        }\n\n        extractor = type_mappings.get(provider)\n        return extractor(payload, headers) if extractor else None\n\n    async def _handle_processing_error(self, webhook_id: str, error: Exception) -&gt; None:\n        \"\"\"Handle webhook processing error with retry logic.\"\"\"\n        logger.error(f\"Webhook processing failed: {webhook_id} - {error}\")\n\n        # Get current retry count\n        webhook_data = await self.storage.get_webhook(webhook_id)\n        retry_count = webhook_data.get(\"retry_count\", 0)\n\n        if retry_count &lt; self.max_retries:\n            # Schedule retry\n            retry_delay = self.retry_delays[min(retry_count, len(self.retry_delays) - 1)]\n            retry_at = datetime.utcnow() + timedelta(seconds=retry_delay)\n\n            await self.storage.update_webhook_status(\n                webhook_id,\n                \"retry_scheduled\",\n                metadata={\n                    \"retry_count\": retry_count + 1,\n                    \"retry_at\": retry_at.isoformat(),\n                    \"error\": str(error)\n                }\n            )\n\n            # Schedule retry (implement based on your task queue)\n            await self._schedule_retry(webhook_id, retry_delay)\n\n        else:\n            # Max retries exceeded\n            await self.storage.update_webhook_status(\n                webhook_id,\n                \"failed\",\n                metadata={\n                    \"retry_count\": retry_count,\n                    \"final_error\": str(error)\n                }\n            )\n\n    async def _schedule_retry(self, webhook_id: str, delay_seconds: int) -&gt; None:\n        \"\"\"Schedule webhook retry.\"\"\"\n        # Implement based on your task queue system (Celery, RQ, etc.)\n        # For simple cases, you can use asyncio.sleep in a background task\n        asyncio.create_task(self._retry_webhook_after_delay(webhook_id, delay_seconds))\n\n    async def _retry_webhook_after_delay(self, webhook_id: str, delay_seconds: int) -&gt; None:\n        \"\"\"Retry webhook processing after delay.\"\"\"\n        await asyncio.sleep(delay_seconds)\n\n        # Get webhook data\n        webhook_data = await self.storage.get_webhook(webhook_id)\n        if not webhook_data:\n            logger.error(f\"Webhook not found for retry: {webhook_id}\")\n            return\n\n        # Retry processing\n        await self.process_webhook(\n            webhook_id=webhook_id,\n            provider=webhook_data[\"provider\"],\n            payload=webhook_data[\"payload\"],\n            headers=webhook_data[\"headers\"]\n        )\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#3-webhook-handlers","title":"3. Webhook Handlers","text":"<pre><code># src/services/webhooks/webhook_handlers.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional, List\nfrom datetime import datetime\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nclass WebhookHandler(ABC):\n    \"\"\"Abstract base class for webhook handlers.\"\"\"\n\n    @abstractmethod\n    async def handle(\n        self,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Handle webhook payload and return events to publish.\"\"\"\n        pass\n\nclass StripeWebhookHandler(WebhookHandler):\n    \"\"\"Handle Stripe webhooks.\"\"\"\n\n    async def handle(\n        self,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Handle Stripe webhook events.\"\"\"\n        event_type = payload.get(\"type\")\n        event_data = payload.get(\"data\", {}).get(\"object\", {})\n\n        logger.info(f\"Processing Stripe event: {event_type}\")\n\n        events_to_publish = []\n\n        if event_type == \"payment_intent.succeeded\":\n            events_to_publish.append({\n                \"type\": \"payment.completed\",\n                \"data\": {\n                    \"payment_intent_id\": event_data.get(\"id\"),\n                    \"amount\": event_data.get(\"amount\", 0) / 100,\n                    \"currency\": event_data.get(\"currency\"),\n                    \"customer_id\": event_data.get(\"customer\"),\n                    \"metadata\": event_data.get(\"metadata\", {}),\n                    \"provider\": \"stripe\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif event_type == \"payment_intent.payment_failed\":\n            events_to_publish.append({\n                \"type\": \"payment.failed\",\n                \"data\": {\n                    \"payment_intent_id\": event_data.get(\"id\"),\n                    \"amount\": event_data.get(\"amount\", 0) / 100,\n                    \"currency\": event_data.get(\"currency\"),\n                    \"customer_id\": event_data.get(\"customer\"),\n                    \"failure_reason\": event_data.get(\"last_payment_error\", {}).get(\"message\"),\n                    \"provider\": \"stripe\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif event_type == \"customer.subscription.created\":\n            events_to_publish.append({\n                \"type\": \"subscription.created\",\n                \"data\": {\n                    \"subscription_id\": event_data.get(\"id\"),\n                    \"customer_id\": event_data.get(\"customer\"),\n                    \"status\": event_data.get(\"status\"),\n                    \"plan_id\": event_data.get(\"items\", {}).get(\"data\", [{}])[0].get(\"price\", {}).get(\"id\"),\n                    \"current_period_start\": event_data.get(\"current_period_start\"),\n                    \"current_period_end\": event_data.get(\"current_period_end\"),\n                    \"provider\": \"stripe\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif event_type == \"invoice.payment_succeeded\":\n            events_to_publish.append({\n                \"type\": \"invoice.paid\",\n                \"data\": {\n                    \"invoice_id\": event_data.get(\"id\"),\n                    \"subscription_id\": event_data.get(\"subscription\"),\n                    \"customer_id\": event_data.get(\"customer\"),\n                    \"amount_paid\": event_data.get(\"amount_paid\", 0) / 100,\n                    \"currency\": event_data.get(\"currency\"),\n                    \"provider\": \"stripe\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        return {\"events\": events_to_publish} if events_to_publish else None\n\nclass TwilioWebhookHandler(WebhookHandler):\n    \"\"\"Handle Twilio webhooks.\"\"\"\n\n    async def handle(\n        self,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Handle Twilio webhook events.\"\"\"\n        logger.info(f\"Processing Twilio webhook: {payload}\")\n\n        events_to_publish = []\n\n        # SMS Status callbacks\n        if \"MessageSid\" in payload and \"MessageStatus\" in payload:\n            events_to_publish.append({\n                \"type\": \"sms.status_update\",\n                \"data\": {\n                    \"message_sid\": payload.get(\"MessageSid\"),\n                    \"status\": payload.get(\"MessageStatus\"),\n                    \"to\": payload.get(\"To\"),\n                    \"from\": payload.get(\"From\"),\n                    \"error_code\": payload.get(\"ErrorCode\"),\n                    \"error_message\": payload.get(\"ErrorMessage\"),\n                    \"provider\": \"twilio\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        # Call status callbacks\n        elif \"CallSid\" in payload and \"CallStatus\" in payload:\n            events_to_publish.append({\n                \"type\": \"call.status_update\",\n                \"data\": {\n                    \"call_sid\": payload.get(\"CallSid\"),\n                    \"status\": payload.get(\"CallStatus\"),\n                    \"to\": payload.get(\"To\"),\n                    \"from\": payload.get(\"From\"),\n                    \"duration\": payload.get(\"CallDuration\"),\n                    \"provider\": \"twilio\",\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        return {\"events\": events_to_publish} if events_to_publish else None\n\nclass GitHubWebhookHandler(WebhookHandler):\n    \"\"\"Handle GitHub webhooks.\"\"\"\n\n    async def handle(\n        self,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Handle GitHub webhook events.\"\"\"\n        event_type = headers.get(\"x-github-event\")\n        action = payload.get(\"action\")\n\n        logger.info(f\"Processing GitHub event: {event_type}.{action}\")\n\n        events_to_publish = []\n\n        if event_type == \"push\":\n            events_to_publish.append({\n                \"type\": \"git.push\",\n                \"data\": {\n                    \"repository\": payload.get(\"repository\", {}).get(\"full_name\"),\n                    \"ref\": payload.get(\"ref\"),\n                    \"commits\": len(payload.get(\"commits\", [])),\n                    \"pusher\": payload.get(\"pusher\", {}).get(\"name\"),\n                    \"head_commit\": payload.get(\"head_commit\", {}).get(\"id\"),\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif event_type == \"pull_request\":\n            events_to_publish.append({\n                \"type\": f\"pull_request.{action}\",\n                \"data\": {\n                    \"repository\": payload.get(\"repository\", {}).get(\"full_name\"),\n                    \"pr_number\": payload.get(\"pull_request\", {}).get(\"number\"),\n                    \"title\": payload.get(\"pull_request\", {}).get(\"title\"),\n                    \"author\": payload.get(\"pull_request\", {}).get(\"user\", {}).get(\"login\"),\n                    \"base_branch\": payload.get(\"pull_request\", {}).get(\"base\", {}).get(\"ref\"),\n                    \"head_branch\": payload.get(\"pull_request\", {}).get(\"head\", {}).get(\"ref\"),\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif event_type == \"issues\" and action in [\"opened\", \"closed\"]:\n            events_to_publish.append({\n                \"type\": f\"issue.{action}\",\n                \"data\": {\n                    \"repository\": payload.get(\"repository\", {}).get(\"full_name\"),\n                    \"issue_number\": payload.get(\"issue\", {}).get(\"number\"),\n                    \"title\": payload.get(\"issue\", {}).get(\"title\"),\n                    \"author\": payload.get(\"issue\", {}).get(\"user\", {}).get(\"login\"),\n                    \"labels\": [label.get(\"name\") for label in payload.get(\"issue\", {}).get(\"labels\", [])],\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        return {\"events\": events_to_publish} if events_to_publish else None\n\nclass ShopifyWebhookHandler(WebhookHandler):\n    \"\"\"Handle Shopify webhooks.\"\"\"\n\n    async def handle(\n        self,\n        payload: Dict[str, Any],\n        headers: Dict[str, str]\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Handle Shopify webhook events.\"\"\"\n        topic = headers.get(\"x-shopify-topic\")\n        shop_domain = headers.get(\"x-shopify-shop-domain\")\n\n        logger.info(f\"Processing Shopify event: {topic} from {shop_domain}\")\n\n        events_to_publish = []\n\n        if topic == \"orders/create\":\n            events_to_publish.append({\n                \"type\": \"order.created\",\n                \"data\": {\n                    \"order_id\": payload.get(\"id\"),\n                    \"order_number\": payload.get(\"order_number\"),\n                    \"customer_id\": payload.get(\"customer\", {}).get(\"id\"),\n                    \"total_price\": float(payload.get(\"total_price\", 0)),\n                    \"currency\": payload.get(\"currency\"),\n                    \"line_items_count\": len(payload.get(\"line_items\", [])),\n                    \"shop_domain\": shop_domain,\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif topic == \"orders/paid\":\n            events_to_publish.append({\n                \"type\": \"order.paid\",\n                \"data\": {\n                    \"order_id\": payload.get(\"id\"),\n                    \"order_number\": payload.get(\"order_number\"),\n                    \"total_price\": float(payload.get(\"total_price\", 0)),\n                    \"currency\": payload.get(\"currency\"),\n                    \"financial_status\": payload.get(\"financial_status\"),\n                    \"shop_domain\": shop_domain,\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        elif topic == \"customers/create\":\n            events_to_publish.append({\n                \"type\": \"customer.created\",\n                \"data\": {\n                    \"customer_id\": payload.get(\"id\"),\n                    \"email\": payload.get(\"email\"),\n                    \"first_name\": payload.get(\"first_name\"),\n                    \"last_name\": payload.get(\"last_name\"),\n                    \"orders_count\": payload.get(\"orders_count\", 0),\n                    \"shop_domain\": shop_domain,\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            })\n\n        return {\"events\": events_to_publish} if events_to_publish else None\n\nclass WebhookHandlerRegistry:\n    \"\"\"Registry for webhook handlers.\"\"\"\n\n    def __init__(self):\n        self.handlers = {\n            \"stripe\": StripeWebhookHandler(),\n            \"twilio\": TwilioWebhookHandler(),\n            \"github\": GitHubWebhookHandler(),\n            \"shopify\": ShopifyWebhookHandler(),\n        }\n\n    def get_handler(self, provider: str, event_type: str) -&gt; Optional[WebhookHandler]:\n        \"\"\"Get appropriate handler for provider and event type.\"\"\"\n        return self.handlers.get(provider)\n\n    def register_handler(self, provider: str, handler: WebhookHandler) -&gt; None:\n        \"\"\"Register custom webhook handler.\"\"\"\n        self.handlers[provider] = handler\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#4-webhook-storage","title":"4. Webhook Storage","text":"<pre><code># src/services/webhooks/webhook_storage.py\nfrom typing import Dict, Any, Optional, List\nfrom datetime import datetime, timedelta\nimport asyncpg\nimport redis.asyncio as redis\nimport json\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nclass WebhookStorage:\n    \"\"\"Storage layer for webhook data and processing state.\"\"\"\n\n    def __init__(self):\n        self.redis_client = redis.from_url(settings.redis_url)\n\n    async def store_webhook(self, webhook_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Store webhook data.\"\"\"\n        webhook_id = webhook_data[\"id\"]\n\n        # Store in Redis for fast access (with TTL)\n        redis_key = f\"webhook:{webhook_id}\"\n        await self.redis_client.setex(\n            redis_key,\n            timedelta(days=7),  # Keep for 7 days\n            json.dumps(webhook_data, default=str)\n        )\n\n        # Store in PostgreSQL for permanent audit log\n        await self._store_webhook_in_postgres(webhook_data)\n\n        logger.debug(f\"Stored webhook: {webhook_id}\")\n\n    async def get_webhook(self, webhook_id: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get webhook data by ID.\"\"\"\n        # Try Redis first\n        redis_key = f\"webhook:{webhook_id}\"\n        redis_data = await self.redis_client.get(redis_key)\n\n        if redis_data:\n            return json.loads(redis_data)\n\n        # Fallback to PostgreSQL\n        return await self._get_webhook_from_postgres(webhook_id)\n\n    async def update_webhook_status(\n        self,\n        webhook_id: str,\n        status: str,\n        updated_at: Optional[datetime] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -&gt; None:\n        \"\"\"Update webhook processing status.\"\"\"\n        if updated_at is None:\n            updated_at = datetime.utcnow()\n\n        # Update Redis\n        redis_key = f\"webhook:{webhook_id}\"\n        webhook_data = await self.get_webhook(webhook_id)\n\n        if webhook_data:\n            webhook_data.update({\n                \"status\": status,\n                \"updated_at\": updated_at.isoformat()\n            })\n\n            if metadata:\n                webhook_data.setdefault(\"metadata\", {}).update(metadata)\n\n            await self.redis_client.setex(\n                redis_key,\n                timedelta(days=7),\n                json.dumps(webhook_data, default=str)\n            )\n\n        # Update PostgreSQL\n        await self._update_webhook_in_postgres(webhook_id, status, updated_at, metadata)\n\n        logger.debug(f\"Updated webhook status: {webhook_id} -&gt; {status}\")\n\n    async def check_event_processed(self, provider: str, event_id: str) -&gt; bool:\n        \"\"\"Check if event has already been processed (idempotency).\"\"\"\n        redis_key = f\"processed_event:{provider}:{event_id}\"\n        exists = await self.redis_client.exists(redis_key)\n\n        if not exists:\n            # Mark as seen for 24 hours\n            await self.redis_client.setex(redis_key, timedelta(hours=24), \"1\")\n            return False\n\n        return True\n\n    async def get_webhook_statistics(\n        self,\n        provider: Optional[str] = None,\n        start_date: Optional[datetime] = None,\n        end_date: Optional[datetime] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Get webhook processing statistics.\"\"\"\n        # This would query PostgreSQL for statistics\n        # Implementation depends on your specific needs\n        return await self._get_webhook_stats_from_postgres(provider, start_date, end_date)\n\n    async def _store_webhook_in_postgres(self, webhook_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Store webhook in PostgreSQL.\"\"\"\n        query = \"\"\"\n        INSERT INTO webhooks (\n            id, provider, event_type, status, headers, payload,\n            received_at, client_ip, created_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n        \"\"\"\n\n        async with asyncpg.create_pool(settings.postgres_url) as pool:\n            async with pool.acquire() as conn:\n                await conn.execute(\n                    query,\n                    webhook_data[\"id\"],\n                    webhook_data[\"provider\"],\n                    webhook_data.get(\"event_type\"),\n                    webhook_data[\"status\"],\n                    json.dumps(webhook_data[\"headers\"]),\n                    json.dumps(webhook_data.get(\"payload\")),\n                    webhook_data[\"received_at\"],\n                    webhook_data.get(\"client_ip\"),\n                    datetime.utcnow()\n                )\n\n    async def _get_webhook_from_postgres(self, webhook_id: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get webhook from PostgreSQL.\"\"\"\n        query = \"\"\"\n        SELECT id, provider, event_type, status, headers, payload,\n               received_at, client_ip, created_at, updated_at, metadata\n        FROM webhooks WHERE id = $1\n        \"\"\"\n\n        async with asyncpg.create_pool(settings.postgres_url) as pool:\n            async with pool.acquire() as conn:\n                row = await conn.fetchrow(query, webhook_id)\n\n                if row:\n                    return {\n                        \"id\": row[\"id\"],\n                        \"provider\": row[\"provider\"],\n                        \"event_type\": row[\"event_type\"],\n                        \"status\": row[\"status\"],\n                        \"headers\": json.loads(row[\"headers\"]) if row[\"headers\"] else {},\n                        \"payload\": json.loads(row[\"payload\"]) if row[\"payload\"] else {},\n                        \"received_at\": row[\"received_at\"].isoformat() if row[\"received_at\"] else None,\n                        \"client_ip\": row[\"client_ip\"],\n                        \"created_at\": row[\"created_at\"].isoformat() if row[\"created_at\"] else None,\n                        \"updated_at\": row[\"updated_at\"].isoformat() if row[\"updated_at\"] else None,\n                        \"metadata\": json.loads(row[\"metadata\"]) if row[\"metadata\"] else {}\n                    }\n\n        return None\n\n    async def _update_webhook_in_postgres(\n        self,\n        webhook_id: str,\n        status: str,\n        updated_at: datetime,\n        metadata: Optional[Dict[str, Any]]\n    ) -&gt; None:\n        \"\"\"Update webhook in PostgreSQL.\"\"\"\n        query = \"\"\"\n        UPDATE webhooks\n        SET status = $2, updated_at = $3, metadata = $4\n        WHERE id = $1\n        \"\"\"\n\n        async with asyncpg.create_pool(settings.postgres_url) as pool:\n            async with pool.acquire() as conn:\n                await conn.execute(\n                    query,\n                    webhook_id,\n                    status,\n                    updated_at,\n                    json.dumps(metadata) if metadata else None\n                )\n\n    async def _get_webhook_stats_from_postgres(\n        self,\n        provider: Optional[str],\n        start_date: Optional[datetime],\n        end_date: Optional[datetime]\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Get webhook statistics from PostgreSQL.\"\"\"\n        conditions = []\n        params = []\n\n        if provider:\n            conditions.append(f\"provider = ${len(params) + 1}\")\n            params.append(provider)\n\n        if start_date:\n            conditions.append(f\"received_at &gt;= ${len(params) + 1}\")\n            params.append(start_date)\n\n        if end_date:\n            conditions.append(f\"received_at &lt;= ${len(params) + 1}\")\n            params.append(end_date)\n\n        where_clause = \"WHERE \" + \" AND \".join(conditions) if conditions else \"\"\n\n        query = f\"\"\"\n        SELECT\n            provider,\n            status,\n            COUNT(*) as count,\n            AVG(EXTRACT(EPOCH FROM (updated_at - received_at))) as avg_processing_time\n        FROM webhooks\n        {where_clause}\n        GROUP BY provider, status\n        ORDER BY provider, status\n        \"\"\"\n\n        async with asyncpg.create_pool(settings.postgres_url) as pool:\n            async with pool.acquire() as conn:\n                rows = await conn.fetch(query, *params)\n\n                stats = {}\n                for row in rows:\n                    provider_name = row[\"provider\"]\n                    if provider_name not in stats:\n                        stats[provider_name] = {}\n\n                    stats[provider_name][row[\"status\"]] = {\n                        \"count\": row[\"count\"],\n                        \"avg_processing_time\": float(row[\"avg_processing_time\"]) if row[\"avg_processing_time\"] else None\n                    }\n\n                return stats\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#webhook-security-patterns","title":"Webhook Security Patterns","text":""},{"location":"atomic/external-integrations/webhook-handling/#1-rate-limiting-and-ddos-protection","title":"1. Rate Limiting and DDoS Protection","text":"<pre><code># src/middleware/webhook_security.py\nfrom fastapi import Request, HTTPException, status\nfrom fastapi.responses import Response\nimport time\nfrom typing import Dict, Any\nimport redis.asyncio as redis\nfrom src.core.config import settings\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nclass WebhookSecurityMiddleware:\n    \"\"\"Security middleware for webhook endpoints.\"\"\"\n\n    def __init__(self):\n        self.redis = redis.from_url(settings.redis_url)\n        self.rate_limit_window = 60  # seconds\n        self.rate_limit_max_requests = 100  # per window\n        self.ddos_threshold = 500  # requests per minute\n\n    async def __call__(self, request: Request, call_next):\n        \"\"\"Apply security checks to webhook requests.\"\"\"\n\n        # Skip security checks for non-webhook endpoints\n        if not request.url.path.startswith(\"/webhooks/\"):\n            return await call_next(request)\n\n        client_ip = request.client.host\n        current_time = int(time.time())\n\n        try:\n            # DDoS protection\n            if await self._check_ddos_protection(client_ip, current_time):\n                logger.warning(f\"DDoS protection triggered for IP: {client_ip}\")\n                raise HTTPException(\n                    status_code=status.HTTP_429_TOO_MANY_REQUESTS,\n                    detail=\"Rate limit exceeded\"\n                )\n\n            # Rate limiting per IP\n            if await self._check_rate_limit(client_ip, current_time):\n                logger.warning(f\"Rate limit exceeded for IP: {client_ip}\")\n                raise HTTPException(\n                    status_code=status.HTTP_429_TOO_MANY_REQUESTS,\n                    detail=\"Rate limit exceeded\"\n                )\n\n            # Request size validation\n            content_length = request.headers.get(\"content-length\")\n            if content_length and int(content_length) &gt; settings.webhook_max_body_size:\n                logger.warning(f\"Webhook body too large from IP: {client_ip}\")\n                raise HTTPException(\n                    status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,\n                    detail=\"Request body too large\"\n                )\n\n            # Process request\n            response = await call_next(request)\n\n            # Log successful webhook\n            await self._log_webhook_request(client_ip, request.url.path, response.status_code)\n\n            return response\n\n        except HTTPException:\n            raise\n        except Exception as e:\n            logger.error(f\"Webhook security middleware error: {e}\")\n            raise HTTPException(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                detail=\"Internal server error\"\n            )\n\n    async def _check_rate_limit(self, client_ip: str, current_time: int) -&gt; bool:\n        \"\"\"Check rate limiting for client IP.\"\"\"\n        window_start = current_time - (current_time % self.rate_limit_window)\n        redis_key = f\"webhook_rate_limit:{client_ip}:{window_start}\"\n\n        # Get current request count\n        request_count = await self.redis.get(redis_key)\n        if request_count is None:\n            request_count = 0\n        else:\n            request_count = int(request_count)\n\n        # Check if limit exceeded\n        if request_count &gt;= self.rate_limit_max_requests:\n            return True\n\n        # Increment counter\n        pipe = self.redis.pipeline()\n        pipe.incr(redis_key)\n        pipe.expire(redis_key, self.rate_limit_window)\n        await pipe.execute()\n\n        return False\n\n    async def _check_ddos_protection(self, client_ip: str, current_time: int) -&gt; bool:\n        \"\"\"Check DDoS protection.\"\"\"\n        minute = current_time - (current_time % 60)\n        redis_key = f\"webhook_ddos:{client_ip}:{minute}\"\n\n        request_count = await self.redis.get(redis_key)\n        if request_count is None:\n            request_count = 0\n        else:\n            request_count = int(request_count)\n\n        if request_count &gt;= self.ddos_threshold:\n            return True\n\n        # Track request\n        pipe = self.redis.pipeline()\n        pipe.incr(redis_key)\n        pipe.expire(redis_key, 60)\n        await pipe.execute()\n\n        return False\n\n    async def _log_webhook_request(self, client_ip: str, path: str, status_code: int) -&gt; None:\n        \"\"\"Log webhook request for monitoring.\"\"\"\n        log_data = {\n            \"client_ip\": client_ip,\n            \"path\": path,\n            \"status_code\": status_code,\n            \"timestamp\": time.time()\n        }\n\n        # Store in Redis for recent activity monitoring\n        redis_key = f\"webhook_log:{int(time.time())}\"\n        await self.redis.setex(redis_key, 3600, str(log_data))  # Keep for 1 hour\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#2-webhook-monitoring-and-alerting","title":"2. Webhook Monitoring and Alerting","text":"<pre><code># src/services/webhooks/webhook_monitor.py\nfrom typing import Dict, Any, List\nfrom datetime import datetime, timedelta\nimport asyncio\nfrom src.services.webhooks.webhook_storage import WebhookStorage\nfrom src.core.alerts import AlertManager\nfrom src.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nclass WebhookMonitor:\n    \"\"\"Monitor webhook health and performance.\"\"\"\n\n    def __init__(self):\n        self.storage = WebhookStorage()\n        self.alert_manager = AlertManager()\n        self.monitoring_interval = 300  # 5 minutes\n\n    async def start_monitoring(self) -&gt; None:\n        \"\"\"Start webhook monitoring loop.\"\"\"\n        logger.info(\"Starting webhook monitoring\")\n\n        while True:\n            try:\n                await self._check_webhook_health()\n                await asyncio.sleep(self.monitoring_interval)\n            except Exception as e:\n                logger.error(f\"Webhook monitoring error: {e}\")\n                await asyncio.sleep(60)  # Wait before retrying\n\n    async def _check_webhook_health(self) -&gt; None:\n        \"\"\"Check webhook processing health.\"\"\"\n        end_time = datetime.utcnow()\n        start_time = end_time - timedelta(minutes=15)\n\n        # Get recent webhook statistics\n        stats = await self.storage.get_webhook_statistics(\n            start_date=start_time,\n            end_date=end_time\n        )\n\n        # Check for issues\n        await self._check_error_rates(stats)\n        await self._check_processing_delays(stats)\n        await self._check_missing_webhooks()\n\n    async def _check_error_rates(self, stats: Dict[str, Any]) -&gt; None:\n        \"\"\"Check for high error rates.\"\"\"\n        for provider, provider_stats in stats.items():\n            total_webhooks = sum(status_data[\"count\"] for status_data in provider_stats.values())\n            failed_webhooks = provider_stats.get(\"failed\", {}).get(\"count\", 0)\n\n            if total_webhooks &gt; 0:\n                error_rate = failed_webhooks / total_webhooks\n\n                if error_rate &gt; 0.1:  # 10% error rate threshold\n                    await self.alert_manager.send_alert(\n                        title=f\"High webhook error rate for {provider}\",\n                        message=f\"Error rate: {error_rate:.2%} ({failed_webhooks}/{total_webhooks})\",\n                        severity=\"warning\"\n                    )\n\n                if error_rate &gt; 0.3:  # 30% error rate threshold\n                    await self.alert_manager.send_alert(\n                        title=f\"Critical webhook error rate for {provider}\",\n                        message=f\"Error rate: {error_rate:.2%} ({failed_webhooks}/{total_webhooks})\",\n                        severity=\"critical\"\n                    )\n\n    async def _check_processing_delays(self, stats: Dict[str, Any]) -&gt; None:\n        \"\"\"Check for processing delays.\"\"\"\n        for provider, provider_stats in stats.items():\n            completed_stats = provider_stats.get(\"completed\", {})\n            avg_processing_time = completed_stats.get(\"avg_processing_time\")\n\n            if avg_processing_time and avg_processing_time &gt; 30:  # 30 seconds threshold\n                await self.alert_manager.send_alert(\n                    title=f\"Slow webhook processing for {provider}\",\n                    message=f\"Average processing time: {avg_processing_time:.2f} seconds\",\n                    severity=\"warning\"\n                )\n\n    async def _check_missing_webhooks(self) -&gt; None:\n        \"\"\"Check for missing expected webhooks.\"\"\"\n        # This would implement provider-specific checks\n        # For example, checking if we haven't received any Stripe webhooks in the last hour\n        # when we expect regular activity\n        pass\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#testing-webhook-handling","title":"Testing Webhook Handling","text":""},{"location":"atomic/external-integrations/webhook-handling/#1-webhook-handler-tests","title":"1. Webhook Handler Tests","text":"<pre><code># tests/test_webhook_handling.py\nimport pytest\nimport json\nimport hmac\nimport hashlib\nfrom unittest.mock import Mock, patch, AsyncMock\nfrom fastapi.testclient import TestClient\nfrom src.services.webhooks.webhook_gateway import webhook_gateway\nfrom src.services.webhooks.webhook_handlers import StripeWebhookHandler, TwilioWebhookHandler\n\nclass TestWebhookGateway:\n    \"\"\"Test webhook gateway functionality.\"\"\"\n\n    @pytest.fixture\n    def client(self):\n        return TestClient(webhook_gateway.app)\n\n    def test_stripe_webhook_success(self, client):\n        \"\"\"Test successful Stripe webhook processing.\"\"\"\n        payload = {\n            \"id\": \"evt_test_webhook\",\n            \"type\": \"payment_intent.succeeded\",\n            \"data\": {\n                \"object\": {\n                    \"id\": \"pi_test_123\",\n                    \"amount\": 2000,\n                    \"currency\": \"usd\",\n                    \"customer\": \"cus_test_123\"\n                }\n            }\n        }\n\n        # Create valid Stripe signature\n        payload_json = json.dumps(payload)\n        timestamp = \"1234567890\"\n        signed_payload = f\"{timestamp}.{payload_json}\"\n        signature = hmac.new(\n            \"test_webhook_secret\".encode(),\n            signed_payload.encode(),\n            hashlib.sha256\n        ).hexdigest()\n\n        stripe_signature = f\"t={timestamp},v1={signature}\"\n\n        with patch(\"src.services.webhooks.webhook_gateway.WebhookProcessor.process_webhook\") as mock_process:\n            response = client.post(\n                \"/webhooks/stripe\",\n                json=payload,\n                headers={\"stripe-signature\": stripe_signature}\n            )\n\n            assert response.status_code == 200\n            mock_process.assert_called_once()\n\n    def test_webhook_invalid_signature(self, client):\n        \"\"\"Test webhook with invalid signature.\"\"\"\n        payload = {\"test\": \"data\"}\n\n        response = client.post(\n            \"/webhooks/stripe\",\n            json=payload,\n            headers={\"stripe-signature\": \"invalid_signature\"}\n        )\n\n        assert response.status_code == 401\n\n    def test_webhook_missing_signature(self, client):\n        \"\"\"Test webhook without signature header.\"\"\"\n        payload = {\"test\": \"data\"}\n\n        response = client.post(\"/webhooks/stripe\", json=payload)\n\n        assert response.status_code == 401\n\n    def test_webhook_invalid_json(self, client):\n        \"\"\"Test webhook with invalid JSON.\"\"\"\n        with patch(\"src.services.webhooks.webhook_gateway.WebhookGateway._verify_stripe_signature\", return_value=True):\n            response = client.post(\n                \"/webhooks/stripe\",\n                data=\"invalid json\",\n                headers={\n                    \"stripe-signature\": \"valid_signature\",\n                    \"content-type\": \"application/json\"\n                }\n            )\n\n            assert response.status_code == 400\n\nclass TestWebhookHandlers:\n    \"\"\"Test webhook handlers.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_stripe_payment_succeeded_handler(self):\n        \"\"\"Test Stripe payment succeeded handler.\"\"\"\n        handler = StripeWebhookHandler()\n\n        payload = {\n            \"type\": \"payment_intent.succeeded\",\n            \"data\": {\n                \"object\": {\n                    \"id\": \"pi_test_123\",\n                    \"amount\": 2000,\n                    \"currency\": \"usd\",\n                    \"customer\": \"cus_test_123\",\n                    \"metadata\": {\"order_id\": \"order_123\"}\n                }\n            }\n        }\n\n        result = await handler.handle(payload, {})\n\n        assert result is not None\n        assert len(result[\"events\"]) == 1\n\n        event = result[\"events\"][0]\n        assert event[\"type\"] == \"payment.completed\"\n        assert event[\"data\"][\"payment_intent_id\"] == \"pi_test_123\"\n        assert event[\"data\"][\"amount\"] == 20.0  # Converted from cents\n        assert event[\"data\"][\"currency\"] == \"usd\"\n\n    @pytest.mark.asyncio\n    async def test_twilio_sms_status_handler(self):\n        \"\"\"Test Twilio SMS status handler.\"\"\"\n        handler = TwilioWebhookHandler()\n\n        payload = {\n            \"MessageSid\": \"SM123456789\",\n            \"MessageStatus\": \"delivered\",\n            \"To\": \"+1234567890\",\n            \"From\": \"+0987654321\"\n        }\n\n        result = await handler.handle(payload, {})\n\n        assert result is not None\n        assert len(result[\"events\"]) == 1\n\n        event = result[\"events\"][0]\n        assert event[\"type\"] == \"sms.status_update\"\n        assert event[\"data\"][\"message_sid\"] == \"SM123456789\"\n        assert event[\"data\"][\"status\"] == \"delivered\"\n\n    @pytest.mark.asyncio\n    async def test_handler_no_events(self):\n        \"\"\"Test handler that produces no events.\"\"\"\n        handler = StripeWebhookHandler()\n\n        payload = {\n            \"type\": \"unknown_event_type\",\n            \"data\": {\"object\": {}}\n        }\n\n        result = await handler.handle(payload, {})\n\n        assert result is None\n\nclass TestWebhookSecurity:\n    \"\"\"Test webhook security features.\"\"\"\n\n    def test_rate_limiting(self, client):\n        \"\"\"Test webhook rate limiting.\"\"\"\n        # This would test the rate limiting middleware\n        # Implementation depends on your specific rate limiting logic\n        pass\n\n    def test_request_size_validation(self, client):\n        \"\"\"Test webhook request size validation.\"\"\"\n        # Test with very large payload\n        large_payload = {\"data\": \"x\" * 1000000}  # 1MB payload\n\n        with patch(\"src.services.webhooks.webhook_gateway.WebhookGateway._verify_stripe_signature\", return_value=True):\n            response = client.post(\n                \"/webhooks/stripe\",\n                json=large_payload,\n                headers={\"stripe-signature\": \"valid_signature\"}\n            )\n\n            # Should be rejected if payload is too large\n            assert response.status_code in [413, 400]\n\nclass TestWebhookStorage:\n    \"\"\"Test webhook storage functionality.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_webhook_storage_and_retrieval(self):\n        \"\"\"Test storing and retrieving webhook data.\"\"\"\n        from src.services.webhooks.webhook_storage import WebhookStorage\n\n        storage = WebhookStorage()\n\n        webhook_data = {\n            \"id\": \"test_webhook_123\",\n            \"provider\": \"stripe\",\n            \"status\": \"received\",\n            \"headers\": {\"content-type\": \"application/json\"},\n            \"payload\": {\"test\": \"data\"},\n            \"received_at\": \"2023-01-01T00:00:00Z\"\n        }\n\n        # Store webhook\n        await storage.store_webhook(webhook_data)\n\n        # Retrieve webhook\n        retrieved = await storage.get_webhook(\"test_webhook_123\")\n\n        assert retrieved is not None\n        assert retrieved[\"id\"] == \"test_webhook_123\"\n        assert retrieved[\"provider\"] == \"stripe\"\n\n    @pytest.mark.asyncio\n    async def test_webhook_status_update(self):\n        \"\"\"Test webhook status updates.\"\"\"\n        from src.services.webhooks.webhook_storage import WebhookStorage\n\n        storage = WebhookStorage()\n\n        # First store a webhook\n        webhook_data = {\n            \"id\": \"test_webhook_456\",\n            \"provider\": \"stripe\",\n            \"status\": \"received\",\n            \"received_at\": \"2023-01-01T00:00:00Z\"\n        }\n\n        await storage.store_webhook(webhook_data)\n\n        # Update status\n        await storage.update_webhook_status(\n            \"test_webhook_456\",\n            \"completed\",\n            metadata={\"processing_time\": 1.5}\n        )\n\n        # Verify update\n        updated = await storage.get_webhook(\"test_webhook_456\")\n        assert updated[\"status\"] == \"completed\"\n        assert updated[\"metadata\"][\"processing_time\"] == 1.5\n\n    @pytest.mark.asyncio\n    async def test_duplicate_event_detection(self):\n        \"\"\"Test duplicate event detection.\"\"\"\n        from src.services.webhooks.webhook_storage import WebhookStorage\n\n        storage = WebhookStorage()\n\n        # First check should return False (not duplicate)\n        is_duplicate_1 = await storage.check_event_processed(\"stripe\", \"evt_123\")\n        assert is_duplicate_1 is False\n\n        # Second check should return True (duplicate)\n        is_duplicate_2 = await storage.check_event_processed(\"stripe\", \"evt_123\")\n        assert is_duplicate_2 is True\n</code></pre>"},{"location":"atomic/external-integrations/webhook-handling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/external-integrations/payment-gateways.md</code> - Payment webhooks</li> <li><code>docs/atomic/external-integrations/communication-apis.md</code> - Communication webhooks</li> <li><code>docs/atomic/external-integrations/api-rate-limiting.md</code> - Rate limiting patterns</li> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> - Webhook authentication</li> <li><code>docs/atomic/testing/integration-testing/http-integration-testing.md</code> - HTTP testing</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/#implementation-checklist","title":"Implementation Checklist","text":""},{"location":"atomic/external-integrations/webhook-handling/#webhook-gateway","title":"Webhook Gateway","text":"<ul> <li> Centralized webhook endpoint setup</li> <li> Provider-specific routing</li> <li> Request size validation</li> <li> Health check endpoint</li> <li> Error handling and logging</li> <li> Background task processing</li> <li> Audit trail storage</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/#security-verification","title":"Security &amp; Verification","text":"<ul> <li> Signature verification for each provider</li> <li> Rate limiting per IP</li> <li> DDoS protection</li> <li> Request size limits</li> <li> HTTPS enforcement</li> <li> Security headers</li> <li> IP whitelisting (optional)</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/#processing-reliability","title":"Processing &amp; Reliability","text":"<ul> <li> Idempotency handling</li> <li> Retry mechanisms with exponential backoff</li> <li> Dead letter queue for failed webhooks</li> <li> Event publishing to internal services</li> <li> Processing status tracking</li> <li> Webhook replay capability</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<ul> <li> Processing success/failure rates</li> <li> Processing time monitoring</li> <li> Error rate alerting</li> <li> Missing webhook detection</li> <li> Performance metrics</li> <li> Dashboard integration</li> </ul>"},{"location":"atomic/external-integrations/webhook-handling/#testing","title":"Testing","text":"<ul> <li> Unit tests for all handlers</li> <li> Integration tests with test webhooks</li> <li> Security testing</li> <li> Load testing</li> <li> Signature verification testing</li> <li> Error scenario testing</li> </ul>"},{"location":"atomic/file-storage/backup-strategies/","title":"Backup Strategies","text":"<p>Comprehensive guide for implementing file backup strategies with automated scheduling, versioning, disaster recovery, and cross-region replication.</p>"},{"location":"atomic/file-storage/backup-strategies/#backup-architecture","title":"Backup Architecture","text":"<pre><code>from typing import Dict, List, Optional, Any, Union\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nimport asyncio\nimport json\nimport hashlib\nimport uuid\nfrom pathlib import Path\n\nclass BackupType(Enum):\n    FULL = \"full\"\n    INCREMENTAL = \"incremental\"\n    DIFFERENTIAL = \"differential\"\n    SNAPSHOT = \"snapshot\"\n\nclass BackupStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass RestoreStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n@dataclass\nclass BackupPolicy:\n    name: str\n    backup_type: BackupType\n    schedule_cron: str  # Cron expression for scheduling\n    retention_days: int\n    source_paths: List[str] = field(default_factory=list)\n    destination_config: Dict[str, Any] = field(default_factory=dict)\n    compression_enabled: bool = True\n    encryption_enabled: bool = True\n    verify_integrity: bool = True\n    max_concurrent_files: int = 10\n    exclude_patterns: List[str] = field(default_factory=list)\n\n@dataclass\nclass BackupJob:\n    id: str\n    policy_name: str\n    backup_type: BackupType\n    status: BackupStatus = BackupStatus.PENDING\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    total_files: int = 0\n    processed_files: int = 0\n    total_size: int = 0\n    compressed_size: int = 0\n    error_message: Optional[str] = None\n    manifest_path: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n@dataclass\nclass RestoreJob:\n    id: str\n    backup_job_id: str\n    restore_type: str  # \"full\", \"selective\", \"point_in_time\"\n    status: RestoreStatus = RestoreStatus.PENDING\n    target_path: str = \"\"\n    file_filters: List[str] = field(default_factory=list)\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    restored_files: int = 0\n    error_message: Optional[str] = None\n\nclass BackupService:\n    \"\"\"Core backup service with scheduling and retention management\"\"\"\n\n    def __init__(self, storage_backends: Dict[str, Any], temp_dir: str = \"/tmp/backups\"):\n        self.storage_backends = storage_backends\n        self.temp_dir = Path(temp_dir)\n        self.temp_dir.mkdir(exist_ok=True)\n        self.active_jobs: Dict[str, BackupJob] = {}\n        self.policies: Dict[str, BackupPolicy] = {}\n\n    async def create_backup_policy(self, policy: BackupPolicy) -&gt; str:\n        \"\"\"Create and register a backup policy\"\"\"\n        self.policies[policy.name] = policy\n        return policy.name\n\n    async def execute_backup(self, policy_name: str, force_full: bool = False) -&gt; BackupJob:\n        \"\"\"Execute backup according to policy\"\"\"\n        if policy_name not in self.policies:\n            raise ValueError(f\"Policy {policy_name} not found\")\n\n        policy = self.policies[policy_name]\n\n        # Determine backup type\n        backup_type = BackupType.FULL if force_full else policy.backup_type\n\n        # Create backup job\n        job = BackupJob(\n            id=str(uuid.uuid4()),\n            policy_name=policy_name,\n            backup_type=backup_type\n        )\n\n        self.active_jobs[job.id] = job\n\n        # Start backup asynchronously\n        asyncio.create_task(self._execute_backup_job(job, policy))\n\n        return job\n\n    async def _execute_backup_job(self, job: BackupJob, policy: BackupPolicy):\n        \"\"\"Execute the actual backup job\"\"\"\n        try:\n            job.status = BackupStatus.RUNNING\n            job.started_at = datetime.utcnow()\n\n            # Collect files to backup\n            files_to_backup = await self._collect_files(policy, job)\n\n            # Create backup manifest\n            manifest = await self._create_backup_manifest(job, files_to_backup, policy)\n\n            # Perform backup based on type\n            if job.backup_type == BackupType.FULL:\n                await self._perform_full_backup(job, files_to_backup, policy)\n            elif job.backup_type == BackupType.INCREMENTAL:\n                await self._perform_incremental_backup(job, files_to_backup, policy)\n            elif job.backup_type == BackupType.DIFFERENTIAL:\n                await self._perform_differential_backup(job, files_to_backup, policy)\n\n            # Upload manifest\n            job.manifest_path = await self._upload_manifest(manifest, job, policy)\n\n            # Verify backup integrity if enabled\n            if policy.verify_integrity:\n                await self._verify_backup_integrity(job, policy)\n\n            # Clean up old backups according to retention policy\n            await self._cleanup_old_backups(policy)\n\n            job.status = BackupStatus.COMPLETED\n            job.completed_at = datetime.utcnow()\n\n        except Exception as e:\n            job.status = BackupStatus.FAILED\n            job.error_message = str(e)\n            job.completed_at = datetime.utcnow()\n\n    async def _collect_files(self, policy: BackupPolicy, job: BackupJob) -&gt; List[Dict[str, Any]]:\n        \"\"\"Collect files to backup based on policy\"\"\"\n        files_to_backup = []\n\n        for source_path in policy.source_paths:\n            source = Path(source_path)\n\n            if source.is_file():\n                file_info = await self._get_file_info(source)\n                if self._should_include_file(file_info, policy):\n                    files_to_backup.append(file_info)\n            elif source.is_dir():\n                async for file_info in self._scan_directory(source, policy):\n                    if self._should_include_file(file_info, policy):\n                        files_to_backup.append(file_info)\n\n        job.total_files = len(files_to_backup)\n        job.total_size = sum(f[\"size\"] for f in files_to_backup)\n\n        return files_to_backup\n\n    async def _get_file_info(self, file_path: Path) -&gt; Dict[str, Any]:\n        \"\"\"Get file information for backup\"\"\"\n        stat = file_path.stat()\n\n        # Calculate file hash for integrity checking\n        hash_obj = hashlib.sha256()\n        async with aiofiles.open(file_path, \"rb\") as f:\n            while chunk := await f.read(8192):\n                hash_obj.update(chunk)\n\n        return {\n            \"path\": str(file_path),\n            \"relative_path\": str(file_path.relative_to(file_path.parent.parent)),\n            \"size\": stat.st_size,\n            \"modified_time\": datetime.fromtimestamp(stat.st_mtime),\n            \"permissions\": oct(stat.st_mode),\n            \"file_hash\": hash_obj.hexdigest()\n        }\n\n    async def _scan_directory(self, directory: Path, policy: BackupPolicy) -&gt; List[Dict[str, Any]]:\n        \"\"\"Recursively scan directory for files\"\"\"\n        for item in directory.rglob(\"*\"):\n            if item.is_file():\n                file_info = await self._get_file_info(item)\n                yield file_info\n\n    def _should_include_file(self, file_info: Dict[str, Any], policy: BackupPolicy) -&gt; bool:\n        \"\"\"Check if file should be included in backup\"\"\"\n        file_path = file_info[\"path\"]\n\n        # Check exclude patterns\n        for pattern in policy.exclude_patterns:\n            if Path(file_path).match(pattern):\n                return False\n\n        # Additional filters can be added here\n        return True\n\n    async def _create_backup_manifest(\n        self,\n        job: BackupJob,\n        files: List[Dict[str, Any]],\n        policy: BackupPolicy\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create backup manifest with metadata\"\"\"\n        manifest = {\n            \"backup_id\": job.id,\n            \"policy_name\": policy.name,\n            \"backup_type\": job.backup_type.value,\n            \"created_at\": job.started_at.isoformat(),\n            \"total_files\": len(files),\n            \"total_size\": sum(f[\"size\"] for f in files),\n            \"compression_enabled\": policy.compression_enabled,\n            \"encryption_enabled\": policy.encryption_enabled,\n            \"files\": files,\n            \"schema_version\": \"1.0\"\n        }\n\n        return manifest\n\n    async def _perform_full_backup(\n        self,\n        job: BackupJob,\n        files: List[Dict[str, Any]],\n        policy: BackupPolicy\n    ):\n        \"\"\"Perform full backup of all files\"\"\"\n        semaphore = asyncio.Semaphore(policy.max_concurrent_files)\n\n        async def backup_file(file_info: Dict[str, Any]):\n            async with semaphore:\n                await self._backup_single_file(file_info, job, policy)\n                job.processed_files += 1\n\n        # Process all files concurrently\n        tasks = [backup_file(file_info) for file_info in files]\n        await asyncio.gather(*tasks)\n\n    async def _perform_incremental_backup(\n        self,\n        job: BackupJob,\n        files: List[Dict[str, Any]],\n        policy: BackupPolicy\n    ):\n        \"\"\"Perform incremental backup (only changed files since last backup)\"\"\"\n        # Get last backup manifest\n        last_manifest = await self._get_last_backup_manifest(policy.name)\n\n        if not last_manifest:\n            # No previous backup, perform full backup\n            await self._perform_full_backup(job, files, policy)\n            return\n\n        # Create hash map of previous files\n        previous_files = {f[\"path\"]: f[\"file_hash\"] for f in last_manifest.get(\"files\", [])}\n\n        # Filter files that have changed\n        changed_files = []\n        for file_info in files:\n            path = file_info[\"path\"]\n            current_hash = file_info[\"file_hash\"]\n\n            if path not in previous_files or previous_files[path] != current_hash:\n                changed_files.append(file_info)\n\n        job.total_files = len(changed_files)\n        job.total_size = sum(f[\"size\"] for f in changed_files)\n\n        # Backup only changed files\n        semaphore = asyncio.Semaphore(policy.max_concurrent_files)\n\n        async def backup_file(file_info: Dict[str, Any]):\n            async with semaphore:\n                await self._backup_single_file(file_info, job, policy)\n                job.processed_files += 1\n\n        tasks = [backup_file(file_info) for file_info in changed_files]\n        await asyncio.gather(*tasks)\n\n    async def _backup_single_file(\n        self,\n        file_info: Dict[str, Any],\n        job: BackupJob,\n        policy: BackupPolicy\n    ):\n        \"\"\"Backup a single file with compression and encryption\"\"\"\n        source_path = Path(file_info[\"path\"])\n\n        # Read file data\n        async with aiofiles.open(source_path, \"rb\") as f:\n            file_data = await f.read()\n\n        # Compress if enabled\n        if policy.compression_enabled:\n            file_data = await self._compress_data(file_data)\n\n        # Encrypt if enabled\n        if policy.encryption_enabled:\n            file_data = await self._encrypt_data(file_data, job.id)\n\n        # Generate backup storage path\n        backup_path = self._generate_backup_path(file_info, job, policy)\n\n        # Upload to storage backend\n        storage_backend = self.storage_backends[policy.destination_config[\"provider\"]]\n        await storage_backend.upload_file(file_data, backup_path)\n\n        # Update job metadata\n        if \"files_backed_up\" not in job.metadata:\n            job.metadata[\"files_backed_up\"] = []\n\n        job.metadata[\"files_backed_up\"].append({\n            \"original_path\": file_info[\"path\"],\n            \"backup_path\": backup_path,\n            \"original_size\": file_info[\"size\"],\n            \"backup_size\": len(file_data)\n        })\n\n        job.compressed_size += len(file_data)\n\n    async def _compress_data(self, data: bytes) -&gt; bytes:\n        \"\"\"Compress data using gzip\"\"\"\n        import gzip\n\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, gzip.compress, data)\n\n    async def _encrypt_data(self, data: bytes, backup_id: str) -&gt; bytes:\n        \"\"\"Encrypt data using AES\"\"\"\n        from cryptography.fernet import Fernet\n        import base64\n\n        # In production, use proper key management\n        key = base64.urlsafe_b64encode(backup_id.encode()[:32].ljust(32, b'0'))\n        fernet = Fernet(key)\n\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, fernet.encrypt, data)\n\n    def _generate_backup_path(\n        self,\n        file_info: Dict[str, Any],\n        job: BackupJob,\n        policy: BackupPolicy\n    ) -&gt; str:\n        \"\"\"Generate storage path for backup file\"\"\"\n        relative_path = file_info[\"relative_path\"]\n        timestamp = job.started_at.strftime(\"%Y%m%d_%H%M%S\")\n\n        return f\"backups/{policy.name}/{job.backup_type.value}/{timestamp}/{job.id}/{relative_path}\"\n\n    async def _upload_manifest(\n        self,\n        manifest: Dict[str, Any],\n        job: BackupJob,\n        policy: BackupPolicy\n    ) -&gt; str:\n        \"\"\"Upload backup manifest to storage\"\"\"\n        manifest_data = json.dumps(manifest, indent=2, default=str).encode()\n\n        # Compress manifest\n        if policy.compression_enabled:\n            manifest_data = await self._compress_data(manifest_data)\n\n        # Generate manifest path\n        timestamp = job.started_at.strftime(\"%Y%m%d_%H%M%S\")\n        manifest_path = f\"backups/{policy.name}/manifests/{timestamp}_{job.id}.json\"\n\n        # Upload manifest\n        storage_backend = self.storage_backends[policy.destination_config[\"provider\"]]\n        await storage_backend.upload_file(manifest_data, manifest_path)\n\n        return manifest_path\n\n    async def _verify_backup_integrity(self, job: BackupJob, policy: BackupPolicy):\n        \"\"\"Verify backup integrity by sampling files\"\"\"\n        if \"files_backed_up\" not in job.metadata:\n            return\n\n        # Sample 10% of files for verification\n        files_to_verify = job.metadata[\"files_backed_up\"][:max(1, len(job.metadata[\"files_backed_up\"]) // 10)]\n\n        storage_backend = self.storage_backends[policy.destination_config[\"provider\"]]\n\n        for file_info in files_to_verify:\n            try:\n                # Download backup file\n                backup_data = await storage_backend.download_file(file_info[\"backup_path\"])\n\n                # Decrypt if needed\n                if policy.encryption_enabled:\n                    backup_data = await self._decrypt_data(backup_data, job.id)\n\n                # Decompress if needed\n                if policy.compression_enabled:\n                    backup_data = await self._decompress_data(backup_data)\n\n                # Verify hash\n                backup_hash = hashlib.sha256(backup_data).hexdigest()\n                original_path = Path(file_info[\"original_path\"])\n\n                if original_path.exists():\n                    original_hash = await self._calculate_file_hash(original_path)\n                    if backup_hash != original_hash:\n                        raise ValueError(f\"Hash mismatch for {original_path}\")\n\n            except Exception as e:\n                job.metadata.setdefault(\"verification_errors\", []).append({\n                    \"file\": file_info[\"original_path\"],\n                    \"error\": str(e)\n                })\n\n    async def _cleanup_old_backups(self, policy: BackupPolicy):\n        \"\"\"Clean up old backups according to retention policy\"\"\"\n        cutoff_date = datetime.utcnow() - timedelta(days=policy.retention_days)\n\n        storage_backend = self.storage_backends[policy.destination_config[\"provider\"]]\n\n        # List backup manifests\n        manifest_prefix = f\"backups/{policy.name}/manifests/\"\n        manifests = await storage_backend.list_files(manifest_prefix)\n\n        for manifest_file in manifests:\n            if manifest_file.last_modified &lt; cutoff_date:\n                # Download and parse manifest to get file list\n                manifest_data = await storage_backend.download_file(manifest_file.path)\n\n                if policy.compression_enabled:\n                    manifest_data = await self._decompress_data(manifest_data)\n\n                manifest = json.loads(manifest_data.decode())\n\n                # Delete backup files\n                for file_info in manifest.get(\"files\", []):\n                    if \"backup_path\" in file_info:\n                        await storage_backend.delete_file(file_info[\"backup_path\"])\n\n                # Delete manifest\n                await storage_backend.delete_file(manifest_file.path)\n\n    async def restore_backup(\n        self,\n        backup_job_id: str,\n        target_path: str,\n        file_filters: List[str] = None\n    ) -&gt; RestoreJob:\n        \"\"\"Restore files from backup\"\"\"\n        restore_job = RestoreJob(\n            id=str(uuid.uuid4()),\n            backup_job_id=backup_job_id,\n            restore_type=\"selective\" if file_filters else \"full\",\n            target_path=target_path,\n            file_filters=file_filters or []\n        )\n\n        # Start restore asynchronously\n        asyncio.create_task(self._execute_restore_job(restore_job))\n\n        return restore_job\n\n    async def _execute_restore_job(self, restore_job: RestoreJob):\n        \"\"\"Execute restore job\"\"\"\n        try:\n            restore_job.status = RestoreStatus.RUNNING\n            restore_job.started_at = datetime.utcnow()\n\n            # Find backup manifest\n            manifest = await self._find_backup_manifest(restore_job.backup_job_id)\n            if not manifest:\n                raise ValueError(f\"Backup manifest not found for job {restore_job.backup_job_id}\")\n\n            # Filter files if needed\n            files_to_restore = manifest[\"files\"]\n            if restore_job.file_filters:\n                files_to_restore = [\n                    f for f in files_to_restore\n                    if any(Path(f[\"path\"]).match(pattern) for pattern in restore_job.file_filters)\n                ]\n\n            # Restore files\n            target_base = Path(restore_job.target_path)\n            target_base.mkdir(parents=True, exist_ok=True)\n\n            for file_info in files_to_restore:\n                await self._restore_single_file(file_info, target_base, manifest, restore_job)\n                restore_job.restored_files += 1\n\n            restore_job.status = RestoreStatus.COMPLETED\n            restore_job.completed_at = datetime.utcnow()\n\n        except Exception as e:\n            restore_job.status = RestoreStatus.FAILED\n            restore_job.error_message = str(e)\n            restore_job.completed_at = datetime.utcnow()\n\n    async def _restore_single_file(\n        self,\n        file_info: Dict[str, Any],\n        target_base: Path,\n        manifest: Dict[str, Any],\n        restore_job: RestoreJob\n    ):\n        \"\"\"Restore a single file\"\"\"\n        # Find backup path\n        backup_path = None\n        for backed_up_file in self.active_jobs.get(restore_job.backup_job_id, {}).metadata.get(\"files_backed_up\", []):\n            if backed_up_file[\"original_path\"] == file_info[\"path\"]:\n                backup_path = backed_up_file[\"backup_path\"]\n                break\n\n        if not backup_path:\n            raise ValueError(f\"Backup path not found for {file_info['path']}\")\n\n        # Download backup file\n        storage_backend = list(self.storage_backends.values())[0]  # Use first available\n        backup_data = await storage_backend.download_file(backup_path)\n\n        # Decrypt if needed\n        if manifest.get(\"encryption_enabled\"):\n            backup_data = await self._decrypt_data(backup_data, restore_job.backup_job_id)\n\n        # Decompress if needed\n        if manifest.get(\"compression_enabled\"):\n            backup_data = await self._decompress_data(backup_data)\n\n        # Write to target location\n        relative_path = file_info[\"relative_path\"]\n        target_file = target_base / relative_path\n        target_file.parent.mkdir(parents=True, exist_ok=True)\n\n        async with aiofiles.open(target_file, \"wb\") as f:\n            await f.write(backup_data)\n\n        # Restore permissions\n        target_file.chmod(int(file_info[\"permissions\"], 8))\n\n    async def _decrypt_data(self, data: bytes, backup_id: str) -&gt; bytes:\n        \"\"\"Decrypt data\"\"\"\n        from cryptography.fernet import Fernet\n        import base64\n\n        key = base64.urlsafe_b64encode(backup_id.encode()[:32].ljust(32, b'0'))\n        fernet = Fernet(key)\n\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, fernet.decrypt, data)\n\n    async def _decompress_data(self, data: bytes) -&gt; bytes:\n        \"\"\"Decompress data\"\"\"\n        import gzip\n\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, gzip.decompress, data)\n\n    def get_backup_status(self, job_id: str) -&gt; Optional[BackupJob]:\n        \"\"\"Get backup job status\"\"\"\n        return self.active_jobs.get(job_id)\n\n    async def list_backups(self, policy_name: str = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"List available backups\"\"\"\n        backups = []\n\n        for job in self.active_jobs.values():\n            if policy_name and job.policy_name != policy_name:\n                continue\n\n            if job.status == BackupStatus.COMPLETED:\n                backups.append({\n                    \"job_id\": job.id,\n                    \"policy_name\": job.policy_name,\n                    \"backup_type\": job.backup_type.value,\n                    \"created_at\": job.started_at,\n                    \"total_files\": job.total_files,\n                    \"total_size\": job.total_size,\n                    \"compressed_size\": job.compressed_size\n                })\n\n        return sorted(backups, key=lambda x: x[\"created_at\"], reverse=True)\n</code></pre>"},{"location":"atomic/file-storage/backup-strategies/#automated-backup-scheduling","title":"Automated Backup Scheduling","text":"<pre><code>from apscheduler.schedulers.asyncio import AsyncIOScheduler\nfrom apscheduler.triggers.cron import CronTrigger\n\nclass BackupScheduler:\n    \"\"\"Automated backup scheduling with cron-like expressions\"\"\"\n\n    def __init__(self, backup_service: BackupService):\n        self.backup_service = backup_service\n        self.scheduler = AsyncIOScheduler()\n        self.scheduled_jobs = {}\n\n    async def start(self):\n        \"\"\"Start the scheduler\"\"\"\n        self.scheduler.start()\n\n    async def stop(self):\n        \"\"\"Stop the scheduler\"\"\"\n        self.scheduler.shutdown()\n\n    async def schedule_policy(self, policy_name: str):\n        \"\"\"Schedule backup policy for automatic execution\"\"\"\n        if policy_name not in self.backup_service.policies:\n            raise ValueError(f\"Policy {policy_name} not found\")\n\n        policy = self.backup_service.policies[policy_name]\n\n        # Parse cron expression\n        trigger = CronTrigger.from_crontab(policy.schedule_cron)\n\n        # Schedule job\n        job = self.scheduler.add_job(\n            self._execute_scheduled_backup,\n            trigger=trigger,\n            args=[policy_name],\n            id=f\"backup_{policy_name}\",\n            replace_existing=True\n        )\n\n        self.scheduled_jobs[policy_name] = job\n\n    async def _execute_scheduled_backup(self, policy_name: str):\n        \"\"\"Execute scheduled backup\"\"\"\n        try:\n            backup_job = await self.backup_service.execute_backup(policy_name)\n            print(f\"Scheduled backup started: {backup_job.id}\")\n        except Exception as e:\n            print(f\"Scheduled backup failed for policy {policy_name}: {e}\")\n\n    async def unschedule_policy(self, policy_name: str):\n        \"\"\"Remove policy from schedule\"\"\"\n        if policy_name in self.scheduled_jobs:\n            self.scheduler.remove_job(f\"backup_{policy_name}\")\n            del self.scheduled_jobs[policy_name]\n\n    def get_scheduled_jobs(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get list of scheduled backup jobs\"\"\"\n        jobs = []\n        for job in self.scheduler.get_jobs():\n            if job.id.startswith(\"backup_\"):\n                policy_name = job.id.replace(\"backup_\", \"\")\n                jobs.append({\n                    \"policy_name\": policy_name,\n                    \"next_run_time\": job.next_run_time,\n                    \"trigger\": str(job.trigger)\n                })\n        return jobs\n</code></pre>"},{"location":"atomic/file-storage/backup-strategies/#disaster-recovery-manager","title":"Disaster Recovery Manager","text":"<pre><code>class DisasterRecoveryManager:\n    \"\"\"Manages disaster recovery scenarios with cross-region replication\"\"\"\n\n    def __init__(self, backup_service: BackupService, recovery_configs: Dict[str, Any]):\n        self.backup_service = backup_service\n        self.recovery_configs = recovery_configs\n\n    async def create_dr_plan(\n        self,\n        plan_name: str,\n        primary_region: str,\n        backup_regions: List[str],\n        recovery_time_objective: int,  # minutes\n        recovery_point_objective: int  # minutes\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create disaster recovery plan\"\"\"\n        dr_plan = {\n            \"plan_name\": plan_name,\n            \"primary_region\": primary_region,\n            \"backup_regions\": backup_regions,\n            \"rto_minutes\": recovery_time_objective,\n            \"rpo_minutes\": recovery_point_objective,\n            \"created_at\": datetime.utcnow(),\n            \"status\": \"active\"\n        }\n\n        # Store DR plan\n        await self._store_dr_plan(dr_plan)\n\n        return dr_plan\n\n    async def test_disaster_recovery(self, plan_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Test disaster recovery procedures\"\"\"\n        dr_plan = await self._get_dr_plan(plan_name)\n        if not dr_plan:\n            raise ValueError(f\"DR plan {plan_name} not found\")\n\n        test_results = {\n            \"test_id\": str(uuid.uuid4()),\n            \"plan_name\": plan_name,\n            \"started_at\": datetime.utcnow(),\n            \"tests\": []\n        }\n\n        # Test backup availability in each region\n        for region in dr_plan[\"backup_regions\"]:\n            region_test = await self._test_region_recovery(region)\n            test_results[\"tests\"].append({\n                \"region\": region,\n                \"success\": region_test[\"success\"],\n                \"response_time_seconds\": region_test[\"response_time\"],\n                \"error\": region_test.get(\"error\")\n            })\n\n        test_results[\"completed_at\"] = datetime.utcnow()\n        test_results[\"overall_success\"] = all(t[\"success\"] for t in test_results[\"tests\"])\n\n        return test_results\n\n    async def _test_region_recovery(self, region: str) -&gt; Dict[str, Any]:\n        \"\"\"Test recovery capabilities in a specific region\"\"\"\n        start_time = datetime.utcnow()\n\n        try:\n            # Test storage backend connectivity\n            storage_backend = self.backup_service.storage_backends.get(region)\n            if not storage_backend:\n                return {\n                    \"success\": False,\n                    \"error\": f\"No storage backend configured for region {region}\",\n                    \"response_time\": 0\n                }\n\n            # Test listing backups\n            backups = await storage_backend.list_files(\"backups/\", limit=10)\n\n            response_time = (datetime.utcnow() - start_time).total_seconds()\n\n            return {\n                \"success\": True,\n                \"response_time\": response_time,\n                \"backup_count\": len(backups)\n            }\n\n        except Exception as e:\n            response_time = (datetime.utcnow() - start_time).total_seconds()\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"response_time\": response_time\n            }\n\n    async def initiate_failover(\n        self,\n        plan_name: str,\n        target_region: str,\n        reason: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Initiate failover to backup region\"\"\"\n        dr_plan = await self._get_dr_plan(plan_name)\n        if not dr_plan:\n            raise ValueError(f\"DR plan {plan_name} not found\")\n\n        if target_region not in dr_plan[\"backup_regions\"]:\n            raise ValueError(f\"Region {target_region} not in backup regions\")\n\n        failover_job = {\n            \"failover_id\": str(uuid.uuid4()),\n            \"plan_name\": plan_name,\n            \"target_region\": target_region,\n            \"reason\": reason,\n            \"initiated_at\": datetime.utcnow(),\n            \"status\": \"in_progress\",\n            \"steps\": []\n        }\n\n        # Execute failover steps\n        try:\n            # Step 1: Verify backup integrity in target region\n            await self._verify_backup_integrity_in_region(target_region, failover_job)\n\n            # Step 2: Update DNS/load balancer to point to backup region\n            await self._update_traffic_routing(target_region, failover_job)\n\n            # Step 3: Start services in backup region\n            await self._start_services_in_region(target_region, failover_job)\n\n            # Step 4: Verify application functionality\n            await self._verify_application_health(target_region, failover_job)\n\n            failover_job[\"status\"] = \"completed\"\n            failover_job[\"completed_at\"] = datetime.utcnow()\n\n        except Exception as e:\n            failover_job[\"status\"] = \"failed\"\n            failover_job[\"error\"] = str(e)\n            failover_job[\"failed_at\"] = datetime.utcnow()\n\n        return failover_job\n\n    async def _verify_backup_integrity_in_region(self, region: str, failover_job: Dict):\n        \"\"\"Verify backup integrity in target region\"\"\"\n        step = {\n            \"step\": \"verify_backup_integrity\",\n            \"started_at\": datetime.utcnow(),\n            \"status\": \"running\"\n        }\n\n        try:\n            storage_backend = self.backup_service.storage_backends[region]\n\n            # List recent backups\n            recent_backups = await storage_backend.list_files(\"backups/\", limit=5)\n\n            if not recent_backups:\n                raise ValueError(\"No backups found in target region\")\n\n            # Verify a sample of backups\n            verified_count = 0\n            for backup in recent_backups[:2]:  # Verify 2 most recent\n                try:\n                    # Download and verify backup file\n                    backup_data = await storage_backend.download_file(backup.path)\n                    if backup_data:\n                        verified_count += 1\n                except Exception:\n                    continue\n\n            if verified_count == 0:\n                raise ValueError(\"No backups could be verified\")\n\n            step[\"status\"] = \"completed\"\n            step[\"verified_backups\"] = verified_count\n\n        except Exception as e:\n            step[\"status\"] = \"failed\"\n            step[\"error\"] = str(e)\n            raise\n\n        finally:\n            step[\"completed_at\"] = datetime.utcnow()\n            failover_job[\"steps\"].append(step)\n\n    async def _update_traffic_routing(self, target_region: str, failover_job: Dict):\n        \"\"\"Update traffic routing to target region\"\"\"\n        step = {\n            \"step\": \"update_traffic_routing\",\n            \"started_at\": datetime.utcnow(),\n            \"status\": \"running\"\n        }\n\n        try:\n            # This would integrate with your DNS/load balancer\n            # Implementation depends on your infrastructure\n            await asyncio.sleep(2)  # Simulate routing update\n\n            step[\"status\"] = \"completed\"\n\n        except Exception as e:\n            step[\"status\"] = \"failed\"\n            step[\"error\"] = str(e)\n            raise\n\n        finally:\n            step[\"completed_at\"] = datetime.utcnow()\n            failover_job[\"steps\"].append(step)\n\n    async def _start_services_in_region(self, target_region: str, failover_job: Dict):\n        \"\"\"Start services in backup region\"\"\"\n        step = {\n            \"step\": \"start_services\",\n            \"started_at\": datetime.utcnow(),\n            \"status\": \"running\"\n        }\n\n        try:\n            # This would start your application services in the target region\n            # Implementation depends on your orchestration platform\n            await asyncio.sleep(5)  # Simulate service startup\n\n            step[\"status\"] = \"completed\"\n\n        except Exception as e:\n            step[\"status\"] = \"failed\"\n            step[\"error\"] = str(e)\n            raise\n\n        finally:\n            step[\"completed_at\"] = datetime.utcnow()\n            failover_job[\"steps\"].append(step)\n\n    async def _verify_application_health(self, target_region: str, failover_job: Dict):\n        \"\"\"Verify application health in target region\"\"\"\n        step = {\n            \"step\": \"verify_application_health\",\n            \"started_at\": datetime.utcnow(),\n            \"status\": \"running\"\n        }\n\n        try:\n            # This would perform health checks on your application\n            # Implementation depends on your application architecture\n            await asyncio.sleep(3)  # Simulate health checks\n\n            step[\"status\"] = \"completed\"\n            step[\"health_check_results\"] = {\n                \"api_responsive\": True,\n                \"database_accessible\": True,\n                \"external_services_available\": True\n            }\n\n        except Exception as e:\n            step[\"status\"] = \"failed\"\n            step[\"error\"] = str(e)\n            raise\n\n        finally:\n            step[\"completed_at\"] = datetime.utcnow()\n            failover_job[\"steps\"].append(step)\n\n    async def _store_dr_plan(self, dr_plan: Dict[str, Any]):\n        \"\"\"Store disaster recovery plan\"\"\"\n        # Implementation would store in your configuration database\n        pass\n\n    async def _get_dr_plan(self, plan_name: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Retrieve disaster recovery plan\"\"\"\n        # Implementation would retrieve from your configuration database\n        return None\n</code></pre>"},{"location":"atomic/file-storage/backup-strategies/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, BackgroundTasks, HTTPException, Depends\nfrom typing import List\n\napp = FastAPI()\n\n# Initialize services\nbackup_service = BackupService(storage_backends)\nbackup_scheduler = BackupScheduler(backup_service)\ndr_manager = DisasterRecoveryManager(backup_service, recovery_configs)\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    await backup_scheduler.start()\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    await backup_scheduler.stop()\n\n@app.post(\"/backup/policies\")\nasync def create_backup_policy(\n    policy_data: Dict[str, Any],\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Create backup policy\"\"\"\n    policy = BackupPolicy(\n        name=policy_data[\"name\"],\n        backup_type=BackupType(policy_data[\"backup_type\"]),\n        schedule_cron=policy_data[\"schedule_cron\"],\n        retention_days=policy_data[\"retention_days\"],\n        source_paths=policy_data[\"source_paths\"],\n        destination_config=policy_data[\"destination_config\"]\n    )\n\n    policy_name = await backup_service.create_backup_policy(policy)\n\n    # Schedule if requested\n    if policy_data.get(\"auto_schedule\", False):\n        await backup_scheduler.schedule_policy(policy_name)\n\n    return {\"policy_name\": policy_name, \"status\": \"created\"}\n\n@app.post(\"/backup/execute/{policy_name}\")\nasync def execute_backup(\n    policy_name: str,\n    force_full: bool = False,\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Execute backup manually\"\"\"\n    try:\n        job = await backup_service.execute_backup(policy_name, force_full)\n        return {\n            \"job_id\": job.id,\n            \"status\": job.status.value,\n            \"message\": \"Backup started\"\n        }\n    except ValueError as e:\n        raise HTTPException(404, str(e))\n\n@app.get(\"/backup/jobs/{job_id}\")\nasync def get_backup_status(\n    job_id: str,\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Get backup job status\"\"\"\n    job = backup_service.get_backup_status(job_id)\n    if not job:\n        raise HTTPException(404, \"Job not found\")\n\n    return {\n        \"job_id\": job.id,\n        \"policy_name\": job.policy_name,\n        \"backup_type\": job.backup_type.value,\n        \"status\": job.status.value,\n        \"progress\": f\"{job.processed_files}/{job.total_files}\",\n        \"started_at\": job.started_at,\n        \"completed_at\": job.completed_at,\n        \"error\": job.error_message\n    }\n\n@app.get(\"/backup/list\")\nasync def list_backups(\n    policy_name: Optional[str] = None,\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"List available backups\"\"\"\n    backups = await backup_service.list_backups(policy_name)\n    return {\"backups\": backups}\n\n@app.post(\"/backup/restore\")\nasync def restore_backup(\n    restore_request: Dict[str, Any],\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Restore files from backup\"\"\"\n    restore_job = await backup_service.restore_backup(\n        backup_job_id=restore_request[\"backup_job_id\"],\n        target_path=restore_request[\"target_path\"],\n        file_filters=restore_request.get(\"file_filters\")\n    )\n\n    return {\n        \"restore_job_id\": restore_job.id,\n        \"status\": restore_job.status.value,\n        \"message\": \"Restore started\"\n    }\n\n@app.get(\"/backup/schedule\")\nasync def get_scheduled_jobs(user: User = Depends(get_current_admin_user)):\n    \"\"\"Get scheduled backup jobs\"\"\"\n    jobs = backup_scheduler.get_scheduled_jobs()\n    return {\"scheduled_jobs\": jobs}\n\n@app.post(\"/dr/test/{plan_name}\")\nasync def test_disaster_recovery(\n    plan_name: str,\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Test disaster recovery plan\"\"\"\n    test_results = await dr_manager.test_disaster_recovery(plan_name)\n    return test_results\n\n@app.post(\"/dr/failover/{plan_name}\")\nasync def initiate_failover(\n    plan_name: str,\n    failover_request: Dict[str, Any],\n    user: User = Depends(get_current_admin_user)\n):\n    \"\"\"Initiate disaster recovery failover\"\"\"\n    failover_job = await dr_manager.initiate_failover(\n        plan_name=plan_name,\n        target_region=failover_request[\"target_region\"],\n        reason=failover_request[\"reason\"]\n    )\n\n    return failover_job\n</code></pre>"},{"location":"atomic/file-storage/backup-strategies/#testing-backup-systems","title":"Testing Backup Systems","text":"<pre><code>import pytest\nimport tempfile\nimport shutil\nfrom unittest.mock import AsyncMock\n\nclass TestBackupService:\n\n    @pytest.fixture\n    async def backup_service(self):\n        storage_backends = {\n            \"local\": AsyncMock(),\n            \"s3\": AsyncMock()\n        }\n        return BackupService(storage_backends)\n\n    @pytest.fixture\n    def sample_policy(self):\n        return BackupPolicy(\n            name=\"test_policy\",\n            backup_type=BackupType.FULL,\n            schedule_cron=\"0 2 * * *\",  # Daily at 2 AM\n            retention_days=30,\n            source_paths=[\"/tmp/test_source\"],\n            destination_config={\"provider\": \"local\"}\n        )\n\n    async def test_policy_creation(self, backup_service, sample_policy):\n        policy_name = await backup_service.create_backup_policy(sample_policy)\n        assert policy_name == \"test_policy\"\n        assert \"test_policy\" in backup_service.policies\n\n    async def test_full_backup_execution(self, backup_service, sample_policy):\n        # Create test files\n        with tempfile.TemporaryDirectory() as temp_dir:\n            test_file = Path(temp_dir) / \"test.txt\"\n            test_file.write_text(\"test content\")\n\n            sample_policy.source_paths = [str(test_file)]\n            await backup_service.create_backup_policy(sample_policy)\n\n            # Mock storage backend\n            backup_service.storage_backends[\"local\"].upload_file = AsyncMock()\n\n            job = await backup_service.execute_backup(\"test_policy\")\n\n            assert job.policy_name == \"test_policy\"\n            assert job.backup_type == BackupType.FULL\n\n    async def test_incremental_backup(self, backup_service, sample_policy):\n        # Test incremental backup logic\n        sample_policy.backup_type = BackupType.INCREMENTAL\n        await backup_service.create_backup_policy(sample_policy)\n\n        # Mock previous backup manifest\n        backup_service._get_last_backup_manifest = AsyncMock(return_value=None)\n\n        with tempfile.TemporaryDirectory() as temp_dir:\n            test_file = Path(temp_dir) / \"test.txt\"\n            test_file.write_text(\"test content\")\n            sample_policy.source_paths = [str(test_file)]\n\n            job = await backup_service.execute_backup(\"test_policy\")\n            # First incremental backup should be full since no previous backup exists\n\n    async def test_backup_restoration(self, backup_service):\n        # Mock backup manifest\n        manifest = {\n            \"backup_id\": \"test_backup\",\n            \"files\": [\n                {\n                    \"path\": \"/tmp/test.txt\",\n                    \"relative_path\": \"test.txt\",\n                    \"size\": 100,\n                    \"file_hash\": \"abcdef\"\n                }\n            ],\n            \"compression_enabled\": False,\n            \"encryption_enabled\": False\n        }\n\n        backup_service._find_backup_manifest = AsyncMock(return_value=manifest)\n        backup_service.storage_backends[\"local\"].download_file = AsyncMock(return_value=b\"test content\")\n\n        with tempfile.TemporaryDirectory() as temp_dir:\n            restore_job = await backup_service.restore_backup(\n                \"test_backup\",\n                temp_dir\n            )\n\n            assert restore_job.backup_job_id == \"test_backup\"\n\n    def test_backup_policy_validation(self):\n        # Test invalid cron expression\n        with pytest.raises(ValueError):\n            BackupPolicy(\n                name=\"invalid\",\n                backup_type=BackupType.FULL,\n                schedule_cron=\"invalid cron\",\n                retention_days=30,\n                source_paths=[\"/tmp\"]\n            )\n\n    async def test_disaster_recovery_test(self):\n        dr_manager = DisasterRecoveryManager(None, {})\n\n        # Mock DR plan\n        dr_manager._get_dr_plan = AsyncMock(return_value={\n            \"plan_name\": \"test_plan\",\n            \"primary_region\": \"us-east-1\",\n            \"backup_regions\": [\"us-west-2\"],\n            \"rto_minutes\": 15,\n            \"rpo_minutes\": 5\n        })\n\n        dr_manager._test_region_recovery = AsyncMock(return_value={\n            \"success\": True,\n            \"response_time\": 2.5\n        })\n\n        test_results = await dr_manager.test_disaster_recovery(\"test_plan\")\n\n        assert test_results[\"overall_success\"] is True\n        assert len(test_results[\"tests\"]) == 1\n</code></pre>"},{"location":"atomic/file-storage/backup-strategies/#related-documentation","title":"Related Documentation","text":"<ul> <li>File Upload Patterns - File upload and validation</li> <li>Media Processing Patterns - Media processing workflows</li> <li>Cloud Storage Integration - Multi-cloud storage</li> <li>Infrastructure - Infrastructure and deployment guides</li> </ul>"},{"location":"atomic/file-storage/backup-strategies/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>3-2-1 Rule: Keep 3 copies of data, on 2 different media, with 1 offsite</li> <li>Automation: Automate backup scheduling and monitoring</li> <li>Testing: Regularly test backup restoration and disaster recovery</li> <li>Encryption: Always encrypt backups in transit and at rest</li> <li>Monitoring: Monitor backup success rates and storage usage</li> <li>Documentation: Document recovery procedures and test results</li> <li>Compliance: Ensure backup retention meets regulatory requirements</li> <li>Performance: Optimize backup performance with compression and parallelization</li> </ol>"},{"location":"atomic/file-storage/backup-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/file-storage/cloud-integration.md</code> \u2014 Cloud storage integration</li> <li><code>docs/atomic/infrastructure/docker-volumes.md</code> \u2014 Volume management</li> <li><code>docs/atomic/file-storage/media-processing.md</code> \u2014 Media file handling</li> <li><code>docs/atomic/infrastructure/backup-restore.md</code> \u2014 Backup procedures</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/","title":"CDN Integration Guide","text":"<p>Comprehensive guidance for integrating Content Delivery Networks (CDNs) with microservices, covering asset versioning, cache strategy, invalidation workflows, and security hardening.</p>"},{"location":"atomic/file-storage/cdn-integration/#cdn-integration-strategy","title":"CDN Integration Strategy","text":""},{"location":"atomic/file-storage/cdn-integration/#asset-classification","title":"Asset Classification","text":"<ul> <li>Static immutable assets: Versioned bundles (JS/CSS), hashed filenames, long-lived cache headers.</li> <li>Semi-static assets: Marketing images, generated PDFs with periodic updates, cache control tuned per TTL requirements.</li> <li>Dynamic assets: User-specific downloads sent through signed URLs with short-term caching at the edge.</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/#cdn-selection-criteria","title":"CDN Selection Criteria","text":"Capability Considerations Global POP coverage Evaluate latency benchmarks for target regions. Programmable edge Support for Workers/Lambda@Edge for auth, headers, dynamic redirects. HTTP/3 + TLS 1.3 Required for modern browsers and latency-sensitive workloads. Purge APIs REST/GraphQL purge endpoints, bulk purges, invalidation speed guarantees. Metrics &amp; logging Real-time analytics, log streaming to SIEM, request sampling."},{"location":"atomic/file-storage/cdn-integration/#asset-deployment-workflow","title":"Asset Deployment Workflow","text":""},{"location":"atomic/file-storage/cdn-integration/#build-pipeline-integration-cicd","title":"Build Pipeline Integration (CI/CD)","text":"<pre><code># CI step example for versioning and uploading static assets\ndependencies:\n  predeploy:\n    - name: Install dependencies\n      run: npm ci\n    - name: Build static bundle\n      run: npm run build\n    - name: Upload assets to storage\n      run: &gt;\n        aws s3 sync dist/ s3://my-bucket/static/\n        --cache-control \"public, max-age=31536000, immutable\"\n        --content-encoding gzip\n    - name: Invalidate CDN cache\n      run: &gt;\n        aws cloudfront create-invalidation\n        --distribution-id $CLOUDFRONT_DIST\n        --paths \"/static/*\"\n</code></pre>"},{"location":"atomic/file-storage/cdn-integration/#versioning-rules","title":"Versioning Rules","text":"<ol> <li>Compute content hashes for every bundle.</li> <li>Embed hash in file name and release manifest.</li> <li>Maintain backward compatibility manifest for rollback.</li> <li>Align backend references via environment-specific config service.</li> </ol>"},{"location":"atomic/file-storage/cdn-integration/#dynamic-asset-delivery","title":"Dynamic Asset Delivery","text":""},{"location":"atomic/file-storage/cdn-integration/#signed-urls-with-cdn","title":"Signed URLs with CDN","text":"<pre><code>from datetime import datetime, timedelta\nfrom urllib.parse import urljoin\nfrom botocore.signers import CloudFrontSigner\nimport rsa\n\nwith open(\"cloudfront_private_key.pem\", \"rb\") as fh:\n    private_key = rsa.PrivateKey.load_pkcs1(fh.read())\n\nsigner = CloudFrontSigner(key_id=\"K123456789\", private_key=private_key)\n\ndef generate_signed_url(path: str, expires_minutes: int = 10) -&gt; str:\n    expire_at = datetime.utcnow() + timedelta(minutes=expires_minutes)\n\n    def rsa_signer(message: bytes) -&gt; bytes:\n        return rsa.sign(message, private_key, \"SHA-1\")\n\n    signed_url = signer.generate_presigned_url(\n        urljoin(\"https://d123.cloudfront.net\", path),\n        date_less_than=expire_at,\n        rsa_signer=rsa_signer\n    )\n    return signed_url\n</code></pre>"},{"location":"atomic/file-storage/cdn-integration/#edge-authorization-checks","title":"Edge Authorization Checks","text":"<p>Configure edge function (Cloudflare Worker, Lambda@Edge) to verify JWT scopes or tenant metadata before serving sensitive objects.</p> <pre><code>export default {\n  async fetch(request, env, ctx) {\n    const token = request.headers.get(\"Authorization\");\n    if (!token) {\n      return new Response(\"Unauthorized\", { status: 401 });\n    }\n\n    const claims = await env.AUTH_SERVICE.validate(token);\n    if (!claims || !claims.scopes.includes(\"asset:read\")) {\n      return new Response(\"Forbidden\", { status: 403 });\n    }\n\n    const response = await fetch(request);\n    return new Response(response.body, {\n      ...response,\n      headers: {\n        ...response.headers,\n        \"Cache-Control\": \"public, max-age=60\"\n      }\n    });\n  }\n};\n</code></pre>"},{"location":"atomic/file-storage/cdn-integration/#cache-invalidation-patterns","title":"Cache Invalidation Patterns","text":""},{"location":"atomic/file-storage/cdn-integration/#event-driven-invalidation","title":"Event-Driven Invalidation","text":"<ol> <li>Emit <code>asset.updated</code> event from content service.</li> <li>Fan-out to CDN invalidation worker via queue.</li> <li>Batch purge requests to stay within rate limits.</li> <li>Log invalidation results and retry failures with exponential backoff.</li> </ol>"},{"location":"atomic/file-storage/cdn-integration/#stale-while-revalidate-swr","title":"Stale-While-Revalidate (SWR)","text":"<ul> <li>Serve stale content while background refresh runs at the edge.</li> <li>Use origin response headers: <code>Cache-Control: public, max-age=60, stale-while-revalidate=300</code>.</li> <li>Combine with ETag/If-None-Match to reduce origin load.</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<ul> <li>Track cache hit ratio, origin latency, error rate, bandwidth usage.</li> <li>Set alerts for sudden cache miss spikes (&gt;15% delta) indicating purge issues.</li> <li>Stream CDN logs to SIEM with enriched headers (request ID, user agent).</li> <li>Monitor TLS certificate expiry and automate rotation.</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Enforce HTTPS with HSTS (<code>Strict-Transport-Security</code>).</li> <li>Strip sensitive headers at the edge (cookies, Authorization) for public assets.</li> <li>Implement signed cookies for batch downloads.</li> <li>Enable WAF rules for bot mitigation and rate limiting.</li> <li>Audit CDN access keys; rotate at least every 90 days.</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/#operational-checklist","title":"Operational Checklist","text":"<ul> <li> Automated asset hashing and manifest generation.</li> <li> Environment-specific CDN distribution mappings.</li> <li> Multi-region failover via secondary origins.</li> <li> Synthetic monitoring from customer regions.</li> <li> Runbooks for purge failures and degradation triage.</li> </ul>"},{"location":"atomic/file-storage/cdn-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/file-storage/cloud-integration.md</code> \u2014 Cloud storage providers</li> <li><code>docs/atomic/file-storage/media-processing.md</code> \u2014 Media optimization</li> <li><code>docs/atomic/infrastructure/nginx.md</code> \u2014 Nginx CDN configuration</li> <li><code>docs/atomic/file-storage/upload-patterns.md</code> \u2014 File upload handling</li> </ul>"},{"location":"atomic/file-storage/cloud-integration/","title":"Cloud Storage Integration","text":"<p>Comprehensive guide for integrating with AWS S3, Google Cloud Storage, Azure Blob Storage, and multi-cloud strategies with CDN optimization and disaster recovery.</p>"},{"location":"atomic/file-storage/cloud-integration/#universal-storage-interface","title":"Universal Storage Interface","text":"<pre><code>from typing import Optional, Dict, List, Any, AsyncIterator, Union\nfrom dataclasses import dataclass, field\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nimport asyncio\nimport hashlib\nimport mimetypes\nfrom datetime import datetime, timedelta\nimport json\n\nclass StorageProvider(Enum):\n    AWS_S3 = \"aws_s3\"\n    GOOGLE_CLOUD = \"google_cloud\"\n    AZURE_BLOB = \"azure_blob\"\n    LOCAL = \"local\"\n\n@dataclass\nclass StorageConfig:\n    provider: StorageProvider\n    bucket_name: str\n    region: Optional[str] = None\n    access_key: Optional[str] = None\n    secret_key: Optional[str] = None\n    endpoint_url: Optional[str] = None  # For S3-compatible services\n    cdn_domain: Optional[str] = None\n    encryption_enabled: bool = True\n    versioning_enabled: bool = False\n    lifecycle_rules: List[Dict] = field(default_factory=list)\n\n@dataclass\nclass FileMetadata:\n    path: str\n    size: int\n    content_type: str\n    etag: str\n    last_modified: datetime\n    metadata: Dict[str, str] = field(default_factory=dict)\n    storage_class: Optional[str] = None\n    version_id: Optional[str] = None\n\nclass CloudStorageInterface(ABC):\n    \"\"\"Abstract interface for cloud storage providers\"\"\"\n\n    @abstractmethod\n    async def upload_file(\n        self,\n        file_data: bytes,\n        path: str,\n        content_type: Optional[str] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        storage_class: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Upload file and return public URL\"\"\"\n        pass\n\n    @abstractmethod\n    async def download_file(self, path: str) -&gt; bytes:\n        \"\"\"Download file content\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_file(self, path: str) -&gt; bool:\n        \"\"\"Delete file\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_file_metadata(self, path: str) -&gt; FileMetadata:\n        \"\"\"Get file metadata\"\"\"\n        pass\n\n    @abstractmethod\n    async def list_files(self, prefix: str = \"\", limit: int = 1000) -&gt; List[FileMetadata]:\n        \"\"\"List files with optional prefix filter\"\"\"\n        pass\n\n    @abstractmethod\n    async def generate_presigned_url(\n        self,\n        path: str,\n        operation: str = \"get\",\n        expiry_seconds: int = 3600\n    ) -&gt; str:\n        \"\"\"Generate presigned URL for direct client access\"\"\"\n        pass\n\n    @abstractmethod\n    async def copy_file(self, source_path: str, dest_path: str) -&gt; bool:\n        \"\"\"Copy file within storage\"\"\"\n        pass\n\nclass AWSS3Storage(CloudStorageInterface):\n    \"\"\"AWS S3 storage implementation\"\"\"\n\n    def __init__(self, config: StorageConfig):\n        self.config = config\n        self._client = None\n        self._session = None\n\n    async def _get_client(self):\n        \"\"\"Lazy initialization of S3 client\"\"\"\n        if not self._client:\n            import boto3\n            from botocore.config import Config\n\n            session = boto3.Session(\n                aws_access_key_id=self.config.access_key,\n                aws_secret_access_key=self.config.secret_key,\n                region_name=self.config.region\n            )\n\n            # Configure client with retry and timeout settings\n            client_config = Config(\n                region_name=self.config.region,\n                retries={'max_attempts': 3},\n                max_pool_connections=50\n            )\n\n            self._client = session.client(\n                's3',\n                config=client_config,\n                endpoint_url=self.config.endpoint_url\n            )\n\n        return self._client\n\n    async def upload_file(\n        self,\n        file_data: bytes,\n        path: str,\n        content_type: Optional[str] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        storage_class: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Upload file to S3\"\"\"\n        client = await self._get_client()\n\n        # Guess content type if not provided\n        if not content_type:\n            content_type, _ = mimetypes.guess_type(path)\n            content_type = content_type or 'application/octet-stream'\n\n        # Prepare upload parameters\n        upload_params = {\n            'Bucket': self.config.bucket_name,\n            'Key': path,\n            'Body': file_data,\n            'ContentType': content_type\n        }\n\n        # Add metadata\n        if metadata:\n            upload_params['Metadata'] = metadata\n\n        # Add storage class\n        if storage_class:\n            upload_params['StorageClass'] = storage_class\n\n        # Add server-side encryption\n        if self.config.encryption_enabled:\n            upload_params['ServerSideEncryption'] = 'AES256'\n\n        # Perform upload\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(None, lambda: client.put_object(**upload_params))\n\n        # Return URL\n        if self.config.cdn_domain:\n            return f\"https://{self.config.cdn_domain}/{path}\"\n        else:\n            return f\"https://{self.config.bucket_name}.s3.{self.config.region}.amazonaws.com/{path}\"\n\n    async def download_file(self, path: str) -&gt; bytes:\n        \"\"\"Download file from S3\"\"\"\n        client = await self._get_client()\n\n        loop = asyncio.get_event_loop()\n        response = await loop.run_in_executor(\n            None,\n            lambda: client.get_object(Bucket=self.config.bucket_name, Key=path)\n        )\n\n        return response['Body'].read()\n\n    async def delete_file(self, path: str) -&gt; bool:\n        \"\"\"Delete file from S3\"\"\"\n        client = await self._get_client()\n\n        try:\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(\n                None,\n                lambda: client.delete_object(Bucket=self.config.bucket_name, Key=path)\n            )\n            return True\n        except Exception:\n            return False\n\n    async def get_file_metadata(self, path: str) -&gt; FileMetadata:\n        \"\"\"Get S3 object metadata\"\"\"\n        client = await self._get_client()\n\n        loop = asyncio.get_event_loop()\n        response = await loop.run_in_executor(\n            None,\n            lambda: client.head_object(Bucket=self.config.bucket_name, Key=path)\n        )\n\n        return FileMetadata(\n            path=path,\n            size=response['ContentLength'],\n            content_type=response['ContentType'],\n            etag=response['ETag'].strip('\"'),\n            last_modified=response['LastModified'],\n            metadata=response.get('Metadata', {}),\n            storage_class=response.get('StorageClass'),\n            version_id=response.get('VersionId')\n        )\n\n    async def list_files(self, prefix: str = \"\", limit: int = 1000) -&gt; List[FileMetadata]:\n        \"\"\"List S3 objects\"\"\"\n        client = await self._get_client()\n\n        params = {\n            'Bucket': self.config.bucket_name,\n            'MaxKeys': limit\n        }\n\n        if prefix:\n            params['Prefix'] = prefix\n\n        loop = asyncio.get_event_loop()\n        response = await loop.run_in_executor(\n            None,\n            lambda: client.list_objects_v2(**params)\n        )\n\n        files = []\n        for obj in response.get('Contents', []):\n            files.append(FileMetadata(\n                path=obj['Key'],\n                size=obj['Size'],\n                content_type='',  # Not available in list operation\n                etag=obj['ETag'].strip('\"'),\n                last_modified=obj['LastModified'],\n                storage_class=obj.get('StorageClass')\n            ))\n\n        return files\n\n    async def generate_presigned_url(\n        self,\n        path: str,\n        operation: str = \"get\",\n        expiry_seconds: int = 3600\n    ) -&gt; str:\n        \"\"\"Generate presigned URL for S3 object\"\"\"\n        client = await self._get_client()\n\n        method_map = {\n            'get': 'get_object',\n            'put': 'put_object',\n            'delete': 'delete_object'\n        }\n\n        loop = asyncio.get_event_loop()\n        url = await loop.run_in_executor(\n            None,\n            lambda: client.generate_presigned_url(\n                method_map[operation],\n                Params={'Bucket': self.config.bucket_name, 'Key': path},\n                ExpiresIn=expiry_seconds\n            )\n        )\n\n        return url\n\n    async def copy_file(self, source_path: str, dest_path: str) -&gt; bool:\n        \"\"\"Copy object within S3\"\"\"\n        client = await self._get_client()\n\n        try:\n            copy_source = {\n                'Bucket': self.config.bucket_name,\n                'Key': source_path\n            }\n\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(\n                None,\n                lambda: client.copy_object(\n                    CopySource=copy_source,\n                    Bucket=self.config.bucket_name,\n                    Key=dest_path\n                )\n            )\n            return True\n        except Exception:\n            return False\n\nclass GoogleCloudStorage(CloudStorageInterface):\n    \"\"\"Google Cloud Storage implementation\"\"\"\n\n    def __init__(self, config: StorageConfig):\n        self.config = config\n        self._client = None\n\n    async def _get_client(self):\n        \"\"\"Lazy initialization of GCS client\"\"\"\n        if not self._client:\n            from google.cloud import storage\n\n            # Initialize client with service account or default credentials\n            self._client = storage.Client()\n            self._bucket = self._client.bucket(self.config.bucket_name)\n\n        return self._client\n\n    async def upload_file(\n        self,\n        file_data: bytes,\n        path: str,\n        content_type: Optional[str] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        storage_class: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Upload file to Google Cloud Storage\"\"\"\n        await self._get_client()\n\n        blob = self._bucket.blob(path)\n\n        # Set content type\n        if content_type:\n            blob.content_type = content_type\n\n        # Set metadata\n        if metadata:\n            blob.metadata = metadata\n\n        # Set storage class\n        if storage_class:\n            blob.storage_class = storage_class\n\n        # Upload in executor to avoid blocking\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(\n            None,\n            lambda: blob.upload_from_string(file_data)\n        )\n\n        # Return public URL\n        if self.config.cdn_domain:\n            return f\"https://{self.config.cdn_domain}/{path}\"\n        else:\n            return blob.public_url\n\n    async def download_file(self, path: str) -&gt; bytes:\n        \"\"\"Download file from GCS\"\"\"\n        await self._get_client()\n\n        blob = self._bucket.blob(path)\n\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, blob.download_as_bytes)\n\n    async def delete_file(self, path: str) -&gt; bool:\n        \"\"\"Delete file from GCS\"\"\"\n        await self._get_client()\n\n        try:\n            blob = self._bucket.blob(path)\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(None, blob.delete)\n            return True\n        except Exception:\n            return False\n\n    async def get_file_metadata(self, path: str) -&gt; FileMetadata:\n        \"\"\"Get GCS blob metadata\"\"\"\n        await self._get_client()\n\n        blob = self._bucket.blob(path)\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(None, blob.reload)\n\n        return FileMetadata(\n            path=path,\n            size=blob.size,\n            content_type=blob.content_type or '',\n            etag=blob.etag,\n            last_modified=blob.updated,\n            metadata=blob.metadata or {},\n            storage_class=blob.storage_class\n        )\n\n    async def list_files(self, prefix: str = \"\", limit: int = 1000) -&gt; List[FileMetadata]:\n        \"\"\"List GCS blobs\"\"\"\n        await self._get_client()\n\n        loop = asyncio.get_event_loop()\n        blobs = await loop.run_in_executor(\n            None,\n            lambda: list(self._bucket.list_blobs(prefix=prefix, max_results=limit))\n        )\n\n        files = []\n        for blob in blobs:\n            files.append(FileMetadata(\n                path=blob.name,\n                size=blob.size,\n                content_type=blob.content_type or '',\n                etag=blob.etag,\n                last_modified=blob.updated,\n                metadata=blob.metadata or {},\n                storage_class=blob.storage_class\n            ))\n\n        return files\n\n    async def generate_presigned_url(\n        self,\n        path: str,\n        operation: str = \"get\",\n        expiry_seconds: int = 3600\n    ) -&gt; str:\n        \"\"\"Generate signed URL for GCS blob\"\"\"\n        await self._get_client()\n\n        blob = self._bucket.blob(path)\n\n        method_map = {\n            'get': 'GET',\n            'put': 'PUT',\n            'delete': 'DELETE'\n        }\n\n        loop = asyncio.get_event_loop()\n        url = await loop.run_in_executor(\n            None,\n            lambda: blob.generate_signed_url(\n                expiration=timedelta(seconds=expiry_seconds),\n                method=method_map[operation]\n            )\n        )\n\n        return url\n\n    async def copy_file(self, source_path: str, dest_path: str) -&gt; bool:\n        \"\"\"Copy blob within GCS\"\"\"\n        await self._get_client()\n\n        try:\n            source_blob = self._bucket.blob(source_path)\n            dest_blob = self._bucket.blob(dest_path)\n\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(\n                None,\n                lambda: self._bucket.copy_blob(source_blob, self._bucket, dest_path)\n            )\n            return True\n        except Exception:\n            return False\n\nclass AzureBlobStorage(CloudStorageInterface):\n    \"\"\"Azure Blob Storage implementation\"\"\"\n\n    def __init__(self, config: StorageConfig):\n        self.config = config\n        self._client = None\n\n    async def _get_client(self):\n        \"\"\"Lazy initialization of Azure client\"\"\"\n        if not self._client:\n            from azure.storage.blob.aio import BlobServiceClient\n\n            self._client = BlobServiceClient(\n                account_url=f\"https://{self.config.access_key}.blob.core.windows.net\",\n                credential=self.config.secret_key\n            )\n\n        return self._client\n\n    async def upload_file(\n        self,\n        file_data: bytes,\n        path: str,\n        content_type: Optional[str] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        storage_class: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Upload file to Azure Blob Storage\"\"\"\n        client = await self._get_client()\n\n        blob_client = client.get_blob_client(\n            container=self.config.bucket_name,\n            blob=path\n        )\n\n        upload_params = {\n            'data': file_data,\n            'overwrite': True\n        }\n\n        if content_type:\n            upload_params['content_type'] = content_type\n\n        if metadata:\n            upload_params['metadata'] = metadata\n\n        await blob_client.upload_blob(**upload_params)\n\n        # Return URL\n        if self.config.cdn_domain:\n            return f\"https://{self.config.cdn_domain}/{path}\"\n        else:\n            return blob_client.url\n\n    async def download_file(self, path: str) -&gt; bytes:\n        \"\"\"Download file from Azure\"\"\"\n        client = await self._get_client()\n\n        blob_client = client.get_blob_client(\n            container=self.config.bucket_name,\n            blob=path\n        )\n\n        stream = await blob_client.download_blob()\n        return await stream.readall()\n\n    async def delete_file(self, path: str) -&gt; bool:\n        \"\"\"Delete file from Azure\"\"\"\n        client = await self._get_client()\n\n        try:\n            blob_client = client.get_blob_client(\n                container=self.config.bucket_name,\n                blob=path\n            )\n            await blob_client.delete_blob()\n            return True\n        except Exception:\n            return False\n\n    async def get_file_metadata(self, path: str) -&gt; FileMetadata:\n        \"\"\"Get Azure blob properties\"\"\"\n        client = await self._get_client()\n\n        blob_client = client.get_blob_client(\n            container=self.config.bucket_name,\n            blob=path\n        )\n\n        properties = await blob_client.get_blob_properties()\n\n        return FileMetadata(\n            path=path,\n            size=properties.size,\n            content_type=properties.content_type or '',\n            etag=properties.etag,\n            last_modified=properties.last_modified,\n            metadata=properties.metadata or {}\n        )\n\n    async def list_files(self, prefix: str = \"\", limit: int = 1000) -&gt; List[FileMetadata]:\n        \"\"\"List Azure blobs\"\"\"\n        client = await self._get_client()\n\n        container_client = client.get_container_client(self.config.bucket_name)\n\n        files = []\n        async for blob in container_client.list_blobs(name_starts_with=prefix):\n            if len(files) &gt;= limit:\n                break\n\n            files.append(FileMetadata(\n                path=blob.name,\n                size=blob.size,\n                content_type=blob.content_type or '',\n                etag=blob.etag,\n                last_modified=blob.last_modified,\n                metadata=blob.metadata or {}\n            ))\n\n        return files\n\n    async def generate_presigned_url(\n        self,\n        path: str,\n        operation: str = \"get\",\n        expiry_seconds: int = 3600\n    ) -&gt; str:\n        \"\"\"Generate SAS URL for Azure blob\"\"\"\n        from azure.storage.blob import generate_blob_sas, BlobSasPermissions\n\n        permissions = BlobSasPermissions()\n        if operation == \"get\":\n            permissions.read = True\n        elif operation == \"put\":\n            permissions.write = True\n        elif operation == \"delete\":\n            permissions.delete = True\n\n        sas_token = generate_blob_sas(\n            account_name=self.config.access_key,\n            container_name=self.config.bucket_name,\n            blob_name=path,\n            account_key=self.config.secret_key,\n            permission=permissions,\n            expiry=datetime.utcnow() + timedelta(seconds=expiry_seconds)\n        )\n\n        return f\"https://{self.config.access_key}.blob.core.windows.net/{self.config.bucket_name}/{path}?{sas_token}\"\n\n    async def copy_file(self, source_path: str, dest_path: str) -&gt; bool:\n        \"\"\"Copy blob within Azure\"\"\"\n        client = await self._get_client()\n\n        try:\n            source_blob = client.get_blob_client(\n                container=self.config.bucket_name,\n                blob=source_path\n            )\n\n            dest_blob = client.get_blob_client(\n                container=self.config.bucket_name,\n                blob=dest_path\n            )\n\n            await dest_blob.start_copy_from_url(source_blob.url)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"atomic/file-storage/cloud-integration/#multi-cloud-storage-manager","title":"Multi-Cloud Storage Manager","text":"<pre><code>class MultiCloudStorageManager:\n    \"\"\"Manages multiple cloud storage providers with failover and replication\"\"\"\n\n    def __init__(self, primary_config: StorageConfig, backup_configs: List[StorageConfig] = None):\n        self.primary_storage = self._create_storage(primary_config)\n        self.backup_storages = [self._create_storage(config) for config in (backup_configs or [])]\n        self.all_storages = [self.primary_storage] + self.backup_storages\n\n    def _create_storage(self, config: StorageConfig) -&gt; CloudStorageInterface:\n        \"\"\"Factory method to create storage instances\"\"\"\n        if config.provider == StorageProvider.AWS_S3:\n            return AWSS3Storage(config)\n        elif config.provider == StorageProvider.GOOGLE_CLOUD:\n            return GoogleCloudStorage(config)\n        elif config.provider == StorageProvider.AZURE_BLOB:\n            return AzureBlobStorage(config)\n        else:\n            raise ValueError(f\"Unsupported provider: {config.provider}\")\n\n    async def upload_file(\n        self,\n        file_data: bytes,\n        path: str,\n        replicate: bool = True,\n        **kwargs\n    ) -&gt; Dict[str, str]:\n        \"\"\"Upload file with optional replication to backup storages\"\"\"\n        results = {}\n        errors = {}\n\n        # Upload to primary storage\n        try:\n            primary_url = await self.primary_storage.upload_file(file_data, path, **kwargs)\n            results[\"primary\"] = primary_url\n        except Exception as e:\n            errors[\"primary\"] = str(e)\n            raise RuntimeError(f\"Primary upload failed: {e}\")\n\n        # Replicate to backup storages if requested\n        if replicate and self.backup_storages:\n            replication_tasks = []\n            for i, storage in enumerate(self.backup_storages):\n                task = asyncio.create_task(\n                    self._upload_with_retry(storage, file_data, path, f\"backup_{i}\", **kwargs)\n                )\n                replication_tasks.append(task)\n\n            # Wait for all replications with timeout\n            try:\n                replication_results = await asyncio.wait_for(\n                    asyncio.gather(*replication_tasks, return_exceptions=True),\n                    timeout=30.0\n                )\n\n                for i, result in enumerate(replication_results):\n                    if isinstance(result, Exception):\n                        errors[f\"backup_{i}\"] = str(result)\n                    else:\n                        results[f\"backup_{i}\"] = result\n            except asyncio.TimeoutError:\n                errors[\"replication\"] = \"Replication timeout\"\n\n        return {\n            \"urls\": results,\n            \"errors\": errors,\n            \"replicated\": len(results) - 1  # Exclude primary\n        }\n\n    async def _upload_with_retry(\n        self,\n        storage: CloudStorageInterface,\n        file_data: bytes,\n        path: str,\n        storage_name: str,\n        max_retries: int = 3,\n        **kwargs\n    ) -&gt; str:\n        \"\"\"Upload with retry logic\"\"\"\n        for attempt in range(max_retries):\n            try:\n                return await storage.upload_file(file_data, path, **kwargs)\n            except Exception as e:\n                if attempt == max_retries - 1:\n                    raise e\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n    async def download_file(self, path: str, prefer_backup: bool = False) -&gt; bytes:\n        \"\"\"Download file with failover to backup storages\"\"\"\n        storages = self.all_storages if not prefer_backup else self.all_storages[::-1]\n\n        for storage in storages:\n            try:\n                return await storage.download_file(path)\n            except Exception as e:\n                continue  # Try next storage\n\n        raise RuntimeError(\"File not found in any storage\")\n\n    async def delete_file(self, path: str, delete_all: bool = True) -&gt; Dict[str, bool]:\n        \"\"\"Delete file from all or just primary storage\"\"\"\n        results = {}\n\n        if delete_all:\n            storages = self.all_storages\n            storage_names = [\"primary\"] + [f\"backup_{i}\" for i in range(len(self.backup_storages))]\n        else:\n            storages = [self.primary_storage]\n            storage_names = [\"primary\"]\n\n        for storage, name in zip(storages, storage_names):\n            try:\n                results[name] = await storage.delete_file(path)\n            except Exception:\n                results[name] = False\n\n        return results\n\n    async def sync_between_storages(self, path: str) -&gt; Dict[str, str]:\n        \"\"\"Ensure file exists in all configured storages\"\"\"\n        results = {}\n\n        # Download from primary\n        try:\n            file_data = await self.primary_storage.download_file(path)\n        except Exception as e:\n            raise RuntimeError(f\"Cannot sync: file not found in primary storage: {e}\")\n\n        # Upload to backup storages\n        for i, storage in enumerate(self.backup_storages):\n            try:\n                url = await storage.upload_file(file_data, path)\n                results[f\"backup_{i}\"] = url\n            except Exception as e:\n                results[f\"backup_{i}\"] = f\"Failed: {e}\"\n\n        return results\n\n    async def verify_file_integrity(self, path: str) -&gt; Dict[str, Dict[str, Any]]:\n        \"\"\"Verify file exists and matches across all storages\"\"\"\n        results = {}\n        storage_names = [\"primary\"] + [f\"backup_{i}\" for i in range(len(self.backup_storages))]\n\n        for storage, name in zip(self.all_storages, storage_names):\n            try:\n                metadata = await storage.get_file_metadata(path)\n                results[name] = {\n                    \"exists\": True,\n                    \"size\": metadata.size,\n                    \"etag\": metadata.etag,\n                    \"last_modified\": metadata.last_modified\n                }\n            except Exception as e:\n                results[name] = {\n                    \"exists\": False,\n                    \"error\": str(e)\n                }\n\n        # Check consistency\n        sizes = [r[\"size\"] for r in results.values() if r.get(\"exists\")]\n        etags = [r[\"etag\"] for r in results.values() if r.get(\"exists\")]\n\n        consistent = len(set(sizes)) &lt;= 1 and len(set(etags)) &lt;= 1\n\n        return {\n            \"storages\": results,\n            \"consistent\": consistent,\n            \"total_copies\": len(sizes)\n        }\n</code></pre>"},{"location":"atomic/file-storage/cloud-integration/#cdn-integration","title":"CDN Integration","text":"<pre><code>class CDNManager:\n    \"\"\"Manages CDN integration for optimized content delivery\"\"\"\n\n    def __init__(self, storage_manager: MultiCloudStorageManager, cdn_configs: Dict[str, Any]):\n        self.storage_manager = storage_manager\n        self.cdn_configs = cdn_configs\n\n    async def upload_with_cdn_optimization(\n        self,\n        file_data: bytes,\n        path: str,\n        content_type: str,\n        cache_control: str = \"public, max-age=31536000\"  # 1 year\n    ) -&gt; Dict[str, str]:\n        \"\"\"Upload file optimized for CDN delivery\"\"\"\n\n        # Set CDN-optimized metadata\n        metadata = {\n            \"cache-control\": cache_control,\n            \"cdn-optimized\": \"true\"\n        }\n\n        # Upload to storage\n        upload_result = await self.storage_manager.upload_file(\n            file_data=file_data,\n            path=path,\n            content_type=content_type,\n            metadata=metadata\n        )\n\n        # Invalidate CDN cache if needed\n        if \"cloudfront\" in self.cdn_configs:\n            await self._invalidate_cloudfront(path)\n\n        return upload_result\n\n    async def _invalidate_cloudfront(self, path: str):\n        \"\"\"Invalidate CloudFront cache for updated content\"\"\"\n        import boto3\n\n        if \"distribution_id\" not in self.cdn_configs[\"cloudfront\"]:\n            return\n\n        cloudfront = boto3.client('cloudfront')\n\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(\n            None,\n            lambda: cloudfront.create_invalidation(\n                DistributionId=self.cdn_configs[\"cloudfront\"][\"distribution_id\"],\n                InvalidationBatch={\n                    'Paths': {\n                        'Quantity': 1,\n                        'Items': [f\"/{path}\"]\n                    },\n                    'CallerReference': str(uuid.uuid4())\n                }\n            )\n        )\n\n    async def get_optimized_urls(self, path: str) -&gt; Dict[str, str]:\n        \"\"\"Get URLs optimized for different use cases\"\"\"\n        urls = {}\n\n        # Original URL\n        primary_url = await self.storage_manager.primary_storage.generate_presigned_url(path)\n        urls[\"original\"] = primary_url\n\n        # CDN URLs for different optimizations\n        base_cdn_url = self.cdn_configs.get(\"base_url\", \"\")\n\n        if base_cdn_url:\n            urls[\"cdn\"] = f\"{base_cdn_url}/{path}\"\n            urls[\"cdn_compressed\"] = f\"{base_cdn_url}/{path}?format=auto&amp;quality=80\"\n            urls[\"cdn_webp\"] = f\"{base_cdn_url}/{path}?format=webp\"\n            urls[\"cdn_thumbnail\"] = f\"{base_cdn_url}/{path}?w=300&amp;h=300&amp;fit=cover\"\n\n        return urls\n</code></pre>"},{"location":"atomic/file-storage/cloud-integration/#storage-analytics-and-monitoring","title":"Storage Analytics and Monitoring","text":"<pre><code>class StorageAnalytics:\n    \"\"\"Analytics and monitoring for cloud storage usage\"\"\"\n\n    def __init__(self, storage_manager: MultiCloudStorageManager):\n        self.storage_manager = storage_manager\n        self.metrics = {}\n\n    async def collect_storage_metrics(self) -&gt; Dict[str, Any]:\n        \"\"\"Collect storage metrics from all providers\"\"\"\n        metrics = {\n            \"timestamp\": datetime.utcnow(),\n            \"storages\": {}\n        }\n\n        storage_names = [\"primary\"] + [f\"backup_{i}\" for i in range(len(self.storage_manager.backup_storages))]\n\n        for storage, name in zip(self.storage_manager.all_storages, storage_names):\n            try:\n                # Get storage-specific metrics\n                storage_metrics = await self._collect_storage_specific_metrics(storage)\n                metrics[\"storages\"][name] = storage_metrics\n            except Exception as e:\n                metrics[\"storages\"][name] = {\"error\": str(e)}\n\n        return metrics\n\n    async def _collect_storage_specific_metrics(self, storage: CloudStorageInterface) -&gt; Dict[str, Any]:\n        \"\"\"Collect metrics from a specific storage provider\"\"\"\n        # List recent files to estimate usage\n        recent_files = await storage.list_files(limit=1000)\n\n        total_size = sum(f.size for f in recent_files)\n        file_count = len(recent_files)\n\n        # Calculate storage classes distribution\n        storage_classes = {}\n        for file in recent_files:\n            sc = file.storage_class or \"STANDARD\"\n            storage_classes[sc] = storage_classes.get(sc, 0) + 1\n\n        return {\n            \"file_count\": file_count,\n            \"total_size_bytes\": total_size,\n            \"total_size_gb\": round(total_size / (1024**3), 2),\n            \"storage_classes\": storage_classes,\n            \"average_file_size\": total_size // max(file_count, 1),\n            \"collection_time\": datetime.utcnow()\n        }\n\n    async def generate_cost_estimate(self) -&gt; Dict[str, Any]:\n        \"\"\"Generate cost estimates for storage usage\"\"\"\n        metrics = await self.collect_storage_metrics()\n\n        # Simplified cost calculation (would need real pricing data)\n        cost_estimates = {}\n\n        for storage_name, storage_metrics in metrics[\"storages\"].items():\n            if \"error\" in storage_metrics:\n                continue\n\n            size_gb = storage_metrics[\"total_size_gb\"]\n\n            # Example pricing (update with real values)\n            if \"primary\" in storage_name:\n                monthly_cost = size_gb * 0.023  # S3 Standard pricing\n            else:\n                monthly_cost = size_gb * 0.0125  # S3 IA pricing\n\n            cost_estimates[storage_name] = {\n                \"monthly_storage_cost\": round(monthly_cost, 2),\n                \"size_gb\": size_gb,\n                \"cost_per_gb\": 0.023 if \"primary\" in storage_name else 0.0125\n            }\n\n        return cost_estimates\n\n    async def check_redundancy_health(self) -&gt; Dict[str, Any]:\n        \"\"\"Check health of redundant storage setup\"\"\"\n        health_report = {\n            \"timestamp\": datetime.utcnow(),\n            \"overall_health\": \"healthy\",\n            \"issues\": [],\n            \"recommendations\": []\n        }\n\n        # Sample some files to check consistency\n        sample_files = await self.storage_manager.primary_storage.list_files(limit=10)\n\n        inconsistent_files = []\n        for file in sample_files:\n            integrity_check = await self.storage_manager.verify_file_integrity(file.path)\n            if not integrity_check[\"consistent\"]:\n                inconsistent_files.append(file.path)\n\n        if inconsistent_files:\n            health_report[\"overall_health\"] = \"degraded\"\n            health_report[\"issues\"].append(f\"Inconsistent files: {len(inconsistent_files)}\")\n            health_report[\"recommendations\"].append(\"Run sync_between_storages for inconsistent files\")\n\n        # Check backup storage availability\n        for i, storage in enumerate(self.storage_manager.backup_storages):\n            try:\n                await storage.list_files(limit=1)\n            except Exception as e:\n                health_report[\"overall_health\"] = \"critical\"\n                health_report[\"issues\"].append(f\"Backup storage {i} unavailable: {e}\")\n\n        return health_report\n</code></pre>"},{"location":"atomic/file-storage/cloud-integration/#testing-cloud-storage","title":"Testing Cloud Storage","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock, patch\n\nclass TestCloudStorage:\n\n    @pytest.fixture\n    def s3_config(self):\n        return StorageConfig(\n            provider=StorageProvider.AWS_S3,\n            bucket_name=\"test-bucket\",\n            region=\"us-east-1\",\n            access_key=\"test-key\",\n            secret_key=\"test-secret\"\n        )\n\n    @pytest.fixture\n    async def s3_storage(self, s3_config):\n        with patch('boto3.Session'):\n            storage = AWSS3Storage(s3_config)\n            return storage\n\n    async def test_file_upload_success(self, s3_storage):\n        file_data = b\"test file content\"\n        path = \"test/file.txt\"\n\n        # Mock the S3 client\n        mock_client = AsyncMock()\n        s3_storage._client = mock_client\n\n        url = await s3_storage.upload_file(file_data, path, content_type=\"text/plain\")\n\n        assert url.startswith(\"https://\")\n        assert path in url\n        mock_client.put_object.assert_called_once()\n\n    async def test_multi_cloud_upload_with_replication(self):\n        # Mock storage configurations\n        primary_config = StorageConfig(\n            provider=StorageProvider.AWS_S3,\n            bucket_name=\"primary\",\n            access_key=\"key1\",\n            secret_key=\"secret1\"\n        )\n\n        backup_config = StorageConfig(\n            provider=StorageProvider.GOOGLE_CLOUD,\n            bucket_name=\"backup\",\n            access_key=\"key2\",\n            secret_key=\"secret2\"\n        )\n\n        with patch.multiple(\n            'your_module',\n            AWSS3Storage=AsyncMock(),\n            GoogleCloudStorage=AsyncMock()\n        ):\n            manager = MultiCloudStorageManager(primary_config, [backup_config])\n\n            # Mock successful uploads\n            manager.primary_storage.upload_file.return_value = \"https://primary.com/file.txt\"\n            manager.backup_storages[0].upload_file.return_value = \"https://backup.com/file.txt\"\n\n            result = await manager.upload_file(b\"test data\", \"test.txt\", replicate=True)\n\n            assert \"primary\" in result[\"urls\"]\n            assert \"backup_0\" in result[\"urls\"]\n            assert result[\"replicated\"] == 1\n\n    async def test_failover_download(self):\n        \"\"\"Test download failover when primary storage fails\"\"\"\n        with patch.multiple(\n            'your_module',\n            AWSS3Storage=AsyncMock(),\n            GoogleCloudStorage=AsyncMock()\n        ):\n            manager = MultiCloudStorageManager(\n                StorageConfig(StorageProvider.AWS_S3, \"primary\"),\n                [StorageConfig(StorageProvider.GOOGLE_CLOUD, \"backup\")]\n            )\n\n            # Primary fails, backup succeeds\n            manager.primary_storage.download_file.side_effect = Exception(\"Primary down\")\n            manager.backup_storages[0].download_file.return_value = b\"file content\"\n\n            data = await manager.download_file(\"test.txt\")\n\n            assert data == b\"file content\"\n            manager.primary_storage.download_file.assert_called_once()\n            manager.backup_storages[0].download_file.assert_called_once()\n\n    async def test_storage_integrity_check(self):\n        \"\"\"Test file integrity verification across storages\"\"\"\n        with patch.multiple(\n            'your_module',\n            AWSS3Storage=AsyncMock(),\n            GoogleCloudStorage=AsyncMock()\n        ):\n            manager = MultiCloudStorageManager(\n                StorageConfig(StorageProvider.AWS_S3, \"primary\"),\n                [StorageConfig(StorageProvider.GOOGLE_CLOUD, \"backup\")]\n            )\n\n            # Mock consistent metadata\n            consistent_metadata = FileMetadata(\n                path=\"test.txt\",\n                size=1000,\n                etag=\"abc123\",\n                content_type=\"text/plain\",\n                last_modified=datetime.utcnow()\n            )\n\n            manager.primary_storage.get_file_metadata.return_value = consistent_metadata\n            manager.backup_storages[0].get_file_metadata.return_value = consistent_metadata\n\n            result = await manager.verify_file_integrity(\"test.txt\")\n\n            assert result[\"consistent\"] is True\n            assert result[\"total_copies\"] == 2\n\n    def test_cdn_url_generation(self):\n        \"\"\"Test CDN URL generation for different optimizations\"\"\"\n        cdn_manager = CDNManager(\n            storage_manager=None,\n            cdn_configs={\"base_url\": \"https://cdn.example.com\"}\n        )\n\n        urls = cdn_manager.get_optimized_urls(\"images/photo.jpg\")\n\n        assert \"cdn\" in urls\n        assert \"cdn_compressed\" in urls\n        assert \"cdn_webp\" in urls\n        assert \"format=webp\" in urls[\"cdn_webp\"]\n</code></pre>"},{"location":"atomic/file-storage/cloud-integration/#related-documentation","title":"Related Documentation","text":"<ul> <li>File Upload Patterns - File upload and validation</li> <li>Media Processing Patterns - Media processing workflows</li> <li>Backup Strategies - Backup and disaster recovery</li> <li>External Integrations - Third-party service integrations</li> </ul>"},{"location":"atomic/file-storage/cloud-integration/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Multi-Cloud Strategy: Use multiple providers for redundancy and cost optimization</li> <li>Async Operations: All storage operations should be asynchronous</li> <li>Error Handling: Robust error handling with fallback strategies</li> <li>Cost Optimization: Monitor usage and optimize storage classes</li> <li>Security: Use encryption at rest and in transit</li> <li>Monitoring: Track metrics and set up alerts for issues</li> <li>CDN Integration: Leverage CDNs for global content delivery</li> <li>Testing: Comprehensive testing with mocked cloud services</li> </ol>"},{"location":"atomic/file-storage/cloud-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/file-storage/backup-strategies.md</code> \u2014 Backup to cloud</li> <li><code>docs/atomic/file-storage/cdn-integration.md</code> \u2014 CDN distribution</li> <li><code>docs/atomic/file-storage/upload-patterns.md</code> \u2014 Cloud upload patterns</li> <li><code>docs/atomic/infrastructure/secrets-management.md</code> \u2014 Cloud credentials</li> </ul>"},{"location":"atomic/file-storage/media-processing/","title":"Media Processing Workflows","text":"<p>Comprehensive guide for processing images, videos, and audio files with thumbnails, format conversion, optimization, and real-time processing pipelines.</p>"},{"location":"atomic/file-storage/media-processing/#core-media-processing-service","title":"Core Media Processing Service","text":"<pre><code>from typing import Dict, List, Optional, Any, Union, Tuple\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport asyncio\nimport json\nimport subprocess\nimport tempfile\nimport aiofiles\nfrom pathlib import Path\nfrom datetime import datetime\nimport uuid\n\nclass MediaType(Enum):\n    IMAGE = \"image\"\n    VIDEO = \"video\"\n    AUDIO = \"audio\"\n\nclass ProcessingStatus(Enum):\n    PENDING = \"pending\"\n    PROCESSING = \"processing\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n@dataclass\nclass ProcessingJob:\n    id: str\n    media_type: MediaType\n    input_path: str\n    output_specs: List[Dict[str, Any]]\n    status: ProcessingStatus = ProcessingStatus.PENDING\n    progress: float = 0.0\n    error_message: Optional[str] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    completed_at: Optional[datetime] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n@dataclass\nclass OutputSpec:\n    \"\"\"Specification for media output format\"\"\"\n    format: str\n    quality: Optional[int] = None\n    width: Optional[int] = None\n    height: Optional[int] = None\n    maintain_aspect_ratio: bool = True\n    filename_suffix: str = \"\"\n\nclass MediaProcessor:\n    \"\"\"Core media processing service with FFmpeg integration\"\"\"\n\n    def __init__(self, storage_backend, temp_dir: str = \"/tmp\", max_concurrent_jobs: int = 5):\n        self.storage_backend = storage_backend\n        self.temp_dir = Path(temp_dir)\n        self.semaphore = asyncio.Semaphore(max_concurrent_jobs)\n        self.active_jobs: Dict[str, ProcessingJob] = {}\n\n    async def process_media(\n        self,\n        input_path: str,\n        output_specs: List[OutputSpec],\n        media_type: MediaType,\n        callback_url: Optional[str] = None\n    ) -&gt; ProcessingJob:\n        \"\"\"Queue media for processing\"\"\"\n\n        job = ProcessingJob(\n            id=str(uuid.uuid4()),\n            media_type=media_type,\n            input_path=input_path,\n            output_specs=[self._spec_to_dict(spec) for spec in output_specs]\n        )\n\n        self.active_jobs[job.id] = job\n\n        # Start processing asynchronously\n        asyncio.create_task(self._process_job(job, callback_url))\n\n        return job\n\n    def _spec_to_dict(self, spec: OutputSpec) -&gt; Dict[str, Any]:\n        return {\n            \"format\": spec.format,\n            \"quality\": spec.quality,\n            \"width\": spec.width,\n            \"height\": spec.height,\n            \"maintain_aspect_ratio\": spec.maintain_aspect_ratio,\n            \"filename_suffix\": spec.filename_suffix\n        }\n\n    async def _process_job(self, job: ProcessingJob, callback_url: Optional[str]):\n        \"\"\"Process media job with error handling\"\"\"\n        async with self.semaphore:\n            try:\n                job.status = ProcessingStatus.PROCESSING\n                await self._update_job_progress(job, 0.1)\n\n                # Download input file\n                input_data = await self.storage_backend.retrieve_file(job.input_path)\n                temp_input = self.temp_dir / f\"{job.id}_input\"\n\n                async with aiofiles.open(temp_input, \"wb\") as f:\n                    await f.write(input_data)\n\n                # Process based on media type\n                if job.media_type == MediaType.IMAGE:\n                    outputs = await self._process_image(temp_input, job.output_specs, job)\n                elif job.media_type == MediaType.VIDEO:\n                    outputs = await self._process_video(temp_input, job.output_specs, job)\n                elif job.media_type == MediaType.AUDIO:\n                    outputs = await self._process_audio(temp_input, job.output_specs, job)\n\n                # Upload outputs\n                job.metadata[\"outputs\"] = []\n                for output_path, spec in outputs:\n                    async with aiofiles.open(output_path, \"rb\") as f:\n                        output_data = await f.read()\n\n                    storage_path = self._generate_output_path(job.input_path, spec[\"filename_suffix\"])\n                    public_url = await self.storage_backend.store_file(output_data, storage_path)\n\n                    job.metadata[\"outputs\"].append({\n                        \"spec\": spec,\n                        \"path\": storage_path,\n                        \"url\": public_url,\n                        \"size\": len(output_data)\n                    })\n\n                    # Cleanup temp file\n                    output_path.unlink()\n\n                job.status = ProcessingStatus.COMPLETED\n                job.completed_at = datetime.utcnow()\n                await self._update_job_progress(job, 1.0)\n\n                # Cleanup input temp file\n                temp_input.unlink()\n\n                # Send callback if provided\n                if callback_url:\n                    await self._send_callback(callback_url, job)\n\n            except Exception as e:\n                job.status = ProcessingStatus.FAILED\n                job.error_message = str(e)\n                job.completed_at = datetime.utcnow()\n\n                # Cleanup temp files\n                try:\n                    temp_input.unlink()\n                except:\n                    pass\n\n    async def _process_image(self, input_path: Path, output_specs: List[Dict], job: ProcessingJob) -&gt; List[Tuple[Path, Dict]]:\n        \"\"\"Process image using Pillow\"\"\"\n        from PIL import Image, ImageFilter, ImageEnhance\n        import io\n\n        outputs = []\n\n        # Load image\n        with Image.open(input_path) as img:\n            # Extract metadata\n            job.metadata[\"original\"] = {\n                \"width\": img.width,\n                \"height\": img.height,\n                \"format\": img.format,\n                \"mode\": img.mode\n            }\n\n            for i, spec in enumerate(output_specs):\n                await self._update_job_progress(job, 0.2 + (i * 0.6 / len(output_specs)))\n\n                processed_img = img.copy()\n\n                # Resize if specified\n                if spec.get(\"width\") or spec.get(\"height\"):\n                    new_size = self._calculate_resize(\n                        img.width, img.height,\n                        spec.get(\"width\"), spec.get(\"height\"),\n                        spec.get(\"maintain_aspect_ratio\", True)\n                    )\n                    processed_img = processed_img.resize(new_size, Image.Resampling.LANCZOS)\n\n                # Apply format-specific optimizations\n                if spec[\"format\"].lower() in [\"jpeg\", \"jpg\"]:\n                    # JPEG optimization\n                    processed_img = processed_img.convert(\"RGB\")\n                    if spec.get(\"quality\"):\n                        save_kwargs = {\"quality\": spec[\"quality\"], \"optimize\": True}\n                    else:\n                        save_kwargs = {\"quality\": 85, \"optimize\": True}\n                elif spec[\"format\"].lower() == \"png\":\n                    # PNG optimization\n                    save_kwargs = {\"optimize\": True}\n                elif spec[\"format\"].lower() == \"webp\":\n                    # WebP optimization\n                    save_kwargs = {\"quality\": spec.get(\"quality\", 80), \"method\": 6}\n                else:\n                    save_kwargs = {}\n\n                # Save processed image\n                output_path = self.temp_dir / f\"{job.id}_output_{i}.{spec['format'].lower()}\"\n                processed_img.save(output_path, format=spec[\"format\"], **save_kwargs)\n\n                outputs.append((output_path, spec))\n\n        return outputs\n\n    async def _process_video(self, input_path: Path, output_specs: List[Dict], job: ProcessingJob) -&gt; List[Tuple[Path, Dict]]:\n        \"\"\"Process video using FFmpeg\"\"\"\n        outputs = []\n\n        # Extract video metadata first\n        metadata_cmd = [\n            \"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", \"-show_streams\",\n            str(input_path)\n        ]\n\n        result = await self._run_command(metadata_cmd)\n        metadata = json.loads(result.stdout)\n\n        video_stream = next((s for s in metadata[\"streams\"] if s[\"codec_type\"] == \"video\"), None)\n        if video_stream:\n            job.metadata[\"original\"] = {\n                \"width\": int(video_stream.get(\"width\", 0)),\n                \"height\": int(video_stream.get(\"height\", 0)),\n                \"duration\": float(metadata[\"format\"].get(\"duration\", 0)),\n                \"codec\": video_stream.get(\"codec_name\"),\n                \"fps\": eval(video_stream.get(\"r_frame_rate\", \"0/1\"))\n            }\n\n        for i, spec in enumerate(output_specs):\n            await self._update_job_progress(job, 0.2 + (i * 0.6 / len(output_specs)))\n\n            output_path = self.temp_dir / f\"{job.id}_output_{i}.{spec['format'].lower()}\"\n\n            # Build FFmpeg command\n            cmd = [\"ffmpeg\", \"-i\", str(input_path)]\n\n            # Video codec and quality settings\n            if spec[\"format\"].lower() == \"mp4\":\n                cmd.extend([\"-c:v\", \"libx264\", \"-preset\", \"medium\"])\n                if spec.get(\"quality\"):\n                    cmd.extend([\"-crf\", str(spec[\"quality\"])])\n                else:\n                    cmd.extend([\"-crf\", \"23\"])  # Default quality\n            elif spec[\"format\"].lower() == \"webm\":\n                cmd.extend([\"-c:v\", \"libvpx-vp9\", \"-crf\", str(spec.get(\"quality\", 30))])\n\n            # Resize if specified\n            if spec.get(\"width\") or spec.get(\"height\"):\n                if spec.get(\"maintain_aspect_ratio\", True):\n                    scale_filter = f\"scale={spec.get('width', -1)}:{spec.get('height', -1)}\"\n                else:\n                    scale_filter = f\"scale={spec.get('width')}:{spec.get('height')}\"\n                cmd.extend([\"-vf\", scale_filter])\n\n            # Audio codec\n            cmd.extend([\"-c:a\", \"aac\", \"-b:a\", \"128k\"])\n\n            # Output file\n            cmd.extend([\"-y\", str(output_path)])\n\n            # Execute FFmpeg\n            await self._run_command_with_progress(cmd, job, metadata[\"format\"].get(\"duration\"))\n\n            outputs.append((output_path, spec))\n\n        return outputs\n\n    async def _process_audio(self, input_path: Path, output_specs: List[Dict], job: ProcessingJob) -&gt; List[Tuple[Path, Dict]]:\n        \"\"\"Process audio using FFmpeg\"\"\"\n        outputs = []\n\n        # Extract audio metadata\n        metadata_cmd = [\n            \"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", \"-show_streams\",\n            str(input_path)\n        ]\n\n        result = await self._run_command(metadata_cmd)\n        metadata = json.loads(result.stdout)\n\n        audio_stream = next((s for s in metadata[\"streams\"] if s[\"codec_type\"] == \"audio\"), None)\n        if audio_stream:\n            job.metadata[\"original\"] = {\n                \"duration\": float(metadata[\"format\"].get(\"duration\", 0)),\n                \"codec\": audio_stream.get(\"codec_name\"),\n                \"sample_rate\": int(audio_stream.get(\"sample_rate\", 0)),\n                \"channels\": int(audio_stream.get(\"channels\", 0))\n            }\n\n        for i, spec in enumerate(output_specs):\n            await self._update_job_progress(job, 0.2 + (i * 0.6 / len(output_specs)))\n\n            output_path = self.temp_dir / f\"{job.id}_output_{i}.{spec['format'].lower()}\"\n\n            # Build FFmpeg command\n            cmd = [\"ffmpeg\", \"-i\", str(input_path)]\n\n            # Audio codec and quality settings\n            if spec[\"format\"].lower() == \"mp3\":\n                cmd.extend([\"-c:a\", \"libmp3lame\"])\n                if spec.get(\"quality\"):\n                    cmd.extend([\"-q:a\", str(spec[\"quality\"])])  # VBR quality 0-9\n                else:\n                    cmd.extend([\"-b:a\", \"192k\"])  # Default bitrate\n            elif spec[\"format\"].lower() == \"aac\":\n                cmd.extend([\"-c:a\", \"aac\", \"-b:a\", f\"{spec.get('quality', 128)}k\"])\n            elif spec[\"format\"].lower() == \"ogg\":\n                cmd.extend([\"-c:a\", \"libvorbis\", \"-q:a\", str(spec.get(\"quality\", 5))])\n\n            # Output file\n            cmd.extend([\"-y\", str(output_path)])\n\n            # Execute FFmpeg\n            await self._run_command_with_progress(cmd, job, metadata[\"format\"].get(\"duration\"))\n\n            outputs.append((output_path, spec))\n\n        return outputs\n\n    async def _run_command(self, cmd: List[str]) -&gt; subprocess.CompletedProcess:\n        \"\"\"Run subprocess command asynchronously\"\"\"\n        process = await asyncio.create_subprocess_exec(\n            *cmd,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE\n        )\n\n        stdout, stderr = await process.communicate()\n\n        if process.returncode != 0:\n            raise RuntimeError(f\"Command failed: {stderr.decode()}\")\n\n        return subprocess.CompletedProcess(cmd, process.returncode, stdout, stderr)\n\n    async def _run_command_with_progress(self, cmd: List[str], job: ProcessingJob, duration: Optional[float]):\n        \"\"\"Run FFmpeg command with progress tracking\"\"\"\n        process = await asyncio.create_subprocess_exec(\n            *cmd,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE\n        )\n\n        # Monitor progress if duration is available\n        if duration:\n            asyncio.create_task(self._monitor_ffmpeg_progress(process, job, duration))\n\n        stdout, stderr = await process.communicate()\n\n        if process.returncode != 0:\n            raise RuntimeError(f\"FFmpeg failed: {stderr.decode()}\")\n\n    async def _monitor_ffmpeg_progress(self, process, job: ProcessingJob, total_duration: float):\n        \"\"\"Monitor FFmpeg progress through stderr output\"\"\"\n        import re\n\n        time_pattern = re.compile(r\"time=(\\d+):(\\d+):(\\d+\\.\\d+)\")\n\n        while process.returncode is None:\n            try:\n                line = await asyncio.wait_for(process.stderr.readline(), timeout=1.0)\n                if not line:\n                    break\n\n                line_str = line.decode()\n                match = time_pattern.search(line_str)\n                if match:\n                    hours, minutes, seconds = match.groups()\n                    current_time = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n                    progress = min(current_time / total_duration, 0.95)  # Cap at 95% until complete\n                    await self._update_job_progress(job, 0.2 + progress * 0.6)\n\n            except asyncio.TimeoutError:\n                continue\n\n    def _calculate_resize(self, orig_width: int, orig_height: int, new_width: Optional[int],\n                         new_height: Optional[int], maintain_aspect: bool) -&gt; Tuple[int, int]:\n        \"\"\"Calculate new dimensions for resizing\"\"\"\n        if not maintain_aspect:\n            return (new_width or orig_width, new_height or orig_height)\n\n        aspect_ratio = orig_width / orig_height\n\n        if new_width and new_height:\n            # Fit within bounds\n            if new_width / new_height &gt; aspect_ratio:\n                return (int(new_height * aspect_ratio), new_height)\n            else:\n                return (new_width, int(new_width / aspect_ratio))\n        elif new_width:\n            return (new_width, int(new_width / aspect_ratio))\n        elif new_height:\n            return (int(new_height * aspect_ratio), new_height)\n        else:\n            return (orig_width, orig_height)\n\n    def _generate_output_path(self, input_path: str, suffix: str) -&gt; str:\n        \"\"\"Generate output storage path\"\"\"\n        path_obj = Path(input_path)\n        stem = path_obj.stem\n        parent = path_obj.parent\n        return str(parent / f\"{stem}{suffix}\")\n\n    async def _update_job_progress(self, job: ProcessingJob, progress: float):\n        \"\"\"Update job progress and notify if needed\"\"\"\n        job.progress = progress\n        # Here you could emit websocket updates or save to database\n        print(f\"Job {job.id}: {progress:.1%} complete\")\n\n    async def _send_callback(self, url: str, job: ProcessingJob):\n        \"\"\"Send job completion callback\"\"\"\n        import aiohttp\n\n        payload = {\n            \"job_id\": job.id,\n            \"status\": job.status.value,\n            \"outputs\": job.metadata.get(\"outputs\", []),\n            \"completed_at\": job.completed_at.isoformat() if job.completed_at else None\n        }\n\n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.post(url, json=payload) as response:\n                    if response.status &gt;= 400:\n                        print(f\"Callback failed: {response.status}\")\n            except Exception as e:\n                print(f\"Callback error: {e}\")\n\n    def get_job_status(self, job_id: str) -&gt; Optional[ProcessingJob]:\n        \"\"\"Get current job status\"\"\"\n        return self.active_jobs.get(job_id)\n</code></pre>"},{"location":"atomic/file-storage/media-processing/#image-processing-pipelines","title":"Image Processing Pipelines","text":"<pre><code>class ImageProcessingPipeline:\n    \"\"\"Specialized image processing with filters and effects\"\"\"\n\n    def __init__(self, media_processor: MediaProcessor):\n        self.processor = media_processor\n\n    async def create_thumbnails(self, input_path: str, user_id: str) -&gt; ProcessingJob:\n        \"\"\"Generate standard thumbnail sizes\"\"\"\n        output_specs = [\n            OutputSpec(format=\"jpeg\", width=150, height=150, filename_suffix=\"_thumb_150\"),\n            OutputSpec(format=\"jpeg\", width=300, height=300, filename_suffix=\"_thumb_300\"),\n            OutputSpec(format=\"jpeg\", width=800, height=600, filename_suffix=\"_thumb_800\"),\n            OutputSpec(format=\"webp\", width=300, height=300, filename_suffix=\"_thumb_300_webp\")\n        ]\n\n        return await self.processor.process_media(\n            input_path, output_specs, MediaType.IMAGE\n        )\n\n    async def optimize_for_web(self, input_path: str) -&gt; ProcessingJob:\n        \"\"\"Optimize images for web delivery\"\"\"\n        output_specs = [\n            OutputSpec(format=\"jpeg\", quality=85, filename_suffix=\"_optimized\"),\n            OutputSpec(format=\"webp\", quality=80, filename_suffix=\"_webp\"),\n            OutputSpec(format=\"avif\", quality=75, filename_suffix=\"_avif\")  # Modern format\n        ]\n\n        return await self.processor.process_media(\n            input_path, output_specs, MediaType.IMAGE\n        )\n\n    async def apply_filters(self, input_path: str, filters: List[str]) -&gt; ProcessingJob:\n        \"\"\"Apply Instagram-style filters\"\"\"\n        # This would extend the image processing to include PIL filters\n        # Implementation would modify _process_image to apply specific filters\n        pass\n\nclass VideoProcessingPipeline:\n    \"\"\"Specialized video processing workflows\"\"\"\n\n    def __init__(self, media_processor: MediaProcessor):\n        self.processor = media_processor\n\n    async def create_streaming_formats(self, input_path: str) -&gt; ProcessingJob:\n        \"\"\"Create multiple formats for adaptive streaming\"\"\"\n        output_specs = [\n            # Different quality levels for adaptive streaming\n            OutputSpec(format=\"mp4\", width=1920, height=1080, quality=23, filename_suffix=\"_1080p\"),\n            OutputSpec(format=\"mp4\", width=1280, height=720, quality=25, filename_suffix=\"_720p\"),\n            OutputSpec(format=\"mp4\", width=854, height=480, quality=28, filename_suffix=\"_480p\"),\n            OutputSpec(format=\"webm\", width=1280, height=720, quality=30, filename_suffix=\"_720p_webm\")\n        ]\n\n        return await self.processor.process_media(\n            input_path, output_specs, MediaType.VIDEO\n        )\n\n    async def extract_thumbnail(self, input_path: str, timestamp: float = 1.0) -&gt; ProcessingJob:\n        \"\"\"Extract video thumbnail at specific timestamp\"\"\"\n        # This would require extending FFmpeg commands to extract frames\n        pass\n\n    async def create_gif_preview(self, input_path: str, start_time: float = 0, duration: float = 3) -&gt; ProcessingJob:\n        \"\"\"Create animated GIF preview from video\"\"\"\n        # FFmpeg command to create GIF from video segment\n        pass\n</code></pre>"},{"location":"atomic/file-storage/media-processing/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, BackgroundTasks, HTTPException, Depends\nfrom fastapi.responses import StreamingResponse\nimport aiohttp\n\napp = FastAPI()\n\n# Initialize processor\nmedia_processor = MediaProcessor(storage_backend, max_concurrent_jobs=10)\nimage_pipeline = ImageProcessingPipeline(media_processor)\nvideo_pipeline = VideoProcessingPipeline(media_processor)\n\n@app.post(\"/media/process\")\nasync def process_media(\n    input_path: str,\n    media_type: str,\n    output_formats: List[Dict[str, Any]],\n    callback_url: Optional[str] = None,\n    user: User = Depends(get_current_user)\n):\n    \"\"\"Start media processing job\"\"\"\n\n    # Convert output_formats to OutputSpec objects\n    output_specs = []\n    for fmt in output_formats:\n        spec = OutputSpec(\n            format=fmt[\"format\"],\n            quality=fmt.get(\"quality\"),\n            width=fmt.get(\"width\"),\n            height=fmt.get(\"height\"),\n            filename_suffix=fmt.get(\"suffix\", \"\")\n        )\n        output_specs.append(spec)\n\n    # Validate file access\n    if not await user_can_access_file(user.id, input_path):\n        raise HTTPException(403, \"Access denied\")\n\n    job = await media_processor.process_media(\n        input_path,\n        output_specs,\n        MediaType(media_type),\n        callback_url\n    )\n\n    return {\n        \"job_id\": job.id,\n        \"status\": job.status.value,\n        \"estimated_completion\": \"2-5 minutes\"  # Based on file size and complexity\n    }\n\n@app.get(\"/media/jobs/{job_id}\")\nasync def get_job_status(job_id: str, user: User = Depends(get_current_user)):\n    \"\"\"Get processing job status\"\"\"\n\n    job = media_processor.get_job_status(job_id)\n    if not job:\n        raise HTTPException(404, \"Job not found\")\n\n    return {\n        \"job_id\": job.id,\n        \"status\": job.status.value,\n        \"progress\": job.progress,\n        \"error\": job.error_message,\n        \"outputs\": job.metadata.get(\"outputs\", []),\n        \"created_at\": job.created_at,\n        \"completed_at\": job.completed_at\n    }\n\n@app.post(\"/media/thumbnails\")\nasync def generate_thumbnails(\n    input_path: str,\n    user: User = Depends(get_current_user)\n):\n    \"\"\"Quick thumbnail generation endpoint\"\"\"\n\n    if not await user_can_access_file(user.id, input_path):\n        raise HTTPException(403, \"Access denied\")\n\n    job = await image_pipeline.create_thumbnails(input_path, user.id)\n\n    return {\n        \"job_id\": job.id,\n        \"message\": \"Thumbnail generation started\"\n    }\n\n@app.post(\"/media/optimize\")\nasync def optimize_for_web(\n    input_path: str,\n    user: User = Depends(get_current_user)\n):\n    \"\"\"Optimize images for web delivery\"\"\"\n\n    job = await image_pipeline.optimize_for_web(input_path)\n\n    return {\n        \"job_id\": job.id,\n        \"message\": \"Web optimization started\"\n    }\n\n@app.post(\"/video/streaming\")\nasync def create_streaming_versions(\n    input_path: str,\n    user: User = Depends(get_current_user)\n):\n    \"\"\"Create multiple video formats for streaming\"\"\"\n\n    job = await video_pipeline.create_streaming_formats(input_path)\n\n    return {\n        \"job_id\": job.id,\n        \"message\": \"Streaming format creation started\"\n    }\n\n@app.websocket(\"/media/jobs/{job_id}/progress\")\nasync def job_progress_websocket(websocket: WebSocket, job_id: str):\n    \"\"\"Real-time job progress updates\"\"\"\n    await websocket.accept()\n\n    try:\n        while True:\n            job = media_processor.get_job_status(job_id)\n            if not job:\n                await websocket.send_json({\"error\": \"Job not found\"})\n                break\n\n            await websocket.send_json({\n                \"job_id\": job.id,\n                \"status\": job.status.value,\n                \"progress\": job.progress,\n                \"error\": job.error_message\n            })\n\n            if job.status in [ProcessingStatus.COMPLETED, ProcessingStatus.FAILED]:\n                break\n\n            await asyncio.sleep(1)\n\n    except Exception as e:\n        await websocket.send_json({\"error\": str(e)})\n    finally:\n        await websocket.close()\n</code></pre>"},{"location":"atomic/file-storage/media-processing/#real-time-processing-with-webrtc","title":"Real-time Processing with WebRTC","text":"<pre><code>import aiortc\nfrom aiortc import VideoStreamTrack, RTCPeerConnection\n\nclass MediaProcessingTrack(VideoStreamTrack):\n    \"\"\"Real-time video processing track for WebRTC\"\"\"\n\n    def __init__(self, track, processor_func):\n        super().__init__()\n        self.track = track\n        self.processor_func = processor_func\n\n    async def recv(self):\n        frame = await self.track.recv()\n\n        # Apply real-time processing\n        processed_frame = await self.processor_func(frame)\n\n        return processed_frame\n\nasync def apply_real_time_filter(frame):\n    \"\"\"Apply real-time filters to video frame\"\"\"\n    # Convert aiortc frame to PIL Image\n    import cv2\n    import numpy as np\n\n    # Convert frame to numpy array\n    img = frame.to_ndarray(format=\"bgr24\")\n\n    # Apply OpenCV filters\n    img = cv2.GaussianBlur(img, (15, 15), 0)  # Blur filter\n    # img = cv2.Canny(img, 100, 200)  # Edge detection\n\n    # Convert back to aiortc frame\n    new_frame = aiortc.VideoFrame.from_ndarray(img, format=\"bgr24\")\n    new_frame.pts = frame.pts\n    new_frame.time_base = frame.time_base\n\n    return new_frame\n\n@app.websocket(\"/rtc/connect\")\nasync def webrtc_endpoint(websocket: WebSocket):\n    \"\"\"WebRTC endpoint for real-time media processing\"\"\"\n    await websocket.accept()\n\n    pc = RTCPeerConnection()\n\n    @pc.on(\"track\")\n    def on_track(track):\n        if track.kind == \"video\":\n            # Add processed track\n            processed_track = MediaProcessingTrack(track, apply_real_time_filter)\n            pc.addTrack(processed_track)\n\n    # Handle WebRTC signaling\n    async for message in websocket.iter_json():\n        if message[\"type\"] == \"offer\":\n            offer = RTCSessionDescription(sdp=message[\"sdp\"], type=message[\"type\"])\n            await pc.setRemoteDescription(offer)\n\n            answer = await pc.createAnswer()\n            await pc.setLocalDescription(answer)\n\n            await websocket.send_json({\n                \"type\": answer.type,\n                \"sdp\": answer.sdp\n            })\n</code></pre>"},{"location":"atomic/file-storage/media-processing/#testing-media-processing","title":"Testing Media Processing","text":"<pre><code>import pytest\nimport tempfile\nfrom PIL import Image\nimport subprocess\n\nclass TestMediaProcessing:\n\n    @pytest.fixture\n    async def media_processor(self):\n        from unittest.mock import AsyncMock\n        storage_backend = AsyncMock()\n        return MediaProcessor(storage_backend, max_concurrent_jobs=2)\n\n    async def test_image_thumbnail_generation(self, media_processor):\n        # Create test image\n        img = Image.new('RGB', (1000, 800), color='red')\n        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as f:\n            img.save(f.name, 'JPEG')\n            input_path = f.name\n\n        output_specs = [\n            OutputSpec(format=\"jpeg\", width=300, height=300, filename_suffix=\"_thumb\")\n        ]\n\n        # Mock storage backend\n        media_processor.storage_backend.retrieve_file.return_value = open(input_path, 'rb').read()\n        media_processor.storage_backend.store_file.return_value = \"http://example.com/thumb.jpg\"\n\n        job = await media_processor.process_media(\n            input_path, output_specs, MediaType.IMAGE\n        )\n\n        # Wait for processing\n        while job.status == ProcessingStatus.PROCESSING:\n            await asyncio.sleep(0.1)\n\n        assert job.status == ProcessingStatus.COMPLETED\n        assert len(job.metadata[\"outputs\"]) == 1\n\n    async def test_video_format_conversion(self, media_processor):\n        # This test would require a sample video file\n        # In practice, you'd use a small test video\n        pass\n\n    def test_image_optimization_quality(self):\n        \"\"\"Test image quality optimization\"\"\"\n        # Create test image\n        img = Image.new('RGB', (1000, 1000), color='blue')\n        original_buffer = io.BytesIO()\n        img.save(original_buffer, format='JPEG', quality=100)\n        original_size = original_buffer.tell()\n\n        # Optimize\n        optimized_buffer = io.BytesIO()\n        img.save(optimized_buffer, format='JPEG', quality=85, optimize=True)\n        optimized_size = optimized_buffer.tell()\n\n        # Should be smaller\n        assert optimized_size &lt; original_size\n        assert optimized_size / original_size &lt; 0.8  # At least 20% reduction\n\n    def test_video_metadata_extraction(self):\n        \"\"\"Test FFmpeg metadata extraction\"\"\"\n        # This would test the actual FFmpeg integration\n        # Requires sample video file for testing\n        pass\n</code></pre>"},{"location":"atomic/file-storage/media-processing/#related-documentation","title":"Related Documentation","text":"<ul> <li>File Upload Patterns - File upload and validation</li> <li>Cloud Storage Integration - Storage backends</li> <li>Backup Strategies - Media backup and archival</li> <li>External Integrations - Third-party media services</li> </ul>"},{"location":"atomic/file-storage/media-processing/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Async Processing: Always process media asynchronously to avoid blocking</li> <li>Progress Tracking: Provide real-time progress updates for long operations</li> <li>Format Support: Support modern formats (WebP, AVIF) for better compression</li> <li>Quality Control: Balance file size and quality based on use case</li> <li>Resource Management: Limit concurrent jobs to prevent resource exhaustion</li> <li>Error Handling: Robust error handling with detailed error messages</li> <li>Security: Validate input files and sanitize metadata</li> <li>Monitoring: Track processing times and resource usage for optimization</li> </ol>"},{"location":"atomic/file-storage/media-processing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/file-storage/upload-patterns.md</code> \u2014 File upload handling</li> <li><code>docs/atomic/file-storage/cdn-integration.md</code> \u2014 CDN distribution</li> <li><code>docs/atomic/services/asyncio/task-scheduling.md</code> \u2014 Background processing</li> <li><code>docs/atomic/rabbitmq/message-publishing.md</code> \u2014 Processing queues</li> </ul>"},{"location":"atomic/file-storage/upload-patterns/","title":"File Upload Patterns","text":"<p>Comprehensive guide for handling file uploads in microservices with validation, processing, security, and multi-storage backend support.</p>"},{"location":"atomic/file-storage/upload-patterns/#core-upload-service","title":"Core Upload Service","text":"<pre><code>from typing import Optional, Dict, List, Any, Union\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport hashlib\nimport mimetypes\nimport asyncio\nimport aiofiles\nimport magic\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport uuid\n\nclass FileType(Enum):\n    IMAGE = \"image\"\n    DOCUMENT = \"document\"\n    VIDEO = \"video\"\n    AUDIO = \"audio\"\n    ARCHIVE = \"archive\"\n    TEXT = \"text\"\n\n@dataclass\nclass FileUploadConfig:\n    max_file_size: int = 10 * 1024 * 1024  # 10MB\n    allowed_mime_types: List[str] = field(default_factory=list)\n    allowed_extensions: List[str] = field(default_factory=list)\n    require_authentication: bool = True\n    virus_scan_enabled: bool = True\n    process_async: bool = True\n    generate_thumbnails: bool = False\n    storage_backend: str = \"local\"  # local, s3, gcs, azure\n\n@dataclass\nclass UploadedFile:\n    id: str\n    original_filename: str\n    content_type: str\n    size: int\n    file_hash: str\n    upload_path: str\n    public_url: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    processed: bool = False\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\nclass FileValidator:\n    \"\"\"Validates uploaded files for security and compliance\"\"\"\n\n    def __init__(self, config: FileUploadConfig):\n        self.config = config\n\n    async def validate_file(self, file_data: bytes, filename: str, content_type: str) -&gt; Dict[str, Any]:\n        \"\"\"Comprehensive file validation\"\"\"\n        errors = []\n        warnings = []\n\n        # Size validation\n        if len(file_data) &gt; self.config.max_file_size:\n            errors.append(f\"File size {len(file_data)} exceeds maximum {self.config.max_file_size}\")\n\n        # Extension validation\n        if self.config.allowed_extensions:\n            ext = Path(filename).suffix.lower()\n            if ext not in self.config.allowed_extensions:\n                errors.append(f\"Extension {ext} not allowed\")\n\n        # MIME type validation\n        detected_mime = magic.from_buffer(file_data, mime=True)\n        if content_type != detected_mime:\n            warnings.append(f\"Declared MIME {content_type} differs from detected {detected_mime}\")\n\n        if self.config.allowed_mime_types and detected_mime not in self.config.allowed_mime_types:\n            errors.append(f\"MIME type {detected_mime} not allowed\")\n\n        # Malware scanning (placeholder for real implementation)\n        if self.config.virus_scan_enabled:\n            is_safe = await self._scan_for_malware(file_data)\n            if not is_safe:\n                errors.append(\"File failed malware scan\")\n\n        # Content-specific validation\n        content_errors = await self._validate_content(file_data, detected_mime)\n        errors.extend(content_errors)\n\n        return {\n            \"valid\": len(errors) == 0,\n            \"errors\": errors,\n            \"warnings\": warnings,\n            \"detected_mime\": detected_mime,\n            \"file_size\": len(file_data)\n        }\n\n    async def _scan_for_malware(self, file_data: bytes) -&gt; bool:\n        \"\"\"Integrate with ClamAV or similar antivirus\"\"\"\n        # Placeholder for actual malware scanning\n        # In production, integrate with ClamAV daemon or cloud scanning service\n        suspicious_patterns = [b\"&lt;script\", b\"javascript:\", b\"eval(\"]\n        return not any(pattern in file_data.lower() for pattern in suspicious_patterns)\n\n    async def _validate_content(self, file_data: bytes, mime_type: str) -&gt; List[str]:\n        \"\"\"Content-specific validation based on file type\"\"\"\n        errors = []\n\n        if mime_type.startswith(\"image/\"):\n            errors.extend(await self._validate_image(file_data))\n        elif mime_type == \"application/pdf\":\n            errors.extend(await self._validate_pdf(file_data))\n        elif mime_type.startswith(\"text/\"):\n            errors.extend(await self._validate_text(file_data))\n\n        return errors\n\n    async def _validate_image(self, file_data: bytes) -&gt; List[str]:\n        \"\"\"Validate image files\"\"\"\n        try:\n            from PIL import Image\n            import io\n\n            image = Image.open(io.BytesIO(file_data))\n\n            # Check for suspicious metadata\n            if hasattr(image, '_getexif') and image._getexif():\n                # Remove or validate EXIF data\n                pass\n\n            # Validate image dimensions\n            width, height = image.size\n            if width &gt; 10000 or height &gt; 10000:\n                return [\"Image dimensions too large\"]\n\n        except Exception as e:\n            return [f\"Invalid image file: {str(e)}\"]\n        return []\n\n    async def _validate_pdf(self, file_data: bytes) -&gt; List[str]:\n        \"\"\"Validate PDF files\"\"\"\n        # Check for PDF structure\n        if not file_data.startswith(b\"%PDF\"):\n            return [\"Invalid PDF header\"]\n\n        # Check for embedded JavaScript (security risk)\n        if b\"/JavaScript\" in file_data or b\"/JS\" in file_data:\n            return [\"PDF contains JavaScript\"]\n\n        return []\n\n    async def _validate_text(self, file_data: bytes) -&gt; List[str]:\n        \"\"\"Validate text files\"\"\"\n        try:\n            # Attempt to decode as UTF-8\n            text = file_data.decode('utf-8')\n\n            # Check for suspiciously long lines (potential attack)\n            lines = text.split('\\n')\n            if any(len(line) &gt; 10000 for line in lines):\n                return [\"Text file contains suspiciously long lines\"]\n\n        except UnicodeDecodeError:\n            return [\"Text file contains invalid UTF-8\"]\n\n        return []\n\nclass FileUploadService:\n    \"\"\"Main service for handling file uploads\"\"\"\n\n    def __init__(self, storage_backends: Dict[str, Any], default_config: FileUploadConfig):\n        self.storage_backends = storage_backends\n        self.default_config = default_config\n        self.validator = FileValidator(default_config)\n\n    async def upload_file(\n        self,\n        file_data: bytes,\n        filename: str,\n        content_type: str,\n        user_id: Optional[str] = None,\n        config: Optional[FileUploadConfig] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -&gt; UploadedFile:\n        \"\"\"Process and store uploaded file\"\"\"\n\n        config = config or self.default_config\n        metadata = metadata or {}\n\n        # Validate file\n        validation_result = await self.validator.validate_file(file_data, filename, content_type)\n        if not validation_result[\"valid\"]:\n            raise FileUploadError(f\"Validation failed: {', '.join(validation_result['errors'])}\")\n\n        # Generate unique file ID and path\n        file_id = str(uuid.uuid4())\n        file_hash = hashlib.sha256(file_data).hexdigest()\n\n        # Check for duplicate files\n        existing_file = await self._check_duplicate(file_hash)\n        if existing_file:\n            return existing_file\n\n        # Determine file type and storage path\n        file_type = self._determine_file_type(validation_result[\"detected_mime\"])\n        storage_path = self._generate_storage_path(file_id, filename, file_type, user_id)\n\n        # Store file\n        storage_backend = self.storage_backends[config.storage_backend]\n        public_url = await storage_backend.store_file(file_data, storage_path)\n\n        # Create file record\n        uploaded_file = UploadedFile(\n            id=file_id,\n            original_filename=filename,\n            content_type=validation_result[\"detected_mime\"],\n            size=len(file_data),\n            file_hash=file_hash,\n            upload_path=storage_path,\n            public_url=public_url,\n            metadata={\n                **metadata,\n                \"user_id\": user_id,\n                \"validation_warnings\": validation_result.get(\"warnings\", [])\n            }\n        )\n\n        # Save to database\n        await self._save_file_record(uploaded_file)\n\n        # Process asynchronously if configured\n        if config.process_async:\n            asyncio.create_task(self._process_file_async(uploaded_file, config))\n\n        return uploaded_file\n\n    async def _check_duplicate(self, file_hash: str) -&gt; Optional[UploadedFile]:\n        \"\"\"Check if file already exists based on hash\"\"\"\n        # Implementation would query database for existing file with same hash\n        # This enables deduplication to save storage space\n        pass\n\n    def _determine_file_type(self, mime_type: str) -&gt; FileType:\n        \"\"\"Determine file category from MIME type\"\"\"\n        if mime_type.startswith(\"image/\"):\n            return FileType.IMAGE\n        elif mime_type.startswith(\"video/\"):\n            return FileType.VIDEO\n        elif mime_type.startswith(\"audio/\"):\n            return FileType.AUDIO\n        elif mime_type in [\"application/pdf\", \"text/plain\", \"application/msword\"]:\n            return FileType.DOCUMENT\n        elif mime_type in [\"application/zip\", \"application/x-rar\", \"application/x-tar\"]:\n            return FileType.ARCHIVE\n        else:\n            return FileType.DOCUMENT\n\n    def _generate_storage_path(self, file_id: str, filename: str, file_type: FileType, user_id: Optional[str]) -&gt; str:\n        \"\"\"Generate organized storage path\"\"\"\n        date_path = datetime.utcnow().strftime(\"%Y/%m/%d\")\n        extension = Path(filename).suffix\n\n        if user_id:\n            return f\"uploads/{file_type.value}/{user_id}/{date_path}/{file_id}{extension}\"\n        else:\n            return f\"uploads/{file_type.value}/anonymous/{date_path}/{file_id}{extension}\"\n\n    async def _save_file_record(self, file_record: UploadedFile):\n        \"\"\"Save file metadata to database\"\"\"\n        # Implementation would save to your database\n        # Include fields: id, original_filename, content_type, size, file_hash,\n        # upload_path, public_url, metadata, created_at, user_id\n        pass\n\n    async def _process_file_async(self, uploaded_file: UploadedFile, config: FileUploadConfig):\n        \"\"\"Asynchronous post-upload processing\"\"\"\n        try:\n            if uploaded_file.content_type.startswith(\"image/\") and config.generate_thumbnails:\n                await self._generate_thumbnails(uploaded_file)\n\n            # Extract metadata\n            await self._extract_metadata(uploaded_file)\n\n            # Mark as processed\n            uploaded_file.processed = True\n            await self._update_file_record(uploaded_file)\n\n        except Exception as e:\n            # Log error but don't fail the upload\n            print(f\"Async processing failed for {uploaded_file.id}: {e}\")\n\n    async def _generate_thumbnails(self, uploaded_file: UploadedFile):\n        \"\"\"Generate image thumbnails\"\"\"\n        from PIL import Image\n        import io\n\n        # Download original file\n        storage_backend = self.storage_backends[self.default_config.storage_backend]\n        file_data = await storage_backend.retrieve_file(uploaded_file.upload_path)\n\n        image = Image.open(io.BytesIO(file_data))\n\n        # Generate different thumbnail sizes\n        thumbnail_sizes = [(150, 150), (300, 300), (800, 600)]\n\n        for width, height in thumbnail_sizes:\n            thumbnail = image.copy()\n            thumbnail.thumbnail((width, height), Image.Resampling.LANCZOS)\n\n            # Save thumbnail\n            thumb_buffer = io.BytesIO()\n            thumbnail.save(thumb_buffer, format=image.format)\n\n            thumb_path = uploaded_file.upload_path.replace(\n                Path(uploaded_file.upload_path).suffix,\n                f\"_thumb_{width}x{height}{Path(uploaded_file.upload_path).suffix}\"\n            )\n\n            await storage_backend.store_file(thumb_buffer.getvalue(), thumb_path)\n\n    async def _extract_metadata(self, uploaded_file: UploadedFile):\n        \"\"\"Extract and store file metadata\"\"\"\n        storage_backend = self.storage_backends[self.default_config.storage_backend]\n        file_data = await storage_backend.retrieve_file(uploaded_file.upload_path)\n\n        if uploaded_file.content_type.startswith(\"image/\"):\n            metadata = await self._extract_image_metadata(file_data)\n        elif uploaded_file.content_type.startswith(\"video/\"):\n            metadata = await self._extract_video_metadata(file_data)\n        else:\n            metadata = {}\n\n        # Update file record with metadata\n        uploaded_file.metadata.update(metadata)\n\n    async def _extract_image_metadata(self, file_data: bytes) -&gt; Dict[str, Any]:\n        \"\"\"Extract EXIF and other image metadata\"\"\"\n        from PIL import Image\n        from PIL.ExifTags import TAGS\n        import io\n\n        try:\n            image = Image.open(io.BytesIO(file_data))\n            metadata = {\n                \"width\": image.width,\n                \"height\": image.height,\n                \"format\": image.format,\n                \"mode\": image.mode\n            }\n\n            # Extract EXIF data (be careful with privacy)\n            if hasattr(image, '_getexif') and image._getexif():\n                exif = {TAGS.get(k, k): v for k, v in image._getexif().items()}\n                # Only include safe metadata, exclude GPS and personal info\n                safe_exif = {k: v for k, v in exif.items()\n                           if k not in ['GPS', 'UserComment', 'ImageDescription']}\n                metadata[\"exif\"] = safe_exif\n\n            return metadata\n        except Exception:\n            return {}\n\n    async def _extract_video_metadata(self, file_data: bytes) -&gt; Dict[str, Any]:\n        \"\"\"Extract video metadata using ffprobe\"\"\"\n        # Implementation would use ffmpeg-python or similar\n        # to extract duration, resolution, codec, etc.\n        return {}\n\nclass FileUploadError(Exception):\n    pass\n</code></pre>"},{"location":"atomic/file-storage/upload-patterns/#fastapi-upload-endpoints","title":"FastAPI Upload Endpoints","text":"<pre><code>from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Depends, BackgroundTasks\nfrom fastapi.responses import JSONResponse\nfrom fastapi.security import HTTPBearer\nfrom typing import List, Optional\nimport aiofiles\n\napp = FastAPI()\nsecurity = HTTPBearer()\n\n# Initialize upload service\nupload_service = FileUploadService(storage_backends, default_config)\n\n@app.post(\"/upload/single\")\nasync def upload_single_file(\n    file: UploadFile = File(...),\n    user_id: Optional[str] = Form(None),\n    generate_thumbnails: bool = Form(False),\n    background_tasks: BackgroundTasks = BackgroundTasks(),\n    token: str = Depends(security)\n):\n    \"\"\"Upload a single file\"\"\"\n\n    # Validate token and get user\n    user = await validate_token(token.credentials)\n    if not user and upload_service.default_config.require_authentication:\n        raise HTTPException(401, \"Authentication required\")\n\n    try:\n        # Read file data\n        file_data = await file.read()\n\n        # Configure upload\n        config = FileUploadConfig(\n            generate_thumbnails=generate_thumbnails,\n            process_async=True\n        )\n\n        # Upload file\n        uploaded_file = await upload_service.upload_file(\n            file_data=file_data,\n            filename=file.filename,\n            content_type=file.content_type,\n            user_id=user.id if user else None,\n            config=config\n        )\n\n        return {\n            \"file_id\": uploaded_file.id,\n            \"filename\": uploaded_file.original_filename,\n            \"size\": uploaded_file.size,\n            \"content_type\": uploaded_file.content_type,\n            \"public_url\": uploaded_file.public_url,\n            \"upload_path\": uploaded_file.upload_path\n        }\n\n    except FileUploadError as e:\n        raise HTTPException(400, str(e))\n    except Exception as e:\n        raise HTTPException(500, f\"Upload failed: {str(e)}\")\n\n@app.post(\"/upload/multiple\")\nasync def upload_multiple_files(\n    files: List[UploadFile] = File(...),\n    user_id: Optional[str] = Form(None),\n    token: str = Depends(security)\n):\n    \"\"\"Upload multiple files\"\"\"\n\n    user = await validate_token(token.credentials)\n    if not user and upload_service.default_config.require_authentication:\n        raise HTTPException(401, \"Authentication required\")\n\n    if len(files) &gt; 10:  # Limit batch uploads\n        raise HTTPException(400, \"Maximum 10 files per batch\")\n\n    results = []\n    errors = []\n\n    for file in files:\n        try:\n            file_data = await file.read()\n            uploaded_file = await upload_service.upload_file(\n                file_data=file_data,\n                filename=file.filename,\n                content_type=file.content_type,\n                user_id=user.id if user else None\n            )\n\n            results.append({\n                \"file_id\": uploaded_file.id,\n                \"filename\": uploaded_file.original_filename,\n                \"size\": uploaded_file.size,\n                \"status\": \"success\"\n            })\n\n        except Exception as e:\n            errors.append({\n                \"filename\": file.filename,\n                \"error\": str(e),\n                \"status\": \"error\"\n            })\n\n    return {\n        \"uploaded\": results,\n        \"errors\": errors,\n        \"total_files\": len(files),\n        \"successful_uploads\": len(results)\n    }\n\n@app.post(\"/upload/chunked\")\nasync def upload_chunked_file(\n    chunk: UploadFile = File(...),\n    chunk_number: int = Form(...),\n    total_chunks: int = Form(...),\n    file_id: str = Form(...),\n    filename: str = Form(...),\n    token: str = Depends(security)\n):\n    \"\"\"Handle chunked file uploads for large files\"\"\"\n\n    user = await validate_token(token.credentials)\n    if not user:\n        raise HTTPException(401, \"Authentication required\")\n\n    chunk_dir = f\"/tmp/chunks/{file_id}\"\n    Path(chunk_dir).mkdir(parents=True, exist_ok=True)\n\n    # Save chunk\n    chunk_path = f\"{chunk_dir}/chunk_{chunk_number}\"\n    async with aiofiles.open(chunk_path, \"wb\") as f:\n        chunk_data = await chunk.read()\n        await f.write(chunk_data)\n\n    # Check if all chunks received\n    existing_chunks = list(Path(chunk_dir).glob(\"chunk_*\"))\n    if len(existing_chunks) == total_chunks:\n        # Reassemble file\n        complete_file_data = b\"\"\n        for i in range(total_chunks):\n            chunk_file = f\"{chunk_dir}/chunk_{i}\"\n            async with aiofiles.open(chunk_file, \"rb\") as f:\n                chunk_content = await f.read()\n                complete_file_data += chunk_content\n\n        # Upload complete file\n        try:\n            uploaded_file = await upload_service.upload_file(\n                file_data=complete_file_data,\n                filename=filename,\n                content_type=\"application/octet-stream\",  # Will be detected\n                user_id=user.id\n            )\n\n            # Cleanup chunks\n            import shutil\n            shutil.rmtree(chunk_dir)\n\n            return {\n                \"file_id\": uploaded_file.id,\n                \"status\": \"complete\",\n                \"filename\": uploaded_file.original_filename,\n                \"size\": uploaded_file.size\n            }\n\n        except Exception as e:\n            # Cleanup on error\n            import shutil\n            shutil.rmtree(chunk_dir)\n            raise HTTPException(500, f\"Assembly failed: {str(e)}\")\n\n    return {\n        \"status\": \"chunk_received\",\n        \"chunk_number\": chunk_number,\n        \"total_chunks\": total_chunks,\n        \"received_chunks\": len(existing_chunks)\n    }\n\n@app.get(\"/files/{file_id}\")\nasync def get_file_info(file_id: str, token: str = Depends(security)):\n    \"\"\"Get file information\"\"\"\n    user = await validate_token(token.credentials)\n\n    # Get file record from database\n    file_record = await get_file_by_id(file_id)\n    if not file_record:\n        raise HTTPException(404, \"File not found\")\n\n    # Check permissions\n    if file_record.user_id != user.id and not user.is_admin:\n        raise HTTPException(403, \"Access denied\")\n\n    return {\n        \"file_id\": file_record.id,\n        \"filename\": file_record.original_filename,\n        \"content_type\": file_record.content_type,\n        \"size\": file_record.size,\n        \"public_url\": file_record.public_url,\n        \"created_at\": file_record.created_at,\n        \"processed\": file_record.processed,\n        \"metadata\": file_record.metadata\n    }\n\n@app.delete(\"/files/{file_id}\")\nasync def delete_file(file_id: str, token: str = Depends(security)):\n    \"\"\"Delete uploaded file\"\"\"\n    user = await validate_token(token.credentials)\n\n    file_record = await get_file_by_id(file_id)\n    if not file_record:\n        raise HTTPException(404, \"File not found\")\n\n    # Check permissions\n    if file_record.user_id != user.id and not user.is_admin:\n        raise HTTPException(403, \"Access denied\")\n\n    # Delete from storage\n    storage_backend = upload_service.storage_backends[upload_service.default_config.storage_backend]\n    await storage_backend.delete_file(file_record.upload_path)\n\n    # Delete from database\n    await delete_file_record(file_id)\n\n    return {\"message\": \"File deleted successfully\"}\n\nasync def validate_token(token: str):\n    \"\"\"Validate JWT token and return user\"\"\"\n    # Implementation depends on your auth system\n    pass\n\nasync def get_file_by_id(file_id: str):\n    \"\"\"Get file record from database\"\"\"\n    # Implementation depends on your database\n    pass\n\nasync def delete_file_record(file_id: str):\n    \"\"\"Delete file record from database\"\"\"\n    # Implementation depends on your database\n    pass\n</code></pre>"},{"location":"atomic/file-storage/upload-patterns/#storage-backend-implementations","title":"Storage Backend Implementations","text":"<pre><code>from abc import ABC, abstractmethod\nimport boto3\nfrom azure.storage.blob import BlobServiceClient\nfrom google.cloud import storage as gcs\n\nclass StorageBackend(ABC):\n    @abstractmethod\n    async def store_file(self, file_data: bytes, path: str) -&gt; str:\n        \"\"\"Store file and return public URL\"\"\"\n        pass\n\n    @abstractmethod\n    async def retrieve_file(self, path: str) -&gt; bytes:\n        \"\"\"Retrieve file data\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_file(self, path: str) -&gt; bool:\n        \"\"\"Delete file\"\"\"\n        pass\n\nclass LocalStorageBackend(StorageBackend):\n    def __init__(self, base_path: str, public_url_base: str):\n        self.base_path = Path(base_path)\n        self.public_url_base = public_url_base.rstrip('/')\n\n    async def store_file(self, file_data: bytes, path: str) -&gt; str:\n        full_path = self.base_path / path\n        full_path.parent.mkdir(parents=True, exist_ok=True)\n\n        async with aiofiles.open(full_path, \"wb\") as f:\n            await f.write(file_data)\n\n        return f\"{self.public_url_base}/{path}\"\n\n    async def retrieve_file(self, path: str) -&gt; bytes:\n        full_path = self.base_path / path\n        async with aiofiles.open(full_path, \"rb\") as f:\n            return await f.read()\n\n    async def delete_file(self, path: str) -&gt; bool:\n        full_path = self.base_path / path\n        try:\n            full_path.unlink()\n            return True\n        except FileNotFoundError:\n            return False\n\nclass S3StorageBackend(StorageBackend):\n    def __init__(self, bucket_name: str, aws_access_key: str, aws_secret_key: str, region: str):\n        self.bucket_name = bucket_name\n        self.s3_client = boto3.client(\n            's3',\n            aws_access_key_id=aws_access_key,\n            aws_secret_access_key=aws_secret_key,\n            region_name=region\n        )\n\n    async def store_file(self, file_data: bytes, path: str) -&gt; str:\n        # Run S3 upload in thread pool since boto3 is synchronous\n        import asyncio\n        loop = asyncio.get_event_loop()\n\n        await loop.run_in_executor(\n            None,\n            lambda: self.s3_client.put_object(\n                Bucket=self.bucket_name,\n                Key=path,\n                Body=file_data,\n                ContentType=self._guess_content_type(path)\n            )\n        )\n\n        return f\"https://{self.bucket_name}.s3.amazonaws.com/{path}\"\n\n    async def retrieve_file(self, path: str) -&gt; bytes:\n        import asyncio\n        loop = asyncio.get_event_loop()\n\n        response = await loop.run_in_executor(\n            None,\n            lambda: self.s3_client.get_object(Bucket=self.bucket_name, Key=path)\n        )\n\n        return response['Body'].read()\n\n    async def delete_file(self, path: str) -&gt; bool:\n        import asyncio\n        loop = asyncio.get_event_loop()\n\n        try:\n            await loop.run_in_executor(\n                None,\n                lambda: self.s3_client.delete_object(Bucket=self.bucket_name, Key=path)\n            )\n            return True\n        except Exception:\n            return False\n\n    def _guess_content_type(self, path: str) -&gt; str:\n        content_type, _ = mimetypes.guess_type(path)\n        return content_type or 'application/octet-stream'\n</code></pre>"},{"location":"atomic/file-storage/upload-patterns/#testing-file-uploads","title":"Testing File Uploads","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nimport tempfile\nimport io\n\nclass TestFileUpload:\n\n    @pytest.fixture\n    def upload_service(self):\n        config = FileUploadConfig(\n            max_file_size=1024 * 1024,  # 1MB for testing\n            allowed_extensions=['.txt', '.jpg', '.png'],\n            allowed_mime_types=['text/plain', 'image/jpeg', 'image/png']\n        )\n\n        storage_backends = {\n            'local': LocalStorageBackend('/tmp/test_uploads', 'http://localhost/files')\n        }\n\n        return FileUploadService(storage_backends, config)\n\n    async def test_valid_file_upload(self, upload_service):\n        file_data = b\"Test file content\"\n        filename = \"test.txt\"\n        content_type = \"text/plain\"\n\n        uploaded_file = await upload_service.upload_file(\n            file_data, filename, content_type\n        )\n\n        assert uploaded_file.id is not None\n        assert uploaded_file.original_filename == filename\n        assert uploaded_file.size == len(file_data)\n        assert uploaded_file.file_hash == hashlib.sha256(file_data).hexdigest()\n\n    async def test_file_too_large(self, upload_service):\n        large_file_data = b\"x\" * (2 * 1024 * 1024)  # 2MB\n\n        with pytest.raises(FileUploadError):\n            await upload_service.upload_file(\n                large_file_data, \"large.txt\", \"text/plain\"\n            )\n\n    async def test_invalid_extension(self, upload_service):\n        file_data = b\"executable content\"\n\n        with pytest.raises(FileUploadError):\n            await upload_service.upload_file(\n                file_data, \"malware.exe\", \"application/x-executable\"\n            )\n\n    def test_upload_endpoint(self):\n        client = TestClient(app)\n\n        # Create test file\n        test_file = io.BytesIO(b\"Test file content\")\n\n        response = client.post(\n            \"/upload/single\",\n            files={\"file\": (\"test.txt\", test_file, \"text/plain\")},\n            headers={\"Authorization\": \"Bearer valid_token\"}\n        )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert \"file_id\" in data\n        assert data[\"filename\"] == \"test.txt\"\n\n    def test_multiple_upload_endpoint(self):\n        client = TestClient(app)\n\n        files = [\n            (\"files\", (\"test1.txt\", io.BytesIO(b\"File 1\"), \"text/plain\")),\n            (\"files\", (\"test2.txt\", io.BytesIO(b\"File 2\"), \"text/plain\"))\n        ]\n\n        response = client.post(\n            \"/upload/multiple\",\n            files=files,\n            headers={\"Authorization\": \"Bearer valid_token\"}\n        )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert len(data[\"uploaded\"]) == 2\n        assert data[\"successful_uploads\"] == 2\n\n    async def test_image_validation(self, upload_service):\n        # Create a simple PNG file\n        from PIL import Image\n        import io\n\n        img = Image.new('RGB', (100, 100), color='red')\n        img_buffer = io.BytesIO()\n        img.save(img_buffer, format='PNG')\n        img_data = img_buffer.getvalue()\n\n        uploaded_file = await upload_service.upload_file(\n            img_data, \"test.png\", \"image/png\"\n        )\n\n        assert uploaded_file.content_type == \"image/png\"\n        assert uploaded_file.size == len(img_data)\n\n    async def test_malicious_file_detection(self, upload_service):\n        # File with suspicious content\n        malicious_data = b'&lt;script&gt;alert(\"xss\")&lt;/script&gt;'\n\n        with pytest.raises(FileUploadError):\n            await upload_service.upload_file(\n                malicious_data, \"innocent.txt\", \"text/plain\"\n            )\n</code></pre>"},{"location":"atomic/file-storage/upload-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Media Processing Patterns - Image/video processing workflows</li> <li>Cloud Storage Integration - AWS S3, Google Cloud, Azure storage</li> <li>Backup Strategies - File backup and disaster recovery</li> <li>Authentication Guide - User authentication for uploads</li> </ul>"},{"location":"atomic/file-storage/upload-patterns/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Security First: Always validate file types, scan for malware, and sanitize metadata</li> <li>Chunked Uploads: Support large file uploads through chunking</li> <li>Async Processing: Process thumbnails and metadata extraction asynchronously</li> <li>Deduplication: Use file hashes to prevent storing duplicate files</li> <li>Storage Abstraction: Support multiple storage backends through common interface</li> <li>Monitoring: Log upload patterns and failures for security analysis</li> </ol>"},{"location":"atomic/file-storage/upload-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/file-storage/media-processing.md</code> \u2014 File processing</li> <li><code>docs/atomic/file-storage/cloud-integration.md</code> \u2014 Cloud storage</li> <li><code>docs/atomic/services/fastapi/request-validation.md</code> \u2014 Upload validation</li> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> \u2014 Upload authorization</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/","title":"Load Balancing with Nginx","text":"<p>Comprehensive guide for Nginx load balancing strategies, health checks, session persistence, and high-availability configurations for microservices.</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#load-balancing-fundamentals","title":"Load Balancing Fundamentals","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#basic-upstream-configuration","title":"Basic Upstream Configuration","text":"<pre><code># /etc/nginx/conf.d/upstream.conf\n\n# API Service load balancing\nupstream template_business_api {\n    # Load balancing method (default: round-robin)\n    least_conn;\n\n    # Backend servers\n    server api_service_1:8000 weight=3 max_fails=3 fail_timeout=30s;\n    server api_service_2:8000 weight=3 max_fails=3 fail_timeout=30s;\n    server api_service_3:8000 weight=2 max_fails=3 fail_timeout=30s;\n\n    # Backup server (used only when primary servers are down)\n    server api_service_backup:8000 backup;\n\n    # Connection keepalive for better performance\n    keepalive 32;\n    keepalive_timeout 60s;\n    keepalive_requests 100;\n}\n\n# Data Service (PostgreSQL) - Internal only\nupstream template_data_postgres_api {\n    least_conn;\n    server db_postgres_service_1:8001 max_fails=2 fail_timeout=10s;\n    server db_postgres_service_2:8001 max_fails=2 fail_timeout=10s;\n    keepalive 16;\n}\n\n# Data Service (MongoDB) - Internal only\nupstream template_data_mongo_api {\n    least_conn;\n    server db_mongo_service_1:8002 max_fails=2 fail_timeout=10s;\n    server db_mongo_service_2:8002 max_fails=2 fail_timeout=10s;\n    keepalive 16;\n}\n\n# Worker Service (AsyncIO)\nupstream template_business_worker {\n    least_conn;\n    server worker_service_1:8003 max_fails=3 fail_timeout=20s;\n    server worker_service_2:8003 max_fails=3 fail_timeout=20s;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#load-balancing-methods","title":"Load Balancing Methods","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#1-round-robin-default","title":"1. Round Robin (Default)","text":"<pre><code># Distribute requests sequentially across servers\nupstream template_business_api {\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre> <p>Use case: Equal server capacity, stateless requests</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#2-least-connections","title":"2. Least Connections","text":"<pre><code># Send requests to server with fewest active connections\nupstream template_business_api {\n    least_conn;\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre> <p>Use case: Long-lived connections, varying request processing times</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#3-ip-hash-session-persistence","title":"3. IP Hash (Session Persistence)","text":"<pre><code># Same client always goes to same server\nupstream template_business_api {\n    ip_hash;\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre> <p>Use case: Sticky sessions, server-side session storage</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#4-generic-hash","title":"4. Generic Hash","text":"<pre><code># Hash based on custom key (e.g., user ID)\nupstream template_business_api {\n    hash $request_uri consistent;\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre> <p>Use case: Cache distribution, consistent routing</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#5-weighted-load-balancing","title":"5. Weighted Load Balancing","text":"<pre><code># Distribute based on server capacity\nupstream template_business_api {\n    server api-1:8000 weight=5;  # Gets 5/10 of traffic\n    server api-2:8000 weight=3;  # Gets 3/10 of traffic\n    server api-3:8000 weight=2;  # Gets 2/10 of traffic\n}\n</code></pre> <p>Use case: Heterogeneous server capacities</p>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#health-checks","title":"Health Checks","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#passive-health-checks","title":"Passive Health Checks","text":"<pre><code># Built-in passive health monitoring\nupstream template_business_api {\n    server api-1:8000 max_fails=3 fail_timeout=30s;\n    server api-2:8000 max_fails=3 fail_timeout=30s;\n    server api-3:8000 max_fails=3 fail_timeout=30s;\n}\n\n# Parameters:\n# - max_fails: number of failed attempts before marking server as unavailable\n# - fail_timeout: time to wait before retrying failed server\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#active-health-checks-nginx-plus","title":"Active Health Checks (Nginx Plus)","text":"<pre><code># Nginx Plus only - active health checks\nupstream template_business_api {\n    zone template_business_api 64k;\n\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n\n    # Active health check configuration\n    health_check interval=5s fails=3 passes=2 uri=/health;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#custom-health-check-endpoint","title":"Custom Health Check Endpoint","text":"<pre><code># FastAPI health check endpoint\n\nfrom fastapi import APIRouter, Response\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom redis.asyncio import Redis\n\nrouter = APIRouter(tags=[\"health\"])\n\n\n@router.get(\"/health\")\nasync def health_check(\n    db: AsyncSession,\n    redis: Redis,\n) -&gt; dict:\n    \"\"\"Health check for load balancer\"\"\"\n\n    health_status = {\n        \"status\": \"healthy\",\n        \"checks\": {}\n    }\n\n    # Check database connectivity\n    try:\n        await db.execute(\"SELECT 1\")\n        health_status[\"checks\"][\"database\"] = \"up\"\n    except Exception:\n        health_status[\"checks\"][\"database\"] = \"down\"\n        health_status[\"status\"] = \"unhealthy\"\n\n    # Check Redis connectivity\n    try:\n        await redis.ping()\n        health_status[\"checks\"][\"redis\"] = \"up\"\n    except Exception:\n        health_status[\"checks\"][\"redis\"] = \"down\"\n        health_status[\"status\"] = \"unhealthy\"\n\n    # Return 503 if unhealthy\n    if health_status[\"status\"] == \"unhealthy\":\n        return Response(\n            content=health_status,\n            status_code=503\n        )\n\n    return health_status\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#session-persistence-strategies","title":"Session Persistence Strategies","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#1-cookie-based-sticky-sessions","title":"1. Cookie-based Sticky Sessions","text":"<pre><code>upstream template_business_api {\n    # Use cookie for session persistence\n    sticky cookie srv_id expires=1h domain=.example.com path=/;\n\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#2-client-ip-based-persistence","title":"2. Client IP-based Persistence","text":"<pre><code>upstream template_business_api {\n    ip_hash;\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#3-jwt-based-routing","title":"3. JWT-based Routing","text":"<pre><code># Route based on JWT claim (requires Nginx Plus or custom Lua)\nmap $cookie_jwt_token $backend_server {\n    ~*user_id:1.*  api-1:8000;\n    ~*user_id:2.*  api-2:8000;\n    default        api-3:8000;\n}\n\nupstream template_business_api {\n    server $backend_server;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#connection-management","title":"Connection Management","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#keepalive-connections","title":"Keepalive Connections","text":"<pre><code>upstream template_business_api {\n    server api-1:8000;\n    server api-2:8000;\n\n    # Keepalive settings\n    keepalive 32;              # Number of idle keepalive connections\n    keepalive_timeout 60s;     # Timeout for keepalive connections\n    keepalive_requests 100;    # Max requests per connection\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://template_business_api;\n\n        # Required for keepalive to work\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#connection-limits","title":"Connection Limits","text":"<pre><code># Limit connections per upstream server\nupstream template_business_api {\n    server api-1:8000 max_conns=100;\n    server api-2:8000 max_conns=100;\n    server api-3:8000 max_conns=50;  # Lower capacity server\n}\n\n# Global connection limiting\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\n\nserver {\n    # Limit concurrent connections per IP\n    limit_conn addr 10;\n\n    location /api/ {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#high-availability-configuration","title":"High Availability Configuration","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#multi-datacenter-setup","title":"Multi-datacenter Setup","text":"<pre><code># Primary datacenter\nupstream api_primary {\n    zone api_primary 64k;\n    server dc1-api-1:8000;\n    server dc1-api-2:8000;\n    server dc1-api-3:8000;\n}\n\n# Secondary datacenter (backup)\nupstream api_secondary {\n    zone api_secondary 64k;\n    server dc2-api-1:8000 backup;\n    server dc2-api-2:8000 backup;\n}\n\n# Combined upstream with failover\nupstream template_business_api {\n    server api_primary;\n    server api_secondary backup;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#slow-start-nginx-plus","title":"Slow Start (Nginx Plus)","text":"<pre><code># Gradually increase traffic to newly added server\nupstream template_business_api {\n    zone template_business_api 64k;\n\n    server api-1:8000;\n    server api-2:8000;\n    server api-3:8000 slow_start=30s;  # Ramp up over 30 seconds\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#performance-tuning","title":"Performance Tuning","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#buffer-configuration","title":"Buffer Configuration","text":"<pre><code>server {\n    location /api/ {\n        proxy_pass http://template_business_api;\n\n        # Buffer settings for better performance\n        proxy_buffering on;\n        proxy_buffer_size 4k;\n        proxy_buffers 8 4k;\n        proxy_busy_buffers_size 8k;\n\n        # Disable buffering for streaming endpoints\n        location /api/stream {\n            proxy_pass http://template_business_api;\n            proxy_buffering off;\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#timeout-configuration","title":"Timeout Configuration","text":"<pre><code>upstream template_business_api {\n    server api-1:8000;\n    server api-2:8000;\n\n    keepalive 32;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://template_business_api;\n\n        # Timeout settings\n        proxy_connect_timeout 5s;      # Time to connect to upstream\n        proxy_send_timeout 60s;        # Time to send request to upstream\n        proxy_read_timeout 60s;        # Time to read response from upstream\n\n        # Long-running endpoints\n        location /api/reports {\n            proxy_pass http://template_business_api;\n            proxy_read_timeout 300s;   # 5 minutes for reports\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#status-page-nginx-plus","title":"Status Page (Nginx Plus)","text":"<pre><code>server {\n    listen 8080;\n    server_name localhost;\n\n    # Status page\n    location /status {\n        status;\n        access_log off;\n    }\n\n    # Detailed upstream statistics\n    location /status/upstreams {\n        status_zone upstream_stats;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#prometheus-metrics-export","title":"Prometheus Metrics Export","text":"<pre><code># Using nginx-prometheus-exporter\n\n# Install:\n# docker run -p 9113:9113 nginx/nginx-prometheus-exporter:latest \\\n#   -nginx.scrape-uri=http://nginx:8080/status\n\nserver {\n    listen 8080;\n    location /stub_status {\n        stub_status;\n        access_log off;\n        allow 127.0.0.1;\n        deny all;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#custom-access-logging","title":"Custom Access Logging","text":"<pre><code># Log upstream server information\nlog_format upstreamlog '$remote_addr - $remote_user [$time_local] '\n                       '\"$request\" $status $body_bytes_sent '\n                       '\"$http_referer\" \"$http_user_agent\" '\n                       'upstream: $upstream_addr '\n                       'upstream_status: $upstream_status '\n                       'upstream_response_time: $upstream_response_time '\n                       'request_time: $request_time';\n\nserver {\n    access_log /var/log/nginx/upstream_access.log upstreamlog;\n\n    location /api/ {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#docker-compose-example","title":"Docker Compose Example","text":"<pre><code># docker-compose.yml\n\nversion: '3.8'\n\nservices:\n  nginx:\n    image: nginx:1.25-alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n    depends_on:\n      - api_service_1\n      - api_service_2\n      - api_service_3\n    networks:\n      - frontend\n      - backend\n\n  api_service_1:\n    build: ./services/api\n    environment:\n      - SERVICE_ID=1\n    networks:\n      - backend\n\n  api_service_2:\n    build: ./services/api\n    environment:\n      - SERVICE_ID=2\n    networks:\n      - backend\n\n  api_service_3:\n    build: ./services/api\n    environment:\n      - SERVICE_ID=3\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#testing-load-balancing","title":"Testing Load Balancing","text":""},{"location":"atomic/infrastructure/api-gateway/load-balancing/#test-round-robin-distribution","title":"Test Round Robin Distribution","text":"<pre><code># Send 10 requests and observe distribution\nfor i in {1..10}; do\n  curl -s http://localhost/api/health | jq '.server_id'\ndone\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#test-health-check-failover","title":"Test Health Check Failover","text":"<pre><code># Stop one backend server\ndocker-compose stop api_service_1\n\n# Verify traffic routes to remaining servers\ncurl http://localhost/api/health\n\n# Restart server\ndocker-compose start api_service_1\n\n# Verify server rejoins pool after health check passes\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#load-testing","title":"Load Testing","text":"<pre><code># Using Apache Bench\nab -n 10000 -c 100 http://localhost/api/\n\n# Using wrk\nwrk -t4 -c100 -d30s http://localhost/api/\n\n# Using hey\nhey -n 10000 -c 100 http://localhost/api/\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use health checks - Always configure health checks to detect and remove failed servers</p> </li> <li> <p>Configure appropriate timeouts - Set reasonable timeouts based on endpoint characteristics</p> </li> <li> <p>Enable keepalive - Use keepalive connections for better performance</p> </li> <li> <p>Monitor upstream health - Track upstream server health and response times</p> </li> <li> <p>Gradual rollout - Use slow start when adding new servers</p> </li> <li> <p>Session persistence strategy - Choose appropriate method based on application requirements</p> </li> <li> <p>Capacity planning - Use weights to match server capacities</p> </li> <li> <p>Backup servers - Always configure backup servers for high availability</p> </li> </ol>"},{"location":"atomic/infrastructure/api-gateway/load-balancing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Nginx Setup - Basic Nginx installation and configuration</li> <li>Routing Patterns - Advanced routing strategies</li> <li>Security Hardening - Security best practices</li> <li>SSL Configuration - TLS/SSL setup</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/","title":"Nginx Setup and Configuration","text":"<p>This document covers the basic setup and configuration of Nginx as an API Gateway for the Improved Hybrid Approach microservices architecture.</p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#purpose-and-role","title":"Purpose and Role","text":"<p>Nginx serves as the single entry point for all external traffic to your microservices: - Reverse Proxy: Routes requests to internal services - SSL/TLS Termination: Handles HTTPS encryption/decryption - Load Balancing: Distributes traffic across service instances - Security Layer: Rate limiting, CORS, security headers - Static Content: Serves static files if needed</p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#architecture-integration","title":"Architecture Integration","text":"<pre><code>External Traffic (Internet)\n         \u2193\n    [Nginx :80/:443]\n         \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2193          \u2193         \u2193           \u2193\ntemplate_business_api  template_business_bot  db-*-services\n(internal)   (internal)   (internal)\n</code></pre> <p>Key Principle: Only nginx is exposed to the internet; all services communicate internally via Docker network.</p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#directory-structure","title":"Directory Structure","text":"<pre><code>nginx/\n\u251c\u2500\u2500 nginx.conf                  # Main nginx configuration\n\u251c\u2500\u2500 conf.d/                     # Configuration modules\n\u2502   \u251c\u2500\u2500 api-gateway.conf        # Routing rules for all services\n\u2502   \u251c\u2500\u2500 upstream.conf           # Upstream service definitions\n\u2502   \u2514\u2500\u2500 ssl.conf                # SSL/TLS configuration (if using HTTPS)\n\u251c\u2500\u2500 Dockerfile                  # Nginx container build\n\u251c\u2500\u2500 certs/                      # SSL certificates (gitignored)\n\u2502   \u251c\u2500\u2500 server.crt\n\u2502   \u2514\u2500\u2500 server.key\n\u2514\u2500\u2500 html/                       # Static files (optional)\n    \u2514\u2500\u2500 index.html\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#basic-configuration-files","title":"Basic Configuration Files","text":""},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#nginxconf-main-configuration","title":"nginx.conf (Main Configuration)","text":"<pre><code>user nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n    use epoll;\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    # Logging format\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\" '\n                    'rt=$request_time uct=\"$upstream_connect_time\" '\n                    'uht=\"$upstream_header_time\" urt=\"$upstream_response_time\"';\n\n    access_log /var/log/nginx/access.log main;\n\n    # Performance tuning\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n    client_max_body_size 20M;\n\n    # Security headers (default)\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n\n    # Gzip compression\n    gzip on;\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 6;\n    gzip_types text/plain text/css text/xml text/javascript\n               application/json application/javascript application/xml+rss;\n\n    # Include additional configurations\n    include /etc/nginx/conf.d/*.conf;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#confdupstreamconf-upstream-definitions","title":"conf.d/upstream.conf (Upstream Definitions)","text":"<pre><code># Define upstream services\n# Use Docker service names for internal DNS resolution\n\nupstream template_business_api {\n    # template_business_api is the Docker Compose service name\n    server template_business_api:8000;\n    # For multiple instances (load balancing):\n    # server template_business_api-1:8000;\n    # server template_business_api-2:8000;\n    keepalive 32;\n}\n\nupstream bot_webhook_service {\n    server template_business_bot:8002;\n    keepalive 16;\n}\n\nupstream template_data_postgres_api {\n    # Data services should NOT be exposed externally\n    # Only include if you need admin/debug access (not recommended for production)\n    server template_data_postgres_api:8001;\n    keepalive 16;\n}\n\nupstream template_data_mongo_api {\n    server template_data_mongo_api:8002;\n    keepalive 16;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#confdapi-gatewayconf-routing-rules","title":"conf.d/api-gateway.conf (Routing Rules)","text":"<pre><code>server {\n    listen 80;\n    server_name localhost;\n\n    # Health check endpoint\n    location /health {\n        access_log off;\n        return 200 \"healthy\\n\";\n        add_header Content-Type text/plain;\n    }\n\n    # Route to FastAPI service\n    location /api/v1/ {\n        proxy_pass http://template_business_api;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # Request ID propagation\n        proxy_set_header X-Request-ID $request_id;\n\n        # Timeouts\n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n\n        # Buffering\n        proxy_buffering on;\n        proxy_buffer_size 4k;\n        proxy_buffers 8 4k;\n    }\n\n    # Telegram webhook endpoint\n    location /webhook/telegram {\n        proxy_pass http://bot_webhook_service/webhook;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        # Telegram-specific settings\n        proxy_connect_timeout 10s;\n        proxy_read_timeout 30s;\n    }\n\n    # Admin endpoints (optional, restrict access)\n    # location /admin/ {\n    #     # Restrict to internal IPs\n    #     allow 10.0.0.0/8;\n    #     allow 172.16.0.0/12;\n    #     deny all;\n    #\n    #     proxy_pass http://template_business_api/admin/;\n    #     proxy_set_header Host $host;\n    #     proxy_set_header X-Real-IP $remote_addr;\n    # }\n\n    # Static files (optional)\n    # location /static/ {\n    #     alias /usr/share/nginx/html/static/;\n    #     expires 30d;\n    #     add_header Cache-Control \"public, immutable\";\n    # }\n\n    # Default 404 for unknown routes\n    location / {\n        return 404 '{\"error\": \"Not Found\"}';\n        add_header Content-Type application/json;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM nginx:1.25-alpine\n\n# Copy configuration files\nCOPY nginx.conf /etc/nginx/nginx.conf\nCOPY conf.d/ /etc/nginx/conf.d/\n\n# Copy static files (if any)\n# COPY html/ /usr/share/nginx/html/\n\n# Copy SSL certificates (if using HTTPS)\n# COPY certs/ /etc/nginx/certs/\n\n# Create log directories\nRUN mkdir -p /var/log/nginx &amp;&amp; \\\n    chown -R nginx:nginx /var/log/nginx\n\n# Expose ports\nEXPOSE 80 443\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD wget --quiet --tries=1 --spider http://localhost/health || exit 1\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#docker-compose-integration","title":"Docker Compose Integration","text":"<pre><code>services:\n  nginx:\n    build: ./nginx\n    container_name: nginx-gateway\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    depends_on:\n      - template_business_api\n      - template_business_bot\n    networks:\n      - app_network\n    volumes:\n      # For development: live reload configs\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n      # Logs\n      - nginx-logs:/var/log/nginx\n    restart: unless-stopped\n\n  template_business_api:\n    build: ./services/template_business_api\n    # NO ports exposed - internal only\n    networks:\n      - app_network\n    restart: unless-stopped\n\n  template_business_bot:\n    build: ./services/template_business_bot\n    # NO ports exposed - internal only\n    networks:\n      - app_network\n    restart: unless-stopped\n\nnetworks:\n  app_network:\n    driver: bridge\n\nvolumes:\n  nginx-logs:\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#testing-configuration","title":"Testing Configuration","text":"<pre><code># Test nginx configuration syntax\ndocker-compose exec nginx nginx -t\n\n# Reload nginx without downtime\ndocker-compose exec nginx nginx -s reload\n\n# View access logs\ndocker-compose logs -f nginx\n\n# Test endpoint\ncurl http://localhost/api/v1/health\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#security","title":"Security","text":"<ul> <li>Never expose service ports directly - only nginx should be accessible</li> <li>Use internal Docker network for service-to-service communication</li> <li>Implement rate limiting (see security-hardening.md)</li> <li>Enable SSL/TLS for production (see ssl-configuration.md)</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#performance","title":"Performance","text":"<ul> <li>Enable keepalive connections to upstreams</li> <li>Use gzip compression for text responses</li> <li>Set appropriate timeouts based on service requirements</li> <li>Buffer responses to prevent slow client issues</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#monitoring","title":"Monitoring","text":"<ul> <li>Structured logging with request IDs and timing</li> <li>Health checks for nginx and upstream services</li> <li>Metrics export (optional: nginx-prometheus-exporter)</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#development","title":"Development","text":"<ul> <li>Mount configs as volumes for live reload during development</li> <li>Use <code>nginx -t</code> before reloading to catch syntax errors</li> <li>Centralize logging to files accessible via Docker logs</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#common-issues","title":"Common Issues","text":""},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#issue-502-bad-gateway","title":"Issue: 502 Bad Gateway","text":"<p>Cause: Upstream service is not running or not reachable Solution: <pre><code># Check if service is running\ndocker-compose ps template_business_api\n\n# Check service logs\ndocker-compose logs template_business_api\n\n# Verify Docker network connectivity\ndocker-compose exec nginx ping template_business_api\n</code></pre></p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#issue-504-gateway-timeout","title":"Issue: 504 Gateway Timeout","text":"<p>Cause: Upstream service is too slow or hung Solution: Increase timeouts in nginx config: <pre><code>proxy_connect_timeout 120s;\nproxy_read_timeout 120s;\n</code></pre></p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#issue-configuration-not-reloading","title":"Issue: Configuration not reloading","text":"<p>Cause: Syntax error or volume mount issue Solution: <pre><code># Test config\ndocker-compose exec nginx nginx -t\n\n# If syntax is OK, reload\ndocker-compose exec nginx nginx -s reload\n\n# If still not working, restart container\ndocker-compose restart nginx\n</code></pre></p>"},{"location":"atomic/infrastructure/api-gateway/nginx-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Routing Patterns - Advanced routing strategies</li> <li>SSL Configuration - HTTPS setup and certificate management</li> <li>Security Hardening - Rate limiting, CORS, and security headers</li> <li>Container Networking - Docker network setup</li> <li>Load Balancing Patterns - Multi-instance service load balancing</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/","title":"Nginx Routing Patterns","text":"<p>This document covers advanced routing strategies for Nginx as an API Gateway in the Improved Hybrid Approach.</p>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#core-routing-principles","title":"Core Routing Principles","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#path-based-routing","title":"Path-Based Routing","text":"<p>Route requests to different services based on URL path prefix:</p> <pre><code># Route by API version and service\nlocation /api/v1/auth/ {\n    proxy_pass http://auth_service/;\n}\n\nlocation /api/v1/users/ {\n    proxy_pass http://user_service/;\n}\n\nlocation /api/v1/orders/ {\n    proxy_pass http://order_service/;\n}\n</code></pre> <p>Key Points: - Trailing slashes matter: <code>/api/v1/auth/</code> vs <code>/api/v1/auth</code> - <code>proxy_pass</code> with trailing <code>/</code> removes the location prefix - Without trailing <code>/</code>, the full path is forwarded</p>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#header-based-routing","title":"Header-Based Routing","text":"<p>Route based on request headers (e.g., API versioning):</p> <pre><code>map $http_api_version $backend_service {\n    default api_service_v1;\n    \"v2\" api_service_v2;\n    \"beta\" api_service_beta;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://$backend_service;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#host-based-routing","title":"Host-Based Routing","text":"<p>Route based on domain/subdomain:</p> <pre><code># api.example.com -&gt; template_business_api\nserver {\n    listen 80;\n    server_name api.example.com;\n\n    location / {\n        proxy_pass http://template_business_api;\n    }\n}\n\n# admin.example.com -&gt; admin-service\nserver {\n    listen 80;\n    server_name admin.example.com;\n\n    location / {\n        proxy_pass http://admin_service;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#common-routing-patterns","title":"Common Routing Patterns","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#microservices-api-gateway-pattern","title":"Microservices API Gateway Pattern","text":"<pre><code># Upstream definitions\nupstream auth_service { server auth-service:8000; }\nupstream user_service { server user-service:8001; }\nupstream product_service { server product-service:8002; }\nupstream order_service { server order-service:8003; }\n\nserver {\n    listen 80;\n    server_name api.example.com;\n\n    # Authentication service\n    location /api/v1/auth/ {\n        proxy_pass http://auth_service/;\n        include /etc/nginx/proxy_params.conf;\n    }\n\n    # User service\n    location /api/v1/users/ {\n        proxy_pass http://user_service/;\n        include /etc/nginx/proxy_params.conf;\n\n        # Require authentication\n        auth_request /auth/verify;\n    }\n\n    # Product service\n    location /api/v1/products/ {\n        proxy_pass http://product_service/;\n        include /etc/nginx/proxy_params.conf;\n    }\n\n    # Order service\n    location /api/v1/orders/ {\n        proxy_pass http://order_service/;\n        include /etc/nginx/proxy_params.conf;\n\n        # Require authentication\n        auth_request /auth/verify;\n    }\n\n    # Internal auth verification endpoint\n    location = /auth/verify {\n        internal;\n        proxy_pass http://auth_service/verify;\n        proxy_pass_request_body off;\n        proxy_set_header Content-Length \"\";\n        proxy_set_header X-Original-URI $request_uri;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#websocket-support","title":"WebSocket Support","text":"<pre><code>upstream websocket_service {\n    server websocket-service:8080;\n}\n\nserver {\n    location /ws/ {\n        proxy_pass http://websocket_service;\n\n        # WebSocket upgrade headers\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n\n        # Timeouts for long-lived connections\n        proxy_read_timeout 3600s;\n        proxy_send_timeout 3600s;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#static-content-with-fallback","title":"Static Content with Fallback","text":"<pre><code>server {\n    location / {\n        # Try static file first, then proxy to backend\n        try_files $uri $uri/ @backend;\n    }\n\n    location @backend {\n        proxy_pass http://template_business_api;\n        include /etc/nginx/proxy_params.conf;\n    }\n\n    location /static/ {\n        alias /usr/share/nginx/html/static/;\n        expires 30d;\n        add_header Cache-Control \"public, immutable\";\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#api-versioning-strategies","title":"API Versioning Strategies","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#url-path-versioning","title":"URL Path Versioning","text":"<pre><code>location /api/v1/ {\n    proxy_pass http://api_service_v1/;\n}\n\nlocation /api/v2/ {\n    proxy_pass http://api_service_v2/;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#header-versioning","title":"Header Versioning","text":"<pre><code>map $http_accept $api_version {\n    default \"v1\";\n    \"~*application/vnd\\.myapi\\.v2\" \"v2\";\n}\n\nlocation /api/ {\n    if ($api_version = \"v2\") {\n        proxy_pass http://api_service_v2;\n    }\n    proxy_pass http://api_service_v1;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#request-transformation","title":"Request Transformation","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#adding-headers","title":"Adding Headers","text":"<pre><code>location /api/ {\n    proxy_pass http://template_business_api;\n\n    # Add custom headers\n    proxy_set_header X-Gateway \"nginx\";\n    proxy_set_header X-Request-ID $request_id;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header X-Forwarded-Host $host;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#rewriting-urls","title":"Rewriting URLs","text":"<pre><code># Remove /api prefix before forwarding\nlocation /api/ {\n    rewrite ^/api/(.*)$ /$1 break;\n    proxy_pass http://template_business_api;\n}\n\n# Add prefix\nlocation /external/ {\n    rewrite ^/external/(.*)$ /api/v1/$1 break;\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#query-string-manipulation","title":"Query String Manipulation","text":"<pre><code># Add query parameter\nlocation /api/ {\n    set $args \"${args}&amp;source=gateway\";\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#error-handling-and-fallbacks","title":"Error Handling and Fallbacks","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#custom-error-pages","title":"Custom Error Pages","text":"<pre><code>server {\n    # Custom error pages\n    error_page 404 /404.json;\n    error_page 500 502 503 504 /50x.json;\n\n    location = /404.json {\n        internal;\n        return 404 '{\"error\": \"Not Found\", \"status\": 404}';\n        add_header Content-Type application/json;\n    }\n\n    location = /50x.json {\n        internal;\n        return 500 '{\"error\": \"Internal Server Error\", \"status\": 500}';\n        add_header Content-Type application/json;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#fallback-to-secondary-service","title":"Fallback to Secondary Service","text":"<pre><code>upstream primary_service {\n    server primary:8000;\n}\n\nupstream fallback_service {\n    server fallback:8000;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://primary_service;\n        proxy_next_upstream error timeout http_502 http_503;\n        proxy_next_upstream_tries 2;\n\n        # If primary fails, try fallback\n        error_page 502 503 = @fallback;\n    }\n\n    location @fallback {\n        proxy_pass http://fallback_service;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#rate-limiting-and-traffic-control","title":"Rate Limiting and Traffic Control","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#basic-rate-limiting","title":"Basic Rate Limiting","text":"<pre><code># Define rate limit zones\nlimit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;\nlimit_req_zone $http_authorization zone=user_limit:10m rate=100r/s;\n\nserver {\n    location /api/v1/public/ {\n        # 10 requests per second per IP\n        limit_req zone=api_limit burst=20 nodelay;\n        proxy_pass http://template_business_api;\n    }\n\n    location /api/v1/user/ {\n        # 100 requests per second per user (by auth token)\n        limit_req zone=user_limit burst=50 nodelay;\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#connection-limiting","title":"Connection Limiting","text":"<pre><code># Limit concurrent connections per IP\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\n\nserver {\n    location /api/ {\n        limit_conn addr 10;  # Max 10 concurrent connections per IP\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>upstream template_business_api {\n    server template_business_api:8000 max_fails=3 fail_timeout=30s;\n    server api_service_backup:8000 backup;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://template_business_api;\n        proxy_next_upstream error timeout http_502;\n        proxy_connect_timeout 5s;\n        proxy_send_timeout 10s;\n        proxy_read_timeout 10s;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#ab-testing","title":"A/B Testing","text":"<pre><code># Split traffic 90% to v1, 10% to v2\nsplit_clients \"${remote_addr}${http_user_agent}\" $variant {\n    90%     \"v1\";\n    *       \"v2\";\n}\n\nserver {\n    location /api/ {\n        if ($variant = \"v2\") {\n            proxy_pass http://api_service_v2;\n        }\n        proxy_pass http://api_service_v1;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#canary-deployments","title":"Canary Deployments","text":"<pre><code># Route based on cookie or header\nmap $cookie_canary $backend {\n    default api_service_stable;\n    \"true\" api_service_canary;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://$backend;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#request-id-propagation","title":"Request ID Propagation","text":"<pre><code>map $http_x_request_id $request_id_to_use {\n    default $http_x_request_id;\n    \"\" $request_id;\n}\n\nserver {\n    location /api/ {\n        proxy_pass http://template_business_api;\n        proxy_set_header X-Request-ID $request_id_to_use;\n\n        # Log request ID\n        access_log /var/log/nginx/access.log main;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#response-time-logging","title":"Response Time Logging","text":"<pre><code>log_format timing '$remote_addr - $remote_user [$time_local] '\n                  '\"$request\" $status $body_bytes_sent '\n                  '\"$http_referer\" \"$http_user_agent\" '\n                  'rt=$request_time uct=$upstream_connect_time '\n                  'uht=$upstream_header_time urt=$upstream_response_time '\n                  'request_id=$request_id';\n\naccess_log /var/log/nginx/timing.log timing;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#1-use-consistent-routing-patterns","title":"1. Use Consistent Routing Patterns","text":"<ul> <li>Stick to path-based routing for simplicity</li> <li>Use prefixes like <code>/api/v1/</code>, <code>/api/v2/</code> for versioning</li> <li>Avoid complex conditionals when possible</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#2-preserve-context","title":"2. Preserve Context","text":"<pre><code># Always forward important headers\nproxy_set_header Host $host;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\nproxy_set_header X-Request-ID $request_id;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#3-centralize-common-settings","title":"3. Centralize Common Settings","text":"<pre><code># /etc/nginx/proxy_params.conf\nproxy_set_header Host $host;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\nproxy_set_header X-Request-ID $request_id;\nproxy_http_version 1.1;\nproxy_set_header Connection \"\";\n\n# Use in locations\nlocation /api/ {\n    include /etc/nginx/proxy_params.conf;\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#4-test-routing-logic","title":"4. Test Routing Logic","text":"<pre><code># Test different paths\ncurl -v http://localhost/api/v1/health\ncurl -v http://localhost/api/v1/users/123\ncurl -v http://localhost/webhook/telegram\n\n# Test headers\ncurl -v -H \"X-API-Version: v2\" http://localhost/api/\ncurl -v -H \"Authorization: Bearer token\" http://localhost/api/protected\n\n# Test rate limiting\nfor i in {1..20}; do curl http://localhost/api/; done\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/routing-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Nginx Setup - Basic nginx configuration</li> <li>SSL Configuration - HTTPS and certificate management</li> <li>Security Hardening - Security best practices</li> <li>Load Balancing Patterns - Multi-instance load balancing</li> <li>HTTP Request Tracing - Request ID propagation</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/","title":"Nginx Security Hardening","text":"<p>This document covers security best practices for Nginx as an API Gateway in microservices architecture.</p>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#core-security-principles","title":"Core Security Principles","text":"<ol> <li>Defense in Depth: Multiple layers of security controls</li> <li>Least Privilege: Minimal permissions and exposure</li> <li>Fail Secure: Default deny, explicit allow</li> <li>Security by Default: Secure defaults in all configurations</li> </ol>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#essential-security-headers","title":"Essential Security Headers","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#basic-security-headers","title":"Basic Security Headers","text":"<pre><code># Add security headers to all responses\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-Frame-Options \"DENY\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\nadd_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n\n# Content Security Policy (adjust based on your needs)\nadd_header Content-Security-Policy \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self'; frame-ancestors 'none';\" always;\n\n# HSTS (HTTP Strict Transport Security) - HTTPS only\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#complete-security-header-configuration","title":"Complete Security Header Configuration","text":"<pre><code># /etc/nginx/conf.d/security-headers.conf\n\n# Prevent MIME type sniffing\nadd_header X-Content-Type-Options \"nosniff\" always;\n\n# Prevent clickjacking\nadd_header X-Frame-Options \"DENY\" always;\n\n# Enable XSS filter\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\n# Control referer information\nadd_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n\n# HSTS - Force HTTPS for 1 year\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n\n# Permissions Policy (formerly Feature-Policy)\nadd_header Permissions-Policy \"geolocation=(), microphone=(), camera=()\" always;\n\n# Content Security Policy\nadd_header Content-Security-Policy \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self'; frame-ancestors 'none'; base-uri 'self'; form-action 'self';\" always;\n\n# Don't expose nginx version\nserver_tokens off;\nmore_clear_headers 'Server';  # Requires headers-more-nginx-module\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#rate-limiting","title":"Rate Limiting","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#ip-based-rate-limiting","title":"IP-Based Rate Limiting","text":"<pre><code># Define rate limit zones in http block\nhttp {\n    # General API rate limit: 10 requests per second per IP\n    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;\n\n    # Strict limit for auth endpoints: 5 requests per second per IP\n    limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=5r/s;\n\n    # Generous limit for static content: 100 requests per second\n    limit_req_zone $binary_remote_addr zone=static_limit:10m rate=100r/s;\n\n    server {\n        # Apply to API endpoints\n        location /api/ {\n            limit_req zone=api_limit burst=20 nodelay;\n            limit_req_status 429;\n            proxy_pass http://template_business_api;\n        }\n\n        # Stricter limit for authentication\n        location /api/v1/auth/login {\n            limit_req zone=auth_limit burst=3 nodelay;\n            limit_req_status 429;\n            proxy_pass http://auth_service;\n        }\n\n        # Generous for static content\n        location /static/ {\n            limit_req zone=static_limit burst=50 nodelay;\n            root /usr/share/nginx/html;\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#usertoken-based-rate-limiting","title":"User/Token-Based Rate Limiting","text":"<pre><code># Rate limit by authorization token\nlimit_req_zone $http_authorization zone=user_limit:10m rate=100r/s;\n\nserver {\n    location /api/v1/user/ {\n        # Limit by auth token (100 req/s per user)\n        limit_req zone=user_limit burst=50 nodelay;\n\n        # Fallback to IP-based limit if no auth token\n        limit_req zone=api_limit burst=20 nodelay;\n\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#connection-limiting","title":"Connection Limiting","text":"<pre><code># Limit concurrent connections per IP\nlimit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;\n\n# Limit concurrent connections to a location\nlimit_conn_zone $server_name zone=conn_limit_per_server:10m;\n\nserver {\n    # Max 10 concurrent connections per IP\n    limit_conn conn_limit_per_ip 10;\n\n    # Max 1000 concurrent connections to server\n    limit_conn conn_limit_per_server 1000;\n\n    location /api/ {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#request-size-limits","title":"Request Size Limits","text":"<pre><code>server {\n    # Limit request body size (default 1M)\n    client_body_buffer_size 128k;\n    client_max_body_size 10M;  # Max upload size\n\n    # Limit header size\n    client_header_buffer_size 1k;\n    large_client_header_buffers 4 8k;\n\n    # Endpoints with larger uploads\n    location /api/v1/upload {\n        client_max_body_size 50M;\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#ip-whitelisting-and-blacklisting","title":"IP Whitelisting and Blacklisting","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#allowdeny-specific-ips","title":"Allow/Deny Specific IPs","text":"<pre><code>server {\n    # Block specific IPs\n    deny 192.168.1.100;\n    deny 10.0.0.0/8;\n\n    # Allow specific IPs\n    allow 192.168.1.0/24;\n    allow 10.1.1.1;\n\n    # Block all others\n    deny all;\n\n    location /api/ {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#protect-admin-endpoints","title":"Protect Admin Endpoints","text":"<pre><code>server {\n    # Public endpoints\n    location /api/v1/public/ {\n        proxy_pass http://template_business_api;\n    }\n\n    # Admin endpoints - restrict to internal IPs\n    location /api/v1/admin/ {\n        # Allow internal networks\n        allow 10.0.0.0/8;\n        allow 172.16.0.0/12;\n        allow 192.168.0.0/16;\n\n        # Allow specific admin IPs\n        allow 203.0.113.0/24;\n\n        # Deny everyone else\n        deny all;\n\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#geoip-blocking","title":"GeoIP Blocking","text":"<pre><code># Requires ngx_http_geoip_module\nhttp {\n    geoip_country /usr/share/GeoIP/GeoIP.dat;\n\n    map $geoip_country_code $allowed_country {\n        default no;\n        US yes;\n        CA yes;\n        GB yes;\n    }\n\n    server {\n        location /api/ {\n            if ($allowed_country = no) {\n                return 403 '{\"error\": \"Access denied from your country\"}';\n            }\n            proxy_pass http://template_business_api;\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#cors-configuration","title":"CORS Configuration","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#basic-cors-setup","title":"Basic CORS Setup","text":"<pre><code># Simple CORS for public API\nlocation /api/v1/public/ {\n    # Allow all origins (not recommended for production)\n    add_header Access-Control-Allow-Origin * always;\n    add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\" always;\n    add_header Access-Control-Allow-Headers \"Authorization, Content-Type\" always;\n\n    # Handle preflight\n    if ($request_method = OPTIONS) {\n        return 204;\n    }\n\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#strict-cors-with-allowed-origins","title":"Strict CORS with Allowed Origins","text":"<pre><code># Define allowed origins\nmap $http_origin $cors_origin {\n    default \"\";\n    \"~^https://app\\.example\\.com$\" $http_origin;\n    \"~^https://admin\\.example\\.com$\" $http_origin;\n}\n\nserver {\n    location /api/ {\n        # Only set CORS headers if origin is allowed\n        add_header Access-Control-Allow-Origin $cors_origin always;\n        add_header Access-Control-Allow-Methods \"GET, POST, PUT, DELETE, OPTIONS\" always;\n        add_header Access-Control-Allow-Headers \"Authorization, Content-Type, X-Request-ID\" always;\n        add_header Access-Control-Max-Age \"3600\" always;\n        add_header Access-Control-Allow-Credentials \"true\" always;\n\n        # Handle preflight\n        if ($request_method = OPTIONS) {\n            add_header Access-Control-Allow-Origin $cors_origin always;\n            add_header Access-Control-Allow-Methods \"GET, POST, PUT, DELETE, OPTIONS\" always;\n            add_header Access-Control-Allow-Headers \"Authorization, Content-Type, X-Request-ID\" always;\n            add_header Access-Control-Max-Age \"3600\" always;\n            add_header Access-Control-Allow-Credentials \"true\" always;\n            return 204;\n        }\n\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#ddos-protection","title":"DDoS Protection","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#syn-flood-protection","title":"SYN Flood Protection","text":"<pre><code># In nginx.conf\nhttp {\n    # Connection limits\n    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;\n\n    # Rate limits\n    limit_req_zone $binary_remote_addr zone=ddos_limit:10m rate=20r/s;\n\n    server {\n        limit_conn conn_limit 10;\n        limit_req zone=ddos_limit burst=50 nodelay;\n\n        location / {\n            proxy_pass http://template_business_api;\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#slow-http-attack-protection","title":"Slow HTTP Attack Protection","text":"<pre><code>server {\n    # Timeout settings\n    client_body_timeout 10s;\n    client_header_timeout 10s;\n    send_timeout 10s;\n\n    # Keep-alive settings\n    keepalive_timeout 65s;\n    keepalive_requests 100;\n\n    location /api/ {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#ssltls-hardening","title":"SSL/TLS Hardening","text":"<p>See SSL Configuration for complete TLS setup.</p> <pre><code>server {\n    listen 443 ssl http2;\n\n    # Strong SSL protocols\n    ssl_protocols TLSv1.2 TLSv1.3;\n\n    # Strong ciphers\n    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';\n    ssl_prefer_server_ciphers on;\n\n    # OCSP stapling\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    location / {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#request-validation","title":"Request Validation","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#block-common-attack-patterns","title":"Block Common Attack Patterns","text":"<pre><code># Block requests with suspicious patterns\nlocation / {\n    # Block SQL injection attempts\n    if ($args ~* \"(union|select|insert|cast|set|declare|drop|update|md5|benchmark)\") {\n        return 403;\n    }\n\n    # Block XSS attempts\n    if ($args ~* \"(&lt;script|&lt;iframe|&lt;object|javascript:|onerror=|onload=)\") {\n        return 403;\n    }\n\n    # Block path traversal\n    if ($uri ~* \"(\\.\\.\\/|\\.\\.\\\\)\") {\n        return 403;\n    }\n\n    # Block suspicious user agents\n    if ($http_user_agent ~* (nmap|nikto|wikto|sf|sqlmap|bsqlbf|w3af|acunetix|havij|appscan)) {\n        return 403;\n    }\n\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#validate-required-headers","title":"Validate Required Headers","text":"<pre><code>location /api/ {\n    # Require User-Agent header\n    if ($http_user_agent = \"\") {\n        return 403 '{\"error\": \"User-Agent header required\"}';\n    }\n\n    # Require Content-Type for POST/PUT\n    if ($request_method ~ ^(POST|PUT)$) {\n        set $has_content_type 0;\n        if ($http_content_type ~ \"application/json\") {\n            set $has_content_type 1;\n        }\n        if ($has_content_type = 0) {\n            return 415 '{\"error\": \"Content-Type must be application/json\"}';\n        }\n    }\n\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#logging-and-monitoring","title":"Logging and Monitoring","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#security-focused-logging","title":"Security-Focused Logging","text":"<pre><code>log_format security '$remote_addr - $remote_user [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\" '\n                    'request_id=$request_id '\n                    'limit_req_status=$limit_req_status '\n                    'upstream_addr=$upstream_addr '\n                    'upstream_status=$upstream_status';\n\naccess_log /var/log/nginx/security.log security;\n\n# Log rate limit violations separately\nerror_log /var/log/nginx/rate_limit.log warn;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#failed-request-logging","title":"Failed Request Logging","text":"<pre><code>map $status $loggable {\n    ~^[23] 0;    # Don't log success\n    default 1;   # Log errors and rate limits\n}\n\naccess_log /var/log/nginx/failed_requests.log combined if=$loggable;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#modsecurity-waf-integration-optional","title":"ModSecurity WAF Integration (Optional)","text":"<pre><code># Install: apt-get install libnginx-mod-security\n# Load module in nginx.conf\nload_module modules/ngx_http_modsecurity_module.so;\n\nhttp {\n    modsecurity on;\n    modsecurity_rules_file /etc/nginx/modsec/main.conf;\n\n    server {\n        location /api/ {\n            modsecurity_rules '\n                SecRule ARGS \"@rx select.*from\" \"id:1,deny,status:403,msg:SQL Injection Detected\"\n            ';\n            proxy_pass http://template_business_api;\n        }\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#security-checklist","title":"Security Checklist","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#essential","title":"Essential","text":"<ul> <li> Remove <code>server_tokens</code> (hide nginx version)</li> <li> Set all security headers (X-Frame-Options, CSP, etc.)</li> <li> Enable HTTPS with strong TLS configuration</li> <li> Implement rate limiting on all public endpoints</li> <li> Set request size limits</li> <li> Configure CORS properly (don't use <code>*</code> in production)</li> <li> Restrict admin endpoints to internal IPs</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#recommended","title":"Recommended","text":"<ul> <li> Enable HSTS with long max-age</li> <li> Implement connection limiting</li> <li> Configure timeout settings to prevent slow attacks</li> <li> Block suspicious user agents and patterns</li> <li> Set up security-focused logging</li> <li> Use GeoIP blocking if applicable</li> <li> Implement request validation</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#advanced","title":"Advanced","text":"<ul> <li> Deploy ModSecurity WAF</li> <li> Set up fail2ban for automated IP blocking</li> <li> Implement certificate pinning (HPKP)</li> <li> Use OCSP stapling</li> <li> Deploy DDoS mitigation (Cloudflare, AWS Shield, etc.)</li> <li> Implement API key validation at gateway level</li> <li> Set up intrusion detection system (IDS)</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#testing-security-configuration","title":"Testing Security Configuration","text":"<pre><code># Test security headers\ncurl -I https://api.example.com\n\n# Test rate limiting\nfor i in {1..100}; do curl https://api.example.com/api/; done\n\n# Test blocked patterns\ncurl \"https://api.example.com/api/?id=1' OR '1'='1\"\n\n# Test SSL configuration\nnmap --script ssl-enum-ciphers -p 443 api.example.com\n\n# Or use online tools:\n# - https://securityheaders.com\n# - https://www.ssllabs.com/ssltest/\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#common-security-pitfalls","title":"Common Security Pitfalls","text":""},{"location":"atomic/infrastructure/api-gateway/security-hardening/#dont-use-if-for-security","title":"\u274c Don't Use <code>if</code> for Security","text":"<pre><code># BAD - if is evil in location context\nlocation /api/ {\n    if ($http_user_agent ~* bot) {\n        return 403;\n    }\n    proxy_pass http://template_business_api;\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#use-map-instead","title":"\u2705 Use <code>map</code> Instead","text":"<pre><code># GOOD - use map directive\nmap $http_user_agent $is_bot {\n    default 0;\n    ~*bot 1;\n}\n\nserver {\n    location /api/ {\n        if ($is_bot) {\n            return 403;\n        }\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#dont-trust-x-forwarded-for","title":"\u274c Don't Trust X-Forwarded-For","text":"<pre><code># BAD - easily spoofed\nlimit_req_zone $http_x_forwarded_for zone=bad:10m rate=10r/s;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#use-binary_remote_addr","title":"\u2705 Use $binary_remote_addr","text":"<pre><code># GOOD - uses actual client IP\nlimit_req_zone $binary_remote_addr zone=good:10m rate=10r/s;\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/security-hardening/#related-documentation","title":"Related Documentation","text":"<ul> <li>Nginx Setup - Basic nginx configuration</li> <li>SSL Configuration - HTTPS and TLS setup</li> <li>Routing Patterns - Request routing strategies</li> <li>Security Testing Guide - Testing security controls</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/","title":"SSL/TLS Configuration for Nginx","text":"<p>This document covers HTTPS setup, certificate management, and TLS best practices for Nginx as an API Gateway.</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#ssltls-basics","title":"SSL/TLS Basics","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#why-https-is-mandatory","title":"Why HTTPS is Mandatory","text":"<ol> <li>Data Encryption: Protects data in transit from eavesdropping</li> <li>Authentication: Verifies server identity</li> <li>Data Integrity: Prevents tampering with requests/responses</li> <li>SEO and Trust: Required by browsers, improves search rankings</li> <li>Compliance: Required by PCI-DSS, GDPR, and other regulations</li> </ol>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#certificate-options","title":"Certificate Options","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#1-lets-encrypt-free-automated","title":"1. Let's Encrypt (Free, Automated)","text":"<p>Pros: Free, automated renewal, trusted by all browsers Cons: 90-day validity, requires public domain</p> <pre><code># Install certbot\nsudo apt-get install certbot python3-certbot-nginx\n\n# Obtain certificate\nsudo certbot --nginx -d api.example.com -d www.example.com\n\n# Auto-renewal (already set up by certbot)\nsudo certbot renew --dry-run\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#2-self-signed-certificates-development-only","title":"2. Self-Signed Certificates (Development Only)","text":"<pre><code># Generate self-signed certificate (valid for 365 days)\nopenssl req -x509 -nodes -days 365 \\\n  -newkey rsa:2048 \\\n  -keyout /etc/nginx/certs/selfsigned.key \\\n  -out /etc/nginx/certs/selfsigned.crt \\\n  -subj \"/C=US/ST=State/L=City/O=Organization/CN=localhost\"\n\n# Generate Diffie-Hellman parameters\nopenssl dhparam -out /etc/nginx/certs/dhparam.pem 2048\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#3-commercial-certificates","title":"3. Commercial Certificates","text":"<p>Purchase from trusted CA (DigiCert, Sectigo, etc.) and install:</p> <pre><code># Place certificate and key\n/etc/nginx/certs/\n\u251c\u2500\u2500 example.com.crt       # SSL certificate\n\u251c\u2500\u2500 example.com.key       # Private key\n\u251c\u2500\u2500 ca-bundle.crt         # CA intermediate certificates\n\u2514\u2500\u2500 dhparam.pem           # DH parameters\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#basic-https-configuration","title":"Basic HTTPS Configuration","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#minimal-https-setup","title":"Minimal HTTPS Setup","text":"<pre><code>server {\n    listen 80;\n    server_name api.example.com;\n\n    # Redirect HTTP to HTTPS\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.example.com;\n\n    # SSL certificate\n    ssl_certificate /etc/nginx/certs/example.com.crt;\n    ssl_certificate_key /etc/nginx/certs/example.com.key;\n\n    # Basic SSL settings\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers HIGH:!aNULL:!MD5;\n\n    location / {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#production-grade-ssl-configuration","title":"Production-Grade SSL Configuration","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#complete-secure-configuration","title":"Complete Secure Configuration","text":"<pre><code># SSL configuration in separate file: /etc/nginx/conf.d/ssl.conf\n\n# SSL session cache and timeout\nssl_session_cache shared:SSL:10m;\nssl_session_timeout 10m;\n\n# DH parameters for perfect forward secrecy\nssl_dhparam /etc/nginx/certs/dhparam.pem;\n\n# Modern TLS protocols only\nssl_protocols TLSv1.2 TLSv1.3;\n\n# Strong cipher suite (Mozilla Intermediate profile)\nssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';\n\n# Server prefers its cipher order\nssl_prefer_server_ciphers on;\n\n# OCSP stapling for faster SSL handshakes\nssl_stapling on;\nssl_stapling_verify on;\nssl_trusted_certificate /etc/nginx/certs/ca-bundle.crt;\nresolver 8.8.8.8 8.8.4.4 valid=300s;\nresolver_timeout 5s;\n\n# Security headers\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\nadd_header X-Frame-Options \"DENY\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\nserver {\n    listen 80;\n    server_name api.example.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.example.com;\n\n    # SSL certificate\n    ssl_certificate /etc/nginx/certs/example.com.crt;\n    ssl_certificate_key /etc/nginx/certs/example.com.key;\n\n    location / {\n        proxy_pass http://template_business_api;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#mozilla-ssl-configuration-generator","title":"Mozilla SSL Configuration Generator","text":"<p>Use Mozilla SSL Configuration Generator for up-to-date cipher suites:</p> <p>Modern (TLS 1.3 only, newer browsers) Intermediate (TLS 1.2+, recommended) Old (TLS 1.0+, legacy compatibility)</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#docker-integration","title":"Docker Integration","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#dockerfile-with-ssl-support","title":"Dockerfile with SSL Support","text":"<pre><code>FROM nginx:1.25-alpine\n\n# Install certbot (for Let's Encrypt)\nRUN apk add --no-cache certbot certbot-nginx\n\n# Copy nginx configuration\nCOPY nginx.conf /etc/nginx/nginx.conf\nCOPY conf.d/ /etc/nginx/conf.d/\n\n# Create directories for certificates\nRUN mkdir -p /etc/nginx/certs /var/www/certbot\n\n# Copy certificates (if not using Let's Encrypt)\n# COPY certs/ /etc/nginx/certs/\n\n# Generate DH parameters if not provided\nRUN if [ ! -f /etc/nginx/certs/dhparam.pem ]; then \\\n        openssl dhparam -out /etc/nginx/certs/dhparam.pem 2048; \\\n    fi\n\nEXPOSE 80 443\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#docker-compose-with-lets-encrypt","title":"Docker Compose with Let's Encrypt","text":"<pre><code>services:\n  nginx:\n    build: ./nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      # Nginx config (read-only)\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n\n      # Let's Encrypt certificates\n      - certbot-etc:/etc/letsencrypt\n      - certbot-var:/var/lib/letsencrypt\n\n      # Challenge directory\n      - ./nginx/html:/var/www/certbot:ro\n\n    networks:\n      - app_network\n    restart: unless-stopped\n\n  certbot:\n    image: certbot/certbot:latest\n    volumes:\n      - certbot-etc:/etc/letsencrypt\n      - certbot-var:/var/lib/letsencrypt\n      - ./nginx/html:/var/www/certbot\n    command: &gt;\n      certonly --webroot --webroot-path=/var/www/certbot\n      --email admin@example.com\n      --agree-tos\n      --no-eff-email\n      -d api.example.com\n    depends_on:\n      - nginx\n\nvolumes:\n  certbot-etc:\n  certbot-var:\n\nnetworks:\n  app_network:\n    driver: bridge\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#nginx-config-for-lets-encrypt-challenge","title":"Nginx Config for Let's Encrypt Challenge","text":"<pre><code>server {\n    listen 80;\n    server_name api.example.com;\n\n    # Let's Encrypt challenge\n    location /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n\n    # Redirect everything else to HTTPS\n    location / {\n        return 301 https://$server_name$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.example.com;\n\n    # Let's Encrypt certificates\n    ssl_certificate /etc/letsencrypt/live/api.example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/api.example.com/privkey.pem;\n\n    # Include SSL configuration\n    include /etc/nginx/conf.d/ssl-params.conf;\n\n    location / {\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#certificate-renewal","title":"Certificate Renewal","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#lets-encrypt-auto-renewal","title":"Let's Encrypt Auto-Renewal","text":"<pre><code># Add to crontab (runs twice daily)\n0 0,12 * * * docker-compose exec certbot renew --quiet &amp;&amp; docker-compose exec nginx nginx -s reload\n</code></pre> <p>Or use docker-compose:</p> <pre><code>services:\n  certbot-renew:\n    image: certbot/certbot:latest\n    volumes:\n      - certbot-etc:/etc/letsencrypt\n      - certbot-var:/var/lib/letsencrypt\n      - ./nginx/html:/var/www/certbot\n    entrypoint: \"/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h &amp; wait $${!}; done;'\"\n    depends_on:\n      - nginx\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#manual-certificate-renewal","title":"Manual Certificate Renewal","text":"<pre><code># Renew Let's Encrypt certificate\ndocker-compose exec certbot certbot renew\n\n# Reload nginx\ndocker-compose exec nginx nginx -s reload\n\n# Or restart nginx\ndocker-compose restart nginx\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#multi-domain-and-wildcard-certificates","title":"Multi-Domain and Wildcard Certificates","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#multiple-domains","title":"Multiple Domains","text":"<pre><code># Single certificate for multiple domains\nsudo certbot --nginx \\\n  -d api.example.com \\\n  -d www.example.com \\\n  -d admin.example.com\n</code></pre> <pre><code>server {\n    listen 443 ssl http2;\n    server_name api.example.com www.example.com admin.example.com;\n\n    ssl_certificate /etc/letsencrypt/live/api.example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/api.example.com/privkey.pem;\n\n    # Route based on hostname\n    if ($host = api.example.com) {\n        proxy_pass http://template_business_api;\n    }\n\n    if ($host = admin.example.com) {\n        proxy_pass http://admin_service;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#wildcard-certificates","title":"Wildcard Certificates","text":"<pre><code># Wildcard certificate (requires DNS validation)\nsudo certbot certonly \\\n  --manual \\\n  --preferred-challenges dns \\\n  -d '*.example.com' \\\n  -d example.com\n</code></pre> <pre><code>server {\n    listen 443 ssl http2;\n    server_name ~^(?&lt;subdomain&gt;.+)\\.example\\.com$;\n\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n\n    # Route based on subdomain\n    location / {\n        proxy_pass http://$subdomain-service;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#client-certificate-authentication-mtls","title":"Client Certificate Authentication (mTLS)","text":"<pre><code>server {\n    listen 443 ssl http2;\n    server_name api.example.com;\n\n    # Server certificates\n    ssl_certificate /etc/nginx/certs/server.crt;\n    ssl_certificate_key /etc/nginx/certs/server.key;\n\n    # Client certificate verification\n    ssl_client_certificate /etc/nginx/certs/ca.crt;\n    ssl_verify_client on;\n    ssl_verify_depth 2;\n\n    location / {\n        # Pass client cert info to backend\n        proxy_set_header X-SSL-Client-Cert $ssl_client_cert;\n        proxy_set_header X-SSL-Client-DN $ssl_client_s_dn;\n        proxy_pass http://template_business_api;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#monitoring-ssltls","title":"Monitoring SSL/TLS","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#certificate-expiry-monitoring","title":"Certificate Expiry Monitoring","text":"<pre><code># Check certificate expiration\necho | openssl s_client -connect api.example.com:443 2&gt;/dev/null | openssl x509 -noout -dates\n\n# Get days until expiry\necho | openssl s_client -connect api.example.com:443 2&gt;/dev/null | openssl x509 -noout -checkend $((86400*30)) &amp;&amp; echo \"Certificate valid for 30+ days\" || echo \"Certificate expires soon\"\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#ssltls-metrics-for-prometheus","title":"SSL/TLS Metrics for Prometheus","text":"<pre><code># nginx-prometheus-exporter can track SSL metrics\n# Install: https://github.com/nginxinc/nginx-prometheus-exporter\n\nserver {\n    listen 9113;\n    location /metrics {\n        stub_status;\n    }\n}\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#testing-ssl-configuration","title":"Testing SSL Configuration","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#command-line-testing","title":"Command-Line Testing","text":"<pre><code># Test SSL connection\nopenssl s_client -connect api.example.com:443\n\n# Test specific TLS version\nopenssl s_client -connect api.example.com:443 -tls1_2\nopenssl s_client -connect api.example.com:443 -tls1_3\n\n# Check certificate chain\nopenssl s_client -connect api.example.com:443 -showcerts\n\n# Verify certificate\necho | openssl s_client -connect api.example.com:443 2&gt;/dev/null | openssl x509 -noout -text\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#online-ssl-testing-tools","title":"Online SSL Testing Tools","text":"<ol> <li>SSL Labs: https://www.ssllabs.com/ssltest/</li> <li>Comprehensive SSL/TLS analysis</li> <li> <p>Grade your configuration (aim for A+)</p> </li> <li> <p>Security Headers: https://securityheaders.com/</p> </li> <li> <p>Check security headers (HSTS, CSP, etc.)</p> </li> <li> <p>SSL Checker: https://www.sslshopper.com/ssl-checker.html</p> </li> <li>Verify certificate installation</li> </ol>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#common-ssl-issues","title":"Common SSL Issues","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#issue-err_cert_common_name_invalid","title":"Issue: ERR_CERT_COMMON_NAME_INVALID","text":"<p>Cause: Certificate doesn't match domain name Solution: Ensure certificate CN/SAN matches your domain</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#issue-err_cert_authority_invalid","title":"Issue: ERR_CERT_AUTHORITY_INVALID","text":"<p>Cause: Self-signed certificate or untrusted CA Solution: Use trusted CA (Let's Encrypt) or import CA to client</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#issue-mixed-content-warnings","title":"Issue: Mixed Content Warnings","text":"<p>Cause: HTTPS page loading HTTP resources Solution: Use relative URLs or HTTPS for all resources</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#issue-certificate-expired","title":"Issue: Certificate Expired","text":"<p>Cause: Forgot to renew certificate Solution: Set up auto-renewal (cron job or certbot-renew container)</p>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#ssltls-best-practices","title":"SSL/TLS Best Practices","text":""},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#security","title":"Security","text":"<ul> <li>\u2705 Use TLS 1.2 and 1.3 only (disable TLS 1.0/1.1)</li> <li>\u2705 Use strong cipher suites (ECDHE, AES-GCM, ChaCha20)</li> <li>\u2705 Enable HSTS with long max-age (31536000 = 1 year)</li> <li>\u2705 Enable OCSP stapling for faster handshakes</li> <li>\u2705 Generate strong DH parameters (2048-bit minimum)</li> <li>\u2705 Use certificate from trusted CA (not self-signed)</li> <li>\u274c Don't use SHA-1 certificates</li> <li>\u274c Don't allow SSL compression (CRIME attack)</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#performance","title":"Performance","text":"<ul> <li>\u2705 Enable SSL session caching</li> <li>\u2705 Use HTTP/2 for better performance</li> <li>\u2705 Enable keep-alive connections</li> <li>\u2705 Use CDN for static content with HTTPS</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#operations","title":"Operations","text":"<ul> <li>\u2705 Automate certificate renewal</li> <li>\u2705 Monitor certificate expiry (alert 30 days before)</li> <li>\u2705 Keep private keys secure (600 permissions, never commit to git)</li> <li>\u2705 Use separate certificates per environment (dev/staging/prod)</li> <li>\u2705 Test SSL configuration after changes</li> </ul>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#quick-ssl-setup-script","title":"Quick SSL Setup Script","text":"<pre><code>#!/bin/bash\n# setup-ssl.sh - Quick SSL setup for development\n\nDOMAIN=${1:-localhost}\nCERT_DIR=\"/etc/nginx/certs\"\n\nmkdir -p \"$CERT_DIR\"\n\n# Generate self-signed certificate\nopenssl req -x509 -nodes -days 365 \\\n  -newkey rsa:2048 \\\n  -keyout \"$CERT_DIR/$DOMAIN.key\" \\\n  -out \"$CERT_DIR/$DOMAIN.crt\" \\\n  -subj \"/C=US/ST=State/L=City/O=Organization/CN=$DOMAIN\"\n\n# Generate DH parameters\nopenssl dhparam -out \"$CERT_DIR/dhparam.pem\" 2048\n\n# Set permissions\nchmod 600 \"$CERT_DIR/$DOMAIN.key\"\nchmod 644 \"$CERT_DIR/$DOMAIN.crt\"\nchmod 644 \"$CERT_DIR/dhparam.pem\"\n\necho \"SSL certificates generated for $DOMAIN\"\necho \"Certificate: $CERT_DIR/$DOMAIN.crt\"\necho \"Private key: $CERT_DIR/$DOMAIN.key\"\necho \"DH params: $CERT_DIR/dhparam.pem\"\n</code></pre>"},{"location":"atomic/infrastructure/api-gateway/ssl-configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>Nginx Setup - Basic nginx configuration</li> <li>Security Hardening - Additional security measures</li> <li>Routing Patterns - Request routing with HTTPS</li> <li>Container Networking - Docker networking with SSL</li> </ul>"},{"location":"atomic/infrastructure/configuration/configuration-validation/","title":"Configuration Validation","text":"<p>Validate configuration at startup to prevent runtime surprises.</p>"},{"location":"atomic/infrastructure/configuration/configuration-validation/#techniques","title":"Techniques","text":"<ul> <li>Use Pydantic validation to ensure required values are present and typed.</li> <li>Perform cross-field checks (e.g., if feature flag enabled, ensure supporting URLs are provided).</li> <li>Validate external connectivity (Redis ping, database connection) inside lifespan startup.</li> </ul>"},{"location":"atomic/infrastructure/configuration/configuration-validation/#failure-handling","title":"Failure Handling","text":"<ul> <li>Fail fast when configuration is invalid; emit clear error messages in logs and exit with non-zero status.</li> <li>Provide remediation hints (<code>export API_DATA_SERVICE_URL=...</code>).</li> </ul>"},{"location":"atomic/infrastructure/configuration/configuration-validation/#testing","title":"Testing","text":"<ul> <li>Add unit tests for settings validators and edge cases.</li> <li>Run smoke tests in CI that load settings from <code>.env.example</code> to ensure defaults remain valid.</li> </ul>"},{"location":"atomic/infrastructure/configuration/configuration-validation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/configuration/settings-patterns.md</code></li> <li><code>docs/atomic/infrastructure/deployment/ci-cd-patterns.md</code></li> </ul>"},{"location":"atomic/infrastructure/configuration/environment-variables/","title":"Environment Variables Management","text":"<p>Environment variables provide runtime configuration without rebuilding images.</p>"},{"location":"atomic/infrastructure/configuration/environment-variables/#principles","title":"Principles","text":"<ul> <li>Define variable names in <code>Settings</code> classes and document them in service READMEs.</li> <li>Provide <code>.env.example</code> files with safe defaults; never commit secrets.</li> <li>Names use uppercase snake case (<code>DATA_SERVICE_URL</code>, <code>RABBITMQ_URL</code>).</li> <li>Scope variables per service to avoid implicit coupling.</li> </ul>"},{"location":"atomic/infrastructure/configuration/environment-variables/#loading-strategy","title":"Loading Strategy","text":"<ul> <li>Use <code>pydantic.BaseSettings</code> or similar to load variables once at startup.</li> <li>Support environment prefixes to differentiate services (<code>API_</code>, <code>BOT_</code>).</li> <li>Fail fast when required variables are missing; include clear error messages.</li> </ul>"},{"location":"atomic/infrastructure/configuration/environment-variables/#environments","title":"Environments","text":"<ul> <li>Maintain separate <code>.env</code> files for local development vs. production (managed via secret stores).</li> <li>In Kubernetes, map environment variables from ConfigMaps (non-sensitive) and Secrets (sensitive).</li> </ul>"},{"location":"atomic/infrastructure/configuration/environment-variables/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/configuration/settings-patterns.md</code></li> <li><code>docs/atomic/infrastructure/deployment/development-environment.md</code></li> </ul>"},{"location":"atomic/infrastructure/configuration/secrets-management/","title":"Secrets Management","text":"<p>Protect credentials, tokens, and certificates across environments.</p>"},{"location":"atomic/infrastructure/configuration/secrets-management/#practices","title":"Practices","text":"<ul> <li>Store secrets in dedicated secret managers (Vault, AWS Secrets Manager, Kubernetes Secrets) rather than <code>.env</code> files.</li> <li>Restrict access using least privilege roles; audit secret usage regularly.</li> <li>Rotate secrets on a defined cadence; automate rotation when supported.</li> <li>Encrypt secrets at rest and in transit.</li> </ul>"},{"location":"atomic/infrastructure/configuration/secrets-management/#application-loading","title":"Application Loading","text":"<ul> <li>Inject secrets via environment variables or mounted files at runtime.</li> <li>Load them using <code>Settings</code> classes and keep them out of logs (mask values when logging configuration).</li> <li>Provide fallbacks for local development (e.g., <code>.env.local</code> stored outside version control).</li> </ul>"},{"location":"atomic/infrastructure/configuration/secrets-management/#incident-response","title":"Incident Response","text":"<ul> <li>Document revocation steps (invalidate tokens, rotate keys) in runbooks.</li> <li>Detect leaked secrets using scanners (Trufflehog, GitGuardian) and fail CI on findings.</li> </ul>"},{"location":"atomic/infrastructure/configuration/secrets-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/configuration/configuration-validation.md</code></li> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> </ul>"},{"location":"atomic/infrastructure/configuration/settings-patterns/","title":"Settings Patterns","text":"<p>Centralise configuration logic to keep services predictable.</p>"},{"location":"atomic/infrastructure/configuration/settings-patterns/#basesettings","title":"BaseSettings","text":"<pre><code>from pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    service_name: str = \"template_business_api\"\n    data_service_url: str\n    redis_url: str\n\n    class Config:\n        env_prefix = \"API_\"\n        case_sensitive = False\n</code></pre> <ul> <li>Instantiate settings once at startup (<code>get_settings()</code> with <code>lru_cache</code>).</li> <li>Support environment-specific prefixes to avoid clashes.</li> <li>Validate values with Pydantic constraints (URLs, enums, ranges).</li> </ul>"},{"location":"atomic/infrastructure/configuration/settings-patterns/#hierarchical-config","title":"Hierarchical Config","text":"<ul> <li>Compose settings: global settings + service overrides + feature-specific settings (e.g., <code>RabbitMQSettings</code>).</li> <li>Provide typed accessors for nested configs to reduce stringly typed usage.</li> </ul>"},{"location":"atomic/infrastructure/configuration/settings-patterns/#testing","title":"Testing","text":"<ul> <li>Override environment variables within tests using <code>monkeypatch</code>.</li> <li>Provide factory helpers to create <code>Settings</code> with sensible defaults for unit tests.</li> </ul>"},{"location":"atomic/infrastructure/configuration/settings-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/configuration/environment-variables.md</code></li> <li><code>docs/atomic/infrastructure/configuration/configuration-validation.md</code></li> </ul>"},{"location":"atomic/infrastructure/containerization/container-networking/","title":"Container Networking","text":"<p>Reliable networking ensures services communicate securely across environments.</p>"},{"location":"atomic/infrastructure/containerization/container-networking/#docker-compose-local","title":"Docker Compose / Local","text":"<ul> <li>Use named networks to segment traffic (<code>backend</code>, <code>frontend</code>).</li> <li>Reference services by Compose service name (DNS) instead of localhost ports.</li> <li>Expose only public-facing ports to the host; keep internal dependencies private.</li> </ul>"},{"location":"atomic/infrastructure/containerization/container-networking/#kubernetes-production","title":"Kubernetes / Production","text":"<ul> <li>Map services to ClusterIP or headless services depending on discovery needs.</li> <li>Apply network policies to restrict ingress/egress between namespaces.</li> <li>Use service meshes (Istio, Linkerd) when advanced routing, mTLS, or traffic shifting is required.</li> </ul>"},{"location":"atomic/infrastructure/containerization/container-networking/#observability","title":"Observability","text":"<ul> <li>Capture connection metrics (error counts, latency) via service mesh or sidecar instrumentation.</li> <li>Log source and destination identifiers for troubleshooting cross-service calls.</li> </ul>"},{"location":"atomic/infrastructure/containerization/container-networking/#security","title":"Security","text":"<ul> <li>Enforce TLS in transit (service mesh or sidecar proxies).</li> <li>Use mutual TLS or API gateways for external ingress.</li> </ul>"},{"location":"atomic/infrastructure/containerization/container-networking/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code></li> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> </ul>"},{"location":"atomic/infrastructure/containerization/docker-compose-setup/","title":"Docker Compose Setup","text":"<p>Compose orchestrates local development environments. Keep configuration deterministic and aligned with production topology.</p>"},{"location":"atomic/infrastructure/containerization/docker-compose-setup/#structure","title":"Structure","text":"<ul> <li>Define services for each microservice, data store, and supporting dependency (Redis, RabbitMQ, PostgreSQL).</li> <li>Use <code>.env</code> files for secrets-free configuration (ports, credentials, feature toggles).</li> <li>Mount source code only for services that require live reload; production builds should copy code during image build.</li> <li>Configure networks to isolate internal communication (<code>backend</code>) from external exposure (<code>public</code>).</li> </ul>"},{"location":"atomic/infrastructure/containerization/docker-compose-setup/#best-practices","title":"Best Practices","text":"<ul> <li>Set <code>depends_on</code> with health checks or wait scripts to avoid race conditions.</li> <li>Persist stateful data (PostgreSQL, RabbitMQ) via named volumes; keep them separate per service.</li> <li>Mirror production environment variables to reduce drift.</li> <li>Keep Compose files under version control and document startup commands in the project README.</li> </ul>"},{"location":"atomic/infrastructure/containerization/docker-compose-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/containerization/volume-management.md</code></li> <li><code>docs/atomic/infrastructure/deployment/development-environment.md</code></li> </ul>"},{"location":"atomic/infrastructure/containerization/dockerfile-patterns/","title":"Dockerfile Patterns","text":"<p>Produce small, secure images that align with the platform runtime.</p>"},{"location":"atomic/infrastructure/containerization/dockerfile-patterns/#guidelines","title":"Guidelines","text":"<ul> <li>Use official Python 3.12 slim images as the base.</li> <li>Install build dependencies separately from runtime dependencies; clean up caches to keep images small.</li> <li>Set the working directory to <code>/app</code> and copy only necessary files.</li> <li>Pin OS packages to avoid nondeterministic builds.</li> <li>Run as non-root (<code>USER app</code>) and create the user in the Dockerfile.</li> <li>Expose ports via configuration variables rather than hard-coded values.</li> </ul>"},{"location":"atomic/infrastructure/containerization/dockerfile-patterns/#example-skeleton","title":"Example Skeleton","text":"<pre><code>FROM python:3.12-slim AS base\nENV PYTHONUNBUFFERED=1\nWORKDIR /app\n\nCOPY pyproject.toml uv.lock ./\nRUN pip install --no-cache-dir uv \\\n    &amp;&amp; uv pip install --system -r requirements.txt\n\nCOPY src ./src\nCMD [\"python\", \"-m\", \"src.main\"]\n</code></pre>"},{"location":"atomic/infrastructure/containerization/dockerfile-patterns/#security","title":"Security","text":"<ul> <li>Use multi-stage builds to exclude dev tooling.</li> <li>Scan images regularly (Trivy, Grype) and fail CI on critical vulnerabilities.</li> <li>Keep base images updated; patch vulnerabilities promptly.</li> </ul>"},{"location":"atomic/infrastructure/containerization/dockerfile-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/containerization/multi-stage-builds.md</code></li> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> </ul>"},{"location":"atomic/infrastructure/containerization/multi-stage-builds/","title":"Multi-Stage Builds","text":"<p>Multi-stage builds keep images lean by separating build-time dependencies from runtime artefacts.</p>"},{"location":"atomic/infrastructure/containerization/multi-stage-builds/#pattern","title":"Pattern","text":"<pre><code>FROM python:3.12-slim AS builder\nWORKDIR /app\nCOPY pyproject.toml uv.lock ./\nRUN pip install --no-cache-dir uv \\\n    &amp;&amp; uv pip install --system -r requirements.txt\nCOPY src ./src\nRUN uv pip install --system .\n\nFROM python:3.12-slim AS runtime\nENV PYTHONUNBUFFERED=1\nWORKDIR /app\nCOPY --from=builder /usr/local/lib/python3.12 /usr/local/lib/python3.12\nCOPY --from=builder /app/src ./src\nUSER app\nCMD [\"python\", \"-m\", \"src.main\"]\n</code></pre>"},{"location":"atomic/infrastructure/containerization/multi-stage-builds/#guidelines","title":"Guidelines","text":"<ul> <li>Place tooling (compilers, build helpers) in the builder stage only.</li> <li>Copy only required artefacts into the runtime stage (application code, dependencies, config templates).</li> <li>Validate image size in CI to detect regressions.</li> <li>Use build arguments to toggle optional components without duplicating Dockerfiles.</li> </ul>"},{"location":"atomic/infrastructure/containerization/multi-stage-builds/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/containerization/dockerfile-patterns.md</code></li> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> </ul>"},{"location":"atomic/infrastructure/containerization/volume-management/","title":"Container Volume Management","text":"<p>Persist stateful data with volumes while keeping stateless services disposable.</p>"},{"location":"atomic/infrastructure/containerization/volume-management/#principles","title":"Principles","text":"<ul> <li>Use named Docker volumes or Kubernetes PersistentVolumeClaims for databases, queues, and caches.</li> <li>Keep volumes per service to avoid cross-service coupling and simplify backups.</li> <li>Store configuration templates in images; mount only secrets or environment-specific files.</li> <li>Avoid bind mounts in production to prevent drift and permission issues.</li> </ul>"},{"location":"atomic/infrastructure/containerization/volume-management/#backups","title":"Backups","text":"<ul> <li>Schedule regular backups for persistent volumes (database dumps, snapshot tools).</li> <li>Test restoration procedures in staging environments.</li> </ul>"},{"location":"atomic/infrastructure/containerization/volume-management/#security","title":"Security","text":"<ul> <li>Restrict volume access to the owning container; drop root privileges to avoid overexposure.</li> <li>Encrypt volumes when storing sensitive data (cloud-managed disks, LUKS).</li> </ul>"},{"location":"atomic/infrastructure/containerization/volume-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> <li><code>docs/atomic/services/data-services/postgres-service-setup.md</code></li> </ul>"},{"location":"atomic/infrastructure/databases/connection-pooling/","title":"Database Connection Pooling","text":"<p>Connection pools balance concurrency and resource usage for data services.</p>"},{"location":"atomic/infrastructure/databases/connection-pooling/#guidelines","title":"Guidelines","text":"<ul> <li>Use async-capable pools (<code>sqlalchemy.asyncio.create_async_engine</code>, Motor connection pools) configured once per process.</li> <li>Size pools based on workload: start with <code>pool_size=10</code> and <code>max_overflow=20</code> for HTTP services; tune using production metrics.</li> <li>Set timeouts (<code>pool_timeout</code>, <code>pool_recycle</code>) to avoid stale connections and detect leaks.</li> <li>Monitor pool utilisation (borrowed connections, wait times) and alert on saturation.</li> <li>Avoid per-request engine creation; reuse pooled sessions through dependency injection.</li> </ul>"},{"location":"atomic/infrastructure/databases/connection-pooling/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Spikes in <code>pool_timeout</code> errors usually indicate blocked transactions or long-running queries\u2014profile and optimize.</li> <li>Recycle connections after network hiccups to avoid using stale sockets.</li> <li>For read replicas, maintain separate pools to keep workloads isolated.</li> </ul>"},{"location":"atomic/infrastructure/databases/connection-pooling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/transaction-management.md</code></li> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> </ul>"},{"location":"atomic/infrastructure/databases/migrations/","title":"Database Migrations","text":"<p>Manage schema changes with automated migrations to keep environments in sync.</p>"},{"location":"atomic/infrastructure/databases/migrations/#tooling","title":"Tooling","text":"<ul> <li>Use Alembic for PostgreSQL; enforce one revision per merge request.</li> <li>For MongoDB, maintain migration scripts (Python modules) that apply incremental changes (indexes, schema adjustments).</li> <li>Version control migration scripts inside each data service repository.</li> </ul>"},{"location":"atomic/infrastructure/databases/migrations/#process","title":"Process","text":"<ol> <li>Generate migration from model changes (<code>alembic revision --autogenerate</code>).</li> <li>Review migration SQL manually; ensure destructive operations are safe.</li> <li>Apply migrations locally and in CI (Testcontainers) before merging.</li> <li>Run migrations during deployment before starting the new application version.</li> </ol>"},{"location":"atomic/infrastructure/databases/migrations/#rollback","title":"Rollback","text":"<ul> <li>Provide downgrade scripts where feasible; if not, document manual rollback steps.</li> <li>Take backups before applying breaking schema changes.</li> </ul>"},{"location":"atomic/infrastructure/databases/migrations/#observability","title":"Observability","text":"<ul> <li>Log migration start/finish events with version numbers.</li> <li>Fail deployments when migrations do not apply cleanly; avoid ignoring errors.</li> </ul>"},{"location":"atomic/infrastructure/databases/migrations/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/transaction-management.md</code></li> <li><code>docs/atomic/infrastructure/deployment/ci-cd-patterns.md</code></li> </ul>"},{"location":"atomic/infrastructure/databases/mongodb-setup/","title":"MongoDB Setup","text":"<p>Prepare MongoDB clusters for document-centric data services.</p>"},{"location":"atomic/infrastructure/databases/mongodb-setup/#configuration-checklist","title":"Configuration Checklist","text":"<ul> <li>Use MongoDB 6.0+ with replica sets to support transactions when required.</li> <li>Enable authentication (<code>SCRAM-SHA-256</code>) and enforce TLS for production traffic.</li> <li>Configure WiredTiger cache size to ~50% of RAM, adjusting for workload.</li> <li>Create separate databases per bounded context to avoid collection leakage.</li> <li>Define indexes ahead of time and manage them via migrations/startup scripts.</li> </ul>"},{"location":"atomic/infrastructure/databases/mongodb-setup/#operational-practices","title":"Operational Practices","text":"<ul> <li>Enable periodic backups (mongodump or continuous backup services) and test restores.</li> <li>Monitor cluster health (replica lag, cache usage, slow queries) via MongoDB Exporter or Atlas metrics.</li> <li>Adjust connection limits to match driver pool sizes.</li> </ul>"},{"location":"atomic/infrastructure/databases/mongodb-setup/#security","title":"Security","text":"<ul> <li>Restrict network access with firewalls or security groups.</li> <li>Rotate credentials using secret managers; avoid embedding passwords in configs.</li> <li>Enable auditing if regulatory requirements apply.</li> </ul>"},{"location":"atomic/infrastructure/databases/mongodb-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/mongo-service-setup.md</code></li> <li><code>docs/atomic/infrastructure/databases/performance-optimization.md</code></li> </ul>"},{"location":"atomic/infrastructure/databases/performance-optimization/","title":"Database Performance Optimization","text":"<p>Optimise databases proactively to maintain low latency and predictable throughput.</p>"},{"location":"atomic/infrastructure/databases/performance-optimization/#monitoring","title":"Monitoring","text":"<ul> <li>Track query latency, lock time, cache hit ratios, and replication lag via exporters.</li> <li>Instrument application code with metrics for slow queries and connection pool waits.</li> </ul>"},{"location":"atomic/infrastructure/databases/performance-optimization/#postgresql-tips","title":"PostgreSQL Tips","text":"<ul> <li>Use <code>EXPLAIN (ANALYZE, BUFFERS)</code> to profile heavy queries.</li> <li>Create composite indexes aligned with filter/order clauses.</li> <li>Vacuum and analyse regularly; configure autovacuum thresholds for large tables.</li> <li>Limit long-running transactions to avoid blocking vacuum and index maintenance.</li> </ul>"},{"location":"atomic/infrastructure/databases/performance-optimization/#mongodb-tips","title":"MongoDB Tips","text":"<ul> <li>Use the profiler sparingly to capture slow query plans.</li> <li>Maintain compound indexes that match query predicates and sort orders.</li> <li>Avoid unbounded array growth in documents; normalize to separate collections when needed.</li> </ul>"},{"location":"atomic/infrastructure/databases/performance-optimization/#capacity-planning","title":"Capacity Planning","text":"<ul> <li>Record baseline performance and growth trends; review quarterly.</li> <li>Scale vertically when CPU or memory saturates; scale horizontally (read replicas, sharding) when needed.</li> </ul>"},{"location":"atomic/infrastructure/databases/performance-optimization/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/testing-strategies.md</code></li> <li><code>docs/atomic/infrastructure/databases/connection-pooling.md</code></li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-replication/","title":"PostgreSQL Replication Setup","text":"<p>Comprehensive guide for PostgreSQL master-slave replication configuration for high availability and read scalability in production deployments (Maturity Level 4).</p>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#overview","title":"Overview","text":"<p>PostgreSQL replication ensures data redundancy, high availability, and improved read performance by maintaining synchronized copies of the database across multiple servers.</p> <p>Use Cases: - High Availability: Automatic failover when master fails - Read Scalability: Distribute read queries across replicas - Disaster Recovery: Geographic replication for business continuity - Zero-Downtime Maintenance: Upgrade replicas without service interruption</p> <p>Required for: Maturity Level 4 (Production) with SLA requirements &gt;99.9%</p>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#prerequisites","title":"Prerequisites","text":"<pre><code># Minimum requirements\nPostgreSQL: 15.x or 16.x\nDocker Compose: 3.8+\nNetwork: Low-latency connection between nodes (&lt;10ms recommended)\nStorage: Fast disk I/O (SSD recommended)\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#replication-architecture","title":"Replication Architecture","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#streaming-replication-recommended","title":"Streaming Replication (Recommended)","text":"<p>PostgreSQL streaming replication provides near real-time data synchronization using Write-Ahead Log (WAL) shipping.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         WAL Stream          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Master    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; \u2502  Replica 1  \u2502\n\u2502 (Read/Write)\u2502                              \u2502 (Read-Only) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502         WAL Stream\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                         \u2502  Replica 2  \u2502\n                                         \u2502 (Read-Only) \u2502\n                                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#replication-modes","title":"Replication Modes","text":"Mode Description Use Case Data Loss Risk Asynchronous Master doesn't wait for replica confirmation High performance, eventual consistency Minimal (&lt;1s of transactions) Synchronous Master waits for at least one replica Strong consistency, slower writes Zero Logical Replication Selective table/row replication Multi-tenant, partial replication Depends on configuration"},{"location":"atomic/infrastructure/databases/postgresql-replication/#docker-compose-configuration","title":"Docker Compose Configuration","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#basic-master-replica-setup","title":"Basic Master-Replica Setup","text":"<pre><code># docker-compose.replication.yml\nversion: '3.8'\n\nservices:\n  postgres_master:\n    image: postgres:16-alpine\n    container_name: postgres-master\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB:-microservices_db}\n      POSTGRES_USER: ${POSTGRES_USER:-postgres}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}\n      POSTGRES_REPLICATION_USER: ${POSTGRES_REPL_USER:-replicator}\n      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPL_PASSWORD:-repl_changeme}\n    volumes:\n      - postgres_master_data:/var/lib/postgresql/data\n      - ./config/master/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n      - ./config/master/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro\n      - ./scripts/init-master.sh:/docker-entrypoint-initdb.d/init-master.sh:ro\n    ports:\n      - \"5432:5432\"\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n    networks:\n      - postgres_replication\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  postgres_replica1:\n    image: postgres:16-alpine\n    container_name: postgres-replica1\n    environment:\n      POSTGRES_MASTER_HOST: postgres_master\n      POSTGRES_MASTER_PORT: 5432\n      POSTGRES_REPLICATION_USER: ${POSTGRES_REPL_USER:-replicator}\n      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPL_PASSWORD:-repl_changeme}\n    volumes:\n      - postgres_replica1_data:/var/lib/postgresql/data\n      - ./config/replica/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n      - ./scripts/init-replica.sh:/docker-entrypoint-initdb.d/init-replica.sh:ro\n    ports:\n      - \"5433:5432\"\n    depends_on:\n      postgres_master:\n        condition: service_healthy\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n    networks:\n      - postgres_replication\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  postgres_replica2:\n    image: postgres:16-alpine\n    container_name: postgres-replica2\n    environment:\n      POSTGRES_MASTER_HOST: postgres_master\n      POSTGRES_MASTER_PORT: 5432\n      POSTGRES_REPLICATION_USER: ${POSTGRES_REPL_USER:-replicator}\n      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPL_PASSWORD:-repl_changeme}\n    volumes:\n      - postgres_replica2_data:/var/lib/postgresql/data\n      - ./config/replica/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n      - ./scripts/init-replica.sh:/docker-entrypoint-initdb.d/init-replica.sh:ro\n    ports:\n      - \"5434:5432\"\n    depends_on:\n      postgres_master:\n        condition: service_healthy\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n    networks:\n      - postgres_replication\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\nvolumes:\n  postgres_master_data:\n  postgres_replica1_data:\n  postgres_replica2_data:\n\nnetworks:\n  postgres_replication:\n    driver: bridge\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#master-configuration","title":"Master Configuration","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#postgresqlconf-master","title":"postgresql.conf (Master)","text":"<pre><code># config/master/postgresql.conf\n\n# Connection settings\nlisten_addresses = '*'\nmax_connections = 200\n\n# Replication settings\nwal_level = replica\nmax_wal_senders = 10\nmax_replication_slots = 10\nwal_keep_size = 1GB\nsynchronous_commit = on\nsynchronous_standby_names = 'replica1,replica2'  # For synchronous replication\n\n# Performance tuning\nshared_buffers = 256MB\neffective_cache_size = 1GB\nmaintenance_work_mem = 64MB\ncheckpoint_completion_target = 0.9\nwal_buffers = 16MB\ndefault_statistics_target = 100\nrandom_page_cost = 1.1\neffective_io_concurrency = 200\nwork_mem = 4MB\nmin_wal_size = 1GB\nmax_wal_size = 4GB\n\n# Logging\nlogging_collector = on\nlog_directory = 'log'\nlog_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\nlog_min_duration_statement = 1000\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_replication_commands = on\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#pg_hbaconf-master","title":"pg_hba.conf (Master)","text":"<pre><code># config/master/pg_hba.conf\n\n# TYPE  DATABASE        USER            ADDRESS                 METHOD\n\n# Local connections\nlocal   all             all                                     trust\nhost    all             all             127.0.0.1/32            md5\nhost    all             all             ::1/128                 md5\n\n# Replication connections\nhost    replication     replicator      0.0.0.0/0               md5\nhost    replication     replicator      ::0/0                   md5\n\n# Application connections\nhost    all             all             0.0.0.0/0               md5\nhost    all             all             ::0/0                   md5\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#master-initialization-script","title":"Master Initialization Script","text":"<pre><code>#!/bin/bash\n# scripts/init-master.sh\n\nset -e\n\necho \"Initializing PostgreSQL master...\"\n\n# Create replication user\npsql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"$POSTGRES_DB\" &lt;&lt;-EOSQL\n    -- Create replication user\n    DO \\$\\$\n    BEGIN\n        IF NOT EXISTS (SELECT FROM pg_catalog.pg_user WHERE usename = '${POSTGRES_REPLICATION_USER}') THEN\n            CREATE USER ${POSTGRES_REPLICATION_USER} WITH REPLICATION ENCRYPTED PASSWORD '${POSTGRES_REPLICATION_PASSWORD}';\n        END IF;\n    END\n    \\$\\$;\n\n    -- Create replication slot for each replica\n    SELECT pg_create_physical_replication_slot('replica1_slot');\n    SELECT pg_create_physical_replication_slot('replica2_slot');\nEOSQL\n\necho \"PostgreSQL master initialization completed\"\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#replica-configuration","title":"Replica Configuration","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#postgresqlconf-replica","title":"postgresql.conf (Replica)","text":"<pre><code># config/replica/postgresql.conf\n\n# Connection settings\nlisten_addresses = '*'\nmax_connections = 200\n\n# Replication settings\nhot_standby = on\nmax_standby_streaming_delay = 30s\nwal_receiver_status_interval = 10s\nhot_standby_feedback = on\n\n# Performance tuning (same as master)\nshared_buffers = 256MB\neffective_cache_size = 1GB\nmaintenance_work_mem = 64MB\nwork_mem = 4MB\n\n# Logging\nlogging_collector = on\nlog_directory = 'log'\nlog_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\nlog_min_duration_statement = 1000\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#replica-initialization-script","title":"Replica Initialization Script","text":"<pre><code>#!/bin/bash\n# scripts/init-replica.sh\n\nset -e\n\necho \"Initializing PostgreSQL replica...\"\n\n# Wait for master to be ready\nuntil pg_isready -h ${POSTGRES_MASTER_HOST} -p ${POSTGRES_MASTER_PORT}; do\n  echo \"Waiting for master to be ready...\"\n  sleep 2\ndone\n\n# Remove existing data directory\nrm -rf ${PGDATA}/*\n\n# Clone data from master using pg_basebackup\nPGPASSWORD=${POSTGRES_REPLICATION_PASSWORD} pg_basebackup \\\n    -h ${POSTGRES_MASTER_HOST} \\\n    -p ${POSTGRES_MASTER_PORT} \\\n    -U ${POSTGRES_REPLICATION_USER} \\\n    -D ${PGDATA} \\\n    -Fp \\\n    -Xs \\\n    -P \\\n    -R\n\necho \"PostgreSQL replica initialization completed\"\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#monitoring-replication-status","title":"Monitoring Replication Status","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#check-replication-on-master","title":"Check Replication on Master","text":"<pre><code>-- View active replication connections\nSELECT\n    client_addr,\n    state,\n    sent_lsn,\n    write_lsn,\n    flush_lsn,\n    replay_lsn,\n    sync_state\nFROM pg_stat_replication;\n\n-- Check replication slots\nSELECT slot_name, slot_type, active, restart_lsn\nFROM pg_replication_slots;\n\n-- Calculate replication lag (bytes)\nSELECT\n    client_addr,\n    pg_wal_lsn_diff(sent_lsn, replay_lsn) AS replication_lag_bytes\nFROM pg_stat_replication;\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#check-replication-on-replica","title":"Check Replication on Replica","text":"<pre><code>-- Check if replica is in recovery mode\nSELECT pg_is_in_recovery();\n\n-- View replication status\nSELECT\n    status,\n    receive_start_lsn,\n    receive_start_tli,\n    received_lsn,\n    last_msg_send_time,\n    last_msg_receipt_time\nFROM pg_stat_wal_receiver;\n\n-- Calculate replication lag (seconds)\nSELECT\n    EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#application-integration","title":"Application Integration","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#connection-pooling-with-read-replicas","title":"Connection Pooling with Read Replicas","text":"<pre><code># src/core/database_replication.py\n\nfrom typing import AsyncGenerator\nfrom sqlalchemy.ext.asyncio import AsyncEngine, AsyncSession, create_async_engine, async_sessionmaker\nimport os\n\nclass ReplicationDatabaseConfig:\n    \"\"\"PostgreSQL replication configuration\"\"\"\n\n    def __init__(self):\n        # Master (write) connection\n        self.master_url = self._build_url(\n            host=os.getenv(\"POSTGRES_MASTER_HOST\", \"postgres_master\"),\n            port=int(os.getenv(\"POSTGRES_MASTER_PORT\", \"5432\"))\n        )\n\n        # Replica (read) connections\n        self.replica_urls = [\n            self._build_url(\n                host=os.getenv(\"POSTGRES_REPLICA1_HOST\", \"postgres_replica1\"),\n                port=int(os.getenv(\"POSTGRES_REPLICA1_PORT\", \"5433\"))\n            ),\n            self._build_url(\n                host=os.getenv(\"POSTGRES_REPLICA2_HOST\", \"postgres_replica2\"),\n                port=int(os.getenv(\"POSTGRES_REPLICA2_PORT\", \"5434\"))\n            ),\n        ]\n\n    def _build_url(self, host: str, port: int) -&gt; str:\n        user = os.getenv(\"POSTGRES_USER\", \"postgres\")\n        password = os.getenv(\"POSTGRES_PASSWORD\", \"\")\n        database = os.getenv(\"POSTGRES_DB\", \"microservices_db\")\n        return f\"postgresql+asyncpg://{user}:{password}@{host}:{port}/{database}\"\n\n\n# Master engine (writes)\n_master_engine: AsyncEngine | None = None\n_master_session_factory: async_sessionmaker[AsyncSession] | None = None\n\n# Replica engines (reads)\n_replica_engines: list[AsyncEngine] = []\n_replica_session_factory: async_sessionmaker[AsyncSession] | None = None\n_current_replica_idx = 0\n\n\ndef init_replication_database(config: ReplicationDatabaseConfig) -&gt; None:\n    \"\"\"Initialize master and replica engines\"\"\"\n    global _master_engine, _master_session_factory, _replica_engines, _replica_session_factory\n\n    # Create master engine\n    _master_engine = create_async_engine(config.master_url, pool_size=20, max_overflow=10)\n    _master_session_factory = async_sessionmaker(_master_engine, expire_on_commit=False)\n\n    # Create replica engines (round-robin)\n    _replica_engines = [\n        create_async_engine(url, pool_size=20, max_overflow=10)\n        for url in config.replica_urls\n    ]\n\n\nasync def get_write_session() -&gt; AsyncGenerator[AsyncSession, None]:\n    \"\"\"Get session for write operations (master)\"\"\"\n    if _master_session_factory is None:\n        raise RuntimeError(\"Database not initialized\")\n\n    async with _master_session_factory() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n\nasync def get_read_session() -&gt; AsyncGenerator[AsyncSession, None]:\n    \"\"\"Get session for read operations (replicas, round-robin)\"\"\"\n    global _current_replica_idx\n\n    if not _replica_engines:\n        raise RuntimeError(\"Replicas not initialized\")\n\n    # Round-robin replica selection\n    engine = _replica_engines[_current_replica_idx]\n    _current_replica_idx = (_current_replica_idx + 1) % len(_replica_engines)\n\n    session_factory = async_sessionmaker(engine, expire_on_commit=False)\n    async with session_factory() as session:\n        yield session\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#fastapi-dependency-injection","title":"FastAPI Dependency Injection","text":"<pre><code># src/api/dependencies.py\n\nfrom fastapi import Depends\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.core.database_replication import get_write_session, get_read_session\n\n\nasync def get_db_write(session: AsyncSession = Depends(get_write_session)) -&gt; AsyncSession:\n    \"\"\"Dependency for write operations\"\"\"\n    return session\n\n\nasync def get_db_read(session: AsyncSession = Depends(get_read_session)) -&gt; AsyncSession:\n    \"\"\"Dependency for read operations\"\"\"\n    return session\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#usage-example","title":"Usage Example","text":"<pre><code># src/api/users.py\n\nfrom fastapi import APIRouter, Depends\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.api.dependencies import get_db_read, get_db_write\n\nrouter = APIRouter()\n\n\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: int, db: AsyncSession = Depends(get_db_read)):\n    \"\"\"Read from replica\"\"\"\n    # Query executes on replica\n    return await user_repository.get_by_id(db, user_id)\n\n\n@router.post(\"/users\")\nasync def create_user(user_data: dict, db: AsyncSession = Depends(get_db_write)):\n    \"\"\"Write to master\"\"\"\n    # Insert executes on master, then replicates to replicas\n    return await user_repository.create(db, user_data)\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#high-availability-with-patroni-advanced","title":"High Availability with Patroni (Advanced)","text":"<p>For automatic failover and cluster management, use Patroni with etcd/Consul:</p> <pre><code># docker-compose.patroni.yml\nversion: '3.8'\n\nservices:\n  etcd:\n    image: quay.io/coreos/etcd:v3.5.0\n    environment:\n      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379\n      ETCD_ADVERTISE_CLIENT_URLS: http://etcd:2379\n\n  patroni1:\n    image: patroni/patroni:3.0.0\n    environment:\n      PATRONI_NAME: patroni1\n      PATRONI_RESTAPI_CONNECT_ADDRESS: patroni1:8008\n      PATRONI_POSTGRESQL_CONNECT_ADDRESS: patroni1:5432\n      PATRONI_POSTGRESQL_DATA_DIR: /data/patroni\n      PATRONI_ETCD3_HOSTS: etcd:2379\n</code></pre> <p>For complete Patroni setup, see Patroni documentation.</p>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"atomic/infrastructure/databases/postgresql-replication/#issue-replication-lag","title":"Issue: Replication Lag","text":"<pre><code># Check lag on master\ndocker exec postgres-master psql -U postgres -c \"\n  SELECT client_addr, pg_wal_lsn_diff(sent_lsn, replay_lsn) AS lag_bytes\n  FROM pg_stat_replication;\"\n\n# Check lag on replica\ndocker exec postgres-replica1 psql -U postgres -c \"\n  SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;\"\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#issue-replication-stopped","title":"Issue: Replication Stopped","text":"<pre><code># Check replica logs\ndocker logs postgres-replica1\n\n# Restart replication\ndocker exec postgres-replica1 psql -U postgres -c \"SELECT pg_wal_replay_resume();\"\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#issue-split-brain-multiple-masters","title":"Issue: Split-Brain (Multiple Masters)","text":"<pre><code># Verify which node is master\ndocker exec postgres-master psql -U postgres -c \"SELECT pg_is_in_recovery();\"\ndocker exec postgres-replica1 psql -U postgres -c \"SELECT pg_is_in_recovery();\"\n\n# If replica shows false (is master), force back to replica:\ndocker exec postgres-replica1 pg_ctl promote\n</code></pre>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#related-documentation","title":"Related Documentation","text":"<ul> <li>PostgreSQL Basic Setup - Initial PostgreSQL configuration</li> <li>Connection Pooling - Connection management patterns</li> <li>Performance Optimization - Query and indexing optimization</li> <li>Maturity Levels - Level 4 (Production) requirements</li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-replication/#production-checklist","title":"Production Checklist","text":"<ul> <li> Synchronous replication enabled for critical transactions</li> <li> At least 2 replicas in different availability zones</li> <li> Replication lag monitoring (&lt;5 seconds)</li> <li> Automatic failover configured (Patroni or similar)</li> <li> Regular backup verification (restore test)</li> <li> Connection pooling for replicas (PgBouncer/application-level)</li> <li> Read-write split implemented in application</li> <li> Replication slots monitored (prevent WAL bloat)</li> <li> Network latency between nodes &lt;10ms</li> <li> Disk I/O capacity sufficient (&gt;1000 IOPS)</li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-setup/","title":"PostgreSQL Setup","text":"<p>Provision PostgreSQL instances with repeatable configuration across environments.</p>"},{"location":"atomic/infrastructure/databases/postgresql-setup/#configuration-checklist","title":"Configuration Checklist","text":"<ul> <li>Use version 15+ (align with <code>docs/reference/tech_stack.md</code>).</li> <li>Enforce UTF-8 encoding and <code>UTC</code> timezone.</li> <li>Configure logical separation (one database per data service) to avoid cross-domain coupling.</li> <li>Enable SSL/TLS for production connections and manage certificates via secrets.</li> <li>Tune parameters based on workload: <code>max_connections</code>, <code>shared_buffers</code>, <code>work_mem</code>, <code>maintenance_work_mem</code>.</li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-setup/#operational-practices","title":"Operational Practices","text":"<ul> <li>Provision read replicas when analytical workloads compete with transactional queries.</li> <li>Automate backups (physical + logical) and test restoration regularly.</li> <li>Monitor with pg_stat_statements and expose metrics through <code>postgres_exporter</code>.</li> <li>Maintain infrastructure-as-code definitions (Terraform, Ansible) for repeatability.</li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-setup/#security","title":"Security","text":"<ul> <li>Use dedicated roles per service with least privileges (separate read/write roles when necessary).</li> <li>Rotate credentials and store them in secret managers.</li> <li>Enforce network policies or security groups to restrict access to trusted services only.</li> </ul>"},{"location":"atomic/infrastructure/databases/postgresql-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/postgres-service-setup.md</code></li> <li><code>docs/atomic/infrastructure/databases/migrations.md</code></li> </ul>"},{"location":"atomic/infrastructure/deployment/ci-cd-patterns/","title":"CI/CD Patterns","text":"<p>Automate build, test, and deployment workflows with consistent pipelines.</p>"},{"location":"atomic/infrastructure/deployment/ci-cd-patterns/#pipeline-stages","title":"Pipeline Stages","text":"<ol> <li>Lint &amp; format \u2013 ruff, mypy, markdownlint.</li> <li>Unit tests \u2013 FastAPI, Aiogram, workers.</li> <li>Integration tests \u2013 Testcontainers (databases, Redis, RabbitMQ).</li> <li>Security scans \u2013 dependency audit, container image scan.</li> <li>Package &amp; publish \u2013 build container images, push to registry.</li> <li>Deploy \u2013 trigger environment-specific deploy jobs (staging, production).</li> </ol>"},{"location":"atomic/infrastructure/deployment/ci-cd-patterns/#best-practices","title":"Best Practices","text":"<ul> <li>Fail fast on linting/type issues to shorten feedback loops.</li> <li>Cache dependencies between jobs to reduce pipeline time.</li> <li>Sign container images and verify signatures before deployment.</li> <li>Use trunk-based development with feature branches gated by pull-request checks.</li> <li>Store pipeline definitions in the repository (GitHub Actions, GitLab CI, Argo Workflows).</li> </ul>"},{"location":"atomic/infrastructure/deployment/ci-cd-patterns/#observability","title":"Observability","text":"<ul> <li>Export pipeline metrics (duration, success rate) to CI dashboards.</li> <li>Notify teams via chat/alerts on failures with actionable context.</li> </ul>"},{"location":"atomic/infrastructure/deployment/ci-cd-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/infrastructure/deployment/development-environment/","title":"Development Environment Setup","text":"<p>Provide a consistent local environment for all contributors.</p>"},{"location":"atomic/infrastructure/deployment/development-environment/#tooling","title":"Tooling","text":"<ul> <li>Install Python 3.12+, uv/pip, Docker, and Docker Compose.</li> <li>Configure pre-commit hooks (ruff, mypy, markdownlint) to catch issues early.</li> <li>Use VS Code or PyCharm settings stored in <code>.editorconfig</code>/<code>.vscode</code> where appropriate.</li> </ul>"},{"location":"atomic/infrastructure/deployment/development-environment/#workflow","title":"Workflow","text":"<ul> <li>Start dependencies via <code>docker-compose up</code> (PostgreSQL, Redis, RabbitMQ).</li> <li>Run <code>uv pip install --sync</code> to align dependencies with <code>uv.lock</code>.</li> <li>Execute <code>make test</code> / <code>make lint</code> (or equivalent scripts) before committing.</li> </ul>"},{"location":"atomic/infrastructure/deployment/development-environment/#environment-variables","title":"Environment Variables","text":"<ul> <li>Copy <code>.env.example</code> to <code>.env</code> and fill in local values.</li> <li>Avoid committing <code>.env</code>; use <code>.env.local</code> overrides for machine-specific settings.</li> </ul>"},{"location":"atomic/infrastructure/deployment/development-environment/#dx-enhancements","title":"DX Enhancements","text":"<ul> <li>Enable auto-reload for FastAPI services using <code>uvicorn --reload</code>.</li> <li>Use Telepresence or port-forwarding to test against remote dependencies when required.</li> </ul>"},{"location":"atomic/infrastructure/deployment/development-environment/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/containerization/docker-compose-setup.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/","title":"Deployment Monitoring Setup","text":"<p>Monitor services and infrastructure to detect regressions quickly.</p>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/#metrics","title":"Metrics","text":"<ul> <li>Deploy Prometheus/Grafana stack (or cloud equivalent) to scrape service metrics.</li> <li>Instrument applications with request latency, error counts, and saturation metrics.</li> <li>Set SLOs for critical services and create alerting rules for breaches.</li> </ul>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/#logging","title":"Logging","text":"<ul> <li>Centralise logs via ELK stack, Loki, or cloud logging services.</li> <li>Enrich logs with request IDs, service name, environment, and deployment version.</li> <li>Configure retention policies and access controls to meet compliance requirements.</li> </ul>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/#tracing","title":"Tracing","text":"<ul> <li>Export traces via OpenTelemetry collectors to Jaeger or Tempo.</li> <li>Correlate traces with logs/metrics using consistent identifiers.</li> </ul>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/#dashboards-alerts","title":"Dashboards &amp; Alerts","text":"<ul> <li>Maintain dashboards per service (overview, dependencies, infrastructure).</li> <li>Alert on deployment anomalies (error spikes, saturation, failing health checks).</li> <li>Route alerts to on-call rotations with runbooks for remediation.</li> </ul>"},{"location":"atomic/infrastructure/deployment/monitoring-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/*</code></li> <li><code>docs/atomic/infrastructure/deployment/production-deployment.md</code></li> </ul>"},{"location":"atomic/infrastructure/deployment/production-deployment/","title":"Production Deployment","text":"<p>Deliver releases safely with predictable pipelines and rollback options.</p>"},{"location":"atomic/infrastructure/deployment/production-deployment/#strategy","title":"Strategy","text":"<ul> <li>Deploy services independently to honour the Improved Hybrid separation (business, data, workers).</li> <li>Use blue/green or rolling strategies to minimise downtime.</li> <li>Apply database migrations before deploying new service versions.</li> <li>Gate production deploys with automated checks (CI status, manual approval when required).</li> </ul>"},{"location":"atomic/infrastructure/deployment/production-deployment/#automation","title":"Automation","text":"<ul> <li>Use Infrastructure as Code (Terraform, Helm) to provision infrastructure.</li> <li>Parameterise deployments with environment-specific values stored in secret managers.</li> <li>Record deployment metadata (build SHA, version, timestamp) for observability.</li> </ul>"},{"location":"atomic/infrastructure/deployment/production-deployment/#rollback","title":"Rollback","text":"<ul> <li>Keep previous container images tagged and ready for immediate rollback.</li> <li>Automate rollback scripts that reapply the last known good configuration.</li> <li>Document manual steps for database rollbacks when automatic reversal is not feasible.</li> </ul>"},{"location":"atomic/infrastructure/deployment/production-deployment/#post-deployment-verification","title":"Post-Deployment Verification","text":"<ul> <li>Run smoke tests and health checks after rollout.</li> <li>Monitor latency, error rate, and saturation for at least one release window.</li> <li>Capture incidents and lessons learned in retrospectives.</li> </ul>"},{"location":"atomic/infrastructure/deployment/production-deployment/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/infrastructure/deployment/monitoring-setup.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/integrations/cross-service/distributed-tracing/","title":"Distributed Tracing","text":"<p>Distributed tracing reveals end-to-end latency across services.</p>"},{"location":"atomic/integrations/cross-service/distributed-tracing/#instrumentation","title":"Instrumentation","text":"<ul> <li>Use OpenTelemetry SDK with auto-instrumentation for FastAPI, httpx, and aio-pika.</li> <li>Start spans around business-critical operations when auto-instrumentation is insufficient.</li> <li>Attach request IDs and user identifiers as span attributes, respecting privacy rules.</li> </ul>"},{"location":"atomic/integrations/cross-service/distributed-tracing/#propagation","title":"Propagation","text":"<ul> <li>Forward <code>traceparent</code> / <code>tracestate</code> headers across HTTP boundaries.</li> <li>Add trace headers to RabbitMQ messages (store in message headers) so background workers extend the same trace.</li> </ul>"},{"location":"atomic/integrations/cross-service/distributed-tracing/#exporters","title":"Exporters","text":"<ul> <li>Use OTLP exporters to send spans to Jaeger, Tempo, or Honeycomb.</li> <li>Configure batching and timeouts to avoid blocking request paths.</li> </ul>"},{"location":"atomic/integrations/cross-service/distributed-tracing/#observability","title":"Observability","text":"<ul> <li>Correlate traces with logs and metrics using consistent request IDs.</li> <li>Set latency SLOs for key transactions and alert when budgets are exceeded.</li> </ul>"},{"location":"atomic/integrations/cross-service/distributed-tracing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code></li> <li><code>docs/atomic/integrations/http-communication/request-tracing.md</code></li> </ul>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/","title":"Graceful Shutdown","text":"<p>Coordinate shutdown across services to avoid data loss and user-visible errors.</p>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#checklist","title":"Checklist","text":"<ol> <li>Signal receipt (<code>SIGTERM</code>, <code>SIGINT</code>).</li> <li>Stop accepting new traffic (update readiness endpoints, drain load balancers).</li> <li>Finish in-flight requests/messages or persist state for later recovery.</li> <li>Close external connections (database, Redis, RabbitMQ) cleanly.</li> <li>Log shutdown completion with request IDs for traceability.</li> </ol>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#fastapi","title":"FastAPI","text":"<ul> <li>Use lifespan shutdown hooks to close connection pools and flush background tasks.</li> <li>Return 503 from readiness checks while shutting down to reroute traffic.</li> </ul>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#aiogram-workers","title":"Aiogram &amp; Workers","text":"<ul> <li>Use <code>asyncio.Event</code> and signal handlers to cancel long-running tasks.</li> <li>Acknowledge or requeue messages before closing broker channels.</li> </ul>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/integrations/cross-service/graceful-shutdown/#no-graceful-shutdown-implementation","title":"\u274c No Graceful Shutdown Implementation","text":"<p>Problem: Service terminates abruptly without handling SIGTERM/SIGINT signals, causing data loss and user-visible errors</p> <p>Symptom: 500 errors during deployment, messages lost on restart, partial data writes, \"connection reset by peer\" errors</p> <p>Impact: User-facing failures, data inconsistency, broken user workflows, poor deployment experience</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: No signal handling for graceful shutdown\nimport asyncio\nfrom aiogram import Bot, Dispatcher\n\nasync def main() -&gt; None:\n    \"\"\"Main bot entry point.\"\"\"\n    bot = Bot(token=settings.bot_token)\n    dp = Dispatcher()\n\n    # Register handlers\n    dp.include_router(router)\n\n    # \u26a0\ufe0f Blocks forever, ignores SIGTERM from orchestrator!\n    await dp.start_polling(bot)\n\n    # \u26a0\ufe0f Code below NEVER runs during normal shutdown\n    await bot.session.close()\n    await storage.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n# When Kubernetes/Docker sends SIGTERM:\n# - Polling continues for grace period (30s default)\n# - SIGKILL terminates process forcefully\n# - In-flight messages lost\n# - Connections not closed\n# - No cleanup ran\n</code></pre></p> <p>Why This Matters: - Orchestrators (Docker, Kubernetes) send SIGTERM on shutdown - Without signal handling, service ignores SIGTERM for 30s grace period - SIGKILL forcefully terminates \u2192 in-flight operations lost - Database transactions not committed \u2192 data loss - Connections not closed \u2192 resource leaks on server - User sees 500 errors during rolling deployments - Violates Twelve-Factor App principles (graceful termination)</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Proper signal handling for graceful shutdown\nfrom __future__ import annotations\n\nimport signal\nimport asyncio\nfrom aiogram import Bot, Dispatcher\nfrom aiogram.fsm.storage.redis import RedisStorage\nimport structlog\n\nlogger = structlog.get_logger()\n\n# Global shutdown event\nshutdown_event = asyncio.Event()\n\ndef handle_signal(signum: int, frame) -&gt; None:\n    \"\"\"\n    Handle shutdown signals (SIGTERM, SIGINT).\n\n    Args:\n        signum: Signal number\n        frame: Stack frame\n    \"\"\"\n    signal_name = signal.Signals(signum).name\n    logger.info(\"shutdown_signal_received\", signal=signal_name)\n    shutdown_event.set()\n\nasync def main() -&gt; None:\n    \"\"\"\n    Main bot entry point with graceful shutdown.\n\n    Handles SIGTERM/SIGINT signals and ensures clean shutdown:\n    1. Stop accepting new messages\n    2. Finish processing in-flight messages\n    3. Close all connections\n    4. Exit cleanly\n    \"\"\"\n    # Register signal handlers BEFORE starting bot\n    signal.signal(signal.SIGTERM, handle_signal)\n    signal.signal(signal.SIGINT, handle_signal)\n\n    bot = Bot(token=settings.bot_token)\n    storage = RedisStorage.from_url(settings.redis_url)\n    dp = Dispatcher(storage=storage)\n\n    # Register handlers\n    dp.include_router(router)\n\n    logger.info(\"bot_startup_initiated\")\n\n    try:\n        # Create polling task (doesn't block)\n        polling_task = asyncio.create_task(dp.start_polling(bot))\n\n        logger.info(\"bot_polling_started\")\n\n        # \u2705 Wait for shutdown signal\n        await shutdown_event.wait()\n\n        logger.info(\"bot_shutdown_initiated\", reason=\"signal\")\n\n        # \u2705 Cancel polling gracefully\n        polling_task.cancel()\n        try:\n            await polling_task\n        except asyncio.CancelledError:\n            logger.info(\"polling_cancelled\")\n\n    except Exception as e:\n        logger.exception(\"bot_error\", error=str(e))\n        raise\n\n    finally:\n        # \u2705 GUARANTEED cleanup: Always runs\n        logger.info(\"bot_cleanup_started\")\n\n        # Close in reverse order of initialization\n        await storage.close()\n        logger.info(\"storage_closed\")\n\n        await bot.session.close()\n        logger.info(\"bot_session_closed\")\n\n        logger.info(\"bot_shutdown_complete\")\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(main())\n    except KeyboardInterrupt:\n        logger.info(\"bot_interrupted_by_user\")\n</code></pre></p> <p>Architecture Rule:</p> <p>All long-running services (bots, workers, APIs) MUST handle SIGTERM/SIGINT signals to enable graceful shutdown. Services MUST finish in-flight operations and close resources before exiting.</p> <p>Shutdown Sequence Best Practices: 1. Receive signal \u2192 Set shutdown event, log signal received 2. Stop accepting new work \u2192 Cancel polling/listening tasks 3. Finish in-flight work \u2192 Wait for tasks with timeout (5-10s) 4. Close connections \u2192 Database, Redis, HTTP clients (reverse order) 5. Log completion \u2192 Final log message before exit 6. Exit cleanly \u2192 Return 0 exit code</p> <p>For FastAPI Services: <pre><code># FastAPI lifespan handles shutdown automatically\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup\n    await db.connect()\n    yield\n    # \u2705 Shutdown runs on SIGTERM automatically\n    await db.disconnect()\n</code></pre></p> <p>Testing Graceful Shutdown: <pre><code>import subprocess\nimport signal\nimport time\n\ndef test_graceful_shutdown():\n    \"\"\"Test bot shuts down gracefully on SIGTERM.\"\"\"\n    # Start bot in subprocess\n    proc = subprocess.Popen([\"python\", \"-m\", \"src.main\"])\n\n    time.sleep(2)  # Let bot start\n\n    # Send SIGTERM (like orchestrator does)\n    proc.send_signal(signal.SIGTERM)\n\n    # Wait for clean exit\n    return_code = proc.wait(timeout=10)\n\n    # \u2705 Should exit cleanly (code 0)\n    assert return_code == 0\n</code></pre></p> <p>Monitoring: <pre><code># Check if service handles SIGTERM (should exit with code 0)\ndocker stop --time=10 service_name\necho $?  # Should be 0\n\n# Monitor shutdown duration (should be &lt; grace period)\ntime docker stop service_name\n</code></pre></p> <p>Related Anti-Patterns: - Deprecated Lifecycle APIs \u2192 <code>docs/atomic/services/fastapi/lifespan-management.md#deprecated-lifecycle-apis</code> - Global FSM Storage Never Closed \u2192 <code>docs/atomic/services/aiogram/state-management.md#global-fsm-storage-never-closed</code></p>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#testing","title":"Testing","text":"<ul> <li>Simulate shutdown in integration tests (send <code>SIGTERM</code> to subprocess) and ensure no messages are lost.</li> <li>Measure shutdown duration and keep it below orchestrator grace periods (30s default).</li> <li>Verify all connections are closed (no FIN_WAIT/TIME_WAIT connection accumulation).</li> </ul>"},{"location":"atomic/integrations/cross-service/graceful-shutdown/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> <li><code>docs/atomic/services/asyncio-workers/signal-handling.md</code></li> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> </ul>"},{"location":"atomic/integrations/cross-service/health-checks/","title":"Health Checks","text":"<p>Health checks signal readiness and liveness to orchestrators and other services.</p>"},{"location":"atomic/integrations/cross-service/health-checks/#types","title":"Types","text":"<ul> <li>Liveness \u2013 indicates the process is running. Should be lightweight and never depend on external systems.</li> <li>Readiness \u2013 confirms the service can accept traffic (database connections, caches, message brokers initialised).</li> <li>Dependency-specific \u2013 optional endpoints for detailed diagnostics (<code>/health/db</code>, <code>/health/rabbitmq</code>).</li> </ul>"},{"location":"atomic/integrations/cross-service/health-checks/#implementation","title":"Implementation","text":"<ul> <li>Expose <code>/health</code> and <code>/ready</code> at the root (non-versioned) router.</li> <li>Return structured JSON with status and optional metadata (component states, build version).</li> <li>Fail readiness when critical dependencies are unavailable; orchestrators will remove the instance from load balancing.</li> </ul>"},{"location":"atomic/integrations/cross-service/health-checks/#monitoring","title":"Monitoring","text":"<ul> <li>Capture health-check response times and failure counts in metrics.</li> <li>Integrate health endpoints with uptime monitors and alerting rules.</li> </ul>"},{"location":"atomic/integrations/cross-service/health-checks/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code></li> <li><code>docs/atomic/services/fastapi/basic-setup.md</code></li> </ul>"},{"location":"atomic/integrations/cross-service/service-discovery/","title":"Service Discovery","text":"<p>Ensure services discover one another reliably in every environment.</p>"},{"location":"atomic/integrations/cross-service/service-discovery/#approaches","title":"Approaches","text":"<ul> <li>Static configuration \u2013 environment variables or configuration files mapping service names to URLs (suitable for small deployments).</li> <li>DNS-based discovery \u2013 rely on container orchestrators (Kubernetes services, Docker Compose hostnames).</li> <li>Registry-based discovery \u2013 use Consul, etcd, or service meshes when dynamic scaling and health-based routing are required.</li> </ul>"},{"location":"atomic/integrations/cross-service/service-discovery/#guidelines","title":"Guidelines","text":"<ul> <li>Reference services by logical names (for example, <code>DATA_SERVICE_URL</code>) rather than hard-coded IP addresses.</li> <li>Document discovery requirements per environment (local, staging, production).</li> <li>Combine discovery with health checks to avoid routing traffic to unhealthy instances.</li> <li>Cache discovery results cautiously and honour TTLs.</li> </ul>"},{"location":"atomic/integrations/cross-service/service-discovery/#security","title":"Security","text":"<ul> <li>Authenticate with the service registry using mTLS or API tokens.</li> <li>Restrict who can register or deregister services to prevent poisoning the registry.</li> </ul>"},{"location":"atomic/integrations/cross-service/service-discovery/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/cross-service/health-checks.md</code></li> <li><code>docs/atomic/architecture/service-separation-principles.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/","title":"Business \u2192 Data Service Calls","text":"<p>Business services call data services exclusively over HTTP. Keep clients typed, resilient, and observability-friendly.</p>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/#client-responsibilities","title":"Client Responsibilities","text":"<ul> <li>Serialize requests and responses with Pydantic models shared between producer and consumer.</li> <li>Propagate headers: <code>X-Request-ID</code>, <code>X-User-ID</code>, auth tokens.</li> <li>Translate HTTP errors into domain-specific exceptions with enough context for callers.</li> </ul>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/#workflow","title":"Workflow","text":"<pre><code>class UserDataClient:\n    def __init__(self, client: AsyncClient, settings: Settings) -&gt; None:\n        self._client = client\n        self._base_url = settings.data_service_url\n\n    async def get_user(self, user_id: str) -&gt; UserPublic:\n        response = await self._client.get(f\"{self._base_url}/api/v1/users/{user_id}\")\n        response.raise_for_status()\n        return UserPublic.model_validate_json(response.text)\n</code></pre>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/#validation","title":"Validation","text":"<ul> <li>Verify contracts in integration tests using real data services (Testcontainers).</li> <li>Snap OpenAPI specs to detect incompatible changes.</li> </ul>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/#observability","title":"Observability","text":"<ul> <li>Tag logs with target service name and request duration.</li> <li>Emit metrics per endpoint call (success rate, latency percentiles).</li> </ul>"},{"location":"atomic/integrations/http-communication/business-to-data-calls/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/http-api-design.md</code></li> <li><code>docs/atomic/integrations/http-communication/http-client-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/","title":"HTTP Error Handling Strategies","text":"<p>Handle downstream HTTP failures consistently and convert them into domain errors.</p>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/#mapping","title":"Mapping","text":"<ul> <li>4xx responses indicate caller issues (validation, authorization). Translate into domain exceptions that surface meaningful Problem Details.</li> <li>5xx responses indicate dependency outages. Log with WARN/ERROR and trigger retries or fallbacks.</li> <li>Timeouts are treated as transient failures; consider retries before raising circuit breaker events.</li> </ul>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/#implementation","title":"Implementation","text":"<pre><code>from httpx import HTTPStatusError\n\n\nasync def fetch_user(client, url):\n    try:\n        response = await client.get(url)\n        response.raise_for_status()\n    except HTTPStatusError as exc:\n        if 400 &lt;= exc.response.status_code &lt; 500:\n            raise DomainValidationError(str(exc)) from exc\n        raise DependencyUnavailableError(str(exc)) from exc\n    return response.json()\n</code></pre>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/#observability","title":"Observability","text":"<ul> <li>Log status code, endpoint name, request ID, and retry count (if any).</li> <li>Emit metrics for error rates per dependency; set SLO thresholds and alerts.</li> </ul>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/#fallbacks","title":"Fallbacks","text":"<ul> <li>Provide cached data or default responses when appropriate.</li> <li>Surface clear messages to users while preserving diagnostics in logs.</li> </ul>"},{"location":"atomic/integrations/http-communication/error-handling-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/timeout-retry-patterns.md</code></li> <li><code>docs/atomic/services/fastapi/error-handling.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/http-client-patterns/","title":"HTTP Client Patterns","text":"<p>Use <code>httpx.AsyncClient</code> as the standard HTTP client for inter-service calls.</p>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#construction","title":"Construction","text":"<pre><code>from httpx import AsyncClient, Limits, Timeout\n\n\ndef build_client(settings):\n    return AsyncClient(\n        timeout=Timeout(5.0, connect=1.0),\n        limits=Limits(max_connections=200, max_keepalive_connections=100),\n        headers={\"User-Agent\": settings.service_name},\n    )\n</code></pre> <ul> <li>Create the client once per process (FastAPI lifespan, worker bootstrap) and reuse it for all requests.</li> <li>Close the client during shutdown to release sockets.</li> </ul>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#middleware","title":"Middleware","text":"<ul> <li>Add logging middleware to capture method, URL, status, and duration.</li> <li>Inject tracing headers (<code>traceparent</code>, <code>tracestate</code>) per request.</li> </ul>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#resilience","title":"Resilience","text":"<ul> <li>Wrap calls with retries/backoff (see <code>timeout-retry-patterns.md</code>).</li> <li>Detect unhealthy dependencies using circuit breakers and fallback behaviour.</li> </ul>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/integrations/http-communication/http-client-patterns/#http-client-proliferation","title":"\u274c HTTP Client Proliferation","text":"<p>Problem: Creating multiple <code>httpx.AsyncClient</code> instances instead of reusing a single shared client with connection pooling</p> <p>Symptom: Connection pool exhaustion, \"connection reset by peer\" errors, high latency, resource leaks</p> <p>Impact: Service degradation under load, connection limits reached, memory leaks from unclosed clients</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: Creating new client per request\nasync def fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from data service.\"\"\"\n    # \u26a0\ufe0f Creates NEW client with NEW connection pool every call!\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"http://finance_user_api:8000/users/{user_id}\"\n        )\n        return response.json()\n\n# Called 100 times \u2192 100 separate connection pools \u2192 resource exhaustion!\n</code></pre></p> <p>Why This Matters: - Each <code>AsyncClient()</code> creates its own connection pool (default 100 connections) - Connection pools are NOT shared between client instances - Creating clients per request \u2192 no connection reuse \u2192 TCP handshake overhead - Unclosed clients leak file descriptors and memory - Under load (1000s requests/sec) \u2192 system connection limit reached</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Single shared client with connection pooling\nfrom httpx import AsyncClient, Limits, Timeout\nfrom contextlib import asynccontextmanager\n\n# Shared client instance (created in lifespan)\n_http_client: AsyncClient | None = None\n\ndef build_http_client(settings) -&gt; AsyncClient:\n    \"\"\"\n    Build shared HTTP client with connection pooling.\n\n    Returns:\n        Configured AsyncClient for inter-service communication\n    \"\"\"\n    return AsyncClient(\n        timeout=Timeout(5.0, connect=1.0),\n        limits=Limits(\n            max_connections=200,\n            max_keepalive_connections=100\n        ),\n        headers={\"User-Agent\": settings.service_name},\n    )\n\nasync def close_http_client() -&gt; None:\n    \"\"\"Close HTTP client and release connections.\"\"\"\n    global _http_client\n    if _http_client is not None:\n        await _http_client.aclose()\n        _http_client = None\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"FastAPI lifespan with HTTP client lifecycle.\"\"\"\n    global _http_client\n    _http_client = build_http_client(settings)\n    app.state.http_client = _http_client\n    try:\n        yield\n    finally:\n        await close_http_client()\n\n# Usage: Inject client from app state\nasync def fetch_user_data(\n    user_id: int,\n    client: AsyncClient = Depends(get_http_client)\n) -&gt; dict:\n    \"\"\"\n    Fetch user data from data service.\n\n    Args:\n        user_id: User identifier\n        client: Shared HTTP client (injected)\n\n    Returns:\n        User data dictionary\n    \"\"\"\n    response = await client.get(\n        f\"http://finance_user_api:8000/users/{user_id}\"\n    )\n    response.raise_for_status()\n    return response.json()\n</code></pre></p> <p>Architecture Rule:</p> <p>HTTP clients MUST be instantiated once per process during startup and shared across all requests via dependency injection or app state.</p> <p>Monitoring: <pre><code># Monitor active connections (should be stable, &lt; max_connections)\nnetstat -an | grep ESTABLISHED | wc -l\n\n# Check for connection leaks (TIME_WAIT should not grow indefinitely)\nnetstat -an | grep TIME_WAIT | wc -l\n\n# Monitor file descriptors\ndocker exec service sh -c 'ls /proc/$$/fd | wc -l'\n</code></pre></p> <p>Related Anti-Patterns: - Global FSM Storage Never Closed \u2192 <code>docs/atomic/services/aiogram/state-management.md#global-fsm-storage-never-closed</code> - Connection Pool Misuse \u2192 <code>docs/atomic/integrations/redis/connection-management.md#connection-pool-misuse</code></p>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#testing","title":"Testing","text":"<ul> <li>Mock responses with <code>respx</code> or <code>pytest-httpx</code> in unit tests.</li> <li>Use Testcontainers or staging data services for end-to-end contract validation.</li> </ul>"},{"location":"atomic/integrations/http-communication/http-client-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/timeout-retry-patterns.md</code></li> <li><code>docs/atomic/integrations/http-communication/error-handling-strategies.md</code></li> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> <li><code>docs/atomic/services/fastapi/dependency-injection.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/request-tracing/","title":"Request Tracing","text":"<p>Propagate correlation identifiers across inter-service HTTP calls for observability.</p>"},{"location":"atomic/integrations/http-communication/request-tracing/#headers","title":"Headers","text":"<ul> <li><code>X-Request-ID</code> \u2013 deterministic identifier for the end-to-end request. Reuse inbound value or generate a UUID.</li> <li><code>traceparent</code> / <code>tracestate</code> \u2013 W3C trace context for distributed tracing when OpenTelemetry is enabled.</li> <li><code>X-User-ID</code> (optional) \u2013 user-level correlation when policy allows.</li> </ul>"},{"location":"atomic/integrations/http-communication/request-tracing/#implementation","title":"Implementation","text":"<pre><code>async def forward_headers(client, url, payload, context):\n    headers = {\n        \"X-Request-ID\": context.request_id,\n        \"traceparent\": context.traceparent,\n        \"tracestate\": context.tracestate or \"\",\n    }\n    return await client.post(url, json=payload, headers=headers)\n</code></pre>"},{"location":"atomic/integrations/http-communication/request-tracing/#logging","title":"Logging","text":"<ul> <li>Include request ID and target service in logs to join producer and consumer events.</li> <li>Record spans around outbound calls to measure dependency latency and populate distributed traces.</li> </ul>"},{"location":"atomic/integrations/http-communication/request-tracing/#testing","title":"Testing","text":"<ul> <li>Assert outbound HTTP calls carry required headers using tooling such as <code>respx</code>.</li> <li>Validate traces appear in Jaeger or Tempo during integration tests.</li> </ul>"},{"location":"atomic/integrations/http-communication/request-tracing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code></li> <li><code>docs/atomic/integrations/http-communication/http-client-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/testing-http-integration/","title":"HTTP Integration Testing","text":"<p>Validate inter-service HTTP calls end-to-end to prevent contract regressions.</p>"},{"location":"atomic/integrations/http-communication/testing-http-integration/#strategy","title":"Strategy","text":"<ul> <li>Spin up dependent services locally (Testcontainers) or use dedicated staging endpoints.</li> <li>Seed known data in data services before calling business APIs.</li> <li>Assert HTTP status codes, response bodies, and headers (including tracing and caching directives).</li> </ul>"},{"location":"atomic/integrations/http-communication/testing-http-integration/#tooling","title":"Tooling","text":"<ul> <li>Use <code>httpx.AsyncClient</code> inside tests for async compatibility.</li> <li>Capture OpenAPI schemas in artifacts to detect breaking changes.</li> <li>Run contract tests (for example, Pact) when consumers and providers are maintained by different teams.</li> </ul>"},{"location":"atomic/integrations/http-communication/testing-http-integration/#failure-modes","title":"Failure Modes","text":"<ul> <li>Simulate timeouts and ensure retry/backoff logic behaves as expected.</li> <li>Inject malformed payloads to confirm the service returns RFC 7807 Problem Details.</li> </ul>"},{"location":"atomic/integrations/http-communication/testing-http-integration/#automation","title":"Automation","text":"<ul> <li>Integrate tests into CI pipelines and tag them as integration to allow parallelism.</li> <li>Publish logs and metrics snapshots from test runs for quick diagnostics.</li> </ul>"},{"location":"atomic/integrations/http-communication/testing-http-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/error-handling-strategies.md</code></li> <li><code>docs/atomic/testing/integration-testing/http-integration-testing.md</code></li> </ul>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/","title":"Timeout and Retry Patterns","text":"<p>Use aggressive timeouts and controlled retries to avoid cascading failures.</p>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/#timeouts","title":"Timeouts","text":"<ul> <li>Set connect timeout \u22641s for in-cluster calls; adjust read timeout based on endpoint SLA.</li> <li>Use per-call overrides for long-running operations instead of raising global limits.</li> <li>Detect slow responses via metrics (P95/P99 latency) and alert when thresholds breach.</li> </ul>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/#retries","title":"Retries","text":"<ul> <li>Retry only idempotent operations (GET, HEAD) by default; allow POST/PUT when coupled with idempotency keys.</li> <li>Apply exponential backoff with jitter (<code>1s, 2s, 4s up to max 10s</code>).</li> <li>Limit total attempts (usually 3) and record retry count in logs/metrics.</li> </ul>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/#circuit-breakers","title":"Circuit Breakers","text":"<ul> <li>Trip the breaker after successive failures and fail fast for a cool-down period.</li> <li>Expose breaker state via health endpoints for observability.</li> </ul>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/#implementation-helpers","title":"Implementation Helpers","text":"<ul> <li>Wrap HTTP clients with libraries such as <code>tenacity</code> or implement custom decorators.</li> <li>Ensure retry logic respects deadline budgets so requests do not exceed overall timeout.</li> </ul>"},{"location":"atomic/integrations/http-communication/timeout-retry-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/error-handling-strategies.md</code></li> <li><code>docs/atomic/integrations/http-communication/request-tracing.md</code></li> </ul>"},{"location":"atomic/integrations/redis/aiogram-integration/","title":"Redis + Aiogram Integration","text":"<p>Aiogram relies on a single event loop, so Redis must be initialised once and injected into handlers via dispatcher startup hooks.</p>"},{"location":"atomic/integrations/redis/aiogram-integration/#startup-hook","title":"Startup Hook","text":"<pre><code>from aiogram import Dispatcher\nfrom redis.asyncio import Redis\n\n\ndef register_redis(dp: Dispatcher, redis: Redis) -&gt; None:\n    async def on_startup() -&gt; dict[str, object]:\n        await redis.ping()\n        return {\"redis\": redis}\n\n    dp.startup.register(on_startup)\n\n    async def on_shutdown() -&gt; None:\n        await redis.close()\n\n    dp.shutdown.register(on_shutdown)\n</code></pre>"},{"location":"atomic/integrations/redis/aiogram-integration/#handler-usage","title":"Handler Usage","text":"<pre><code>from aiogram.types import Message\nfrom redis.asyncio import Redis\n\n\nasync def handle_photo(message: Message, redis: Redis) -&gt; None:\n    key = f\"idempotency:photo:{message.message_id}\"\n    if await redis.setnx(key, \"processed\"):\n        await redis.expire(key, 3600)\n        await message.answer(\"Photo accepted\")\n    else:\n        await message.answer(\"Duplicate photo\")\n</code></pre>"},{"location":"atomic/integrations/redis/aiogram-integration/#testing","title":"Testing","text":"<ul> <li>Provide fakes or Testcontainers Redis inside integration tests and register them with <code>register_redis</code>.</li> <li>Use Aiogram testing utilities to verify dependency injection.</li> </ul>"},{"location":"atomic/integrations/redis/aiogram-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/dependency-injection.md</code></li> <li><code>docs/atomic/integrations/redis/idempotency-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/redis/asyncio-integration/","title":"Redis + AsyncIO Integration","text":"<p>Background workers operate with pure AsyncIO; initialise Redis in <code>main()</code> and pass the client to tasks.</p>"},{"location":"atomic/integrations/redis/asyncio-integration/#bootstrap","title":"Bootstrap","text":"<pre><code>from redis.asyncio import Redis\n\n\nasync def bootstrap(settings):\n    redis = Redis.from_url(settings.redis_url, encoding=\"utf-8\", decode_responses=True)\n    await redis.ping()\n    return redis\n</code></pre>"},{"location":"atomic/integrations/redis/asyncio-integration/#usage-in-tasks","title":"Usage in Tasks","text":"<pre><code>async def process_event(event, redis):\n    key = f\"cache:event:{event.id}\"\n    await redis.setex(key, 600, event.model_dump_json())\n</code></pre> <ul> <li>Share the client across tasks by storing it in a dependency container or dataclass.</li> <li>Close the client during shutdown (<code>await redis.close()</code>).</li> </ul>"},{"location":"atomic/integrations/redis/asyncio-integration/#testing","title":"Testing","text":"<ul> <li>Provide fake Redis implementations for unit tests.</li> <li>Use Testcontainers for integration tests to validate concurrency and TTL behaviour.</li> </ul>"},{"location":"atomic/integrations/redis/asyncio-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/dependency-management.md</code></li> <li><code>docs/atomic/integrations/redis/testing-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/redis/caching-strategies/","title":"Caching Strategies","text":"<p>Redis accelerates read-heavy workflows and rate limiting. Choose caching tactics that balance freshness and cost.</p>"},{"location":"atomic/integrations/redis/caching-strategies/#patterns","title":"Patterns","text":"<ul> <li>Read-through \u2013 fetch from cache first; on miss, load from source and populate cache.</li> <li>Write-through \u2013 update cache immediately after persisting to the data service.</li> <li>Write-behind \u2013 enqueue updates for asynchronous flushing; use only when ordering is controlled.</li> <li>Negative caching \u2013 cache misses (e.g., <code>None</code>) briefly to shield the data service from repeated lookups.</li> </ul>"},{"location":"atomic/integrations/redis/caching-strategies/#ttl-guidelines","title":"TTL Guidelines","text":"Use Case TTL User profiles 5\u201315 minutes Feature flags No TTL; invalidate on change Rate limiting Window duration (e.g., 60 seconds)"},{"location":"atomic/integrations/redis/caching-strategies/#consistency","title":"Consistency","text":"<ul> <li>Invalidate keys on data modifications; keep a helper that derives the key from domain identifiers.</li> <li>For multi-entity updates, use pipelines or Lua scripts to mutate all keys atomically.</li> <li>Prefer eventual consistency and tolerate slightly stale data unless business rules demand strict accuracy.</li> </ul>"},{"location":"atomic/integrations/redis/caching-strategies/#monitoring","title":"Monitoring","text":"<ul> <li>Track hit rate, evictions, and memory usage via Redis INFO metrics.</li> <li>Set alerts for sudden changes in hit rate (indicates cache stampede or invalidation bug).</li> <li>Implement jittered TTL to avoid synchronized expirations.</li> </ul>"},{"location":"atomic/integrations/redis/caching-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/timeout-retry-patterns.md</code></li> <li><code>docs/atomic/services/data-services/http-api-design.md</code></li> </ul>"},{"location":"atomic/integrations/redis/connection-management/","title":"Redis Connection Management","text":"<p>Use a single asynchronous Redis client per process, configured with connection pooling and constructed during service startup.</p>"},{"location":"atomic/integrations/redis/connection-management/#client-construction","title":"Client Construction","text":"<pre><code>from redis.asyncio import Redis\n\n\ndef build_redis(url: str) -&gt; Redis:\n    return Redis.from_url(\n        url,\n        encoding=\"utf-8\",\n        decode_responses=True,\n        max_connections=100,\n    )\n</code></pre> <ul> <li>Instantiate the client inside FastAPI lifespan, Aiogram startup, or the worker <code>main()</code> coroutine.</li> <li>Store the client in application state (<code>app.state.redis</code>) or dispatcher startup context; never create clients per request.</li> <li>Close the client gracefully on shutdown to flush pending commands.</li> </ul>"},{"location":"atomic/integrations/redis/connection-management/#timeouts-and-reliability","title":"Timeouts and Reliability","text":"<ul> <li>Configure socket/connect timeouts to avoid hanging on network outages (<code>Redis.from_url(..., socket_timeout=5.0)</code>).</li> <li>Wrap initial connection attempts with retries (exponential backoff) but fail fast when the service cannot reach Redis.</li> <li>Use health checks that issue lightweight <code>PING</code> commands.</li> </ul>"},{"location":"atomic/integrations/redis/connection-management/#pool-sizing","title":"Pool Sizing","text":"<ul> <li>Size pools according to workload; start with <code>max_connections=100</code> for web services, lower for workers.</li> <li>Monitor pool usage via metrics to detect saturation and tune accordingly.</li> </ul>"},{"location":"atomic/integrations/redis/connection-management/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/integrations/redis/connection-management/#connection-pool-misuse","title":"\u274c Connection Pool Misuse","text":"<p>Problem: Creating new Redis connection pools per operation instead of reusing a single shared pool</p> <p>Symptom: Redis connection leaks, \"max clients reached\" errors, degraded performance, memory growth</p> <p>Impact: Redis server connection limit exhausted, service crashes, requires frequent restarts</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: Creating new Redis client per operation\nfrom redis.asyncio import Redis\n\nasync def cache_user_data(user_id: int, data: dict) -&gt; None:\n    \"\"\"Cache user data in Redis.\"\"\"\n    # \u26a0\ufe0f Creates NEW connection pool every call!\n    redis = Redis.from_url(\n        settings.redis_url,\n        max_connections=100  # New pool with 100 connection slots!\n    )\n    await redis.setex(f\"user:{user_id}\", 3600, json.dumps(data))\n    # \u26a0\ufe0f NO .close() \u2192 connections never released!\n\n# Called 50 times \u2192 50 pools \u00d7 100 connections = 5000 potential connections!\n</code></pre></p> <p>Why This Matters: - Each <code>Redis.from_url()</code> creates a NEW connection pool - Pools are NOT garbage collected until explicitly closed - Leaked pools accumulate \u2192 Redis <code>maxclients</code> limit reached - Performance degradation: Connection handshakes on every operation - Memory leak: Each pool holds internal buffers and state</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Single shared Redis client with proper lifecycle\nfrom redis.asyncio import Redis\n\n# Shared client instance\n_redis_client: Redis | None = None\n\ndef build_redis_client(url: str) -&gt; Redis:\n    \"\"\"\n    Build shared Redis client with connection pooling.\n\n    Args:\n        url: Redis connection URL\n\n    Returns:\n        Configured Redis client with connection pool\n    \"\"\"\n    return Redis.from_url(\n        url,\n        encoding=\"utf-8\",\n        decode_responses=True,\n        max_connections=100,\n        socket_timeout=5.0,\n        socket_connect_timeout=1.0,\n    )\n\nasync def close_redis_client() -&gt; None:\n    \"\"\"Close Redis client and release all connections.\"\"\"\n    global _redis_client\n    if _redis_client is not None:\n        await _redis_client.aclose()\n        _redis_client = None\n        logger.info(\"redis_client_closed\", event=\"cleanup\")\n\n# In FastAPI lifespan\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan with Redis lifecycle.\"\"\"\n    global _redis_client\n    _redis_client = build_redis_client(settings.redis_url)\n    app.state.redis = _redis_client\n\n    # Wait for connection to be ready\n    await _redis_client.ping()\n    logger.info(\"redis_connected\", event=\"startup\")\n\n    try:\n        yield\n    finally:\n        await close_redis_client()\n\n# Usage: Inject client from app state\nasync def cache_user_data(\n    user_id: int,\n    data: dict,\n    redis: Redis = Depends(get_redis)\n) -&gt; None:\n    \"\"\"\n    Cache user data in Redis.\n\n    Args:\n        user_id: User identifier\n        data: Data to cache\n        redis: Shared Redis client (injected)\n    \"\"\"\n    await redis.setex(\n        f\"user:{user_id}\",\n        3600,\n        json.dumps(data)\n    )\n</code></pre></p> <p>Architecture Rule:</p> <p>Redis clients MUST be instantiated once per process during startup, stored in app state, and closed during shutdown. Never create Redis clients per request or per operation.</p> <p>Monitoring: <pre><code># Check Redis connection count (should be stable, &lt; max_connections)\ndocker exec redis redis-cli CLIENT LIST | wc -l\n\n# Monitor Redis memory usage\ndocker exec redis redis-cli INFO memory | grep used_memory_human\n\n# Check for connection leaks (connections should not grow over time)\ndocker exec redis redis-cli INFO stats | grep total_connections_received\n</code></pre></p> <p>Related Anti-Patterns: - HTTP Client Proliferation \u2192 <code>docs/atomic/integrations/http-communication/http-client-patterns.md#http-client-proliferation</code> - Global FSM Storage Never Closed \u2192 <code>docs/atomic/services/aiogram/state-management.md#global-fsm-storage-never-closed</code></p>"},{"location":"atomic/integrations/redis/connection-management/#observability","title":"Observability","text":"<ul> <li>Log connection lifecycle events (<code>redis_connected</code>, <code>redis_disconnected</code>) with request IDs from logging middleware.</li> <li>Emit metrics for command durations and error counts.</li> </ul>"},{"location":"atomic/integrations/redis/connection-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/redis/key-naming-conventions.md</code></li> <li><code>docs/atomic/services/fastapi/dependency-injection.md</code></li> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> </ul>"},{"location":"atomic/integrations/redis/data-serialization/","title":"Data Serialization","text":"<p>Redis stores byte strings; enforce predictable serialization to preserve compatibility across services.</p>"},{"location":"atomic/integrations/redis/data-serialization/#formats","title":"Formats","text":"<ul> <li>Prefer JSON for structured data; set <code>encoding=\"utf-8\", decode_responses=True</code> on the client to store/read strings transparently.</li> <li>Use MessagePack or compressed JSON when payload size becomes a bottleneck, but document the format.</li> <li>Store small primitives (ints, floats) as plain strings; convert explicitly on read.</li> </ul>"},{"location":"atomic/integrations/redis/data-serialization/#helpers","title":"Helpers","text":"<pre><code>import json\nfrom typing import Any\n\n\nasync def cache_json(redis, key: str, value: Any, ttl: int) -&gt; None:\n    await redis.setex(key, ttl, json.dumps(value, default=str))\n\n\nasync def read_json(redis, key: str) -&gt; Any | None:\n    payload = await redis.get(key)\n    return json.loads(payload) if payload else None\n</code></pre>"},{"location":"atomic/integrations/redis/data-serialization/#validation","title":"Validation","text":"<ul> <li>Validate payloads against Pydantic models both before writing and after reading.</li> <li>Include schema version inside the value when compatibility must be preserved across releases.</li> </ul>"},{"location":"atomic/integrations/redis/data-serialization/#binary-assets","title":"Binary Assets","text":"<ul> <li>Avoid storing large binaries directly; store references to object storage and metadata in Redis.</li> <li>If binary storage is unavoidable, use <code>set</code>/<code>get</code> with bytes and document size limits.</li> </ul>"},{"location":"atomic/integrations/redis/data-serialization/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/redis/caching-strategies.md</code></li> <li><code>docs/atomic/services/data-services/repository-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/redis/fastapi-integration/","title":"Redis + FastAPI Integration","text":"<p>Expose Redis to route handlers via FastAPI dependency injection while keeping the event loop single and healthy.</p>"},{"location":"atomic/integrations/redis/fastapi-integration/#lifespan-registration","title":"Lifespan Registration","text":"<pre><code>from redis.asyncio import Redis\nfrom contextlib import asynccontextmanager\n\n\ndef build_lifespan(settings):\n    @asynccontextmanager\n    async def lifespan(app):\n        redis = Redis.from_url(settings.redis_url, encoding=\"utf-8\", decode_responses=True)\n        await redis.ping()\n        app.state.redis = redis\n        try:\n            yield\n        finally:\n            await redis.close()\n\n    return lifespan\n</code></pre>"},{"location":"atomic/integrations/redis/fastapi-integration/#dependency-provider","title":"Dependency Provider","text":"<pre><code>from fastapi import Depends\n\n\ndef get_redis(app = Depends()) -&gt; Redis:\n    return app.state.redis\n</code></pre> <ul> <li>Inject the dependency into handlers (<code>async def handler(redis: Redis = Depends(get_redis))</code>).</li> <li>Optionally wrap Redis operations in application services to avoid leaking low-level commands.</li> </ul>"},{"location":"atomic/integrations/redis/fastapi-integration/#testing","title":"Testing","text":"<ul> <li>Override the dependency with a fake or Testcontainers-backed Redis instance during tests.</li> <li>Ensure tests share the event loop provided by <code>pytest-asyncio</code>; avoid <code>asyncio.run</code>.</li> </ul>"},{"location":"atomic/integrations/redis/fastapi-integration/#observability","title":"Observability","text":"<ul> <li>Log cache hits/misses with request IDs.</li> <li>Export metrics per endpoint (latency impact, hit rate) to Prometheus.</li> </ul>"},{"location":"atomic/integrations/redis/fastapi-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/dependency-injection.md</code></li> <li><code>docs/atomic/integrations/redis/testing-patterns.md</code></li> </ul>"},{"location":"atomic/integrations/redis/idempotency-patterns/","title":"Idempotency Patterns","text":"<p>Redis enforces idempotency for HTTP handlers, bot commands, and worker tasks.</p>"},{"location":"atomic/integrations/redis/idempotency-patterns/#workflow","title":"Workflow","text":"<ol> <li>Generate or propagate a request ID (<code>X-Request-ID</code>, message ID).</li> <li>Build a deterministic key (<code>idempotency:&lt;operation&gt;:&lt;request-id&gt;</code>).</li> <li>Attempt <code>SETNX</code> to reserve the operation; set TTL to expire stale entries.</li> <li>Proceed only when the key is new; otherwise treat as duplicate and short-circuit.</li> </ol> <pre><code>async def check_idempotency(redis, key: str, ttl: int = 3600) -&gt; bool:\n    if await redis.setnx(key, \"processed\"):\n        await redis.expire(key, ttl)\n        return True\n    return False\n</code></pre>"},{"location":"atomic/integrations/redis/idempotency-patterns/#considerations","title":"Considerations","text":"<ul> <li>TTL should exceed the maximum expected retry window (for example, 1 hour for HTTP, a day for async workflows).</li> <li>Store metadata (status, response snapshot) when clients need deterministic replay.</li> <li>Clean up keys proactively if operations fail so that retries can proceed.</li> </ul>"},{"location":"atomic/integrations/redis/idempotency-patterns/#use-cases","title":"Use Cases","text":"<ul> <li>HTTP POST endpoints invoked by clients using retry logic.</li> <li>Telegram bots receiving duplicate updates because of Telegram retries.</li> <li>Workers processing messages from at-least-once queues.</li> </ul>"},{"location":"atomic/integrations/redis/idempotency-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/redis/key-naming-conventions.md</code></li> <li><code>docs/atomic/services/fastapi/performance-optimization.md</code></li> </ul>"},{"location":"atomic/integrations/redis/key-naming-conventions/","title":"Redis Key Naming Conventions","text":"<p>Consistent keys prevent collisions and make debugging easier. Follow a three-part schema: <code>context:entity:identifier</code>.</p>"},{"location":"atomic/integrations/redis/key-naming-conventions/#rules","title":"Rules","text":"<ul> <li>Namespaces \u2013 prefix keys with service or bounded-context names (<code>chatbot:session:abc123</code>).</li> <li>Identifiers \u2013 use stable IDs (UUIDs, message IDs) rather than mutable values.</li> <li>Separators \u2013 use colons (<code>:</code>); avoid other delimiters to keep keys uniform.</li> <li>Environment \u2013 optionally prepend environment tags (<code>prod:</code>) when sharing clusters across stages.</li> </ul>"},{"location":"atomic/integrations/redis/key-naming-conventions/#examples","title":"Examples","text":"Purpose Key Idempotency <code>idempotency:photo_upload:550e8400-e29b-41d4-a716-446655440000</code> Cache entry <code>cache:user_profile:42</code> Rate limiting <code>ratelimit:send_message:chat:1:user:42</code>"},{"location":"atomic/integrations/redis/key-naming-conventions/#expiration-strategy","title":"Expiration Strategy","text":"<ul> <li>Set TTL for ephemeral keys (idempotency, rate limiting, caches).</li> <li>Leave TTL unset for persistent state (feature flags) but document retention and cleanup processes.</li> </ul>"},{"location":"atomic/integrations/redis/key-naming-conventions/#tooling","title":"Tooling","text":"<ul> <li>Provide helper functions to assemble keys (<code>build_cache_key(namespace, *parts)</code>).</li> <li>Validate key format in unit tests to avoid regressions.</li> </ul>"},{"location":"atomic/integrations/redis/key-naming-conventions/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/redis/idempotency-patterns.md</code></li> <li><code>docs/atomic/integrations/redis/caching-strategies.md</code></li> </ul>"},{"location":"atomic/integrations/redis/testing-patterns/","title":"Redis Testing Patterns","text":"<p>Testing ensures Redis usage remains correct across services.</p>"},{"location":"atomic/integrations/redis/testing-patterns/#unit-tests","title":"Unit Tests","text":"<ul> <li>Mock Redis client methods (<code>setnx</code>, <code>expire</code>, <code>get</code>) with <code>unittest.mock.AsyncMock</code>.</li> <li>Verify key naming helpers and TTL logic.</li> <li>Ensure serialization helpers handle edge cases such as timezone-aware datetimes.</li> </ul>"},{"location":"atomic/integrations/redis/testing-patterns/#integration-tests","title":"Integration Tests","text":"<ul> <li>Launch Redis via Testcontainers for each test module.</li> <li>Reuse the event loop provided by <code>pytest-asyncio</code>; avoid nested <code>asyncio.run</code> calls.</li> <li>Assert behaviour under concurrency by issuing parallel commands with <code>asyncio.gather</code>.</li> </ul>"},{"location":"atomic/integrations/redis/testing-patterns/#failure-scenarios","title":"Failure Scenarios","text":"<ul> <li>Stop the container mid-test to simulate connection loss and confirm the service retries or fails fast.</li> <li>Test idempotency collisions by issuing duplicate operations with the same key.</li> </ul>"},{"location":"atomic/integrations/redis/testing-patterns/#tooling","title":"Tooling","text":"<ul> <li>Capture metrics/logs during integration tests to validate observability expectations.</li> <li>Lightweight fakes (for example, <code>fakeredis</code>) are acceptable for pure logic tests, but prefer real Redis for integration coverage.</li> </ul>"},{"location":"atomic/integrations/redis/testing-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/redis-testing.md</code></li> <li><code>docs/atomic/integrations/redis/idempotency-patterns.md</code></li> </ul>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/","title":"Elasticsearch Setup","text":"<p>Deploy and configure Elasticsearch for centralized log storage, full-text search, and analytics across microservices. Elasticsearch provides distributed, scalable storage for structured logs, traces, and metrics, enabling millisecond-latency queries across terabytes of operational data.</p> <p>This document covers Elasticsearch cluster deployment with Docker, index management and templates, retention policies with ILM (Index Lifecycle Management), performance tuning for high-volume log ingestion, security configuration, and backup strategies. Proper Elasticsearch setup ensures reliable log storage and fast search capabilities at scale.</p> <p>Elasticsearch transforms raw logs into searchable intelligence: instead of grepping through files on dozens of servers, you query all logs instantly with Kibana. Complex questions like \"show all errors for user-123 across all services in the last hour\" return results in milliseconds, not minutes.</p>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#docker-deployment","title":"Docker Deployment","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#single-node-development","title":"Single Node (Development)","text":"<pre><code># docker-compose.elasticsearch.yml\nversion: '3.8'\n\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    container_name: elasticsearch\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms1g -Xmx1g\"\n      - xpack.security.enabled=false\n      - xpack.security.http.ssl.enabled=false\n    ports:\n      - \"9200:9200\"\n      - \"9300:9300\"\n    volumes:\n      - elasticsearch_data:/usr/share/elasticsearch/data\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9200/_cluster/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n\nvolumes:\n  elasticsearch_data:\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#production-cluster","title":"Production Cluster","text":"<pre><code># docker-compose.elasticsearch-cluster.yml\nversion: '3.8'\n\nservices:\n  elasticsearch-master:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    container_name: elasticsearch-master\n    environment:\n      - node.name=elasticsearch-master\n      - cluster.name=es-cluster\n      - discovery.seed_hosts=elasticsearch-master,elasticsearch-data1,elasticsearch-data2\n      - cluster.initial_master_nodes=elasticsearch-master\n      - node.roles=master\n      - \"ES_JAVA_OPTS=-Xms2g -Xmx2g\"\n      - xpack.security.enabled=true\n      - xpack.security.transport.ssl.enabled=true\n      - xpack.security.transport.ssl.verification_mode=certificate\n      - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n    ports:\n      - \"9200:9200\"\n    volumes:\n      - elasticsearch_master_data:/usr/share/elasticsearch/data\n      - ./elastic-certificates.p12:/usr/share/elasticsearch/config/elastic-certificates.p12:ro\n    networks:\n      - elastic\n\n  elasticsearch-data1:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    container_name: elasticsearch-data1\n    environment:\n      - node.name=elasticsearch-data1\n      - cluster.name=es-cluster\n      - discovery.seed_hosts=elasticsearch-master,elasticsearch-data1,elasticsearch-data2\n      - cluster.initial_master_nodes=elasticsearch-master\n      - node.roles=data,ingest\n      - \"ES_JAVA_OPTS=-Xms4g -Xmx4g\"\n      - xpack.security.enabled=true\n      - xpack.security.transport.ssl.enabled=true\n      - xpack.security.transport.ssl.verification_mode=certificate\n      - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n    volumes:\n      - elasticsearch_data1:/usr/share/elasticsearch/data\n      - ./elastic-certificates.p12:/usr/share/elasticsearch/config/elastic-certificates.p12:ro\n    networks:\n      - elastic\n\n  elasticsearch-data2:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    container_name: elasticsearch-data2\n    environment:\n      - node.name=elasticsearch-data2\n      - cluster.name=es-cluster\n      - discovery.seed_hosts=elasticsearch-master,elasticsearch-data1,elasticsearch-data2\n      - cluster.initial_master_nodes=elasticsearch-master\n      - node.roles=data,ingest\n      - \"ES_JAVA_OPTS=-Xms4g -Xmx4g\"\n      - xpack.security.enabled=true\n      - xpack.security.transport.ssl.enabled=true\n      - xpack.security.transport.ssl.verification_mode=certificate\n      - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n      - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/elastic-certificates.p12\n    volumes:\n      - elasticsearch_data2:/usr/share/elasticsearch/data\n      - ./elastic-certificates.p12:/usr/share/elasticsearch/config/elastic-certificates.p12:ro\n    networks:\n      - elastic\n\nnetworks:\n  elastic:\n\nvolumes:\n  elasticsearch_master_data:\n  elasticsearch_data1:\n  elasticsearch_data2:\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#index-templates","title":"Index Templates","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#log-index-template","title":"Log Index Template","text":"<pre><code># Create index template for application logs\ncurl -X PUT \"http://localhost:9200/_index_template/logs-template\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"index_patterns\": [\"logs-*\"],\n  \"priority\": 100,\n  \"template\": {\n    \"settings\": {\n      \"number_of_shards\": 3,\n      \"number_of_replicas\": 1,\n      \"index.refresh_interval\": \"5s\",\n      \"index.codec\": \"best_compression\"\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"@timestamp\": {\"type\": \"date\"},\n        \"service\": {\"type\": \"keyword\"},\n        \"level\": {\"type\": \"keyword\"},\n        \"event\": {\"type\": \"keyword\"},\n        \"message\": {\"type\": \"text\"},\n        \"request_id\": {\"type\": \"keyword\"},\n        \"trace_id\": {\"type\": \"keyword\"},\n        \"span_id\": {\"type\": \"keyword\"},\n        \"user_id\": {\"type\": \"keyword\"},\n        \"loan_id\": {\"type\": \"keyword\"},\n        \"error\": {\n          \"properties\": {\n            \"type\": {\"type\": \"keyword\"},\n            \"message\": {\"type\": \"text\"},\n            \"stack_trace\": {\"type\": \"text\"}\n          }\n        },\n        \"duration_ms\": {\"type\": \"long\"},\n        \"status_code\": {\"type\": \"integer\"}\n      }\n    }\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#trace-index-template","title":"Trace Index Template","text":"<pre><code># Create index template for Jaeger traces\ncurl -X PUT \"http://localhost:9200/_index_template/jaeger-span-template\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"index_patterns\": [\"jaeger-span-*\"],\n  \"priority\": 100,\n  \"template\": {\n    \"settings\": {\n      \"number_of_shards\": 5,\n      \"number_of_replicas\": 1,\n      \"index.codec\": \"best_compression\",\n      \"index.mapping.nested_objects.limit\": 50000\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"traceID\": {\"type\": \"keyword\"},\n        \"spanID\": {\"type\": \"keyword\"},\n        \"operationName\": {\"type\": \"keyword\"},\n        \"serviceName\": {\"type\": \"keyword\"},\n        \"startTime\": {\"type\": \"long\"},\n        \"duration\": {\"type\": \"long\"},\n        \"tags\": {\"type\": \"nested\"},\n        \"logs\": {\"type\": \"nested\"},\n        \"references\": {\"type\": \"nested\"}\n      }\n    }\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#index-lifecycle-management-ilm","title":"Index Lifecycle Management (ILM)","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#create-ilm-policy","title":"Create ILM Policy","text":"<pre><code># Create ILM policy for log retention\ncurl -X PUT \"http://localhost:9200/_ilm/policy/logs-policy\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"min_age\": \"0ms\",\n        \"actions\": {\n          \"rollover\": {\n            \"max_age\": \"1d\",\n            \"max_size\": \"50gb\",\n            \"max_docs\": 100000000\n          },\n          \"set_priority\": {\n            \"priority\": 100\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"3d\",\n        \"actions\": {\n          \"set_priority\": {\n            \"priority\": 50\n          },\n          \"allocate\": {\n            \"number_of_replicas\": 0\n          },\n          \"forcemerge\": {\n            \"max_num_segments\": 1\n          },\n          \"shrink\": {\n            \"number_of_shards\": 1\n          }\n        }\n      },\n      \"cold\": {\n        \"min_age\": \"7d\",\n        \"actions\": {\n          \"set_priority\": {\n            \"priority\": 0\n          },\n          \"searchable_snapshot\": {\n            \"snapshot_repository\": \"backup-repo\"\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"30d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#apply-ilm-to-indices","title":"Apply ILM to Indices","text":"<pre><code># Apply ILM policy to log indices\ncurl -X PUT \"http://localhost:9200/logs-*/_settings\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"lifecycle\": {\n      \"name\": \"logs-policy\",\n      \"rollover_alias\": \"logs\"\n    }\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#performance-tuning","title":"Performance Tuning","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#jvm-heap-settings","title":"JVM Heap Settings","text":"<pre><code># docker-compose.yml - Production heap settings\nenvironment:\n  - \"ES_JAVA_OPTS=-Xms8g -Xmx8g\"  # 50% of available RAM\n\n# Best practices:\n# - Set Xms = Xmx (prevent heap resizing)\n# - Use 50% of RAM for heap (max 32GB)\n# - Leave 50% for filesystem cache\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#indexing-performance","title":"Indexing Performance","text":"<pre><code># Bulk indexing optimization\ncurl -X PUT \"http://localhost:9200/_cluster/settings\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"transient\": {\n    \"indices.memory.index_buffer_size\": \"30%\",\n    \"indices.memory.min_index_buffer_size\": \"96mb\",\n    \"indices.recovery.max_bytes_per_sec\": \"100mb\",\n    \"cluster.routing.allocation.node_concurrent_recoveries\": 5\n  }\n}\n'\n\n# Disable refresh during bulk load\ncurl -X PUT \"http://localhost:9200/logs-*/_settings\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"refresh_interval\": \"-1\"\n  }\n}\n'\n\n# Re-enable after bulk load\ncurl -X PUT \"http://localhost:9200/logs-*/_settings\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"refresh_interval\": \"5s\"\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#query-performance","title":"Query Performance","text":"<pre><code># Query cache settings\ncurl -X PUT \"http://localhost:9200/_cluster/settings\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"transient\": {\n    \"indices.queries.cache.size\": \"20%\",\n    \"indices.requests.cache.size\": \"5%\"\n  }\n}\n'\n\n# Force merge old indices for better query performance\ncurl -X POST \"http://localhost:9200/logs-2024.01.*/_forcemerge?max_num_segments=1\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#security-configuration","title":"Security Configuration","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#enable-security","title":"Enable Security","text":"<pre><code># Generate certificates\ndocker exec -it elasticsearch-master \\\n  /usr/share/elasticsearch/bin/elasticsearch-certutil cert \\\n  --silent --pem --in /tmp/instances.yml --out /tmp/certs.zip\n\n# Set built-in user passwords\ndocker exec -it elasticsearch-master \\\n  /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#create-users-and-roles","title":"Create Users and Roles","text":"<pre><code># Create read-only role for developers\ncurl -X POST \"http://localhost:9200/_security/role/logs_reader\" \\\n  -u elastic:password \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"cluster\": [\"monitor\"],\n  \"indices\": [\n    {\n      \"names\": [\"logs-*\"],\n      \"privileges\": [\"read\", \"view_index_metadata\"]\n    }\n  ]\n}\n'\n\n# Create user with logs_reader role\ncurl -X POST \"http://localhost:9200/_security/user/developer\" \\\n  -u elastic:password \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"password\": \"dev_password\",\n  \"roles\": [\"logs_reader\"],\n  \"full_name\": \"Developer User\"\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#python-client","title":"Python Client","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#connection-setup","title":"Connection Setup","text":"<pre><code># src/core/elasticsearch_client.py\nfrom elasticsearch import AsyncElasticsearch\nfrom elasticsearch.helpers import async_bulk\nimport structlog\n\nlogger = structlog.get_logger()\n\nclass ElasticsearchClient:\n    \"\"\"Async Elasticsearch client for log ingestion.\"\"\"\n\n    def __init__(self, hosts: list[str], username: str = None, password: str = None):\n        \"\"\"Initialize Elasticsearch client.\"\"\"\n        self.client = AsyncElasticsearch(\n            hosts=hosts,\n            basic_auth=(username, password) if username else None,\n            verify_certs=True,\n            ssl_show_warn=False,\n            retry_on_timeout=True,\n            max_retries=3,\n            timeout=30\n        )\n\n    async def index_log(self, log_entry: dict) -&gt; None:\n        \"\"\"Index single log entry.\"\"\"\n        try:\n            await self.client.index(\n                index=f\"logs-{log_entry['@timestamp'][:10]}\",\n                document=log_entry\n            )\n        except Exception as e:\n            logger.error(\"Failed to index log\", error=str(e))\n\n    async def bulk_index_logs(self, logs: list[dict]) -&gt; None:\n        \"\"\"Bulk index multiple log entries.\"\"\"\n        actions = [\n            {\n                \"_index\": f\"logs-{log['@timestamp'][:10]}\",\n                \"_source\": log\n            }\n            for log in logs\n        ]\n\n        try:\n            await async_bulk(self.client, actions)\n        except Exception as e:\n            logger.error(\"Bulk indexing failed\", error=str(e))\n\n    async def search_logs(self, query: dict, size: int = 100) -&gt; list[dict]:\n        \"\"\"Search logs with query.\"\"\"\n        try:\n            response = await self.client.search(\n                index=\"logs-*\",\n                body={\"query\": query, \"size\": size},\n                sort=[{\"@timestamp\": \"desc\"}]\n            )\n            return [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n        except Exception as e:\n            logger.error(\"Search failed\", error=str(e))\n            return []\n\n    async def close(self):\n        \"\"\"Close Elasticsearch connection.\"\"\"\n        await self.client.close()\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#usage-example","title":"Usage Example","text":"<pre><code># src/services/log_service.py\nfrom src.core.elasticsearch_client import ElasticsearchClient\n\n# Initialize client\nes_client = ElasticsearchClient(\n    hosts=[\"http://localhost:9200\"],\n    username=\"elastic\",\n    password=\"password\"\n)\n\n# Index log\nawait es_client.index_log({\n    \"@timestamp\": \"2024-01-10T10:30:45.123Z\",\n    \"service\": \"finance_lending_api\",\n    \"level\": \"error\",\n    \"event\": \"loan_creation_failed\",\n    \"request_id\": \"req-abc-123\",\n    \"trace_id\": \"trace-xyz-789\",\n    \"error\": {\n        \"type\": \"ValidationError\",\n        \"message\": \"Invalid loan amount\"\n    }\n})\n\n# Search logs\nresults = await es_client.search_logs({\n    \"bool\": {\n        \"must\": [\n            {\"term\": {\"service\": \"finance_lending_api\"}},\n            {\"term\": {\"level\": \"error\"}},\n            {\"range\": {\"@timestamp\": {\"gte\": \"now-1h\"}}}\n        ]\n    }\n})\n\n# Cleanup\nawait es_client.close()\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#monitoring","title":"Monitoring","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#cluster-health","title":"Cluster Health","text":"<pre><code># Check cluster health\ncurl -X GET \"http://localhost:9200/_cluster/health?pretty\"\n\n# Check node stats\ncurl -X GET \"http://localhost:9200/_nodes/stats?pretty\"\n\n# Check index stats\ncurl -X GET \"http://localhost:9200/logs-*/_stats?pretty\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code># docker-compose.yml - Add Elasticsearch exporter\nelasticsearch-exporter:\n  image: quay.io/prometheuscommunity/elasticsearch-exporter:v1.6.0\n  command:\n    - '--es.uri=http://elasticsearch:9200'\n    - '--es.all'\n    - '--es.indices'\n  ports:\n    - \"9114:9114\"\n  depends_on:\n    - elasticsearch\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#snapshot-repository","title":"Snapshot Repository","text":"<pre><code># Create snapshot repository\ncurl -X PUT \"http://localhost:9200/_snapshot/backup-repo\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"type\": \"fs\",\n  \"settings\": {\n    \"location\": \"/usr/share/elasticsearch/backups\",\n    \"compress\": true\n  }\n}\n'\n\n# Create snapshot\ncurl -X PUT \"http://localhost:9200/_snapshot/backup-repo/snapshot-$(date +%Y%m%d)\"\n\n# Restore snapshot\ncurl -X POST \"http://localhost:9200/_snapshot/backup-repo/snapshot-20240110/_restore\" \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"indices\": \"logs-*\",\n  \"ignore_unavailable\": true,\n  \"include_global_state\": false\n}\n'\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#do-use-index-templates","title":"DO: Use Index Templates","text":"<pre><code># CORRECT: Define mappings via templates\ncurl -X PUT \"http://localhost:9200/_index_template/logs-template\"\n# Ensures consistent mappings across all log indices\n\n\n# INCORRECT: Let Elasticsearch auto-detect mappings\n# \u274c Can lead to mapping conflicts and inefficient storage\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#do-configure-retention","title":"DO: Configure Retention","text":"<pre><code># CORRECT: ILM policy with clear retention\nphases:\n  delete:\n    min_age: \"30d\"  # Delete after 30 days\n\n\n# INCORRECT: No retention policy\n# \u274c Disk fills up, cluster fails\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#dont-use-too-many-shards","title":"DON'T: Use Too Many Shards","text":"<pre><code>// INCORRECT: Over-sharding\n{\n  \"settings\": {\n    \"number_of_shards\": 20  // \u274c Too many for small index\n  }\n}\n\n// CORRECT: Right-size shards\n{\n  \"settings\": {\n    \"number_of_shards\": 3  // \u2705 10-50GB per shard target\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#checklist","title":"Checklist","text":"<ul> <li> Deploy Elasticsearch with Docker</li> <li> Configure cluster settings (single-node or cluster)</li> <li> Create index templates for logs and traces</li> <li> Configure ILM policies for retention</li> <li> Set appropriate JVM heap size (50% of RAM)</li> <li> Enable security and create users/roles</li> <li> Configure snapshot repository for backups</li> <li> Set up Elasticsearch exporter for Prometheus</li> <li> Test log indexing and searching</li> <li> Verify cluster health status is green</li> <li> Document Elasticsearch endpoints and credentials</li> <li> Schedule regular snapshots</li> </ul>"},{"location":"atomic/observability/elk-stack/elasticsearch-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/elk-stack/logstash-configuration.md</code> \u2014 Logstash pipeline setup</li> <li><code>docs/atomic/observability/elk-stack/filebeat-setup.md</code> \u2014 Log shipping configuration</li> <li><code>docs/atomic/observability/elk-stack/kibana-dashboards.md</code> \u2014 Visualization setup</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging patterns</li> </ul>"},{"location":"atomic/observability/elk-stack/filebeat-setup/","title":"Filebeat Setup","text":"<p>Configure Filebeat for lightweight log shipping from containers to Elasticsearch or Logstash. Filebeat provides reliable log collection with minimal resource usage, automatic container discovery, and guaranteed delivery through persistent queues.</p> <p>This document covers Filebeat deployment with Docker, autodiscovery configuration, multiline log handling, and performance optimization. Filebeat is the standard way to ship logs from Docker containers to the ELK stack.</p> <p>Filebeat solves the log collection problem: instead of each container writing directly to Elasticsearch (inefficient), Filebeat tails container logs, enriches them with metadata, and ships them reliably to your centralized logging system.</p>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#docker-deployment","title":"Docker Deployment","text":"<pre><code># docker-compose.filebeat.yml\nversion: '3.8'\n\nservices:\n  filebeat:\n    image: docker.elastic.co/beats/filebeat:8.15.0\n    container_name: filebeat\n    user: root\n    volumes:\n      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - filebeat_data:/usr/share/filebeat/data\n    environment:\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n      - LOGSTASH_HOSTS=logstash:5044\n    command: [\"filebeat\", \"-e\", \"-strict.perms=false\"]\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  filebeat_data:\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#autodiscovery-configuration","title":"Autodiscovery Configuration","text":"<pre><code># filebeat.yml\nfilebeat.autodiscover:\n  providers:\n    - type: docker\n      hints.enabled: true\n      hints.default_config:\n        type: container\n        paths:\n          - /var/lib/docker/containers/${data.container.id}/*.log\n\nprocessors:\n  - add_docker_metadata: ~\n  - decode_json_fields:\n      fields: [\"message\"]\n      target: \"\"\n      overwrite_keys: true\n  - drop_event:\n      when:\n        or:\n          - contains:\n              container.name: \"filebeat\"\n          - contains:\n              message: \"healthcheck\"\n\noutput.elasticsearch:\n  hosts: [\"${ELASTICSEARCH_HOSTS:elasticsearch:9200}\"]\n  index: \"logs-%{[service]:other}-%{+yyyy.MM.dd}\"\n  template.name: \"logs\"\n  template.pattern: \"logs-*\"\n\n# Alternative: Output to Logstash\n# output.logstash:\n#   hosts: [\"${LOGSTASH_HOSTS:logstash:5044}\"]\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#service-specific-configuration","title":"Service-Specific Configuration","text":"<pre><code># Service hints via Docker labels\nservices:\n  finance_lending_api:\n    labels:\n      - \"co.elastic.logs/module=python\"\n      - \"co.elastic.logs/multiline.pattern=^\\\\d{4}-\\\\d{2}-\\\\d{2}\"\n      - \"co.elastic.logs/multiline.negate=true\"\n      - \"co.elastic.logs/multiline.match=after\"\n      - \"co.elastic.logs/processors.1.decode_json_fields.fields=message\"\n      - \"co.elastic.logs/processors.1.decode_json_fields.target=json\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#multiline-configuration","title":"Multiline Configuration","text":"<pre><code>filebeat.inputs:\n  - type: container\n    paths:\n      - /var/lib/docker/containers/*/*.log\n    multiline.pattern: '^\\d{4}-\\d{2}-\\d{2}|^\\{'\n    multiline.negate: true\n    multiline.match: after\n    multiline.timeout: 5s\n    multiline.max_lines: 500\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/elk-stack/filebeat-setup/#do-use-autodiscovery","title":"DO: Use Autodiscovery","text":"<pre><code># CORRECT: Autodiscovery with hints\nfilebeat.autodiscover:\n  providers:\n    - type: docker\n      hints.enabled: true\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#do-add-metadata","title":"DO: Add Metadata","text":"<pre><code># CORRECT: Enrich logs with Docker metadata\nprocessors:\n  - add_docker_metadata:\n      host: \"unix:///var/run/docker.sock\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#checklist","title":"Checklist","text":"<ul> <li> Deploy Filebeat with Docker</li> <li> Configure autodiscovery for containers</li> <li> Set up multiline pattern for stack traces</li> <li> Add Docker metadata enrichment</li> <li> Configure output to Elasticsearch or Logstash</li> <li> Test log shipping from containers</li> <li> Monitor Filebeat metrics</li> </ul>"},{"location":"atomic/observability/elk-stack/filebeat-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> \u2014 Elasticsearch configuration</li> <li><code>docs/atomic/observability/elk-stack/logstash-configuration.md</code> \u2014 Logstash pipeline</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging patterns</li> </ul>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/","title":"Kibana Dashboards","text":"<p>Create Kibana dashboards for log visualization, search, and analysis. Kibana provides the UI layer for Elasticsearch, enabling interactive exploration of logs, creation of visualizations, and building operational dashboards.</p> <p>This document covers dashboard creation, saved searches, visualizations, and index patterns. Kibana transforms raw Elasticsearch data into actionable insights through interactive dashboards.</p> <p>Without Kibana, teams query Elasticsearch via API. With Kibana, they explore logs visually, build dashboards in minutes, and share insights across the organization.</p>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#index-patterns","title":"Index Patterns","text":"<pre><code># Create index pattern via API\ncurl -X POST \"http://kibana:5601/api/saved_objects/index-pattern\" \\\n  -H \"kbn-xsrf: true\" \\\n  -H \"Content-Type: application/json\" -d'\n{\n  \"attributes\": {\n    \"title\": \"logs-*\",\n    \"timeFieldName\": \"@timestamp\"\n  }\n}'\n</code></pre>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#dashboard-configuration","title":"Dashboard Configuration","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Service Logs Overview\",\n    \"panels\": [\n      {\n        \"type\": \"search\",\n        \"title\": \"Recent Errors\",\n        \"query\": \"level:error\"\n      },\n      {\n        \"type\": \"visualization\",\n        \"title\": \"Log Levels Over Time\",\n        \"visType\": \"line\"\n      },\n      {\n        \"type\": \"lens\",\n        \"title\": \"Top Error Messages\",\n        \"query\": \"level:error | stats count() by message\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#saved-searches","title":"Saved Searches","text":"<pre><code>{\n  \"search\": {\n    \"title\": \"Failed Loan Applications\",\n    \"query\": \"service:finance_lending_api AND event:loan_creation_failed\",\n    \"columns\": [\"@timestamp\", \"request_id\", \"user_id\", \"error.message\"],\n    \"sort\": [[\"@timestamp\", \"desc\"]]\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/elk-stack/kibana-dashboards/#do-use-filters","title":"DO: Use Filters","text":"<pre><code># CORRECT: Efficient filtering\nservice:\"finance_lending_api\" AND level:error AND @timestamp:[now-1h TO now]\n</code></pre>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#do-save-searches","title":"DO: Save Searches","text":"<pre><code># CORRECT: Reusable saved searches\nSave commonly used queries for team sharing\n</code></pre>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#checklist","title":"Checklist","text":"<ul> <li> Create index patterns for log indices</li> <li> Build service overview dashboard</li> <li> Create error investigation dashboard</li> <li> Set up saved searches for common queries</li> <li> Configure time range defaults</li> <li> Set up dashboard auto-refresh</li> <li> Export dashboards as JSON for backup</li> </ul>"},{"location":"atomic/observability/elk-stack/kibana-dashboards/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> \u2014 Elasticsearch backend</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Logging patterns</li> </ul>"},{"location":"atomic/observability/elk-stack/logstash-configuration/","title":"Logstash Configuration","text":"<p>Configure Logstash pipelines for log processing, transformation, and enrichment before indexing into Elasticsearch. Logstash provides powerful data transformation capabilities through filters, enabling parsing of unstructured logs, field extraction, data enrichment, and conditional routing.</p> <p>This document covers pipeline configuration, input plugins for various log sources, filter plugins for data transformation, output configuration for Elasticsearch, performance tuning, and monitoring. Proper Logstash configuration ensures logs are properly structured and enriched before storage.</p> <p>Logstash acts as the ETL layer for logs: it receives raw logs from various sources, parses them into structured fields, enriches them with additional context, and routes them to appropriate Elasticsearch indices. Without Logstash, you'd need custom parsing logic in every application.</p>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#pipeline-configuration","title":"Pipeline Configuration","text":""},{"location":"atomic/observability/elk-stack/logstash-configuration/#basic-pipeline","title":"Basic Pipeline","text":"<pre><code># logstash/pipeline/logstash.conf\ninput {\n  # Receive logs from Filebeat\n  beats {\n    port =&gt; 5044\n    ssl =&gt; false\n  }\n\n  # Direct TCP input\n  tcp {\n    port =&gt; 5000\n    codec =&gt; json_lines\n  }\n\n  # HTTP input endpoint\n  http {\n    port =&gt; 8080\n    codec =&gt; json\n  }\n}\n\nfilter {\n  # Parse JSON logs\n  if [message] =~ /^\\{/ {\n    json {\n      source =&gt; \"message\"\n      target =&gt; \"parsed\"\n    }\n\n    mutate {\n      remove_field =&gt; [\"message\"]\n    }\n  }\n\n  # Add timestamp if missing\n  if ![timestamp] {\n    ruby {\n      code =&gt; \"event.set('timestamp', Time.now.utc.iso8601)\"\n    }\n  }\n\n  # Parse log level\n  if [level] {\n    mutate {\n      lowercase =&gt; [\"level\"]\n    }\n  }\n}\n\noutput {\n  # Send to Elasticsearch\n  elasticsearch {\n    hosts =&gt; [\"elasticsearch:9200\"]\n    index =&gt; \"logs-%{[service]}-%{+YYYY.MM.dd}\"\n    template_name =&gt; \"logs-template\"\n    template =&gt; \"/usr/share/logstash/templates/logs-template.json\"\n    template_overwrite =&gt; true\n  }\n\n  # Debug output\n  if [@metadata][debug] {\n    stdout {\n      codec =&gt; rubydebug\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#docker-deployment","title":"Docker Deployment","text":"<pre><code># docker-compose.logstash.yml\nversion: '3.8'\n\nservices:\n  logstash:\n    image: docker.elastic.co/logstash/logstash:8.15.0\n    container_name: logstash\n    ports:\n      - \"5044:5044\"  # Beats input\n      - \"5000:5000\"  # TCP input\n      - \"8080:8080\"  # HTTP input\n      - \"9600:9600\"  # Monitoring API\n    environment:\n      - \"LS_JAVA_OPTS=-Xms2g -Xmx2g\"\n      - PIPELINE_WORKERS=4\n      - PIPELINE_BATCH_SIZE=125\n      - PIPELINE_BATCH_DELAY=50\n    volumes:\n      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro\n      - ./logstash/templates:/usr/share/logstash/templates:ro\n      - logstash_data:/usr/share/logstash/data\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  logstash_data:\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#advanced-filters","title":"Advanced Filters","text":""},{"location":"atomic/observability/elk-stack/logstash-configuration/#log-parsing","title":"Log Parsing","text":"<pre><code>filter {\n  # Parse application logs\n  if [service] == \"finance_lending_api\" {\n    grok {\n      match =&gt; {\n        \"message\" =&gt; \"%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:log_message}\"\n      }\n    }\n\n    # Extract request ID from message\n    if [log_message] =~ /request_id/ {\n      grok {\n        match =&gt; {\n          \"log_message\" =&gt; \"request_id=%{UUID:request_id}\"\n        }\n      }\n    }\n  }\n\n  # Parse nginx access logs\n  if [service] == \"nginx\" {\n    grok {\n      match =&gt; {\n        \"message\" =&gt; '%{IPORHOST:remote_ip} - %{DATA:user} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code} %{NUMBER:bytes_sent} \"%{DATA:referrer}\" \"%{DATA:user_agent}\"'\n      }\n    }\n\n    mutate {\n      convert =&gt; {\n        \"status_code\" =&gt; \"integer\"\n        \"bytes_sent\" =&gt; \"integer\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#data-enrichment","title":"Data Enrichment","text":"<pre><code>filter {\n  # GeoIP enrichment\n  if [remote_ip] {\n    geoip {\n      source =&gt; \"remote_ip\"\n      target =&gt; \"geoip\"\n      fields =&gt; [\"country_name\", \"city_name\", \"location\"]\n    }\n  }\n\n  # User enrichment from database\n  if [user_id] {\n    jdbc_streaming {\n      jdbc_driver_library =&gt; \"/usr/share/logstash/mysql-connector-java.jar\"\n      jdbc_driver_class =&gt; \"com.mysql.cj.jdbc.Driver\"\n      jdbc_connection_string =&gt; \"jdbc:mysql://mysql:3306/users\"\n      jdbc_user =&gt; \"logstash\"\n      jdbc_password =&gt; \"password\"\n      statement =&gt; \"SELECT name, email, tier FROM users WHERE id = :userid\"\n      parameters =&gt; { \"userid\" =&gt; \"user_id\" }\n      target =&gt; \"user_info\"\n    }\n  }\n\n  # Add environment metadata\n  mutate {\n    add_field =&gt; {\n      \"environment\" =&gt; \"${ENVIRONMENT:production}\"\n      \"datacenter\" =&gt; \"${DATACENTER:us-east-1}\"\n      \"cluster\" =&gt; \"${CLUSTER:main}\"\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#conditional-routing","title":"Conditional Routing","text":"<pre><code>output {\n  # Route by log level\n  if [level] == \"error\" or [level] == \"fatal\" {\n    elasticsearch {\n      hosts =&gt; [\"elasticsearch:9200\"]\n      index =&gt; \"errors-%{+YYYY.MM.dd}\"\n    }\n\n    # Send critical errors to alerting\n    if [level] == \"fatal\" {\n      http {\n        url =&gt; \"https://alerts.example.com/webhook\"\n        http_method =&gt; \"post\"\n        format =&gt; \"json\"\n      }\n    }\n  }\n\n  # Route by service\n  else if [service] {\n    elasticsearch {\n      hosts =&gt; [\"elasticsearch:9200\"]\n      index =&gt; \"logs-%{[service]}-%{+YYYY.MM.dd}\"\n    }\n  }\n\n  # Default routing\n  else {\n    elasticsearch {\n      hosts =&gt; [\"elasticsearch:9200\"]\n      index =&gt; \"logs-other-%{+YYYY.MM.dd}\"\n    }\n  }\n\n  # Archive to S3\n  if [archive] == true {\n    s3 {\n      region =&gt; \"us-east-1\"\n      bucket =&gt; \"logs-archive\"\n      prefix =&gt; \"logstash/%{+YYYY/MM/dd}/\"\n      codec =&gt; \"json_lines\"\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"atomic/observability/elk-stack/logstash-configuration/#pipeline-settings","title":"Pipeline Settings","text":"<pre><code># logstash/config/pipelines.yml\n- pipeline.id: main\n  pipeline.workers: 8\n  pipeline.batch.size: 250\n  pipeline.batch.delay: 50\n  queue.type: persisted\n  queue.max_bytes: 4gb\n  queue.checkpoint.writes: 1024\n\n- pipeline.id: metrics\n  pipeline.workers: 2\n  pipeline.batch.size: 100\n  config.string: |\n    input { pipeline { address =&gt; metrics } }\n    output { elasticsearch { index =&gt; \"metrics-%{+YYYY.MM.dd}\" } }\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#jvm-configuration","title":"JVM Configuration","text":"<pre><code># logstash/config/jvm.options\n-Xms4g\n-Xmx4g\n-XX:+UseG1GC\n-XX:MaxGCPauseMillis=200\n-XX:+ParallelRefProcEnabled\n-XX:+UnlockExperimentalVMOptions\n-XX:+DisableExplicitGC\n-Djava.awt.headless=true\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#monitoring","title":"Monitoring","text":""},{"location":"atomic/observability/elk-stack/logstash-configuration/#metrics-api","title":"Metrics API","text":"<pre><code># Check pipeline stats\ncurl -X GET \"http://localhost:9600/_node/stats/pipelines?pretty\"\n\n# Check JVM stats\ncurl -X GET \"http://localhost:9600/_node/stats/jvm?pretty\"\n\n# Check hot threads\ncurl -X GET \"http://localhost:9600/_node/hot_threads?pretty\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code># Enable monitoring\ndocker run -d \\\n  -p 9600:9600 \\\n  docker.elastic.co/logstash/logstash:8.15.0 \\\n  -e \"xpack.monitoring.enabled=true\" \\\n  -e \"xpack.monitoring.elasticsearch.hosts=http://elasticsearch:9200\"\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/elk-stack/logstash-configuration/#do-use-persistent-queues","title":"DO: Use Persistent Queues","text":"<pre><code># CORRECT: Persistent queue for reliability\nqueue.type: persisted\nqueue.max_bytes: 1gb\n\n# INCORRECT: Memory queue (data loss on crash)\nqueue.type: memory  # \u274c Not reliable\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#dont-complex-ruby-code","title":"DON'T: Complex Ruby Code","text":"<pre><code># INCORRECT: Complex processing in Ruby filter\nruby {\n  code =&gt; \"\n    # \u274c 50 lines of complex logic\n    # Move to dedicated service\n  \"\n}\n\n# CORRECT: Simple field manipulation\nruby {\n  code =&gt; \"event.set('timestamp', Time.now.utc.iso8601)\"  # \u2705 Simple\n}\n</code></pre>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#checklist","title":"Checklist","text":"<ul> <li> Configure Logstash pipeline with inputs/filters/outputs</li> <li> Set up JSON parsing for structured logs</li> <li> Configure Grok patterns for unstructured logs</li> <li> Add data enrichment filters if needed</li> <li> Configure conditional routing by service/level</li> <li> Tune pipeline workers and batch size</li> <li> Enable persistent queues for reliability</li> <li> Set appropriate JVM heap size</li> <li> Configure monitoring endpoint</li> <li> Test pipeline with sample logs</li> <li> Verify logs are properly indexed in Elasticsearch</li> <li> Document custom Grok patterns</li> </ul>"},{"location":"atomic/observability/elk-stack/logstash-configuration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> \u2014 Elasticsearch configuration</li> <li><code>docs/atomic/observability/elk-stack/filebeat-setup.md</code> \u2014 Log shipping setup</li> <li><code>docs/atomic/observability/logging/log-formatting.md</code> \u2014 Log format standards</li> </ul>"},{"location":"atomic/observability/error-tracking/alerting-patterns/","title":"Alerting Patterns","text":"<p>Design effective alerting strategies for production errors and performance issues. Proper alerting ensures critical issues are noticed immediately while avoiding alert fatigue from noise.</p> <p>This document covers alert rules, severity levels, routing, and escalation policies. Good alerting patterns mean the right people are notified about the right problems at the right time.</p> <p>Without proper alerting, critical errors go unnoticed until users complain. With smart alerting, you catch and fix issues before users are impacted.</p>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#alert-severity-levels","title":"Alert Severity Levels","text":"<pre><code># src/core/alerting.py\nfrom enum import Enum\n\nclass AlertSeverity(Enum):\n    CRITICAL = \"critical\"  # Page immediately (database down)\n    HIGH = \"high\"         # Notify on-call (error spike)\n    MEDIUM = \"medium\"     # Notify team (degraded performance)\n    LOW = \"low\"           # Log only (minor issues)\n\ndef determine_severity(error: Exception, context: dict) -&gt; AlertSeverity:\n    \"\"\"Determine alert severity based on error and context.\"\"\"\n    # Critical: Infrastructure failures\n    if isinstance(error, (DatabaseConnectionError, RedisConnectionError)):\n        return AlertSeverity.CRITICAL\n\n    # High: Business-critical failures\n    if context.get(\"endpoint\") in [\"/api/payments\", \"/api/loans/approve\"]:\n        if isinstance(error, HTTPException) and error.status_code &gt;= 500:\n            return AlertSeverity.HIGH\n\n    # Medium: Degraded service\n    if context.get(\"response_time_ms\", 0) &gt; 5000:\n        return AlertSeverity.MEDIUM\n\n    return AlertSeverity.LOW\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#alert-rules","title":"Alert Rules","text":"<pre><code># prometheus/alerts.yml\ngroups:\n  - name: error_tracking\n    rules:\n      - alert: HighErrorRate\n        expr: rate(errors_total[5m]) &gt; 10\n        for: 5m\n        labels:\n          severity: high\n        annotations:\n          summary: \"High error rate detected\"\n\n      - alert: CriticalServiceDown\n        expr: up{service=\"finance_lending_api\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Service is down\"\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#notification-routing","title":"Notification Routing","text":"<pre><code># Alert routing configuration\nALERT_ROUTES = {\n    AlertSeverity.CRITICAL: [\n        {\"type\": \"pagerduty\", \"key\": \"critical-incidents\"},\n        {\"type\": \"slack\", \"channel\": \"#incidents\"},\n        {\"type\": \"email\", \"to\": \"oncall@example.com\"}\n    ],\n    AlertSeverity.HIGH: [\n        {\"type\": \"slack\", \"channel\": \"#alerts\"},\n        {\"type\": \"email\", \"to\": \"team@example.com\"}\n    ],\n    AlertSeverity.MEDIUM: [\n        {\"type\": \"slack\", \"channel\": \"#monitoring\"}\n    ],\n    AlertSeverity.LOW: [\n        {\"type\": \"log\"}\n    ]\n}\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#alert-aggregation","title":"Alert Aggregation","text":"<pre><code>from datetime import datetime, timedelta\nfrom collections import defaultdict\n\nclass AlertAggregator:\n    def __init__(self, window_minutes: int = 5):\n        self.window = timedelta(minutes=window_minutes)\n        self.alerts = defaultdict(list)\n\n    def add(self, alert_key: str, alert: dict):\n        \"\"\"Add alert to aggregation window.\"\"\"\n        now = datetime.now()\n        self.alerts[alert_key].append((now, alert))\n\n        # Clean old alerts\n        cutoff = now - self.window\n        self.alerts[alert_key] = [\n            (ts, a) for ts, a in self.alerts[alert_key] \n            if ts &gt; cutoff\n        ]\n\n    def should_alert(self, alert_key: str, threshold: int = 5) -&gt; bool:\n        \"\"\"Check if aggregated alerts exceed threshold.\"\"\"\n        return len(self.alerts[alert_key]) &gt;= threshold\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/error-tracking/alerting-patterns/#do-alert-on-symptoms","title":"DO: Alert on Symptoms","text":"<pre><code># CORRECT: Alert on user-visible symptoms\nif response_time_p95 &gt; 1000:  # Users experiencing slowness\n    send_alert(AlertSeverity.HIGH)\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#dont-alert-on-every-error","title":"DON'T: Alert on Every Error","text":"<pre><code># INCORRECT: Alert fatigue\nfor error in all_errors:\n    send_alert()  # \u274c Too noisy\n\n# CORRECT: Alert on error rate\nif error_rate &gt; threshold:\n    send_alert()  # \u2705 Actionable\n</code></pre>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#checklist","title":"Checklist","text":"<ul> <li> Define alert severity levels</li> <li> Create routing rules by severity</li> <li> Set up notification channels (Slack, PagerDuty)</li> <li> Implement alert aggregation</li> <li> Configure escalation policies</li> <li> Test alert delivery</li> <li> Document on-call procedures</li> </ul>"},{"location":"atomic/observability/error-tracking/alerting-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/error-tracking/sentry-integration.md</code> \u2014 Error capture</li> <li><code>docs/atomic/observability/error-tracking/error-grouping.md</code> \u2014 Error grouping</li> <li><code>docs/atomic/observability/metrics/prometheus-setup.md</code> \u2014 Metrics alerting</li> </ul>"},{"location":"atomic/observability/error-tracking/error-grouping/","title":"Error Grouping","text":"<p>Implement error grouping strategies to reduce noise and identify patterns in production errors. Error grouping consolidates similar errors into issues, making it easier to prioritize fixes and track error trends.</p> <p>This document covers fingerprinting rules, custom grouping logic, and error deduplication. Proper error grouping transforms thousands of error events into manageable issues.</p> <p>Without grouping, every error is noise. With smart grouping, you see patterns: \"500 instances of database timeout\" instead of 500 separate alerts.</p>"},{"location":"atomic/observability/error-tracking/error-grouping/#custom-fingerprinting","title":"Custom Fingerprinting","text":"<pre><code># src/core/error_grouping.py\nimport sentry_sdk\nimport hashlib\n\ndef custom_fingerprint(error: Exception, context: dict) -&gt; list[str]:\n    \"\"\"Generate custom fingerprint for error grouping.\"\"\"\n    if isinstance(error, DatabaseError):\n        # Group database errors by query\n        return [\"database\", error.query]\n\n    elif isinstance(error, HTTPException):\n        # Group HTTP errors by status and endpoint\n        return [\"http\", str(error.status_code), context.get(\"endpoint\", \"unknown\")]\n\n    elif isinstance(error, ValidationError):\n        # Group validation errors by field\n        return [\"validation\", error.field_name]\n\n    else:\n        # Default grouping by error type and message\n        return [error.__class__.__name__, str(error)]\n\n# Apply fingerprint before sending\ndef before_send(event, hint):\n    \"\"\"Add custom fingerprint to Sentry event.\"\"\"\n    if \"exc_info\" in hint:\n        error = hint[\"exc_info\"][1]\n        context = event.get(\"extra\", {})\n        event[\"fingerprint\"] = custom_fingerprint(error, context)\n    return event\n\nsentry_sdk.init(before_send=before_send)\n</code></pre>"},{"location":"atomic/observability/error-tracking/error-grouping/#grouping-rules","title":"Grouping Rules","text":"<pre><code># Group similar database errors\nclass DatabaseErrorGrouper:\n    @staticmethod\n    def normalize_query(query: str) -&gt; str:\n        \"\"\"Normalize SQL for grouping.\"\"\"\n        # Replace values with placeholders\n        import re\n        query = re.sub(r'\\d+', '?', query)  # Numbers\n        query = re.sub(r\"'[^']*'\", '?', query)  # Strings\n        return query\n\n# Group by normalized query\nfingerprint = [\"db_error\", DatabaseErrorGrouper.normalize_query(error.query)]\n</code></pre>"},{"location":"atomic/observability/error-tracking/error-grouping/#error-deduplication","title":"Error Deduplication","text":"<pre><code>from collections import deque\nfrom datetime import datetime, timedelta\n\nclass ErrorDeduplicator:\n    def __init__(self, window_seconds: int = 60):\n        self.recent_errors = deque(maxlen=1000)\n        self.window = timedelta(seconds=window_seconds)\n\n    def should_report(self, error: Exception) -&gt; bool:\n        \"\"\"Check if error should be reported.\"\"\"\n        now = datetime.now()\n        error_hash = self._hash_error(error)\n\n        # Remove old errors\n        while self.recent_errors and (now - self.recent_errors[0][1]) &gt; self.window:\n            self.recent_errors.popleft()\n\n        # Check for duplicate\n        for stored_hash, _ in self.recent_errors:\n            if stored_hash == error_hash:\n                return False\n\n        # New error\n        self.recent_errors.append((error_hash, now))\n        return True\n\n    def _hash_error(self, error: Exception) -&gt; str:\n        \"\"\"Generate hash for error.\"\"\"\n        key = f\"{error.__class__.__name__}:{str(error)}\"\n        return hashlib.md5(key.encode()).hexdigest()\n\ndeduplicator = ErrorDeduplicator(window_seconds=60)\n\nif deduplicator.should_report(error):\n    sentry_sdk.capture_exception(error)\n</code></pre>"},{"location":"atomic/observability/error-tracking/error-grouping/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/error-tracking/error-grouping/#do-group-by-root-cause","title":"DO: Group by Root Cause","text":"<pre><code># CORRECT: Group by root cause\nif \"Connection pool exhausted\" in str(error):\n    fingerprint = [\"database\", \"connection_pool_exhausted\"]\n</code></pre>"},{"location":"atomic/observability/error-tracking/error-grouping/#dont-over-granular-grouping","title":"DON'T: Over-Granular Grouping","text":"<pre><code># INCORRECT: Too specific (creates many groups)\nfingerprint = [str(error), timestamp, user_id]  # \u274c\n\n# CORRECT: Appropriate grouping\nfingerprint = [error.__class__.__name__, endpoint]  # \u2705\n</code></pre>"},{"location":"atomic/observability/error-tracking/error-grouping/#checklist","title":"Checklist","text":"<ul> <li> Implement custom fingerprinting logic</li> <li> Create grouping rules by error type</li> <li> Set up deduplication for noisy errors</li> <li> Test grouping with sample errors</li> <li> Monitor group cardinality</li> <li> Document grouping patterns</li> </ul>"},{"location":"atomic/observability/error-tracking/error-grouping/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/error-tracking/sentry-integration.md</code> \u2014 Sentry setup</li> <li><code>docs/atomic/observability/error-tracking/alerting-patterns.md</code> \u2014 Alert configuration</li> </ul>"},{"location":"atomic/observability/error-tracking/sentry-integration/","title":"Sentry Integration","text":"<p>Integrate Sentry for real-time error tracking, alerting, and debugging across microservices. Sentry provides automatic error capture, stack trace deobfuscation, release tracking, and performance monitoring.</p> <p>This document covers Sentry SDK setup for FastAPI/Aiogram, error capture configuration, performance tracing, and alert rules. Sentry transforms cryptic production errors into actionable bug reports with full context.</p> <p>Without Sentry, errors are buried in logs. With Sentry, every error triggers alerts with stack traces, user context, and breadcrumbs showing what led to the failure.</p>"},{"location":"atomic/observability/error-tracking/sentry-integration/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code># src/core/sentry_config.py\nimport sentry_sdk\nfrom sentry_sdk.integrations.fastapi import FastApiIntegration\nfrom sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration\nfrom sentry_sdk.integrations.logging import LoggingIntegration\n\ndef init_sentry(dsn: str, environment: str = \"production\"):\n    \"\"\"Initialize Sentry error tracking.\"\"\"\n    sentry_sdk.init(\n        dsn=dsn,\n        environment=environment,\n        integrations=[\n            FastApiIntegration(transaction_style=\"endpoint\"),\n            SqlalchemyIntegration(),\n            LoggingIntegration(level=\"ERROR\", event_level=\"ERROR\")\n        ],\n        traces_sample_rate=0.1,  # 10% performance monitoring\n        profiles_sample_rate=0.1,  # 10% profiling\n        attach_stacktrace=True,\n        send_default_pii=False,  # GDPR compliance\n        before_send=filter_sensitive_data\n    )\n\ndef filter_sensitive_data(event, hint):\n    \"\"\"Filter sensitive data before sending to Sentry.\"\"\"\n    # Remove sensitive fields\n    if \"extra\" in event:\n        for key in [\"password\", \"token\", \"api_key\", \"secret\"]:\n            event[\"extra\"].pop(key, None)\n    return event\n\n# src/main.py\nfrom src.core.sentry_config import init_sentry\n\ninit_sentry(\n    dsn=\"https://key@sentry.io/project\",\n    environment=\"production\"\n)\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#manual-error-capture","title":"Manual Error Capture","text":"<pre><code>import sentry_sdk\n\ntry:\n    result = await risky_operation()\nexcept Exception as e:\n    sentry_sdk.capture_exception(e, extra={\n        \"loan_id\": loan_id,\n        \"user_id\": user_id,\n        \"operation\": \"credit_check\"\n    })\n    raise\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>with sentry_sdk.start_transaction(op=\"task\", name=\"process_loan\"):\n    with sentry_sdk.start_span(op=\"db\", description=\"fetch_user\"):\n        user = await db.get_user(user_id)\n\n    with sentry_sdk.start_span(op=\"http\", description=\"credit_check\"):\n        score = await credit_api.check(user_id)\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#docker-configuration","title":"Docker Configuration","text":"<pre><code>services:\n  api:\n    environment:\n      - SENTRY_DSN=https://key@sentry.io/project\n      - SENTRY_ENVIRONMENT=production\n      - SENTRY_RELEASE=${GIT_SHA}\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#alert-rules","title":"Alert Rules","text":"<pre><code># Sentry Alert Configuration\n{\n  \"name\": \"High Error Rate\",\n  \"conditions\": [\n    {\"id\": \"event_frequency\", \"value\": 100, \"interval\": \"1h\"}\n  ],\n  \"actions\": [\n    {\"id\": \"notify_email\", \"targetIdentifier\": \"ops@example.com\"},\n    {\"id\": \"notify_slack\", \"channel\": \"#alerts\"}\n  ]\n}\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/error-tracking/sentry-integration/#do-add-context","title":"DO: Add Context","text":"<pre><code># CORRECT: Rich context for debugging\nsentry_sdk.set_context(\"loan\", {\n    \"id\": loan_id,\n    \"amount\": amount,\n    \"status\": status\n})\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#dont-log-sensitive-data","title":"DON'T: Log Sensitive Data","text":"<pre><code># INCORRECT: PII in Sentry\nsentry_sdk.capture_message(f\"User {email} failed\")  # \u274c\n\n# CORRECT: No PII\nsentry_sdk.capture_message(f\"User {user_id} failed\")  # \u2705\n</code></pre>"},{"location":"atomic/observability/error-tracking/sentry-integration/#checklist","title":"Checklist","text":"<ul> <li> Install Sentry SDK</li> <li> Configure DSN and environment</li> <li> Add integrations (FastAPI, SQLAlchemy)</li> <li> Set up error filtering</li> <li> Configure performance monitoring</li> <li> Create alert rules</li> <li> Test error capture</li> <li> Set up release tracking</li> </ul>"},{"location":"atomic/observability/error-tracking/sentry-integration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/error-tracking/error-grouping.md</code> \u2014 Error grouping strategies</li> <li><code>docs/atomic/observability/error-tracking/alerting-patterns.md</code> \u2014 Alert configuration</li> </ul>"},{"location":"atomic/observability/logging/centralized-logging/","title":"Centralized Logging","text":"<p>Aggregate logs from all microservices into a centralized logging system for unified search, analysis, alerting, and troubleshooting. Centralized logging enables querying logs across services, correlating distributed requests, monitoring system health, and debugging production issues without accessing individual service instances.</p> <p>This document covers centralized logging architecture using Elasticsearch/CloudWatch/Loki, log shipping with Filebeat/Fluentd, log retention policies, access control, query patterns, dashboard creation, and alerting integration. Centralized logging is essential for production observability in distributed systems.</p> <p>Centralized logging solves the distributed logs problem: in microservices architecture with dozens of services running hundreds of containers across multiple servers, logs are scattered everywhere. Without centralization, debugging requires SSH-ing into multiple servers, searching through local files, and manually correlating timestamps\u2014an impossible task at scale.</p>"},{"location":"atomic/observability/logging/centralized-logging/#architecture-patterns","title":"Architecture Patterns","text":""},{"location":"atomic/observability/logging/centralized-logging/#elk-stack-elasticsearch-logstash-kibana","title":"ELK Stack (Elasticsearch, Logstash, Kibana)","text":"<pre><code># docker-compose.elk.yml\nversion: '3.8'\n\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n      - xpack.security.enabled=false\n    ports:\n      - \"9200:9200\"\n    volumes:\n      - elasticsearch_data:/usr/share/elasticsearch/data\n\n  kibana:\n    image: docker.elastic.co/kibana/kibana:8.15.0\n    ports:\n      - \"5601:5601\"\n    environment:\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n    depends_on:\n      - elasticsearch\n\n  filebeat:\n    image: docker.elastic.co/beats/filebeat:8.15.0\n    user: root\n    volumes:\n      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  elasticsearch_data:\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#log-shipping-with-filebeat","title":"Log Shipping with Filebeat","text":"<pre><code># filebeat.yml\nfilebeat.autodiscover:\n  providers:\n    - type: docker\n      hints.enabled: true\n\nprocessors:\n  - add_docker_metadata: ~\n  - decode_json_fields:\n      fields: [\"message\"]\n      target: \"\"\n      overwrite_keys: true\n\noutput.elasticsearch:\n  hosts: [\"elasticsearch:9200\"]\n  index: \"logs-%{[agent.version]}-%{+yyyy.MM.dd}\"\n\nsetup.template.name: \"logs\"\nsetup.template.pattern: \"logs-*\"\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#application-configuration","title":"Application Configuration","text":""},{"location":"atomic/observability/logging/centralized-logging/#json-output-to-stdout","title":"JSON Output to Stdout","text":"<pre><code># CORRECT: JSON logs to stdout for Filebeat collection\nimport structlog\n\n# Configure for production\nstructlog.configure(\n    processors=[\n        structlog.stdlib.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\", utc=True),\n        structlog.processors.format_exc_info,\n        structlog.processors.JSONRenderer()  # JSON to stdout\n    ],\n    logger_factory=structlog.PrintLoggerFactory(),\n)\n\nlogger = structlog.get_logger()\nlogger.info(\n    \"service_started\",\n    service=\"finance_lending_api\",\n    version=\"1.2.3\"\n)\n\n# Filebeat reads from container stdout and ships to Elasticsearch\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#docker-labels-for-routing","title":"Docker Labels for Routing","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  api:\n    image: finance_lending_api:latest\n    labels:\n      - \"logging.environment=production\"\n      - \"logging.service=finance_lending_api\"\n      - \"logging.index=production-api-logs\"\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#querying-logs","title":"Querying Logs","text":""},{"location":"atomic/observability/logging/centralized-logging/#elasticsearch-query-dsl","title":"Elasticsearch Query DSL","text":"<pre><code>{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\"term\": {\"service\": \"finance_lending_api\"}},\n        {\"term\": {\"level\": \"error\"}},\n        {\"range\": {\"@timestamp\": {\"gte\": \"now-1h\"}}}\n      ]\n    }\n  },\n  \"sort\": [{\"@timestamp\": \"desc\"}],\n  \"size\": 100\n}\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#kibana-query-language-kql","title":"Kibana Query Language (KQL)","text":"<pre><code># Errors in last hour\nlevel:error AND @timestamp &gt;= now-1h\n\n# Specific request trace\nrequest_id:\"req-abc-123\"\n\n# Failed payments\nevent:payment_failed AND service:finance_lending_api\n\n# Slow requests\nduration_ms &gt; 1000 AND @timestamp &gt;= now-15m\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#cloudwatch-logs-insights","title":"CloudWatch Logs Insights","text":"<pre><code>fields @timestamp, service, event, message, request_id\n| filter level = \"error\"\n| filter service = \"finance_lending_api\"\n| sort @timestamp desc\n| limit 100\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#log-retention","title":"Log Retention","text":""},{"location":"atomic/observability/logging/centralized-logging/#elasticsearch-ilm-policy","title":"Elasticsearch ILM Policy","text":"<pre><code>{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_size\": \"50gb\",\n            \"max_age\": \"1d\"\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"7d\",\n        \"actions\": {\n          \"forcemerge\": {\"max_num_segments\": 1},\n          \"shrink\": {\"number_of_shards\": 1}\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"30d\",\n        \"actions\": {\"delete\": {}}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#dashboards","title":"Dashboards","text":""},{"location":"atomic/observability/logging/centralized-logging/#kibana-dashboard-example","title":"Kibana Dashboard Example","text":"<pre><code>{\n  \"title\": \"API Service Overview\",\n  \"panels\": [\n    {\n      \"type\": \"metric\",\n      \"title\": \"Total Requests (Last Hour)\",\n      \"query\": \"service:finance_lending_api AND event:request_completed\"\n    },\n    {\n      \"type\": \"line\",\n      \"title\": \"Error Rate Over Time\",\n      \"query\": \"service:finance_lending_api AND level:error\"\n    },\n    {\n      \"type\": \"pie\",\n      \"title\": \"Status Code Distribution\",\n      \"query\": \"service:finance_lending_api\",\n      \"field\": \"status_code\"\n    }\n  ]\n}\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#alerting","title":"Alerting","text":""},{"location":"atomic/observability/logging/centralized-logging/#elasticsearch-watcher-alert","title":"Elasticsearch Watcher Alert","text":"<pre><code>{\n  \"trigger\": {\n    \"schedule\": {\"interval\": \"5m\"}\n  },\n  \"input\": {\n    \"search\": {\n      \"request\": {\n        \"indices\": [\"logs-*\"],\n        \"body\": {\n          \"query\": {\n            \"bool\": {\n              \"must\": [\n                {\"term\": {\"level\": \"error\"}},\n                {\"term\": {\"service\": \"finance_lending_api\"}},\n                {\"range\": {\"@timestamp\": {\"gte\": \"now-5m\"}}}\n              ]\n            }\n          }\n        }\n      }\n    }\n  },\n  \"condition\": {\n    \"compare\": {\"ctx.payload.hits.total\": {\"gt\": 10}}\n  },\n  \"actions\": {\n    \"send_email\": {\n      \"email\": {\n        \"to\": \"ops@example.com\",\n        \"subject\": \"High error rate detected\",\n        \"body\": \"{{ctx.payload.hits.total}} errors in last 5 minutes\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#access-control","title":"Access Control","text":"<pre><code># Elasticsearch API with authentication\nfrom elasticsearch import Elasticsearch\n\nes = Elasticsearch(\n    [\"https://elasticsearch:9200\"],\n    basic_auth=(\"elastic\", \"password\"),\n    verify_certs=True,\n    ca_certs=\"/path/to/ca.crt\"\n)\n\n# Query with access control\nresults = es.search(\n    index=\"logs-production-*\",\n    body={\n        \"query\": {\"term\": {\"service\": \"finance_lending_api\"}}\n    }\n)\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/centralized-logging/#do-structure-logs-for-search","title":"DO: Structure Logs for Search","text":"<pre><code># CORRECT: Searchable structured logs\nlogger.info(\n    \"api_request\",\n    service=\"finance_lending_api\",\n    environment=\"production\",\n    request_id=\"req-abc-123\",\n    user_id=\"user-456\",\n    endpoint=\"/api/loans\",\n    method=\"POST\",\n    status_code=201,\n    duration_ms=145\n)\n\n# Enables queries:\n# - service:finance_lending_api\n# - request_id:req-abc-123\n# - duration_ms &gt; 1000\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#do-include-context-fields","title":"DO: Include Context Fields","text":"<pre><code># CORRECT: Rich context for filtering\nlogger = structlog.get_logger().bind(\n    service=\"finance_lending_api\",\n    environment=\"production\",\n    version=\"1.2.3\",\n    host=socket.gethostname()\n)\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#dont-log-to-files","title":"DON'T: Log to Files","text":"<pre><code># INCORRECT: Local file logging\nlogging.basicConfig(filename='/var/log/app.log')  # \u274c Not centralized\n\n\n# CORRECT: Stdout for container collection\nstructlog.configure(\n    logger_factory=structlog.PrintLoggerFactory()  # Stdout\n)\n</code></pre>"},{"location":"atomic/observability/logging/centralized-logging/#checklist","title":"Checklist","text":"<ul> <li> Deploy centralized logging system (ELK/CloudWatch/Loki)</li> <li> Configure log shipping (Filebeat/Fluentd)</li> <li> Output JSON logs to stdout</li> <li> Add service metadata to all logs</li> <li> Configure log retention policies</li> <li> Create operational dashboards</li> <li> Set up error alerting</li> <li> Implement access control</li> <li> Test log ingestion from all services</li> <li> Document query patterns</li> <li> Train team on log searching</li> <li> Monitor log ingestion rates</li> <li> Test log retention deletion</li> </ul>"},{"location":"atomic/observability/logging/centralized-logging/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> \u2014 Elasticsearch configuration</li> <li><code>docs/atomic/observability/elk-stack/kibana-dashboards.md</code> \u2014 Kibana dashboard creation</li> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging patterns</li> <li><code>docs/atomic/observability/logging/log-correlation.md</code> \u2014 Log correlation across services</li> </ul>"},{"location":"atomic/observability/logging/log-correlation/","title":"Log Correlation","text":"<p>Correlate logs across distributed microservices to trace complete request flows from initial client request through all backend services and background jobs. Log correlation enables debugging multi-service transactions by linking related log entries using shared correlation IDs (request_id, user_id, transaction_id).</p> <p>This document covers request ID propagation patterns, correlation ID standards, tracing requests across FastAPI API \u2192 AsyncIO Worker \u2192 Aiogram Bot flows, querying correlated logs in Elasticsearch/CloudWatch, and implementing correlation metadata in structured logs. Log correlation transforms distributed logs into coherent request narratives.</p> <p>Log correlation solves the distributed observability challenge: when a user request flows through API service \u2192 Worker service \u2192 Bot service, each emitting separate logs, correlation IDs link these logs into a single trace showing the complete request journey, execution order, timings, and any failures encountered across all services.</p>"},{"location":"atomic/observability/logging/log-correlation/#correlation-id-standards","title":"Correlation ID Standards","text":""},{"location":"atomic/observability/logging/log-correlation/#request-id-format","title":"Request ID Format","text":"<pre><code># Standard: req-{uuid}\nrequest_id = f\"req-{uuid.uuid4()}\"\n# Example: \"req-550e8400-e29b-41d4-a716-446655440000\"\n\n# Alternative: timestamp + random\nrequest_id = f\"req-{int(time.time())}-{secrets.token_hex(8)}\"\n# Example: \"req-1705318245-a3b4c5d6e7f8\"\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#multiple-correlation-ids","title":"Multiple Correlation IDs","text":"<pre><code># Required correlation IDs\n{\n    \"request_id\": \"req-abc-123\",  # Request trace ID\n    \"user_id\": \"user-456\",  # User identifier\n    \"session_id\": \"sess-789\"  # Session identifier\n}\n\n# Optional business correlation IDs\n{\n    \"loan_id\": \"loan-123\",  # Business entity\n    \"transaction_id\": \"txn-456\",  # Transaction trace\n    \"batch_id\": \"batch-789\"  # Batch processing\n}\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#request-id-generation","title":"Request ID Generation","text":""},{"location":"atomic/observability/logging/log-correlation/#api-gateway-pattern","title":"API Gateway Pattern","text":"<pre><code># CORRECT: Generate request_id at API entry point\nfrom fastapi import FastAPI, Request\nimport uuid\nimport structlog\n\napp = FastAPI()\n\n\n@app.middleware(\"http\")\nasync def correlation_middleware(request: Request, call_next):\n    \"\"\"Add correlation IDs to all requests.\"\"\"\n    # Get or generate request ID\n    request_id = request.headers.get(\"X-Request-ID\")\n    if not request_id:\n        request_id = f\"req-{uuid.uuid4()}\"\n\n    # Store in request state\n    request.state.request_id = request_id\n\n    # Bind to logger\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        method=request.method,\n        path=request.url.path\n    )\n    request.state.logger = logger\n\n    logger.info(\"request_started\")\n\n    response = await call_next(request)\n\n    # Add to response headers\n    response.headers[\"X-Request-ID\"] = request_id\n\n    logger.info(\n        \"request_completed\",\n        status_code=response.status_code\n    )\n\n    return response\n\n\n# INCORRECT: Generate new request_id for each service call\n@app.post(\"/api/loans\")\nasync def create_loan():\n    request_id = str(uuid.uuid4())  # \u274c Loses correlation with original request\n    logger.info(\"loan_created\", request_id=request_id)\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#propagating-correlation-ids","title":"Propagating Correlation IDs","text":""},{"location":"atomic/observability/logging/log-correlation/#http-client-propagation","title":"HTTP Client Propagation","text":"<pre><code># CORRECT: Propagate request_id in HTTP headers\nimport httpx\nimport structlog\n\nasync def call_data_service(request_id: str, user_id: str):\n    \"\"\"Call data service with correlation headers.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://data-service:8000/api/users\",\n            headers={\n                \"X-Request-ID\": request_id,  # Propagate request ID\n                \"X-User-ID\": user_id\n            },\n            json={\"email\": \"user@example.com\"}\n        )\n\n        logger = structlog.get_logger().bind(\n            request_id=request_id,\n            user_id=user_id\n        )\n        logger.info(\n            \"data_service_called\",\n            status_code=response.status_code\n        )\n\n        return response\n\n\n# INCORRECT: No correlation headers\nasync def call_data_service_wrong():\n    response = await client.post(\n        \"http://data-service:8000/api/users\",\n        json={\"email\": \"user@example.com\"}  # \u274c Lost correlation\n    )\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#rabbitmq-message-propagation","title":"RabbitMQ Message Propagation","text":"<pre><code># CORRECT: Include correlation IDs in message headers\nimport aio_pika\nimport structlog\n\nasync def publish_loan_event(request_id: str, loan_id: str, user_id: str):\n    \"\"\"Publish event with correlation metadata.\"\"\"\n    connection = await aio_pika.connect_robust(\"amqp://localhost/\")\n    channel = await connection.channel()\n\n    message_body = {\n        \"loan_id\": loan_id,\n        \"status\": \"pending\",\n        \"amount\": 10000\n    }\n\n    message = aio_pika.Message(\n        body=json.dumps(message_body).encode(),\n        headers={\n            \"X-Request-ID\": request_id,  # Correlation ID\n            \"X-User-ID\": user_id,\n            \"X-Loan-ID\": loan_id\n        },\n        content_type=\"application/json\",\n        delivery_mode=aio_pika.DeliveryMode.PERSISTENT\n    )\n\n    exchange = await channel.declare_exchange(\"loan_events\", aio_pika.ExchangeType.TOPIC)\n    await exchange.publish(message, routing_key=\"loan.created\")\n\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        loan_id=loan_id,\n        user_id=user_id\n    )\n    logger.info(\"loan_event_published\", event=\"loan.created\")\n\n\n# INCORRECT: No correlation in message\nasync def publish_event_wrong(loan_id: str):\n    message = aio_pika.Message(body=json.dumps({\"loan_id\": loan_id}).encode())\n    await exchange.publish(message, routing_key=\"loan.created\")  # \u274c Lost correlation\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#worker-consumer-pattern","title":"Worker Consumer Pattern","text":"<pre><code># CORRECT: Extract and use correlation IDs from message\nimport aio_pika\nimport structlog\n\nasync def consume_loan_events():\n    \"\"\"Consume events and preserve correlation.\"\"\"\n    connection = await aio_pika.connect_robust(\"amqp://localhost/\")\n    channel = await connection.channel()\n    queue = await channel.declare_queue(\"loan_processing\", durable=True)\n\n    async with queue.iterator() as queue_iter:\n        async for message in queue_iter:\n            async with message.process():\n                # Extract correlation IDs\n                request_id = message.headers.get(\"X-Request-ID\", \"unknown\")\n                user_id = message.headers.get(\"X-User-ID\", \"unknown\")\n                loan_id = message.headers.get(\"X-Loan-ID\", \"unknown\")\n\n                # Bind logger with correlation\n                logger = structlog.get_logger().bind(\n                    request_id=request_id,\n                    user_id=user_id,\n                    loan_id=loan_id,\n                    service=\"finance_lending_worker\"\n                )\n\n                logger.info(\"processing_loan_event\")\n\n                try:\n                    await process_loan(loan_id, request_id, user_id)\n                    logger.info(\"loan_processed_successfully\")\n                except Exception as e:\n                    logger.error(\n                        \"loan_processing_failed\",\n                        error_type=type(e).__name__,\n                        error_message=str(e),\n                        exc_info=True\n                    )\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#cross-service-correlation","title":"Cross-Service Correlation","text":""},{"location":"atomic/observability/logging/log-correlation/#api-worker-bot-flow","title":"API \u2192 Worker \u2192 Bot Flow","text":"<pre><code># Step 1: API Service\n@app.post(\"/api/loans\")\nasync def create_loan(request: Request, loan: LoanCreate):\n    logger = request.state.logger\n    request_id = request.state.request_id\n\n    logger.info(\"loan_creation_started\", amount=loan.amount)\n\n    # Save to database via data service (propagate request_id)\n    loan_id = await data_service.create_loan(request_id, loan)\n\n    # Publish event for worker (include request_id in headers)\n    await publish_loan_event(request_id, loan_id, loan.user_id)\n\n    logger.info(\"loan_created\", loan_id=loan_id)\n\n    return {\"loan_id\": loan_id, \"request_id\": request_id}\n\n\n# Step 2: Worker Service\nasync def process_loan(loan_id: str, request_id: str, user_id: str):\n    \"\"\"Process loan with inherited correlation.\"\"\"\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        loan_id=loan_id,\n        user_id=user_id,\n        service=\"finance_lending_worker\"\n    )\n\n    logger.info(\"credit_check_started\")\n\n    credit_score = await check_credit(user_id, request_id)\n\n    logger.info(\"credit_check_completed\", credit_score=credit_score)\n\n    # Publish notification event for bot\n    await publish_notification_event(request_id, user_id, loan_id, credit_score)\n\n\n# Step 3: Bot Service\nasync def handle_notification(message: aio_pika.IncomingMessage):\n    \"\"\"Send notification with correlation context.\"\"\"\n    request_id = message.headers.get(\"X-Request-ID\")\n    user_id = message.headers.get(\"X-User-ID\")\n    loan_id = message.headers.get(\"X-Loan-ID\")\n\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        user_id=user_id,\n        loan_id=loan_id,\n        service=\"finance_lending_bot\"\n    )\n\n    logger.info(\"sending_bot_notification\")\n\n    telegram_user_id = await get_telegram_user_id(user_id, request_id)\n    await bot.send_message(telegram_user_id, \"Your loan has been approved!\")\n\n    logger.info(\"notification_sent\")\n\n\n# All logs share request_id=\"req-abc-123\"\n# Query: request_id=\"req-abc-123\" returns complete trace:\n# 1. API: loan_creation_started\n# 2. API: loan_created\n# 3. Worker: credit_check_started\n# 4. Worker: credit_check_completed\n# 5. Bot: sending_bot_notification\n# 6. Bot: notification_sent\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#querying-correlated-logs","title":"Querying Correlated Logs","text":""},{"location":"atomic/observability/logging/log-correlation/#elasticsearch-query","title":"Elasticsearch Query","text":"<pre><code>{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\"term\": {\"request_id\": \"req-abc-123\"}}\n      ]\n    }\n  },\n  \"sort\": [\n    {\"timestamp\": \"asc\"}\n  ]\n}\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#kibana-discover-query","title":"Kibana Discover Query","text":"<pre><code>request_id:\"req-abc-123\"\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#cloudwatch-insights-query","title":"CloudWatch Insights Query","text":"<pre><code>fields @timestamp, service, event, message\n| filter request_id = \"req-abc-123\"\n| sort @timestamp asc\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#correlation-patterns","title":"Correlation Patterns","text":""},{"location":"atomic/observability/logging/log-correlation/#user-centric-correlation","title":"User-Centric Correlation","text":"<pre><code># CORRECT: Trace all actions for specific user\nlogger = structlog.get_logger().bind(\n    user_id=\"user-456\",\n    session_id=\"sess-789\"\n)\n\n# Query: user_id=\"user-456\" AND @timestamp &gt; \"2025-01-15T00:00:00Z\"\n# Returns all user activity across all services\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#business-transaction-correlation","title":"Business Transaction Correlation","text":"<pre><code># CORRECT: Trace complete business transaction\nlogger = structlog.get_logger().bind(\n    transaction_id=\"txn-123\",\n    loan_id=\"loan-456\",\n    payment_id=\"pay-789\"\n)\n\n# Query: transaction_id=\"txn-123\"\n# Returns: loan creation \u2192 credit check \u2192 payment \u2192 notification\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/log-correlation/#do-propagate-all-correlation-ids","title":"DO: Propagate All Correlation IDs","text":"<pre><code># CORRECT: Include all relevant IDs\nheaders = {\n    \"X-Request-ID\": request_id,\n    \"X-User-ID\": user_id,\n    \"X-Session-ID\": session_id,\n    \"X-Trace-ID\": trace_id\n}\n\n\n# INCORRECT: Missing IDs\nheaders = {\"X-Request-ID\": request_id}  # \u274c Lost user context\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#do-log-correlation-at-service-boundaries","title":"DO: Log Correlation at Service Boundaries","text":"<pre><code># CORRECT: Log when entering/exiting service\nlogger.info(\n    \"external_service_call_started\",\n    request_id=request_id,\n    target_service=\"data_service\",\n    method=\"POST\",\n    endpoint=\"/api/users\"\n)\n\nresponse = await call_external_service()\n\nlogger.info(\n    \"external_service_call_completed\",\n    request_id=request_id,\n    status_code=response.status_code,\n    duration_ms=duration\n)\n\n\n# INCORRECT: No boundary logging\nresponse = await call_external_service()  # \u274c Cannot trace cross-service calls\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#dont-lose-correlation-in-async-tasks","title":"DON'T: Lose Correlation in Async Tasks","text":"<pre><code># CORRECT: Pass correlation to background tasks\nfrom fastapi import BackgroundTasks\n\n@app.post(\"/api/loans\")\nasync def create_loan(\n    request: Request,\n    background_tasks: BackgroundTasks\n):\n    request_id = request.state.request_id\n    loan_id = \"loan-123\"\n\n    # Pass correlation to background task\n    background_tasks.add_task(\n        send_confirmation_email,\n        loan_id,\n        request_id  # Propagate correlation\n    )\n\n\nasync def send_confirmation_email(loan_id: str, request_id: str):\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        loan_id=loan_id\n    )\n    logger.info(\"sending_confirmation_email\")\n\n\n# INCORRECT: Lost correlation in background task\nbackground_tasks.add_task(send_confirmation_email, loan_id)  # \u274c No request_id\n</code></pre>"},{"location":"atomic/observability/logging/log-correlation/#checklist","title":"Checklist","text":"<ul> <li> Generate request_id at API gateway</li> <li> Include request_id in all log entries</li> <li> Propagate request_id in HTTP headers (X-Request-ID)</li> <li> Include correlation IDs in RabbitMQ message headers</li> <li> Extract correlation IDs from incoming messages/requests</li> <li> Bind correlation IDs to logger context</li> <li> Log at service boundaries (entry/exit)</li> <li> Return request_id in API responses</li> <li> Propagate correlation to background tasks</li> <li> Use consistent ID formats (req-, user-, loan-, etc.)</li> <li> Include multiple correlation IDs (request, user, session)</li> <li> Test correlation across all services</li> <li> Query correlated logs in centralized logging system</li> </ul>"},{"location":"atomic/observability/logging/log-correlation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging with structlog</li> <li><code>docs/atomic/observability/logging/request-id-tracking.md</code> \u2014 Request ID implementation details</li> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing with OpenTelemetry</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging infrastructure</li> </ul>"},{"location":"atomic/observability/logging/log-formatting/","title":"Log Formatting Standards","text":"<p>Define consistent log formatting standards across all microservices to ensure logs are readable, parseable, and searchable in centralized logging systems. Log formatting standards establish field naming conventions, timestamp formats, message templates, and error representations that enable efficient debugging and monitoring.</p> <p>This document covers log message structure, field naming conventions (snake_case), timestamp formatting (ISO 8601), log level standards, message templates for common events, multi-line log handling, and error formatting best practices. Consistent formatting enables reliable log parsing across all services regardless of programming language or framework.</p> <p>Log formatting standards treat logs as a consistent data format across the entire microservices architecture. When all services emit logs with identical field names, timestamp formats, and message structures, centralized logging systems can aggregate, search, and analyze logs from any service using the same queries and dashboards.</p>"},{"location":"atomic/observability/logging/log-formatting/#log-message-structure","title":"Log Message Structure","text":""},{"location":"atomic/observability/logging/log-formatting/#standard-format","title":"Standard Format","text":"<pre><code>{\n    \"timestamp\": \"2025-01-15T10:30:45.123456Z\",\n    \"level\": \"info\",\n    \"service\": \"finance_lending_api\",\n    \"environment\": \"production\",\n    \"version\": \"1.2.3\",\n    \"event\": \"user_created\",\n    \"message\": \"User created successfully\",\n    \"request_id\": \"req-abc-123\",\n    \"user_id\": \"user-456\",\n    \"duration_ms\": 45,\n    \"context\": {\n        \"additional\": \"nested data\"\n    }\n}\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#required-fields","title":"Required Fields","text":"<p>Every log entry must include:</p> Field Type Description Example <code>timestamp</code> string ISO 8601 timestamp with microseconds and UTC timezone <code>2025-01-15T10:30:45.123456Z</code> <code>level</code> string Log level (lowercase) <code>debug</code>, <code>info</code>, <code>warning</code>, <code>error</code>, <code>critical</code> <code>service</code> string Service name (<code>{context}_{domain}_{type}</code>) <code>finance_lending_api</code> <code>event</code> string Event name (snake_case) <code>user_created</code>, <code>payment_processed</code> <code>message</code> string Human-readable message <code>User created successfully</code>"},{"location":"atomic/observability/logging/log-formatting/#optional-standard-fields","title":"Optional Standard Fields","text":"Field Type Description Example <code>request_id</code> string Request correlation ID <code>req-abc-123</code> <code>user_id</code> string User identifier <code>user-456</code> <code>environment</code> string Deployment environment <code>production</code>, <code>staging</code>, <code>development</code> <code>version</code> string Service version (semver) <code>1.2.3</code> <code>host</code> string Hostname or container ID <code>api-pod-7f4d9b</code> <code>duration_ms</code> integer Operation duration in milliseconds <code>145</code> <code>status_code</code> integer HTTP status code <code>201</code>, <code>404</code>, <code>500</code> <code>error_type</code> string Exception class name <code>ValueError</code>, <code>HTTPException</code> <code>error_message</code> string Exception message <code>Invalid input: amount must be positive</code>"},{"location":"atomic/observability/logging/log-formatting/#field-naming-conventions","title":"Field Naming Conventions","text":""},{"location":"atomic/observability/logging/log-formatting/#snake_case-for-field-names","title":"snake_case for Field Names","text":"<pre><code># CORRECT: snake_case field names\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    user_id=\"user-456\",\n    amount_usd=99.99,\n    transaction_type=\"credit_card\",\n    merchant_name=\"Example Store\"\n)\n\n\n# INCORRECT: Mixed naming conventions\nlogger.info(\n    \"PaymentProcessed\",  # \u274c PascalCase event\n    paymentID=\"pay-123\",  # \u274c camelCase\n    \"user-id\"=\"user-456\",  # \u274c kebab-case\n    AMOUNT=99.99  # \u274c SCREAMING_SNAKE_CASE\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#consistent-field-names-across-services","title":"Consistent Field Names Across Services","text":"<pre><code># CORRECT: Same field names across all services\n\n# API service\nlogger.info(\"request_started\", request_id=\"req-123\", user_id=\"user-456\")\n\n# Worker service\nlogger.info(\"task_started\", request_id=\"req-123\", user_id=\"user-456\")\n\n# Bot service\nlogger.info(\"command_received\", request_id=\"req-123\", user_id=\"user-456\")\n\n# Enables query: request_id=\"req-123\" across all services\n\n\n# INCORRECT: Different field names for same concept\n# API service\nlogger.info(\"request\", req_id=\"req-123\", uid=\"user-456\")  # \u274c\n\n# Worker service\nlogger.info(\"task\", requestId=\"req-123\", userId=\"user-456\")  # \u274c\n\n# Cannot correlate across services\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#reserved-field-names","title":"Reserved Field Names","text":"<p>Do not use these field names for custom data:</p> <ul> <li><code>timestamp</code> \u2014 Reserved for log timestamp</li> <li><code>level</code> \u2014 Reserved for log level</li> <li><code>message</code> \u2014 Reserved for human-readable message</li> <li><code>event</code> \u2014 Reserved for event name</li> <li><code>service</code> \u2014 Reserved for service name</li> <li><code>logger</code> \u2014 Reserved for logger name</li> <li><code>exc_info</code> \u2014 Reserved for exception information</li> </ul>"},{"location":"atomic/observability/logging/log-formatting/#timestamp-formatting","title":"Timestamp Formatting","text":""},{"location":"atomic/observability/logging/log-formatting/#iso-8601-with-utc-timezone","title":"ISO 8601 with UTC Timezone","text":"<pre><code># CORRECT: ISO 8601 with microseconds and UTC\nfrom datetime import datetime, timezone\n\ntimestamp = datetime.now(timezone.utc).isoformat()\n# Output: \"2025-01-15T10:30:45.123456+00:00\"\n\n# Preferred: Use 'Z' suffix for UTC\ntimestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n# Output: \"2025-01-15T10:30:45.123456Z\"\n\n\n# INCORRECT: Local time without timezone\ntimestamp = datetime.now().isoformat()  # \u274c Ambiguous timezone\n# Output: \"2025-01-15T10:30:45.123456\" (which timezone?)\n\n# INCORRECT: Non-standard format\ntimestamp = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")  # \u274c\n# Output: \"2025/01/15 10:30:45\" (not ISO 8601)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#structlog-configuration","title":"Structlog Configuration","text":"<pre><code>import structlog\n\nstructlog.configure(\n    processors=[\n        # ISO 8601 timestamp with 'Z' suffix\n        structlog.processors.TimeStamper(fmt=\"iso\", utc=True),\n        structlog.processors.JSONRenderer()\n    ]\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#log-level-standards","title":"Log Level Standards","text":""},{"location":"atomic/observability/logging/log-formatting/#level-naming","title":"Level Naming","text":"<p>Always use lowercase log levels in JSON output:</p> <pre><code># CORRECT: Lowercase levels\n{\n    \"level\": \"debug\",\n    \"level\": \"info\",\n    \"level\": \"warning\",\n    \"level\": \"error\",\n    \"level\": \"critical\"\n}\n\n\n# INCORRECT: Uppercase or mixed case\n{\n    \"level\": \"INFO\",  # \u274c\n    \"level\": \"Warning\",  # \u274c\n    \"level\": \"ERROR\"  # \u274c\n}\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#level-guidelines","title":"Level Guidelines","text":"<pre><code>import structlog\n\nlogger = structlog.get_logger()\n\n# DEBUG: Detailed diagnostic information for developers\nlogger.debug(\n    \"cache_lookup\",\n    key=\"user:123\",\n    hit=True,\n    ttl_seconds=3600\n)\n\n# INFO: Normal application events\nlogger.info(\n    \"user_login\",\n    user_id=\"user-123\",\n    ip_address=\"192.168.1.1\"\n)\n\n# WARNING: Unexpected but handled situations\nlogger.warning(\n    \"rate_limit_approaching\",\n    user_id=\"user-123\",\n    requests=950,\n    limit=1000,\n    reset_time=\"2025-01-15T11:00:00Z\"\n)\n\n# ERROR: Error conditions that affect operations\nlogger.error(\n    \"payment_failed\",\n    payment_id=\"pay-456\",\n    reason=\"insufficient_funds\",\n    amount_required=100.00,\n    amount_available=50.00\n)\n\n# CRITICAL: Critical system failures requiring immediate action\nlogger.critical(\n    \"database_unavailable\",\n    database=\"postgres\",\n    host=\"db.local\",\n    retry_count=5,\n    last_error=\"connection timeout\"\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#message-templates","title":"Message Templates","text":""},{"location":"atomic/observability/logging/log-formatting/#event-driven-messages","title":"Event-Driven Messages","text":"<pre><code># CORRECT: Event name + context\nlogger.info(\n    \"loan_application_submitted\",  # Event (snake_case)\n    loan_id=\"loan-789\",\n    user_id=\"user-123\",\n    amount=10000,\n    purpose=\"business\"\n)\n\n\n# INCORRECT: Verbose sentences\nlogger.info(\n    \"A loan application has been submitted by user-123 for $10,000\"  # \u274c Not searchable\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#consistent-naming-patterns","title":"Consistent Naming Patterns","text":"<p>Use consistent verb tenses and patterns:</p> <pre><code># CORRECT: Consistent patterns\n\n# Past tense for completed events\nlogger.info(\"user_created\", user_id=\"user-123\")\nlogger.info(\"payment_processed\", payment_id=\"pay-456\")\nlogger.info(\"email_sent\", recipient=\"user@example.com\")\n\n# Present continuous for ongoing operations\nlogger.info(\"processing_payment\", payment_id=\"pay-456\")\nlogger.info(\"sending_email\", recipient=\"user@example.com\")\n\n# Failures\nlogger.error(\"user_creation_failed\", reason=\"duplicate_email\")\nlogger.error(\"payment_processing_failed\", reason=\"timeout\")\n\n\n# INCORRECT: Inconsistent patterns\nlogger.info(\"UserWasCreated\")  # \u274c PascalCase, verbose\nlogger.info(\"payment-process\")  # \u274c kebab-case, ambiguous tense\nlogger.error(\"Failed to send email\")  # \u274c Sentence, not event name\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#multi-line-logs","title":"Multi-Line Logs","text":""},{"location":"atomic/observability/logging/log-formatting/#newlines-in-messages","title":"Newlines in Messages","text":"<pre><code># CORRECT: Escape newlines in JSON\nlogger.info(\n    \"stack_trace_captured\",\n    error_type=\"ValueError\",\n    stack_trace=\"Traceback (most recent call last):\\n  File \\\"app.py\\\", line 42\\n    raise ValueError()\"\n)\n\n# JSON output (newlines escaped):\n{\n    \"event\": \"stack_trace_captured\",\n    \"stack_trace\": \"Traceback (most recent call last):\\\\n  File \\\\\"app.py\\\\\", line 42\\\\n    raise ValueError()\"\n}\n\n\n# INCORRECT: Unescaped newlines break JSON parsing\nlogger.info(\n    \"stack_trace\",\n    trace=\"\"\"\n    Line 1\n    Line 2\n    Line 3\n    \"\"\"  # \u274c Breaks JSON parsing\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#nested-context","title":"Nested Context","text":"<pre><code># CORRECT: Use nested objects for complex data\nlogger.info(\n    \"http_request_completed\",\n    request={\n        \"method\": \"POST\",\n        \"path\": \"/api/loans\",\n        \"headers\": {\n            \"user-agent\": \"Mozilla/5.0\",\n            \"content-type\": \"application/json\"\n        }\n    },\n    response={\n        \"status_code\": 201,\n        \"body_size\": 1024\n    }\n)\n\n\n# INCORRECT: Flatten complex data into strings\nlogger.info(\n    \"request\",\n    data=\"POST /api/loans, headers: {...}, status: 201\"  # \u274c Unparseable\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#error-formatting","title":"Error Formatting","text":""},{"location":"atomic/observability/logging/log-formatting/#exception-information","title":"Exception Information","text":"<pre><code># CORRECT: Structured exception logging\nimport structlog\n\nlogger = structlog.get_logger()\n\ntry:\n    result = await process_payment(payment_id=\"pay-123\")\nexcept ValueError as e:\n    logger.error(\n        \"payment_validation_failed\",\n        payment_id=\"pay-123\",\n        error_type=\"ValueError\",\n        error_message=str(e),\n        exc_info=True  # Include full traceback\n    )\nexcept httpx.HTTPError as e:\n    logger.error(\n        \"payment_api_error\",\n        payment_id=\"pay-123\",\n        error_type=\"HTTPError\",\n        status_code=e.response.status_code if e.response else None,\n        url=str(e.request.url),\n        exc_info=True\n    )\n\n\n# INCORRECT: String concatenation\nexcept Exception as e:\n    logger.error(f\"Error processing payment: {e}\")  # \u274c Lost context\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#error-field-standards","title":"Error Field Standards","text":"<pre><code># Standard error fields:\n{\n    \"event\": \"operation_failed\",\n    \"error_type\": \"ValueError\",  # Exception class name\n    \"error_message\": \"Amount must be positive\",  # Exception message\n    \"error_code\": \"INVALID_AMOUNT\",  # Application error code (optional)\n    \"stack_trace\": \"Traceback...\",  # Full stack trace\n    \"recoverable\": false  # Whether error is recoverable (optional)\n}\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#numeric-values","title":"Numeric Values","text":""},{"location":"atomic/observability/logging/log-formatting/#units-in-field-names","title":"Units in Field Names","text":"<pre><code># CORRECT: Include units in field names\nlogger.info(\n    \"api_request_completed\",\n    duration_ms=145,  # Milliseconds\n    duration_seconds=0.145,  # Seconds\n    body_size_bytes=2048,  # Bytes\n    timeout_seconds=30  # Seconds\n)\n\n\n# INCORRECT: Ambiguous units\nlogger.info(\n    \"request_completed\",\n    duration=145,  # \u274c Milliseconds? Seconds?\n    size=2048,  # \u274c Bytes? Kilobytes?\n    timeout=30  # \u274c Seconds? Minutes?\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#number-formatting","title":"Number Formatting","text":"<pre><code># CORRECT: Use native numeric types\nlogger.info(\n    \"payment_processed\",\n    amount=99.99,  # Float\n    quantity=5,  # Integer\n    tax_rate=0.08  # Decimal as float\n)\n\n\n# INCORRECT: Numbers as strings\nlogger.info(\n    \"payment_processed\",\n    amount=\"99.99\",  # \u274c String, not number\n    quantity=\"5\"  # \u274c String, not integer\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#boolean-values","title":"Boolean Values","text":"<pre><code># CORRECT: Use native boolean type\nlogger.info(\n    \"user_verified\",\n    user_id=\"user-123\",\n    email_verified=True,  # Boolean\n    phone_verified=False,  # Boolean\n    kyc_completed=True  # Boolean\n)\n\n\n# INCORRECT: Strings or numbers for booleans\nlogger.info(\n    \"user_status\",\n    verified=\"true\",  # \u274c String\n    active=1  # \u274c Integer\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/log-formatting/#do-use-consistent-field-order","title":"DO: Use Consistent Field Order","text":"<pre><code># CORRECT: Consistent field order (high-priority first)\nlogger.info(\n    \"loan_processed\",\n    loan_id=\"loan-123\",  # Identifiers first\n    user_id=\"user-456\",\n    status=\"approved\",  # Status/result\n    amount=10000,  # Details\n    purpose=\"business\",\n    duration_ms=145  # Metrics last\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#do-include-context-for-debugging","title":"DO: Include Context for Debugging","text":"<pre><code># CORRECT: Rich context\nlogger.error(\n    \"loan_approval_failed\",\n    loan_id=\"loan-123\",\n    user_id=\"user-456\",\n    credit_score=620,\n    required_score=650,\n    income=45000,\n    debt_ratio=0.45,\n    reason=\"insufficient_credit_score\"\n)\n\n\n# INCORRECT: Minimal context\nlogger.error(\"Loan approval failed\")  # \u274c Cannot debug\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#dont-use-ambiguous-field-names","title":"DON'T: Use Ambiguous Field Names","text":"<pre><code># CORRECT: Specific field names\nlogger.info(\n    \"users_processed\",\n    total_users=1000,\n    processed_users=950,\n    failed_users=50\n)\n\n\n# INCORRECT: Ambiguous names\nlogger.info(\n    \"users\",\n    count=1000,  # \u274c Count of what?\n    num=950,  # \u274c Number of what?\n    errors=50  # \u274c Error count? Error IDs?\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#dont-include-redundant-data","title":"DON'T: Include Redundant Data","text":"<pre><code># CORRECT: Concise, non-redundant\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    amount=99.99,\n    currency=\"USD\"\n)\n\n\n# INCORRECT: Redundant data\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    payment_identifier=\"pay-123\",  # \u274c Duplicate\n    amount=99.99,\n    amount_dollars=99.99,  # \u274c Duplicate\n    currency=\"USD\",\n    currency_code=\"USD\"  # \u274c Duplicate\n)\n</code></pre>"},{"location":"atomic/observability/logging/log-formatting/#checklist","title":"Checklist","text":"<ul> <li> Use snake_case for all field names</li> <li> Include required fields (timestamp, level, service, event, message)</li> <li> Use ISO 8601 timestamps with UTC timezone</li> <li> Use lowercase log level names</li> <li> Use consistent event naming patterns (past tense for completed events)</li> <li> Escape newlines and special characters in JSON</li> <li> Include error_type and error_message for exceptions</li> <li> Use native types (numbers, booleans) not strings</li> <li> Include units in field names (duration_ms, size_bytes)</li> <li> Maintain consistent field order across logs</li> <li> Avoid ambiguous or redundant field names</li> <li> Include sufficient context for debugging</li> <li> Test log formatting in development</li> </ul>"},{"location":"atomic/observability/logging/log-formatting/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging implementation with structlog</li> <li><code>docs/atomic/observability/logging/log-correlation.md</code> \u2014 Correlating logs across services</li> <li><code>docs/atomic/observability/logging/request-id-tracking.md</code> \u2014 Request ID propagation</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging infrastructure</li> </ul>"},{"location":"atomic/observability/logging/request-id-tracking/","title":"Request ID Tracking","text":"<p>Implement request ID tracking to trace individual requests through distributed microservices architecture, enabling end-to-end request flow debugging, performance analysis, and error tracking. Request IDs provide unique identifiers linking all operations related to a single user request across multiple services.</p> <p>This document covers request ID generation strategies, propagation through HTTP headers and message queues, middleware implementation for FastAPI and Aiogram, extracting request IDs from incoming requests, and querying logs by request ID. Request ID tracking is foundational for distributed observability.</p> <p>Request ID tracking enables answering critical questions: What happened to user request X? Which services did it touch? Where did it fail? How long did each step take? Without request IDs, debugging distributed systems requires manually correlating logs across services using timestamps\u2014an error-prone and time-consuming process.</p>"},{"location":"atomic/observability/logging/request-id-tracking/#request-id-generation","title":"Request ID Generation","text":""},{"location":"atomic/observability/logging/request-id-tracking/#uuid-based-ids","title":"UUID-Based IDs","text":"<pre><code>import uuid\n\ndef generate_request_id() -&gt; str:\n    \"\"\"Generate unique request ID.\"\"\"\n    return f\"req-{uuid.uuid4()}\"\n\n# Example: \"req-550e8400-e29b-41d4-a716-446655440000\"\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#timestamp-random","title":"Timestamp + Random","text":"<pre><code>import time\nimport secrets\n\ndef generate_request_id() -&gt; str:\n    \"\"\"Generate request ID with timestamp prefix.\"\"\"\n    timestamp = int(time.time())\n    random_suffix = secrets.token_hex(8)\n    return f\"req-{timestamp}-{random_suffix}\"\n\n# Example: \"req-1705318245-a3b4c5d6e7f8\"\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#fastapi-middleware","title":"FastAPI Middleware","text":""},{"location":"atomic/observability/logging/request-id-tracking/#request-id-middleware","title":"Request ID Middleware","text":"<pre><code># CORRECT: Middleware generates or extracts request ID\nfrom fastapi import FastAPI, Request\nimport uuid\nimport structlog\n\napp = FastAPI()\n\n\n@app.middleware(\"http\")\nasync def request_id_middleware(request: Request, call_next):\n    \"\"\"Add request ID to all requests.\"\"\"\n    # Extract from header or generate new\n    request_id = request.headers.get(\"X-Request-ID\")\n    if not request_id:\n        request_id = f\"req-{uuid.uuid4()}\"\n\n    # Store in request state\n    request.state.request_id = request_id\n\n    # Bind to logger\n    logger = structlog.get_logger().bind(request_id=request_id)\n    request.state.logger = logger\n\n    # Process request\n    response = await call_next(request)\n\n    # Return request ID in response header\n    response.headers[\"X-Request-ID\"] = request_id\n\n    return response\n\n\n# Usage in endpoint\n@app.get(\"/api/users/{user_id}\")\nasync def get_user(user_id: str, request: Request):\n    logger = request.state.logger\n    request_id = request.state.request_id\n\n    logger.info(\"fetching_user\", user_id=user_id)\n\n    return {\"user_id\": user_id, \"request_id\": request_id}\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#http-header-propagation","title":"HTTP Header Propagation","text":""},{"location":"atomic/observability/logging/request-id-tracking/#outgoing-requests","title":"Outgoing Requests","text":"<pre><code># CORRECT: Propagate request ID in HTTP client\nimport httpx\nimport structlog\n\nasync def call_data_service(request_id: str, user_id: str):\n    \"\"\"Call external service with request ID.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"http://data-service:8000/api/users/{user_id}\",\n            headers={\"X-Request-ID\": request_id}  # Propagate\n        )\n\n        logger = structlog.get_logger().bind(request_id=request_id)\n        logger.info(\n            \"data_service_called\",\n            status_code=response.status_code,\n            user_id=user_id\n        )\n\n        return response.json()\n\n\n# INCORRECT: No request ID propagation\nasync def call_service_wrong(user_id: str):\n    response = await client.get(f\"http://data-service:8000/api/users/{user_id}\")\n    # \u274c Lost request correlation\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#rabbitmq-message-tracking","title":"RabbitMQ Message Tracking","text":""},{"location":"atomic/observability/logging/request-id-tracking/#publishing-messages","title":"Publishing Messages","text":"<pre><code># CORRECT: Include request ID in message headers\nimport aio_pika\nimport json\n\nasync def publish_loan_event(request_id: str, loan_id: str):\n    \"\"\"Publish event with request ID.\"\"\"\n    connection = await aio_pika.connect_robust(\"amqp://localhost/\")\n    channel = await connection.channel()\n\n    message = aio_pika.Message(\n        body=json.dumps({\"loan_id\": loan_id}).encode(),\n        headers={\"X-Request-ID\": request_id},\n        content_type=\"application/json\"\n    )\n\n    exchange = await channel.declare_exchange(\"loan_events\", aio_pika.ExchangeType.TOPIC)\n    await exchange.publish(message, routing_key=\"loan.created\")\n\n    logger.info(\"event_published\", request_id=request_id, loan_id=loan_id)\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#consuming-messages","title":"Consuming Messages","text":"<pre><code># CORRECT: Extract request ID from message\nasync def consume_loan_events():\n    \"\"\"Consume events with request ID tracking.\"\"\"\n    connection = await aio_pika.connect_robust(\"amqp://localhost/\")\n    channel = await connection.channel()\n    queue = await channel.declare_queue(\"loan_processing\")\n\n    async with queue.iterator() as queue_iter:\n        async for message in queue_iter:\n            async with message.process():\n                # Extract request ID\n                request_id = message.headers.get(\"X-Request-ID\", \"unknown\")\n\n                # Bind to logger\n                logger = structlog.get_logger().bind(request_id=request_id)\n                logger.info(\"processing_loan_event\")\n\n                await process_loan(message, request_id)\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#aiogram-bot-integration","title":"Aiogram Bot Integration","text":"<pre><code># CORRECT: Generate request ID for bot messages\nfrom aiogram import Bot, Dispatcher, types\nimport uuid\nimport structlog\n\nbot = Bot(token=\"TOKEN\")\ndp = Dispatcher(bot)\n\n\n@dp.message_handler(commands=[\"start\"])\nasync def start_command(message: types.Message):\n    \"\"\"Handle /start with request ID.\"\"\"\n    request_id = f\"req-{uuid.uuid4()}\"\n\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        user_id=message.from_user.id\n    )\n\n    logger.info(\"bot_command_received\", command=\"start\")\n\n    await message.reply(f\"Hello! Your request ID: {request_id}\")\n\n    logger.info(\"bot_response_sent\")\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#background-tasks","title":"Background Tasks","text":"<pre><code># CORRECT: Pass request ID to background tasks\nfrom fastapi import BackgroundTasks\n\n@app.post(\"/api/loans\")\nasync def create_loan(\n    request: Request,\n    background_tasks: BackgroundTasks\n):\n    request_id = request.state.request_id\n\n    # Pass request ID to background task\n    background_tasks.add_task(\n        send_notification,\n        loan_id=\"loan-123\",\n        request_id=request_id\n    )\n\n    return {\"request_id\": request_id}\n\n\nasync def send_notification(loan_id: str, request_id: str):\n    \"\"\"Send notification with request tracking.\"\"\"\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        loan_id=loan_id\n    )\n    logger.info(\"sending_notification\")\n    # Notification logic\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#querying-by-request-id","title":"Querying by Request ID","text":""},{"location":"atomic/observability/logging/request-id-tracking/#elasticsearch","title":"Elasticsearch","text":"<pre><code>{\n  \"query\": {\n    \"term\": {\"request_id\": \"req-abc-123\"}\n  },\n  \"sort\": [{\"timestamp\": \"asc\"}]\n}\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#kibana","title":"Kibana","text":"<pre><code>request_id:\"req-abc-123\"\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#cloudwatch-insights","title":"CloudWatch Insights","text":"<pre><code>fields @timestamp, service, event\n| filter request_id = \"req-abc-123\"\n| sort @timestamp asc\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/request-id-tracking/#do-generate-once-at-entry-point","title":"DO: Generate Once at Entry Point","text":"<pre><code># CORRECT: Generate at API gateway\n@app.middleware(\"http\")\nasync def middleware(request: Request, call_next):\n    request_id = request.headers.get(\"X-Request-ID\") or f\"req-{uuid.uuid4()}\"\n    request.state.request_id = request_id\n    return await call_next(request)\n\n\n# INCORRECT: Generate multiple times\ndef handler1():\n    request_id = str(uuid.uuid4())  # \u274c\n\ndef handler2():\n    request_id = str(uuid.uuid4())  # \u274c Different ID\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#do-include-in-all-logs","title":"DO: Include in All Logs","text":"<pre><code># CORRECT: Bind to logger\nlogger = structlog.get_logger().bind(request_id=request_id)\nlogger.info(\"event1\")\nlogger.info(\"event2\")\n# Both logs include request_id\n\n\n# INCORRECT: Manual inclusion\nlogger.info(\"event1\", request_id=request_id)  # Verbose\nlogger.info(\"event2\")  # \u274c Forgot request_id\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#do-return-in-api-responses","title":"DO: Return in API Responses","text":"<pre><code># CORRECT: Return request ID to client\n@app.post(\"/api/loans\")\nasync def create_loan(request: Request):\n    request_id = request.state.request_id\n    return {\n        \"loan_id\": \"loan-123\",\n        \"request_id\": request_id  # Client can use for support\n    }\n</code></pre>"},{"location":"atomic/observability/logging/request-id-tracking/#checklist","title":"Checklist","text":"<ul> <li> Generate request ID at API entry point</li> <li> Extract existing request ID from X-Request-ID header</li> <li> Store request ID in request state</li> <li> Bind request ID to logger context</li> <li> Propagate request ID in HTTP headers</li> <li> Include request ID in RabbitMQ message headers</li> <li> Extract request ID from incoming messages</li> <li> Pass request ID to background tasks</li> <li> Return request ID in API responses</li> <li> Add X-Request-ID to response headers</li> <li> Use consistent format (req-{uuid})</li> <li> Test request ID propagation across services</li> <li> Query logs by request ID in centralized system</li> </ul>"},{"location":"atomic/observability/logging/request-id-tracking/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/log-correlation.md</code> \u2014 Log correlation across services</li> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging with structlog</li> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging setup</li> </ul>"},{"location":"atomic/observability/logging/sensitive-data-handling/","title":"Sensitive Data Handling in Logs","text":"<p>Prevent sensitive data exposure in logs by implementing data masking, redaction, and filtering strategies. Sensitive data handling protects personally identifiable information (PII), authentication credentials, payment data, and confidential business information from accidental logging while maintaining debuggability.</p> <p>This document covers identifying sensitive data types, implementing masking strategies, configuring automatic redaction, handling structured log fields, sanitizing error messages, and complying with GDPR/CCPA data protection regulations. Proper sensitive data handling prevents security breaches, regulatory violations, and customer trust erosion.</p> <p>Sensitive data in logs creates security and compliance risks: leaked credentials enable unauthorized access, exposed PII violates privacy regulations (GDPR fines up to 4% of global revenue), payment card data logging violates PCI DSS, and confidential business data in logs can be accessed by unauthorized personnel or external attackers if logging infrastructure is compromised.</p>"},{"location":"atomic/observability/logging/sensitive-data-handling/#sensitive-data-categories","title":"Sensitive Data Categories","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#never-log-these","title":"Never Log These","text":"<pre><code># \u274c NEVER log these data types:\n\n# Authentication\n- Passwords (plaintext or hashed)\n- API keys and tokens\n- JWT tokens\n- OAuth tokens\n- Session IDs (full values)\n- Security questions/answers\n\n# Payment Data\n- Credit card numbers\n- CVV codes\n- Bank account numbers\n- Cryptocurrency private keys\n\n# Personal Identifiable Information (PII)\n- Social Security Numbers\n- Passport numbers\n- Driver's license numbers\n- Full addresses (without consent)\n- Phone numbers (without masking)\n- Email addresses (mask by default)\n- Biometric data\n\n# Health Information\n- Medical records\n- Health insurance IDs\n- Prescription information\n\n# Confidential Business Data\n- Trade secrets\n- Proprietary algorithms\n- Internal pricing\n- Unannounced product plans\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#data-masking-strategies","title":"Data Masking Strategies","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#email-masking","title":"Email Masking","text":"<pre><code># CORRECT: Mask email addresses\nimport re\n\ndef mask_email(email: str) -&gt; str:\n    \"\"\"Mask email preserving domain.\"\"\"\n    if \"@\" not in email:\n        return \"***@***\"\n    local, domain = email.split(\"@\")\n    if len(local) &lt;= 3:\n        return f\"{local[0]}***@{domain}\"\n    return f\"{local[:2]}***{local[-1]}@{domain}\"\n\n# Examples:\nmask_email(\"user@example.com\")  # \"us***r@example.com\"\nmask_email(\"a@example.com\")  # \"a***@example.com\"\n\n\n# Usage in logging\nlogger.info(\n    \"user_logged_in\",\n    user_id=\"user-123\",\n    email=mask_email(user.email)  # Masked\n)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#credit-card-masking","title":"Credit Card Masking","text":"<pre><code># CORRECT: Show only last 4 digits\ndef mask_credit_card(card_number: str) -&gt; str:\n    \"\"\"Mask credit card showing last 4 digits.\"\"\"\n    cleaned = card_number.replace(\" \", \"\").replace(\"-\", \"\")\n    return f\"****-****-****-{cleaned[-4:]}\"\n\n# Example:\nmask_credit_card(\"4111111111111111\")  # \"****-****-****-1111\"\n\n\n# Usage\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    card_last_four=card_number[-4:],  # Only last 4\n    amount=99.99\n)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#token-masking","title":"Token Masking","text":"<pre><code># CORRECT: Show prefix only\ndef mask_token(token: str) -&gt; str:\n    \"\"\"Mask token showing first 8 chars.\"\"\"\n    if len(token) &lt;= 12:\n        return \"***\"\n    return f\"{token[:8]}...{token[-4:]}\"\n\n# Example:\nmask_token(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\")  # \"eyJhbGci...VCJ9\"\n\n\n# Usage\nlogger.info(\n    \"api_call_authenticated\",\n    user_id=\"user-123\",\n    token_prefix=token[:8]  # Only prefix\n)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#automatic-redaction","title":"Automatic Redaction","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#structlog-processor","title":"Structlog Processor","text":"<pre><code># CORRECT: Automatic redaction processor\nimport structlog\nfrom typing import Any, Dict\n\nSENSITIVE_KEYS = {\n    \"password\", \"token\", \"api_key\", \"secret\",\n    \"credit_card\", \"ssn\", \"passport\"\n}\n\ndef redact_sensitive_processor(\n    logger: Any, method_name: str, event_dict: Dict\n) -&gt; Dict:\n    \"\"\"Redact sensitive fields from logs.\"\"\"\n    for key in list(event_dict.keys()):\n        # Check if key contains sensitive word\n        if any(sensitive in key.lower() for sensitive in SENSITIVE_KEYS):\n            event_dict[key] = \"***REDACTED***\"\n\n    return event_dict\n\n\n# Configure structlog\nstructlog.configure(\n    processors=[\n        redact_sensitive_processor,  # Add first\n        structlog.stdlib.add_log_level,\n        structlog.processors.JSONRenderer()\n    ]\n)\n\n\n# Usage - automatic redaction\nlogger.info(\n    \"user_created\",\n    user_id=\"user-123\",\n    email=\"user@example.com\",\n    password=\"secret123\"  # Automatically redacted\n)\n\n# Output:\n{\n    \"event\": \"user_created\",\n    \"user_id\": \"user-123\",\n    \"email\": \"user@example.com\",\n    \"password\": \"***REDACTED***\"  # Redacted automatically\n}\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#regex-based-redaction","title":"Regex-Based Redaction","text":"<pre><code># CORRECT: Pattern-based redaction\nimport re\n\ndef redact_patterns(text: str) -&gt; str:\n    \"\"\"Redact sensitive patterns in text.\"\"\"\n    # Credit cards\n    text = re.sub(r'\\b\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}\\b', '****-****-****-****', text)\n\n    # Email addresses\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '***@***.***', text)\n\n    # API keys (example pattern)\n    text = re.sub(r'\\b[A-Za-z0-9]{32,}\\b', '***API_KEY***', text)\n\n    return text\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#exception-handling","title":"Exception Handling","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#safe-error-logging","title":"Safe Error Logging","text":"<pre><code># CORRECT: Sanitize exception messages\nimport structlog\n\nlogger = structlog.get_logger()\n\ntry:\n    result = authenticate_user(username, password)\nexcept AuthenticationError as e:\n    logger.error(\n        \"authentication_failed\",\n        user_id=user.id,\n        error_type=\"AuthenticationError\",\n        # \u274c DON'T: error_message=str(e)  # May contain password\n        error_code=\"INVALID_CREDENTIALS\"  # Generic message\n    )\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#redact-stack-traces","title":"Redact Stack Traces","text":"<pre><code># CORRECT: Redact sensitive data from stack traces\ndef sanitize_exception_info(exc_info: tuple) -&gt; str:\n    \"\"\"Sanitize exception traceback.\"\"\"\n    import traceback\n    tb_lines = traceback.format_exception(*exc_info)\n    sanitized = []\n\n    for line in tb_lines:\n        # Redact password parameters\n        line = re.sub(r'password=[\"\\'].*?[\"\\']', 'password=***', line)\n        # Redact tokens\n        line = re.sub(r'token=[\"\\'].*?[\"\\']', 'token=***', line)\n        sanitized.append(line)\n\n    return ''.join(sanitized)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#configuration","title":"Configuration","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#environment-variables","title":"Environment Variables","text":"<pre><code># CORRECT: Mask sensitive config\nfrom pydantic_settings import BaseSettings\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n\n    DATABASE_URL: str\n    REDIS_URL: str\n    SECRET_KEY: str\n    API_KEY: str\n\n    def log_safe_config(self):\n        \"\"\"Log configuration without secrets.\"\"\"\n        return {\n            \"DATABASE_URL\": self.mask_connection_string(self.DATABASE_URL),\n            \"REDIS_URL\": self.mask_connection_string(self.REDIS_URL),\n            \"SECRET_KEY\": \"***\",\n            \"API_KEY\": f\"{self.API_KEY[:8]}***\"\n        }\n\n    @staticmethod\n    def mask_connection_string(url: str) -&gt; str:\n        \"\"\"Mask password in connection string.\"\"\"\n        return re.sub(r':([^@]+)@', ':***@', url)\n\n\n# Usage\nsettings = Settings()\nlogger.info(\"app_starting\", config=settings.log_safe_config())\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#do-mask-by-default","title":"DO: Mask by Default","text":"<pre><code># CORRECT: Mask all potentially sensitive fields\nfrom dataclasses import dataclass\n\n@dataclass\nclass User:\n    id: str\n    email: str\n    phone: str\n\n    def to_log_dict(self) -&gt; dict:\n        \"\"\"Safe representation for logging.\"\"\"\n        return {\n            \"id\": self.id,\n            \"email\": mask_email(self.email),\n            \"phone\": mask_phone(self.phone)\n        }\n\n\nlogger.info(\"user_fetched\", user=user.to_log_dict())\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#dont-log-requestresponse-bodies","title":"DON'T: Log Request/Response Bodies","text":"<pre><code># INCORRECT: Logging entire request body\n@app.post(\"/api/users\")\nasync def create_user(user: UserCreate):\n    logger.info(\"request_received\", body=user.dict())  # \u274c May contain password\n\n\n# CORRECT: Log specific safe fields\n@app.post(\"/api/users\")\nasync def create_user(user: UserCreate):\n    logger.info(\n        \"user_creation_requested\",\n        email=mask_email(user.email),\n        role=user.role\n    )\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#dont-include-sensitive-data-in-error-messages","title":"DON'T: Include Sensitive Data in Error Messages","text":"<pre><code># INCORRECT: Exposing sensitive data in errors\nif not verify_password(password, user.password_hash):\n    raise HTTPException(\n        status_code=401,\n        detail=f\"Password {password} is incorrect\"  # \u274c Exposes password\n    )\n\n\n# CORRECT: Generic error message\nif not verify_password(password, user.password_hash):\n    raise HTTPException(\n        status_code=401,\n        detail=\"Invalid credentials\"  # Generic\n    )\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#compliance","title":"Compliance","text":""},{"location":"atomic/observability/logging/sensitive-data-handling/#gdpr-compliance","title":"GDPR Compliance","text":"<pre><code># Right to be forgotten: Don't log identifiable data\nlogger.info(\n    \"user_action\",\n    user_id=\"user-123\",  # ID is OK (can be deleted)\n    action=\"profile_updated\"\n    # \u274c DON'T: email, name, phone (hard to remove from logs)\n)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#pci-dss-compliance","title":"PCI DSS Compliance","text":"<pre><code># NEVER log full card details\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    card_last_four=\"1111\",  # \u2705 OK (last 4 digits)\n    amount=99.99,\n    # \u274c card_number=card.number  # PCI DSS violation\n)\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#testing","title":"Testing","text":"<pre><code># CORRECT: Test redaction\ndef test_password_redaction():\n    \"\"\"Test passwords are redacted.\"\"\"\n    cap = LogCapture()\n    structlog.configure(processors=[redact_sensitive_processor, cap])\n\n    logger = structlog.get_logger()\n    logger.info(\"test\", password=\"secret123\")\n\n    assert cap.entries[0][\"password\"] == \"***REDACTED***\"\n</code></pre>"},{"location":"atomic/observability/logging/sensitive-data-handling/#checklist","title":"Checklist","text":"<ul> <li> Identify all sensitive data types in application</li> <li> Implement masking functions (email, phone, cards)</li> <li> Configure automatic redaction processor</li> <li> Never log passwords, tokens, API keys</li> <li> Mask credit card numbers (show last 4 only)</li> <li> Redact sensitive data in exception messages</li> <li> Mask connection strings in config logs</li> <li> Avoid logging full request/response bodies</li> <li> Use generic error messages</li> <li> Test redaction in unit tests</li> <li> Audit logs regularly for leaks</li> <li> Train team on sensitive data handling</li> <li> Document what data is safe to log</li> </ul>"},{"location":"atomic/observability/logging/sensitive-data-handling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging implementation</li> <li><code>docs/atomic/observability/logging/log-formatting.md</code> \u2014 Log formatting standards</li> <li><code>docs/atomic/security/authentication/api-key-management.md</code> \u2014 API key best practices</li> </ul>"},{"location":"atomic/observability/logging/structured-logging/","title":"Structured Logging Patterns","text":"<p>Implement structured logging with JSON format to enable efficient log parsing, filtering, searching, and analysis in centralized logging systems. Structured logging emits machine-readable log entries with consistent field names and data types instead of unstructured plain text messages.</p> <p>This document covers structured logging implementation with Python's structlog library, JSON formatting, log enrichment with context data (request IDs, user IDs, service names), log levels configuration, and integration with centralized logging systems like Elasticsearch and CloudWatch. Structured logs enable powerful query capabilities and automated alerting on specific conditions.</p> <p>Structured logging treats logs as data, not text. Each log entry is a structured JSON object with well-defined fields for timestamp, level, message, and custom context. This approach enables querying logs by specific fields, aggregating metrics from logs, and correlating logs across distributed services for end-to-end request tracing.</p>"},{"location":"atomic/observability/logging/structured-logging/#why-structured-logging","title":"Why Structured Logging","text":""},{"location":"atomic/observability/logging/structured-logging/#benefits","title":"Benefits","text":"<p>Queryability: Filter logs by exact field values instead of regex patterns <pre><code># Query: user_id=\"user-123\" AND status_code=500\n# Instead of parsing: \"User user-123 received 500 error\"\n</code></pre></p> <p>Aggregation: Calculate metrics directly from logs <pre><code># Count errors by endpoint: GROUP BY endpoint WHERE level=\"error\"\n# Instead of parsing text patterns\n</code></pre></p> <p>Correlation: Link logs across services using request_id <pre><code># Trace request flow: request_id=\"req-abc\" across API \u2192 Worker \u2192 Bot\n</code></pre></p> <p>Machine Parsing: Automated analysis without regex fragility <pre><code># Reliable: log[\"duration_ms\"] &gt; 1000\n# vs. Fragile: re.search(r'took (\\d+)ms', message)\n</code></pre></p>"},{"location":"atomic/observability/logging/structured-logging/#structlog-setup","title":"Structlog Setup","text":""},{"location":"atomic/observability/logging/structured-logging/#installation","title":"Installation","text":"<pre><code># Install structlog\npip install structlog==24.1.0\n\n# Install optional dependencies\npip install python-json-logger==2.0.7\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#basic-configuration","title":"Basic Configuration","text":"<pre><code># src/core/logging_config.py\nimport structlog\nfrom typing import Any\n\ndef configure_structured_logging() -&gt; None:\n    \"\"\"Configure structlog for JSON output.\"\"\"\n    structlog.configure(\n        processors=[\n            # Add log level to event dict\n            structlog.stdlib.add_log_level,\n            # Add timestamp\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            # Add stack info for exceptions\n            structlog.processors.StackInfoRenderer(),\n            # Format exceptions\n            structlog.processors.format_exc_info,\n            # Render as JSON\n            structlog.processors.JSONRenderer()\n        ],\n        wrapper_class=structlog.stdlib.BoundLogger,\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        cache_logger_on_first_use=True,\n    )\n\n\n# Call once at application startup\nconfigure_structured_logging()\nlogger = structlog.get_logger()\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#json-log-format","title":"JSON Log Format","text":""},{"location":"atomic/observability/logging/structured-logging/#standard-log-structure","title":"Standard Log Structure","text":"<pre><code>import structlog\n\nlogger = structlog.get_logger()\n\n# CORRECT: Structured log with context\nlogger.info(\n    \"user_logged_in\",\n    user_id=\"user-123\",\n    email=\"user@example.com\",\n    ip_address=\"192.168.1.1\",\n    duration_ms=45\n)\n\n# Output JSON:\n{\n    \"event\": \"user_logged_in\",\n    \"level\": \"info\",\n    \"timestamp\": \"2025-01-15T10:30:45.123Z\",\n    \"user_id\": \"user-123\",\n    \"email\": \"user@example.com\",\n    \"ip_address\": \"192.168.1.1\",\n    \"duration_ms\": 45\n}\n\n\n# INCORRECT: Unstructured string interpolation\nlogger.info(f\"User {user_id} logged in from {ip_address}\")\n\n# Output: Plain text, hard to query\n# \"User user-123 logged in from 192.168.1.1\"\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#required-fields","title":"Required Fields","text":"<p>Every log entry should include:</p> <pre><code>{\n    \"timestamp\": \"2025-01-15T10:30:45.123Z\",  # ISO 8601 format\n    \"level\": \"info\",                           # debug, info, warning, error, critical\n    \"event\": \"user_created\",                   # Event name (snake_case)\n    \"service\": \"finance_lending_api\",          # Service name\n    \"request_id\": \"req-abc-123\",               # Request correlation ID\n    \"message\": \"User created successfully\"     # Human-readable message\n}\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#context-enrichment","title":"Context Enrichment","text":""},{"location":"atomic/observability/logging/structured-logging/#service-level-context","title":"Service-Level Context","text":"<pre><code># src/core/logging_config.py\nimport structlog\nfrom src.core.config import settings\n\ndef get_logger() -&gt; structlog.BoundLogger:\n    \"\"\"Get logger with service-level context.\"\"\"\n    logger = structlog.get_logger()\n    return logger.bind(\n        service=settings.SERVICE_NAME,\n        environment=settings.ENVIRONMENT,\n        version=settings.VERSION\n    )\n\n\n# Usage in application code\nlogger = get_logger()\nlogger.info(\"service_started\", port=8000)\n\n# Output includes service context:\n{\n    \"event\": \"service_started\",\n    \"service\": \"finance_lending_api\",\n    \"environment\": \"production\",\n    \"version\": \"1.2.3\",\n    \"port\": 8000\n}\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#request-level-context","title":"Request-Level Context","text":"<pre><code># CORRECT: FastAPI middleware for request context\nfrom fastapi import Request\nimport structlog\nimport uuid\n\nasync def logging_middleware(request: Request, call_next):\n    \"\"\"Add request context to all logs.\"\"\"\n    request_id = request.headers.get(\"X-Request-ID\", str(uuid.uuid4()))\n\n    # Bind request context to logger\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        method=request.method,\n        path=request.url.path,\n        client_ip=request.client.host\n    )\n\n    # Store logger in request state\n    request.state.logger = logger\n\n    logger.info(\"request_started\")\n\n    response = await call_next(request)\n\n    logger.info(\n        \"request_completed\",\n        status_code=response.status_code,\n        duration_ms=calculate_duration()\n    )\n\n    return response\n\n\n# Usage in endpoint\n@router.post(\"/api/loans\")\nasync def create_loan(request: Request, loan: LoanCreate):\n    logger = request.state.logger  # Get logger with request context\n    logger.info(\"creating_loan\", amount=loan.amount)\n    # All logs automatically include request_id, method, path\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#user-context","title":"User Context","text":"<pre><code># CORRECT: Add user context after authentication\nfrom fastapi import Depends\n\nasync def get_current_user(request: Request) -&gt; User:\n    \"\"\"Authenticate user and enrich logger.\"\"\"\n    user = await authenticate(request)\n\n    # Bind user context to logger\n    request.state.logger = request.state.logger.bind(\n        user_id=user.id,\n        user_email=user.email,\n        user_role=user.role\n    )\n\n    return user\n\n\n@router.get(\"/api/profile\")\nasync def get_profile(\n    request: Request,\n    current_user: User = Depends(get_current_user)\n):\n    logger = request.state.logger\n    logger.info(\"profile_accessed\")\n    # Log includes: request_id, user_id, user_email, user_role\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#log-levels","title":"Log Levels","text":""},{"location":"atomic/observability/logging/structured-logging/#standard-levels","title":"Standard Levels","text":"<pre><code>import structlog\n\nlogger = structlog.get_logger()\n\n# DEBUG: Detailed diagnostic information\nlogger.debug(\"cache_hit\", key=\"user:123\", ttl=3600)\n\n# INFO: General informational events\nlogger.info(\"loan_application_submitted\", loan_id=\"loan-456\", amount=10000)\n\n# WARNING: Warning events that should be monitored\nlogger.warning(\"rate_limit_approaching\", user_id=\"user-789\", requests=950, limit=1000)\n\n# ERROR: Error events requiring attention\nlogger.error(\"payment_processing_failed\", payment_id=\"pay-123\", reason=\"insufficient_funds\")\n\n# CRITICAL: Critical failures requiring immediate action\nlogger.critical(\"database_connection_lost\", host=\"postgres.local\", retry_count=5)\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#environment-based-configuration","title":"Environment-Based Configuration","text":"<pre><code># src/core/config.py\nfrom pydantic_settings import BaseSettings\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n\n    LOG_LEVEL: str = \"INFO\"  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n    LOG_JSON: bool = True    # JSON format for production\n\n\n# src/core/logging_config.py\nimport logging\nfrom src.core.config import settings\n\ndef configure_log_level():\n    \"\"\"Configure log level from environment.\"\"\"\n    logging.basicConfig(\n        level=getattr(logging, settings.LOG_LEVEL.upper()),\n        format=\"%(message)s\" if settings.LOG_JSON else \"%(levelname)s: %(message)s\"\n    )\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#application-patterns","title":"Application Patterns","text":""},{"location":"atomic/observability/logging/structured-logging/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code># CORRECT: Structured logging in FastAPI\nfrom fastapi import FastAPI, Request\nimport structlog\n\napp = FastAPI()\nlogger = structlog.get_logger()\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Log service startup.\"\"\"\n    logger.info(\n        \"service_starting\",\n        service=\"finance_lending_api\",\n        port=8000,\n        environment=\"production\"\n    )\n\n\n@app.post(\"/api/loans\")\nasync def create_loan(request: Request, loan: LoanCreate):\n    \"\"\"Create loan with structured logging.\"\"\"\n    logger = request.state.logger\n\n    logger.info(\n        \"loan_creation_started\",\n        user_id=loan.user_id,\n        amount=loan.amount,\n        purpose=loan.purpose\n    )\n\n    try:\n        result = await loan_service.create_loan(loan)\n        logger.info(\n            \"loan_created\",\n            loan_id=result.id,\n            status=result.status\n        )\n        return result\n\n    except InsufficientCreditError as e:\n        logger.warning(\n            \"loan_rejected_credit\",\n            user_id=loan.user_id,\n            credit_score=e.credit_score,\n            required_score=e.required_score\n        )\n        raise HTTPException(status_code=422, detail=\"Insufficient credit score\")\n\n    except Exception as e:\n        logger.error(\n            \"loan_creation_failed\",\n            error_type=type(e).__name__,\n            error_message=str(e),\n            exc_info=True\n        )\n        raise\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#aiogram-bot-integration","title":"Aiogram Bot Integration","text":"<pre><code># CORRECT: Structured logging in Aiogram bot\nfrom aiogram import Bot, Dispatcher, types\nimport structlog\n\nlogger = structlog.get_logger().bind(service=\"finance_lending_bot\")\n\n\n@dp.message_handler(commands=[\"start\"])\nasync def start_command(message: types.Message):\n    \"\"\"Handle /start command with structured logging.\"\"\"\n    logger = structlog.get_logger().bind(\n        user_id=message.from_user.id,\n        username=message.from_user.username,\n        chat_id=message.chat.id\n    )\n\n    logger.info(\"bot_command_received\", command=\"start\")\n\n    try:\n        await message.reply(\"Welcome to Finance Lending Bot!\")\n        logger.info(\"bot_response_sent\", command=\"start\")\n\n    except Exception as e:\n        logger.error(\n            \"bot_command_failed\",\n            command=\"start\",\n            error=str(e),\n            exc_info=True\n        )\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#background-worker-integration","title":"Background Worker Integration","text":"<pre><code># CORRECT: Structured logging in AsyncIO worker\nimport structlog\nimport asyncio\n\nlogger = structlog.get_logger().bind(service=\"finance_lending_worker\")\n\n\nasync def process_loan_application(loan_id: str):\n    \"\"\"Process loan with structured logging.\"\"\"\n    task_logger = logger.bind(loan_id=loan_id, task=\"process_loan\")\n\n    task_logger.info(\"task_started\")\n\n    try:\n        loan = await fetch_loan(loan_id)\n        task_logger.info(\"loan_fetched\", amount=loan.amount)\n\n        credit_score = await check_credit(loan.user_id)\n        task_logger.info(\"credit_checked\", score=credit_score)\n\n        decision = await make_decision(loan, credit_score)\n        task_logger.info(\n            \"decision_made\",\n            decision=decision.status,\n            reason=decision.reason\n        )\n\n        await notify_user(loan.user_id, decision)\n        task_logger.info(\"task_completed\", duration_ms=calculate_duration())\n\n    except Exception as e:\n        task_logger.error(\n            \"task_failed\",\n            error_type=type(e).__name__,\n            error_message=str(e),\n            exc_info=True\n        )\n        raise\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#exception-logging","title":"Exception Logging","text":""},{"location":"atomic/observability/logging/structured-logging/#structured-exception-context","title":"Structured Exception Context","text":"<pre><code># CORRECT: Log exceptions with structured context\nimport structlog\n\nlogger = structlog.get_logger()\n\ntry:\n    result = await external_api.call(user_id=\"user-123\")\nexcept httpx.HTTPError as e:\n    logger.error(\n        \"external_api_error\",\n        user_id=\"user-123\",\n        error_type=\"HTTPError\",\n        status_code=e.response.status_code if e.response else None,\n        url=str(e.request.url),\n        exc_info=True  # Include full traceback\n    )\n    raise\n\nexcept Exception as e:\n    logger.critical(\n        \"unexpected_error\",\n        error_type=type(e).__name__,\n        error_message=str(e),\n        exc_info=True\n    )\n    raise\n\n\n# INCORRECT: Unstructured exception logging\nexcept Exception as e:\n    logger.error(f\"Error occurred: {e}\")  # Lost context, no traceback\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#testing-structured-logs","title":"Testing Structured Logs","text":""},{"location":"atomic/observability/logging/structured-logging/#capturing-logs-in-tests","title":"Capturing Logs in Tests","text":"<pre><code># CORRECT: Test structured log output\nimport pytest\nimport structlog\nfrom structlog.testing import LogCapture\n\n\ndef test_loan_creation_logs():\n    \"\"\"Test loan creation emits correct structured logs.\"\"\"\n    cap = LogCapture()\n    structlog.configure(processors=[cap])\n\n    logger = structlog.get_logger()\n    logger.info(\"loan_created\", loan_id=\"loan-123\", amount=10000)\n\n    # Assert log structure\n    assert len(cap.entries) == 1\n    assert cap.entries[0][\"event\"] == \"loan_created\"\n    assert cap.entries[0][\"loan_id\"] == \"loan-123\"\n    assert cap.entries[0][\"amount\"] == 10000\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/logging/structured-logging/#do-use-consistent-event-names","title":"DO: Use Consistent Event Names","text":"<pre><code># CORRECT: Consistent event naming (snake_case)\nlogger.info(\"user_created\", user_id=\"user-123\")\nlogger.info(\"user_updated\", user_id=\"user-123\")\nlogger.info(\"user_deleted\", user_id=\"user-123\")\n\n# Enables queries: event IN (\"user_created\", \"user_updated\", \"user_deleted\")\n\n\n# INCORRECT: Inconsistent naming\nlogger.info(\"UserCreated\")  # PascalCase\nlogger.info(\"user-updated\")  # kebab-case\nlogger.info(\"USER_DELETED\")  # SCREAMING_SNAKE_CASE\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#do-log-structured-data-not-formatted-strings","title":"DO: Log Structured Data, Not Formatted Strings","text":"<pre><code># CORRECT: Structured fields\nlogger.info(\n    \"payment_processed\",\n    payment_id=\"pay-123\",\n    amount=99.99,\n    currency=\"USD\",\n    user_id=\"user-456\"\n)\n\n# Query: SELECT * WHERE amount &gt; 100 AND currency = 'USD'\n\n\n# INCORRECT: String interpolation\nlogger.info(f\"Processed payment pay-123 for $99.99 USD by user-456\")\n# Cannot query by amount or currency\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#do-include-context-in-every-log","title":"DO: Include Context in Every Log","text":"<pre><code># CORRECT: Rich context\nlogger.info(\n    \"api_request_completed\",\n    request_id=\"req-abc\",\n    method=\"POST\",\n    path=\"/api/loans\",\n    status_code=201,\n    duration_ms=145,\n    user_id=\"user-123\"\n)\n\n\n# INCORRECT: Minimal context\nlogger.info(\"Request completed\")  # No context to debug issues\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#dont-log-sensitive-data","title":"DON'T: Log Sensitive Data","text":"<pre><code># CORRECT: Mask sensitive data\nlogger.info(\n    \"user_authenticated\",\n    user_id=\"user-123\",\n    email=\"u***@example.com\",  # Masked\n    ip_address=\"192.168.1.1\"\n)\n\n\n# INCORRECT: Log passwords, tokens, PII\nlogger.info(\n    \"login_attempt\",\n    email=\"user@example.com\",\n    password=\"secret123\",  # \u274c Never log passwords\n    credit_card=\"4111-1111-1111-1111\"  # \u274c Never log payment data\n)\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#dont-over-log-in-hot-paths","title":"DON'T: Over-Log in Hot Paths","text":"<pre><code># CORRECT: Log summaries, not every iteration\ntotal_processed = 0\nfor user in users:\n    await process_user(user)\n    total_processed += 1\n\nlogger.info(\"batch_processed\", total_users=total_processed, duration_ms=duration)\n\n\n# INCORRECT: Log every iteration\nfor user in users:  # 10,000 users\n    logger.info(\"processing_user\", user_id=user.id)  # \u274c 10,000 log entries!\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#configuration-examples","title":"Configuration Examples","text":""},{"location":"atomic/observability/logging/structured-logging/#development-configuration","title":"Development Configuration","text":"<pre><code># Development: Human-readable console output\nimport structlog\n\nstructlog.configure(\n    processors=[\n        structlog.stdlib.add_log_level,\n        structlog.dev.ConsoleRenderer()  # Colored, formatted output\n    ],\n    logger_factory=structlog.PrintLoggerFactory(),\n)\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#production-configuration","title":"Production Configuration","text":"<pre><code># Production: JSON output for centralized logging\nimport structlog\n\nstructlog.configure(\n    processors=[\n        structlog.stdlib.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.StackInfoRenderer(),\n        structlog.processors.format_exc_info,\n        structlog.processors.UnicodeDecoder(),\n        structlog.processors.JSONRenderer()  # JSON for Elasticsearch/CloudWatch\n    ],\n    wrapper_class=structlog.stdlib.BoundLogger,\n    context_class=dict,\n    logger_factory=structlog.stdlib.LoggerFactory(),\n    cache_logger_on_first_use=True,\n)\n</code></pre>"},{"location":"atomic/observability/logging/structured-logging/#checklist","title":"Checklist","text":"<ul> <li> Install structlog library</li> <li> Configure JSON log format</li> <li> Add service-level context (service name, environment, version)</li> <li> Implement request-level context (request_id, method, path)</li> <li> Add user context after authentication</li> <li> Use consistent event naming (snake_case)</li> <li> Log structured data, not formatted strings</li> <li> Include relevant context in every log</li> <li> Configure appropriate log levels per environment</li> <li> Implement exception logging with exc_info=True</li> <li> Mask sensitive data (passwords, tokens, PII)</li> <li> Avoid over-logging in hot paths</li> <li> Test log output in unit tests</li> <li> Integrate with centralized logging system</li> </ul>"},{"location":"atomic/observability/logging/structured-logging/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/log-formatting.md</code> \u2014 Log formatting standards and conventions</li> <li><code>docs/atomic/observability/logging/log-correlation.md</code> \u2014 Correlating logs across distributed services</li> <li><code>docs/atomic/observability/logging/request-id-tracking.md</code> \u2014 Request ID propagation and tracking</li> <li><code>docs/atomic/observability/logging/sensitive-data-handling.md</code> \u2014 Handling sensitive data in logs</li> <li><code>docs/atomic/observability/logging/centralized-logging.md</code> \u2014 Centralized logging infrastructure setup</li> </ul>"},{"location":"atomic/observability/tracing/distributed-tracing/","title":"Distributed Tracing","text":"<p>Implement end-to-end distributed tracing to track requests flowing through multiple microservices, enabling performance analysis, error debugging, and dependency mapping. Distributed tracing visualizes request paths across service boundaries, revealing bottlenecks, failures, and unexpected behaviors in complex microservices architectures.</p> <p>This document covers tracing patterns for synchronous HTTP communication, asynchronous event-driven workflows via RabbitMQ, cross-service error propagation, trace visualization in Jaeger UI, performance analysis techniques, and debugging distributed failures. Distributed tracing transforms opaque microservices into transparent, observable systems.</p> <p>Without distributed tracing, debugging production issues requires manually searching logs across dozens of services, guessing which service failed, and reconstructing request flows from timestamps. With tracing, you see the complete request journey in seconds: API \u2192 Data Service \u2192 Database \u2192 Worker \u2192 Notification Service, with exact timings and errors.</p>"},{"location":"atomic/observability/tracing/distributed-tracing/#end-to-end-request-flow","title":"End-to-End Request Flow","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#http-api-request","title":"HTTP API Request","text":"<pre><code># Step 1: User calls finance_lending_api\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    \"\"\"Create loan - entry point for distributed trace.\"\"\"\n    # Span 1: \"POST /api/loans\" (automatic from FastAPI)\n\n    # Span 2: Validate user (custom span)\n    with tracer.start_as_current_span(\"validate_user\") as span:\n        span.set_attribute(\"user.id\", loan.user_id)\n\n        # Span 3: Call finance_data_postgres_api (automatic from HTTPX)\n        user = await http_client.get(\n            f\"http://data-api:8000/api/users/{loan.user_id}\"\n        )\n        # HTTP call creates child span with propagated trace context\n\n    # Span 4: Check credit score (custom span)\n    with tracer.start_as_current_span(\"credit_check\") as span:\n        # Span 5: Call external credit API (automatic from HTTPX)\n        credit_score = await credit_api.get_score(loan.user_id)\n        span.set_attribute(\"credit.score\", credit_score)\n\n    # Span 6: Save loan to database (automatic from SQLAlchemy)\n    loan_record = await db.create_loan(loan)\n\n    # Span 7: Publish event to RabbitMQ (manual span)\n    with tracer.start_as_current_span(\"publish_loan_event\") as span:\n        await publish_event(\"loan.created\", loan_record.id)\n\n    return {\"id\": loan_record.id, \"status\": \"pending\"}\n\n\n# Result: Single distributed trace with 7 spans showing complete flow\n# Trace ID propagates through all HTTP calls and events\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#trace-visualization","title":"Trace Visualization","text":"<pre><code>Trace: create_loan (trace_id: abc123)\n\u251c\u2500 POST /api/loans [200ms] (finance_lending_api)\n\u2502  \u251c\u2500 validate_user [45ms]\n\u2502  \u2502  \u2514\u2500 GET /api/users/456 [40ms] (finance_data_postgres_api)\n\u2502  \u2502     \u2514\u2500 SELECT * FROM users [5ms] (postgres)\n\u2502  \u251c\u2500 credit_check [80ms]\n\u2502  \u2502  \u2514\u2500 POST /credit-score [75ms] (external_credit_api)\n\u2502  \u251c\u2500 INSERT INTO loans [20ms] (postgres)\n\u2502  \u2514\u2500 publish_loan_event [10ms]\n\u2502     \u2514\u2500 RabbitMQ publish [8ms]\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#service-to-service-http-tracing","title":"Service-to-Service HTTP Tracing","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#api-to-data-service","title":"API to Data Service","text":"<pre><code># finance_lending_api \u2192 finance_data_postgres_api\nfrom opentelemetry.propagate import inject\nimport httpx\n\nasync def get_user(user_id: str) -&gt; dict:\n    \"\"\"Call data service with trace context propagation.\"\"\"\n    with tracer.start_as_current_span(\"call_data_service\") as span:\n        span.set_attribute(\"service.name\", \"finance_data_postgres_api\")\n        span.set_attribute(\"endpoint\", f\"/api/users/{user_id}\")\n\n        headers = {}\n        inject(headers)  # Inject trace context (traceparent header)\n\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                f\"http://data-api:8000/api/users/{user_id}\",\n                headers=headers\n            )\n\n        span.set_attribute(\"http.status_code\", response.status_code)\n        return response.json()\n\n\n# finance_data_postgres_api receives request with trace context\n@app.get(\"/api/users/{user_id}\")\nasync def get_user_endpoint(user_id: str):\n    \"\"\"Handle request - trace context automatically extracted by FastAPI instrumentation.\"\"\"\n    # This span is child of calling service's span\n\n    with tracer.start_as_current_span(\"fetch_user_from_db\") as span:\n        span.set_attribute(\"user.id\", user_id)\n        user = await db.get_user(user_id)  # Database query span created\n        return user\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#multiple-service-calls","title":"Multiple Service Calls","text":"<pre><code>@app.get(\"/api/loans/{loan_id}/details\")\nasync def get_loan_details(loan_id: str):\n    \"\"\"Fetch loan details from multiple services.\"\"\"\n    with tracer.start_as_current_span(\"fetch_loan_details\") as span:\n        span.set_attribute(\"loan.id\", loan_id)\n\n        # Parallel calls - all part of same trace\n        loan, user, documents = await asyncio.gather(\n            get_loan(loan_id),      # Call data service\n            get_user(loan.user_id),  # Call data service\n            get_documents(loan_id)   # Call document service\n        )\n        # Each creates child span with propagated trace context\n\n        span.set_attribute(\"user.id\", user[\"id\"])\n        span.set_attribute(\"documents.count\", len(documents))\n\n        return {\n            \"loan\": loan,\n            \"user\": user,\n            \"documents\": documents\n        }\n\n\n# Result trace:\n# GET /api/loans/123/details [150ms]\n# \u251c\u2500 fetch_loan_details [145ms]\n# \u2502  \u251c\u2500 get_loan [50ms] \u2192 finance_data_postgres_api\n# \u2502  \u251c\u2500 get_user [45ms] \u2192 finance_data_postgres_api\n# \u2502  \u2514\u2500 get_documents [40ms] \u2192 finance_document_api\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#event-driven-tracing","title":"Event-Driven Tracing","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#rabbitmq-producer","title":"RabbitMQ Producer","text":"<pre><code>from opentelemetry.propagate import inject\nimport aio_pika\n\nasync def publish_loan_created_event(loan_id: str, user_id: str):\n    \"\"\"Publish event with trace context.\"\"\"\n    with tracer.start_as_current_span(\"publish_loan_created\") as span:\n        span.set_attribute(\"loan.id\", loan_id)\n        span.set_attribute(\"event.type\", \"loan.created\")\n\n        # Inject trace context into message headers\n        headers = {}\n        inject(headers)\n\n        message_body = {\n            \"loan_id\": loan_id,\n            \"user_id\": user_id,\n            \"created_at\": datetime.now().isoformat()\n        }\n\n        message = aio_pika.Message(\n            body=json.dumps(message_body).encode(),\n            headers=headers,  # Trace context propagated\n            content_type=\"application/json\"\n        )\n\n        await channel.default_exchange.publish(\n            message,\n            routing_key=\"loans.created\"\n        )\n\n        span.add_event(\"event_published\")\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#rabbitmq-consumer","title":"RabbitMQ Consumer","text":"<pre><code>from opentelemetry.propagate import extract\n\nasync def consume_loan_created(message: aio_pika.IncomingMessage):\n    \"\"\"Process event with trace context from producer.\"\"\"\n    # Extract trace context from message headers\n    context = extract(message.headers)\n\n    # Start span linked to producer's trace\n    with tracer.start_as_current_span(\n        \"process_loan_created\",\n        context=context  # Links to original trace\n    ) as span:\n        body = json.loads(message.body.decode())\n        loan_id = body[\"loan_id\"]\n\n        span.set_attribute(\"loan.id\", loan_id)\n        span.set_attribute(\"event.type\", \"loan.created\")\n\n        # Process loan (creates child spans)\n        with tracer.start_as_current_span(\"generate_documents\") as doc_span:\n            await generate_loan_documents(loan_id)\n\n        with tracer.start_as_current_span(\"send_notification\") as notif_span:\n            await send_approval_notification(loan_id)\n\n        span.add_event(\"event_processed\")\n\n    await message.ack()\n\n\n# Result: Async event processing linked to original trace\n# Trace shows: API \u2192 RabbitMQ \u2192 Worker \u2192 Document Generation \u2192 Notification\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#multi-stage-event-processing","title":"Multi-Stage Event Processing","text":"<pre><code># Stage 1: API publishes event\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    loan_id = await save_loan(loan)\n    await publish_event(\"loan.created\", loan_id)  # Trace continues here\n    return {\"id\": loan_id}\n\n\n# Stage 2: Worker processes event and publishes next stage\nasync def process_loan_created(message):\n    context = extract(message.headers)\n    with tracer.start_as_current_span(\"verify_loan\", context=context) as span:\n        loan_id = json.loads(message.body)[\"loan_id\"]\n\n        # Verify documents\n        verified = await verify_documents(loan_id)\n\n        if verified:\n            # Publish next stage event\n            await publish_event(\"loan.verified\", loan_id)  # Trace continues\n\n        span.set_attribute(\"verification.result\", verified)\n\n\n# Stage 3: Another worker handles verified loans\nasync def process_loan_verified(message):\n    context = extract(message.headers)\n    with tracer.start_as_current_span(\"approve_loan\", context=context) as span:\n        loan_id = json.loads(message.body)[\"loan_id\"]\n\n        # Final approval\n        await approve_loan(loan_id)\n        span.add_event(\"loan_approved\")\n\n\n# Result: Single trace spans entire workflow\n# API \u2192 Worker1 (verify) \u2192 Worker2 (approve)\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#error-propagation","title":"Error Propagation","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#http-error-tracing","title":"HTTP Error Tracing","text":"<pre><code>@app.get(\"/api/loans/{loan_id}\")\nasync def get_loan(loan_id: str):\n    \"\"\"Handle errors in distributed trace.\"\"\"\n    with tracer.start_as_current_span(\"get_loan\") as span:\n        span.set_attribute(\"loan.id\", loan_id)\n\n        try:\n            # Call data service\n            loan = await data_service.get_loan(loan_id)\n\n            if not loan:\n                # Record error in span\n                span.set_status(\n                    trace.Status(trace.StatusCode.ERROR, \"Loan not found\")\n                )\n                span.add_event(\"loan_not_found\")\n                raise HTTPException(status_code=404, detail=\"Loan not found\")\n\n            return loan\n\n        except httpx.HTTPStatusError as e:\n            # Record external service error\n            span.record_exception(e)\n            span.set_status(trace.Status(\n                trace.StatusCode.ERROR,\n                f\"Data service error: {e.response.status_code}\"\n            ))\n            raise HTTPException(\n                status_code=502,\n                detail=\"Data service unavailable\"\n            )\n\n        except Exception as e:\n            # Record unexpected error\n            span.record_exception(e)\n            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n            raise\n\n\n# Result: Error visible in trace with full context\n# Trace shows: API \u2192 Data Service [ERROR 502] \u2192 Database timeout\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#event-processing-errors","title":"Event Processing Errors","text":"<pre><code>async def process_loan_event(message: aio_pika.IncomingMessage):\n    \"\"\"Handle errors in event processing.\"\"\"\n    context = extract(message.headers)\n\n    with tracer.start_as_current_span(\n        \"process_loan_event\",\n        context=context\n    ) as span:\n        try:\n            loan_id = json.loads(message.body)[\"loan_id\"]\n            span.set_attribute(\"loan.id\", loan_id)\n\n            # Process loan\n            result = await process_loan(loan_id)\n\n            await message.ack()\n            span.add_event(\"message_processed\")\n\n        except ValueError as e:\n            # Invalid message format\n            span.record_exception(e)\n            span.set_status(trace.Status(\n                trace.StatusCode.ERROR,\n                \"Invalid message format\"\n            ))\n            await message.reject(requeue=False)  # Dead letter queue\n\n        except Exception as e:\n            # Processing error - retry\n            span.record_exception(e)\n            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n            await message.nack(requeue=True)  # Requeue for retry\n\n\n# Result: Failed events visible in trace with error details\n# Trace shows: API \u2192 Event \u2192 Worker [ERROR] \u2192 Retry\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#performance-analysis","title":"Performance Analysis","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#identifying-bottlenecks","title":"Identifying Bottlenecks","text":"<pre><code># Query Jaeger for slow traces\n# UI Filter: duration &gt; 1000ms\n\n# Analyze trace:\n# Trace: create_loan [2500ms] \u2190 SLOW\n# \u251c\u2500 POST /api/loans [2500ms]\n# \u2502  \u251c\u2500 validate_user [50ms]\n# \u2502  \u251c\u2500 credit_check [2300ms] \u2190 BOTTLENECK\n# \u2502  \u2502  \u2514\u2500 POST /credit-score [2250ms] \u2190 External API slow\n# \u2502  \u2514\u2500 save_loan [100ms]\n\n# Solution: Add caching for credit scores\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    with tracer.start_as_current_span(\"credit_check\") as span:\n        # Check cache first\n        cached_score = await redis.get(f\"credit:{loan.user_id}\")\n\n        if cached_score:\n            span.add_event(\"credit_score_cache_hit\")\n            credit_score = int(cached_score)\n        else:\n            # Call external API only if not cached\n            credit_score = await credit_api.get_score(loan.user_id)\n            await redis.setex(f\"credit:{loan.user_id}\", 3600, credit_score)\n            span.add_event(\"credit_score_cache_miss\")\n\n        span.set_attribute(\"credit.score\", credit_score)\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#comparing-traces","title":"Comparing Traces","text":"<pre><code># Before optimization:\n# Trace: process_loan_batch [5000ms]\n# \u2514\u2500 for each loan [5000ms total]\n#    \u251c\u2500 get_loan [100ms] \u00d7 50 = 5000ms\n\n# After optimization (parallel processing):\n# Trace: process_loan_batch [500ms]\n# \u2514\u2500 asyncio.gather [500ms]\n#    \u2514\u2500 get_loan [100ms] \u00d7 50 (parallel)\n\n@app.post(\"/api/loans/batch\")\nasync def process_loan_batch(loan_ids: list[str]):\n    \"\"\"Process loans in parallel.\"\"\"\n    with tracer.start_as_current_span(\"process_batch\") as span:\n        span.set_attribute(\"batch.size\", len(loan_ids))\n\n        # Parallel processing\n        results = await asyncio.gather(\n            *[process_loan(loan_id) for loan_id in loan_ids]\n        )\n\n        span.add_event(\"batch_completed\")\n        return results\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#trace-sampling","title":"Trace Sampling","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#adaptive-sampling","title":"Adaptive Sampling","text":"<pre><code>from opentelemetry.sdk.trace.sampling import (\n    ParentBasedTraceIdRatio,\n    TraceIdRatioBased\n)\n\n# CORRECT: Sample 10% in production, 100% for errors\nclass ErrorAwareSampler:\n    \"\"\"Sample all errors, 10% of successes.\"\"\"\n\n    def __init__(self):\n        self.default_sampler = TraceIdRatioBased(0.1)\n\n    def should_sample(self, context, trace_id, name, kind, attributes, links):\n        # Always sample if error occurred\n        if attributes.get(\"http.status_code\", 0) &gt;= 500:\n            return trace.SamplingResult(\n                decision=trace.SamplingDecision.RECORD_AND_SAMPLE\n            )\n\n        # Otherwise use default sampling\n        return self.default_sampler.should_sample(\n            context, trace_id, name, kind, attributes, links\n        )\n\n\nprovider = TracerProvider(\n    sampler=ErrorAwareSampler(),\n    resource=resource\n)\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#sampling-by-endpoint","title":"Sampling by Endpoint","text":"<pre><code># CORRECT: Sample critical endpoints 100%, others 10%\ndef custom_sampler(context, trace_id, name, kind, attributes):\n    \"\"\"Sample based on endpoint importance.\"\"\"\n    endpoint = attributes.get(\"http.route\", \"\")\n\n    # Critical endpoints: 100%\n    if endpoint in [\"/api/payments\", \"/api/loans/approve\"]:\n        return trace.SamplingResult(\n            decision=trace.SamplingDecision.RECORD_AND_SAMPLE\n        )\n\n    # Other endpoints: 10%\n    return TraceIdRatioBased(0.1).should_sample(\n        context, trace_id, name, kind, attributes, None\n    )\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/tracing/distributed-tracing/#do-add-business-context","title":"DO: Add Business Context","text":"<pre><code># CORRECT: Add meaningful business attributes\nwith tracer.start_as_current_span(\"process_loan\") as span:\n    span.set_attribute(\"loan.id\", loan_id)\n    span.set_attribute(\"loan.amount\", loan.amount)\n    span.set_attribute(\"loan.status\", \"pending\")\n    span.set_attribute(\"user.id\", user_id)\n    span.set_attribute(\"user.tier\", \"premium\")\n    span.add_event(\"credit_check_passed\", {\"score\": 750})\n\n\n# INCORRECT: Missing context\nwith tracer.start_as_current_span(\"process\"):  # \u274c Generic name\n    result = do_something()  # \u274c No attributes\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#do-propagate-context-everywhere","title":"DO: Propagate Context Everywhere","text":"<pre><code># CORRECT: Propagate in all inter-service calls\nheaders = {}\ninject(headers)  # Always inject before calling another service\n\nresponse = await client.get(url, headers=headers)\n\n\n# INCORRECT: Missing propagation\nresponse = await client.get(url)  # \u274c New trace started, no linking\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#dont-create-excessive-spans","title":"DON'T: Create Excessive Spans","text":"<pre><code># INCORRECT: Too granular\nfor item in items:\n    with tracer.start_as_current_span(f\"process_item_{item.id}\"):\n        process(item)  # \u274c 10000 spans for batch\n\n\n# CORRECT: Appropriate granularity\nwith tracer.start_as_current_span(\"process_items\") as span:\n    span.set_attribute(\"item.count\", len(items))\n    for item in items:\n        process(item)  # \u2705 Single span for batch\n</code></pre>"},{"location":"atomic/observability/tracing/distributed-tracing/#checklist","title":"Checklist","text":"<ul> <li> Instrument all HTTP client calls with trace context propagation</li> <li> Propagate trace context in RabbitMQ message headers</li> <li> Extract trace context in event consumers</li> <li> Add custom spans for business logic</li> <li> Record exceptions in spans with full context</li> <li> Add business attributes to spans (IDs, amounts, statuses)</li> <li> Add events for important milestones</li> <li> Configure sampling for production (10-20%)</li> <li> Test trace visualization in Jaeger UI</li> <li> Verify cross-service trace linking</li> <li> Analyze slow traces to identify bottlenecks</li> <li> Monitor trace sampling rate</li> </ul>"},{"location":"atomic/observability/tracing/distributed-tracing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code> \u2014 OpenTelemetry configuration</li> <li><code>docs/atomic/observability/tracing/trace-correlation.md</code> \u2014 Cross-service correlation</li> <li><code>docs/atomic/observability/tracing/jaeger-configuration.md</code> \u2014 Jaeger backend setup</li> <li><code>docs/atomic/observability/tracing/performance-monitoring.md</code> \u2014 Performance analysis</li> </ul>"},{"location":"atomic/observability/tracing/jaeger-configuration/","title":"Jaeger Configuration","text":"<p>Configure Jaeger backend for production-grade distributed tracing storage, querying, and visualization. Jaeger provides the complete tracing infrastructure: collectors for receiving spans from applications, storage backends for persisting traces, query API for retrieving traces, and UI for visual trace analysis.</p> <p>This document covers Jaeger architecture (collector, query, ingester), storage backends (Elasticsearch, Cassandra, in-memory), Docker deployment configurations, collector tuning for high throughput, retention policies, sampling strategies, and query optimization. Proper Jaeger configuration ensures reliable trace collection and fast query performance at scale.</p> <p>Jaeger backend must handle thousands of spans per second, store traces for days/weeks, and enable sub-second queries across millions of traces. Without proper configuration, Jaeger becomes a bottleneck: dropped spans due to overloaded collectors, slow queries from inadequate storage, or excessive infrastructure costs from retention misconfiguration.</p>"},{"location":"atomic/observability/tracing/jaeger-configuration/#jaeger-architecture","title":"Jaeger Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Application \u2502\n\u2502  (OTLP)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 gRPC/HTTP\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Collector  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Storage    \u2502\n\u2502              \u2502     \u2502 (ES/Cassandra)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Query API  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Jaeger UI  \u2502\n\u2502              \u2502     \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#docker-compose-setup","title":"Docker Compose Setup","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#all-in-one-development","title":"All-in-One (Development)","text":"<pre><code># docker-compose.jaeger.yml\nversion: '3.8'\n\nservices:\n  jaeger:\n    image: jaegertracing/all-in-one:1.52\n    container_name: jaeger\n    ports:\n      - \"16686:16686\"  # Jaeger UI\n      - \"4317:4317\"    # OTLP gRPC collector\n      - \"4318:4318\"    # OTLP HTTP collector\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n      - SPAN_STORAGE_TYPE=memory\n      - MEMORY_MAX_TRACES=10000\n    restart: unless-stopped\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#production-with-elasticsearch","title":"Production with Elasticsearch","text":"<pre><code># docker-compose.jaeger-prod.yml\nversion: '3.8'\n\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms2g -Xmx2g\"\n      - xpack.security.enabled=false\n    ports:\n      - \"9200:9200\"\n    volumes:\n      - elasticsearch_data:/usr/share/elasticsearch/data\n\n  jaeger-collector:\n    image: jaegertracing/jaeger-collector:1.52\n    environment:\n      - SPAN_STORAGE_TYPE=elasticsearch\n      - ES_SERVER_URLS=http://elasticsearch:9200\n      - ES_NUM_SHARDS=3\n      - ES_NUM_REPLICAS=1\n      - COLLECTOR_OTLP_ENABLED=true\n      - COLLECTOR_ZIPKIN_HOST_PORT=:9411\n      - COLLECTOR_QUEUE_SIZE=10000\n      - COLLECTOR_NUM_WORKERS=100\n    ports:\n      - \"4317:4317\"  # OTLP gRPC\n      - \"4318:4318\"  # OTLP HTTP\n      - \"9411:9411\"  # Zipkin compatible\n    depends_on:\n      - elasticsearch\n\n  jaeger-query:\n    image: jaegertracing/jaeger-query:1.52\n    environment:\n      - SPAN_STORAGE_TYPE=elasticsearch\n      - ES_SERVER_URLS=http://elasticsearch:9200\n      - QUERY_BASE_PATH=/jaeger\n    ports:\n      - \"16686:16686\"\n    depends_on:\n      - elasticsearch\n\n  jaeger-ingester:\n    image: jaegertracing/jaeger-ingester:1.52\n    environment:\n      - SPAN_STORAGE_TYPE=elasticsearch\n      - ES_SERVER_URLS=http://elasticsearch:9200\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  elasticsearch_data:\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#storage-backends","title":"Storage Backends","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#in-memory-development-only","title":"In-Memory (Development Only)","text":"<pre><code># jaeger-all-in-one with in-memory storage\nenvironment:\n  - SPAN_STORAGE_TYPE=memory\n  - MEMORY_MAX_TRACES=10000  # Keep last 10k traces\n\n# Pros: Fast, simple, no external dependencies\n# Cons: Data lost on restart, limited capacity\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#elasticsearch-recommended-for-production","title":"Elasticsearch (Recommended for Production)","text":"<pre><code># jaeger-collector with Elasticsearch\nenvironment:\n  - SPAN_STORAGE_TYPE=elasticsearch\n  - ES_SERVER_URLS=http://elasticsearch:9200\n  - ES_INDEX_PREFIX=jaeger\n  - ES_NUM_SHARDS=3\n  - ES_NUM_REPLICAS=1\n  - ES_BULK_SIZE=5000000       # 5MB bulk size\n  - ES_BULK_WORKERS=10\n  - ES_BULK_FLUSH_INTERVAL=1s\n\n# Pros: Production-ready, scalable, fast queries, JSON storage\n# Cons: Requires ES cluster, higher resource usage\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#cassandra-alternative-for-production","title":"Cassandra (Alternative for Production)","text":"<pre><code># jaeger-collector with Cassandra\nenvironment:\n  - SPAN_STORAGE_TYPE=cassandra\n  - CASSANDRA_SERVERS=cassandra:9042\n  - CASSANDRA_KEYSPACE=jaeger_v1_dc1\n  - CASSANDRA_LOCAL_DC=dc1\n  - CASSANDRA_CONSISTENCY=LOCAL_QUORUM\n\n# Pros: High write throughput, distributed, resilient\n# Cons: Complex setup, slower queries than ES\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#collector-configuration","title":"Collector Configuration","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#high-throughput-settings","title":"High-Throughput Settings","text":"<pre><code># jaeger-collector optimized for high load\nenvironment:\n  # Queue settings\n  - COLLECTOR_QUEUE_SIZE=10000        # Span queue size\n  - COLLECTOR_NUM_WORKERS=100          # Concurrent workers\n\n  # Batch processing\n  - ES_BULK_SIZE=5000000              # 5MB batches\n  - ES_BULK_WORKERS=10                 # Parallel bulk indexing\n  - ES_BULK_FLUSH_INTERVAL=1s          # Flush every second\n\n  # Protocol support\n  - COLLECTOR_OTLP_ENABLED=true\n  - COLLECTOR_ZIPKIN_HOST_PORT=:9411\n\n  # Health check\n  - COLLECTOR_HEALTH_CHECK_HTTP_PORT=14269\n\nresources:\n  limits:\n    memory: 2Gi\n    cpu: 2\n  requests:\n    memory: 1Gi\n    cpu: 1\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#sampling-configuration","title":"Sampling Configuration","text":"<pre><code># jaeger-collector with adaptive sampling\nenvironment:\n  - SAMPLING_STRATEGIES_FILE=/etc/jaeger/sampling.json\n\n# /etc/jaeger/sampling.json\n{\n  \"service_strategies\": [\n    {\n      \"service\": \"finance_lending_api\",\n      \"type\": \"probabilistic\",\n      \"param\": 0.1  # 10% sampling\n    },\n    {\n      \"service\": \"finance_lending_worker\",\n      \"type\": \"probabilistic\",\n      \"param\": 0.05  # 5% sampling (lower priority)\n    }\n  ],\n  \"default_strategy\": {\n    \"type\": \"probabilistic\",\n    \"param\": 0.001  # 0.1% for unknown services\n  }\n}\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#query-service-configuration","title":"Query Service Configuration","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#performance-tuning","title":"Performance Tuning","text":"<pre><code># jaeger-query optimized settings\nenvironment:\n  - SPAN_STORAGE_TYPE=elasticsearch\n  - ES_SERVER_URLS=http://elasticsearch:9200\n  - ES_MAX_SPAN_AGE=168h  # 7 days query window\n  - QUERY_MAX_CLOCK_SKEW_ADJUSTMENT=1s\n  - QUERY_BASE_PATH=/jaeger\n  - QUERY_STATIC_FILES=/go/jaeger-ui/\n\n  # Request limits\n  - QUERY_TIMEOUT=30s\n  - QUERY_MAX_RETRIES=3\n\nresources:\n  limits:\n    memory: 1Gi\n    cpu: 1\n  requests:\n    memory: 512Mi\n    cpu: 500m\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#ui-configuration","title":"UI Configuration","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#custom-branding","title":"Custom Branding","text":"<pre><code># jaeger-query with custom UI config\nvolumes:\n  - ./jaeger-ui-config.json:/etc/jaeger/jaeger-ui-config.json:ro\n\nenvironment:\n  - QUERY_UI_CONFIG=/etc/jaeger/jaeger-ui-config.json\n</code></pre> <pre><code>// jaeger-ui-config.json\n{\n  \"monitor\": {\n    \"menuEnabled\": true\n  },\n  \"dependencies\": {\n    \"menuEnabled\": true\n  },\n  \"archiveEnabled\": true,\n  \"tracking\": {\n    \"gaID\": \"UA-000000-1\"\n  },\n  \"linkPatterns\": [\n    {\n      \"type\": \"logs\",\n      \"key\": \"trace_id\",\n      \"url\": \"https://kibana.example.com/app/kibana#/discover?_a=(query:(query_string:(query:'trace_id:#{trace_id}')))\",\n      \"text\": \"View Logs in Kibana\"\n    },\n    {\n      \"type\": \"metrics\",\n      \"key\": \"service\",\n      \"url\": \"https://grafana.example.com/d/service?var-service=#{service}\",\n      \"text\": \"View Metrics in Grafana\"\n    }\n  ]\n}\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#retention-policies","title":"Retention Policies","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#elasticsearch-index-lifecycle","title":"Elasticsearch Index Lifecycle","text":"<pre><code># Create ILM policy for Jaeger indices\ncurl -X PUT \"http://elasticsearch:9200/_ilm/policy/jaeger-ilm-policy\" -H 'Content-Type: application/json' -d'\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_size\": \"50GB\",\n            \"max_age\": \"1d\"\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"3d\",\n        \"actions\": {\n          \"allocate\": {\n            \"number_of_replicas\": 0\n          },\n          \"forcemerge\": {\n            \"max_num_segments\": 1\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"7d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n'\n\n# Apply policy to Jaeger indices\ncurl -X PUT \"http://elasticsearch:9200/jaeger-*/_settings\" -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"lifecycle\": {\n      \"name\": \"jaeger-ilm-policy\"\n    }\n  }\n}\n'\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#manual-cleanup-script","title":"Manual Cleanup Script","text":"<pre><code>#!/bin/bash\n# cleanup_old_traces.sh\n\n# Delete traces older than 7 days\nCUTOFF_DATE=$(date -d '7 days ago' +%Y-%m-%d)\n\ncurl -X DELETE \"http://elasticsearch:9200/jaeger-span-${CUTOFF_DATE}\"\ncurl -X DELETE \"http://elasticsearch:9200/jaeger-service-${CUTOFF_DATE}\"\n\necho \"Deleted indices older than ${CUTOFF_DATE}\"\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#monitoring-jaeger","title":"Monitoring Jaeger","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#collector-metrics","title":"Collector Metrics","text":"<pre><code># Expose Prometheus metrics\nenvironment:\n  - METRICS_BACKEND=prometheus\n  - METRICS_HTTP_ROUTE=/metrics\n\n# Scrape with Prometheus\nscrape_configs:\n  - job_name: 'jaeger-collector'\n    static_configs:\n      - targets: ['jaeger-collector:14269']\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#key-metrics","title":"Key Metrics","text":"<pre><code># Spans received per second\nrate(jaeger_collector_spans_received_total[5m])\n\n# Spans dropped (queue full)\nrate(jaeger_collector_spans_dropped_total[5m])\n\n# Queue size\njaeger_collector_queue_length\n\n# Batch processing latency\nhistogram_quantile(0.95, jaeger_collector_save_latency_bucket)\n\n# Storage write errors\nrate(jaeger_collector_spans_storage_errors_total[5m])\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#alerting-rules","title":"Alerting Rules","text":"<pre><code># prometheus/alerts/jaeger.yml\ngroups:\n  - name: jaeger\n    rules:\n      - alert: JaegerCollectorDroppedSpans\n        expr: rate(jaeger_collector_spans_dropped_total[5m]) &gt; 100\n        for: 5m\n        annotations:\n          summary: \"Jaeger dropping spans - queue overloaded\"\n\n      - alert: JaegerCollectorHighLatency\n        expr: histogram_quantile(0.95, rate(jaeger_collector_save_latency_bucket[5m])) &gt; 1\n        for: 5m\n        annotations:\n          summary: \"Jaeger storage latency high - check Elasticsearch\"\n\n      - alert: JaegerCollectorStorageErrors\n        expr: rate(jaeger_collector_spans_storage_errors_total[5m]) &gt; 10\n        for: 2m\n        annotations:\n          summary: \"Jaeger storage errors - check Elasticsearch health\"\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#do-use-elasticsearch-for-production","title":"DO: Use Elasticsearch for Production","text":"<pre><code># CORRECT: Production setup with Elasticsearch\nservices:\n  jaeger-collector:\n    environment:\n      - SPAN_STORAGE_TYPE=elasticsearch\n      - ES_SERVER_URLS=http://elasticsearch:9200\n      - ES_NUM_REPLICAS=1  # Replication for durability\n\n  elasticsearch:\n    deploy:\n      replicas: 3  # ES cluster for availability\n\n\n# INCORRECT: In-memory storage in production\nservices:\n  jaeger:\n    environment:\n      - SPAN_STORAGE_TYPE=memory  # \u274c Data loss on restart\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#do-configure-retention-policies","title":"DO: Configure Retention Policies","text":"<pre><code># CORRECT: Automatic trace deletion after 7 days\nenvironment:\n  - ES_INDEX_DATE_SEPARATOR=-\n  - ES_CREATE_INDEX_TEMPLATES=true\n\n# ILM policy deletes old indices automatically\n\n\n# INCORRECT: No retention policy\n# \u274c Elasticsearch fills up, queries slow down, costs increase\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#do-monitor-collector-health","title":"DO: Monitor Collector Health","text":"<pre><code># CORRECT: Expose metrics and health checks\nenvironment:\n  - METRICS_BACKEND=prometheus\n  - COLLECTOR_HEALTH_CHECK_HTTP_PORT=14269\n\nhealthcheck:\n  test: [\"CMD\", \"wget\", \"-q\", \"--spider\", \"http://localhost:14269/\"]\n  interval: 30s\n  timeout: 10s\n  retries: 3\n\n\n# INCORRECT: No health checks\n# \u274c Can't detect collector failures\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#dont-use-default-queue-sizes-for-production","title":"DON'T: Use Default Queue Sizes for Production","text":"<pre><code># INCORRECT: Default queue size (too small)\nenvironment:\n  # Defaults: COLLECTOR_QUEUE_SIZE=2000\n  # \u274c Spans dropped under load\n\n\n# CORRECT: Tuned for high throughput\nenvironment:\n  - COLLECTOR_QUEUE_SIZE=10000      # \u2705 Larger queue\n  - COLLECTOR_NUM_WORKERS=100        # \u2705 More workers\n  - ES_BULK_SIZE=5000000             # \u2705 Larger batches\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"atomic/observability/tracing/jaeger-configuration/#helm-chart","title":"Helm Chart","text":"<pre><code># Add Jaeger Helm repository\nhelm repo add jaegertracing https://jaegertracing.github.io/helm-charts\n\n# Install Jaeger with Elasticsearch\nhelm install jaeger jaegertracing/jaeger \\\n  --set provisionDataStore.cassandra=false \\\n  --set provisionDataStore.elasticsearch=true \\\n  --set storage.type=elasticsearch \\\n  --set storage.elasticsearch.host=elasticsearch \\\n  --set storage.elasticsearch.port=9200 \\\n  --set collector.service.otlp.grpc.port=4317 \\\n  --set collector.autoscaling.enabled=true \\\n  --set collector.autoscaling.minReplicas=3 \\\n  --set collector.autoscaling.maxReplicas=10\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#custom-values","title":"Custom Values","text":"<pre><code># values.yaml\ncollector:\n  resources:\n    limits:\n      memory: 2Gi\n      cpu: 2\n    requests:\n      memory: 1Gi\n      cpu: 1\n\n  autoscaling:\n    enabled: true\n    minReplicas: 3\n    maxReplicas: 10\n    targetCPUUtilizationPercentage: 80\n\n  env:\n    - name: COLLECTOR_QUEUE_SIZE\n      value: \"10000\"\n    - name: COLLECTOR_NUM_WORKERS\n      value: \"100\"\n\nquery:\n  resources:\n    limits:\n      memory: 1Gi\n      cpu: 1\n\nstorage:\n  type: elasticsearch\n  elasticsearch:\n    host: elasticsearch-master\n    port: 9200\n    scheme: http\n    indexPrefix: jaeger\n</code></pre>"},{"location":"atomic/observability/tracing/jaeger-configuration/#checklist","title":"Checklist","text":"<ul> <li> Deploy Jaeger collector with OTLP support</li> <li> Configure Elasticsearch storage backend</li> <li> Set up retention policies (7-30 days)</li> <li> Tune collector queue and worker settings</li> <li> Configure sampling strategies per service</li> <li> Deploy Jaeger query service</li> <li> Expose Jaeger UI</li> <li> Add Kibana/Grafana links to UI</li> <li> Set up Prometheus scraping for Jaeger metrics</li> <li> Configure alerting for dropped spans and storage errors</li> <li> Test trace ingestion and query performance</li> <li> Document Jaeger URLs for team</li> </ul>"},{"location":"atomic/observability/tracing/jaeger-configuration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code> \u2014 OpenTelemetry SDK configuration</li> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing patterns</li> <li><code>docs/atomic/observability/tracing/trace-correlation.md</code> \u2014 Linking traces to logs/metrics</li> <li><code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> \u2014 Elasticsearch configuration</li> </ul>"},{"location":"atomic/observability/tracing/opentelemetry-setup/","title":"OpenTelemetry Setup","text":"<p>Configure OpenTelemetry for distributed tracing, enabling end-to-end request tracking across microservices. OpenTelemetry provides vendor-neutral instrumentation for collecting traces, metrics, and logs, with automatic instrumentation for popular frameworks like FastAPI, making distributed systems observable.</p> <p>This document covers OpenTelemetry SDK installation, automatic instrumentation for FastAPI/Aiogram/AsyncIO services, OTLP exporter configuration for Jaeger/Zipkin backends, context propagation patterns, span attributes and events, and performance considerations. OpenTelemetry is the CNCF standard for observability instrumentation.</p> <p>Distributed tracing answers critical questions: Why is this request slow? Which service is the bottleneck? How do requests flow through the system? What caused this error? Without tracing, debugging distributed systems requires manually correlating timestamps across logs\u2014an impossible task when requests traverse dozens of services.</p>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#installation","title":"Installation","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#core-dependencies","title":"Core Dependencies","text":"<pre><code># Install OpenTelemetry SDK and instrumentation\npip install opentelemetry-api==1.22.0\npip install opentelemetry-sdk==1.22.0\npip install opentelemetry-instrumentation-fastapi==0.43b0\npip install opentelemetry-instrumentation-httpx==0.43b0\npip install opentelemetry-instrumentation-sqlalchemy==0.43b0\npip install opentelemetry-instrumentation-redis==0.43b0\npip install opentelemetry-exporter-otlp==1.22.0\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#jaeger-exporter-alternative","title":"Jaeger Exporter (Alternative)","text":"<pre><code># Use OTLP exporter (recommended) or Jaeger-specific exporter\npip install opentelemetry-exporter-jaeger==1.22.0\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#basic-configuration","title":"Basic Configuration","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code># src/core/tracing.py\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\n\ndef configure_tracing(service_name: str) -&gt; None:\n    \"\"\"Configure OpenTelemetry tracing.\"\"\"\n    # Create resource with service name\n    resource = Resource(attributes={\n        SERVICE_NAME: service_name,\n        \"environment\": \"production\",\n        \"version\": \"1.2.3\"\n    })\n\n    # Create tracer provider\n    provider = TracerProvider(resource=resource)\n    trace.set_tracer_provider(provider)\n\n    # Configure OTLP exporter (Jaeger/Zipkin)\n    otlp_exporter = OTLPSpanExporter(\n        endpoint=\"http://jaeger:4317\",  # OTLP gRPC endpoint\n        insecure=True\n    )\n\n    # Add batch processor for performance\n    span_processor = BatchSpanProcessor(otlp_exporter)\n    provider.add_span_processor(span_processor)\n\n\n# src/main.py\nfrom fastapi import FastAPI\nfrom src.core.tracing import configure_tracing\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\n\n# Configure tracing before app creation\nconfigure_tracing(\"finance_lending_api\")\n\napp = FastAPI()\n\n# Instrument FastAPI automatically\nFastAPIInstrumentor.instrument_app(app)\n\n\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Endpoint automatically traced by OpenTelemetry.\"\"\"\n    return {\"loans\": []}\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#automatic-instrumentation","title":"Automatic Instrumentation","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#http-requests-httpx","title":"HTTP Requests (HTTPX)","text":"<pre><code>from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor\nimport httpx\n\n# Instrument HTTPX for outgoing HTTP requests\nHTTPXClientInstrumentor().instrument()\n\n# All HTTP requests are automatically traced\nasync with httpx.AsyncClient() as client:\n    response = await client.get(\"http://data-api:8000/api/users\")\n    # Span automatically created with HTTP method, URL, status code\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#database-queries-sqlalchemy","title":"Database Queries (SQLAlchemy)","text":"<pre><code>from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor\nfrom sqlalchemy.ext.asyncio import create_async_engine\n\n# Instrument SQLAlchemy for database tracing\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@localhost/db\")\nSQLAlchemyInstrumentor().instrument(engine=engine)\n\n# All database queries are automatically traced\nasync with engine.begin() as conn:\n    result = await conn.execute(\"SELECT * FROM loans\")\n    # Span automatically created with SQL query and duration\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#redis-operations","title":"Redis Operations","text":"<pre><code>from opentelemetry.instrumentation.redis import RedisInstrumentor\nimport redis.asyncio as redis\n\n# Instrument Redis for cache tracing\nRedisInstrumentor().instrument()\n\n# All Redis operations are automatically traced\nredis_client = redis.Redis(host=\"redis\", port=6379)\nawait redis_client.get(\"user:123\")\n# Span automatically created with Redis command and key\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#manual-instrumentation","title":"Manual Instrumentation","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#creating-custom-spans","title":"Creating Custom Spans","text":"<pre><code>from opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\n\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    \"\"\"Create loan with custom tracing.\"\"\"\n    # Automatic span from FastAPI instrumentation\n\n    # Add custom span for business logic\n    with tracer.start_as_current_span(\"process_loan_application\") as span:\n        # Add attributes to span\n        span.set_attribute(\"loan.amount\", loan.amount)\n        span.set_attribute(\"loan.purpose\", loan.purpose)\n        span.set_attribute(\"user.id\", loan.user_id)\n\n        try:\n            # Perform credit check (creates child span)\n            with tracer.start_as_current_span(\"credit_check\") as credit_span:\n                credit_score = await check_credit(loan.user_id)\n                credit_span.set_attribute(\"credit.score\", credit_score)\n\n            # Approve or reject loan\n            if credit_score &gt; 700:\n                span.set_attribute(\"loan.status\", \"approved\")\n                span.add_event(\"loan_approved\", {\"reason\": \"good_credit\"})\n                return {\"status\": \"approved\"}\n            else:\n                span.set_attribute(\"loan.status\", \"rejected\")\n                span.add_event(\"loan_rejected\", {\"reason\": \"low_credit\"})\n                return {\"status\": \"rejected\"}\n\n        except Exception as e:\n            # Record exception in span\n            span.record_exception(e)\n            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n            raise\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#span-attributes","title":"Span Attributes","text":"<pre><code># CORRECT: Add meaningful attributes\nspan.set_attribute(\"http.method\", \"POST\")\nspan.set_attribute(\"http.url\", \"/api/loans\")\nspan.set_attribute(\"http.status_code\", 201)\nspan.set_attribute(\"user.id\", \"user-123\")\nspan.set_attribute(\"loan.id\", \"loan-456\")\nspan.set_attribute(\"loan.amount\", 50000)\nspan.set_attribute(\"db.system\", \"postgresql\")\nspan.set_attribute(\"db.operation\", \"INSERT\")\n\n\n# INCORRECT: Don't add sensitive data or high cardinality\nspan.set_attribute(\"user.password\", \"secret\")  # \u274c Sensitive data\nspan.set_attribute(\"request.body\", json.dumps(body))  # \u274c Large data\nspan.set_attribute(\"timestamp\", time.time())  # \u274c High cardinality\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#span-events","title":"Span Events","text":"<pre><code># Add events to mark important moments in span\nspan.add_event(\"credit_check_started\")\n\nspan.add_event(\"credit_check_completed\", {\n    \"score\": 750,\n    \"duration_ms\": 145\n})\n\nspan.add_event(\"notification_sent\", {\n    \"type\": \"email\",\n    \"recipient\": \"user@example.com\"\n})\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#context-propagation","title":"Context Propagation","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#http-headers-propagation","title":"HTTP Headers Propagation","text":"<pre><code>from opentelemetry.propagate import inject\nimport httpx\n\n# CORRECT: Propagate trace context in HTTP headers\nasync def call_data_api(user_id: str) -&gt; dict:\n    \"\"\"Call another service with trace context.\"\"\"\n    headers = {}\n\n    # Inject trace context into headers\n    inject(headers)\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"http://data-api:8000/api/users/{user_id}\",\n            headers=headers  # Trace context propagated\n        )\n\n    return response.json()\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#rabbitmq-message-propagation","title":"RabbitMQ Message Propagation","text":"<pre><code>from opentelemetry.propagate import inject, extract\nimport aio_pika\n\n# Producer: Inject trace context into message headers\nasync def publish_loan_event(loan_id: str):\n    \"\"\"Publish event with trace context.\"\"\"\n    headers = {}\n    inject(headers)  # Inject trace context\n\n    message = aio_pika.Message(\n        body=json.dumps({\"loan_id\": loan_id}).encode(),\n        headers=headers  # Trace context in message headers\n    )\n\n    await channel.default_exchange.publish(message, routing_key=\"loans\")\n\n\n# Consumer: Extract trace context from message headers\nasync def consume_loan_event(message: aio_pika.IncomingMessage):\n    \"\"\"Process event with trace context.\"\"\"\n    # Extract trace context from message headers\n    context = extract(message.headers)\n\n    # Start new span with extracted context as parent\n    with tracer.start_as_current_span(\n        \"process_loan_event\",\n        context=context  # Link to parent trace\n    ) as span:\n        loan_id = json.loads(message.body.decode())[\"loan_id\"]\n        span.set_attribute(\"loan.id\", loan_id)\n\n        # Process event (traced as child span)\n        await process_loan(loan_id)\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#aiogram-bot-tracing","title":"Aiogram Bot Tracing","text":"<pre><code># src/bot/main.py\nfrom opentelemetry import trace\nfrom aiogram import Bot, Dispatcher, types\n\ntracer = trace.get_tracer(__name__)\n\n# Configure tracing\nconfigure_tracing(\"finance_lending_bot\")\n\n\n@dp.message_handler(commands=[\"start\"])\nasync def cmd_start(message: types.Message):\n    \"\"\"Handle /start command with tracing.\"\"\"\n    with tracer.start_as_current_span(\"handle_start_command\") as span:\n        span.set_attribute(\"user.id\", message.from_user.id)\n        span.set_attribute(\"command\", \"start\")\n\n        # Call API (automatically traced if HTTPX instrumented)\n        user = await get_user(message.from_user.id)\n\n        await message.reply(f\"Welcome, {user['name']}!\")\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#background-worker-tracing","title":"Background Worker Tracing","text":"<pre><code># src/worker/tasks.py\nfrom opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\n# Configure tracing\nconfigure_tracing(\"finance_lending_worker\")\n\n\nasync def process_loan_approval(loan_id: str):\n    \"\"\"Process loan approval with tracing.\"\"\"\n    with tracer.start_as_current_span(\"process_loan_approval\") as span:\n        span.set_attribute(\"loan.id\", loan_id)\n\n        # Fetch loan data (creates child span)\n        loan = await get_loan(loan_id)\n\n        # Perform credit check (creates child span)\n        credit_score = await check_credit(loan[\"user_id\"])\n        span.set_attribute(\"credit.score\", credit_score)\n\n        # Update loan status (creates child span)\n        await update_loan_status(loan_id, \"approved\")\n\n        span.add_event(\"loan_processing_completed\")\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#docker-configuration","title":"Docker Configuration","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#jaeger-backend","title":"Jaeger Backend","text":"<pre><code># docker-compose.tracing.yml\nversion: '3.8'\n\nservices:\n  jaeger:\n    image: jaegertracing/all-in-one:1.52\n    ports:\n      - \"16686:16686\"  # Jaeger UI\n      - \"4317:4317\"    # OTLP gRPC receiver\n      - \"4318:4318\"    # OTLP HTTP receiver\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#service-configuration","title":"Service Configuration","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  api:\n    image: finance_lending_api:latest\n    environment:\n      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317\n      - OTEL_SERVICE_NAME=finance_lending_api\n      - OTEL_TRACES_SAMPLER=parentbased_traceidratio\n      - OTEL_TRACES_SAMPLER_ARG=1.0  # 100% sampling (development)\n    depends_on:\n      - jaeger\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#sampling-configuration","title":"Sampling Configuration","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#production-sampling","title":"Production Sampling","text":"<pre><code>from opentelemetry.sdk.trace.sampling import TraceIdRatioBased\n\n# CORRECT: Sample 10% of traces in production\nprovider = TracerProvider(\n    sampler=TraceIdRatioBased(0.1),  # 10% sampling\n    resource=resource\n)\n\n\n# INCORRECT: 100% sampling in production (high overhead)\nprovider = TracerProvider(\n    sampler=TraceIdRatioBased(1.0),  # \u274c 100% sampling\n    resource=resource\n)\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#parent-based-sampling","title":"Parent-Based Sampling","text":"<pre><code>from opentelemetry.sdk.trace.sampling import ParentBasedTraceIdRatio\n\n# CORRECT: Sample based on parent decision\nprovider = TracerProvider(\n    sampler=ParentBasedTraceIdRatio(0.1),\n    resource=resource\n)\n# If parent sampled, child sampled; otherwise follow ratio\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#performance-considerations","title":"Performance Considerations","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#batch-export","title":"Batch Export","text":"<pre><code># CORRECT: Batch span export for performance\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nspan_processor = BatchSpanProcessor(\n    otlp_exporter,\n    max_queue_size=2048,\n    schedule_delay_millis=5000,  # 5 seconds\n    max_export_batch_size=512\n)\n\n\n# INCORRECT: Immediate export (high latency)\nfrom opentelemetry.sdk.trace.export import SimpleSpanProcessor\n\nspan_processor = SimpleSpanProcessor(otlp_exporter)  # \u274c Blocks on export\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#resource-limits","title":"Resource Limits","text":"<pre><code># CORRECT: Limit span attributes and events\nspan.set_attribute(\"request.headers\", headers[:100])  # \u2705 Truncate large data\n\n# INCORRECT: Unlimited data\nspan.set_attribute(\"request.body\", json.dumps(body))  # \u274c Can be megabytes\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/tracing/opentelemetry-setup/#do-use-semantic-conventions","title":"DO: Use Semantic Conventions","text":"<pre><code># CORRECT: Use OpenTelemetry semantic conventions\nfrom opentelemetry.semconv.trace import SpanAttributes\n\nspan.set_attribute(SpanAttributes.HTTP_METHOD, \"POST\")\nspan.set_attribute(SpanAttributes.HTTP_URL, \"/api/loans\")\nspan.set_attribute(SpanAttributes.HTTP_STATUS_CODE, 201)\nspan.set_attribute(SpanAttributes.DB_SYSTEM, \"postgresql\")\nspan.set_attribute(SpanAttributes.DB_STATEMENT, \"SELECT * FROM loans\")\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#do-record-exceptions","title":"DO: Record Exceptions","text":"<pre><code># CORRECT: Record exceptions in spans\ntry:\n    result = await perform_operation()\nexcept Exception as e:\n    span.record_exception(e)\n    span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n    raise\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#dont-create-too-many-spans","title":"DON'T: Create Too Many Spans","text":"<pre><code># INCORRECT: Excessive span creation (performance overhead)\nfor i in range(10000):\n    with tracer.start_as_current_span(f\"iteration_{i}\"):  # \u274c 10k spans\n        process_item(i)\n\n\n# CORRECT: Batch operations\nwith tracer.start_as_current_span(\"process_items\") as span:\n    span.set_attribute(\"item.count\", 10000)\n    for i in range(10000):\n        process_item(i)  # \u2705 Single span for batch\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#environment-variables","title":"Environment Variables","text":"<pre><code># OpenTelemetry environment variables\nexport OTEL_SERVICE_NAME=\"finance_lending_api\"\nexport OTEL_EXPORTER_OTLP_ENDPOINT=\"http://jaeger:4317\"\nexport OTEL_EXPORTER_OTLP_PROTOCOL=\"grpc\"\nexport OTEL_TRACES_SAMPLER=\"parentbased_traceidratio\"\nexport OTEL_TRACES_SAMPLER_ARG=\"0.1\"  # 10% sampling\nexport OTEL_RESOURCE_ATTRIBUTES=\"environment=production,version=1.2.3\"\n</code></pre>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#checklist","title":"Checklist","text":"<ul> <li> Install OpenTelemetry SDK and instrumentation libraries</li> <li> Configure tracer provider with service name and resource</li> <li> Set up OTLP exporter for Jaeger/Zipkin</li> <li> Instrument FastAPI with automatic instrumentation</li> <li> Instrument HTTPX for HTTP client tracing</li> <li> Instrument SQLAlchemy for database tracing</li> <li> Instrument Redis for cache tracing</li> <li> Add custom spans for business logic</li> <li> Propagate trace context in HTTP headers</li> <li> Propagate trace context in RabbitMQ messages</li> <li> Configure sampling for production (10-20%)</li> <li> Use batch span processor for performance</li> <li> Follow OpenTelemetry semantic conventions</li> <li> Test trace collection in Jaeger UI</li> </ul>"},{"location":"atomic/observability/tracing/opentelemetry-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing patterns</li> <li><code>docs/atomic/observability/tracing/trace-correlation.md</code> \u2014 Cross-service trace correlation</li> <li><code>docs/atomic/observability/tracing/jaeger-configuration.md</code> \u2014 Jaeger setup and configuration</li> <li><code>docs/atomic/observability/tracing/performance-monitoring.md</code> \u2014 Performance analysis with tracing</li> </ul>"},{"location":"atomic/observability/tracing/performance-monitoring/","title":"Performance Monitoring with Tracing","text":"<p>Leverage distributed tracing to identify performance bottlenecks, optimize slow endpoints, detect inefficient database queries, and improve overall system throughput. Tracing provides visibility into request execution time distribution across services, enabling data-driven performance optimization.</p> <p>This document covers performance analysis workflows using Jaeger, identifying N+1 query problems, detecting sequential vs parallel execution issues, finding caching opportunities, analyzing database query performance, measuring service dependency latency, and establishing performance baselines with SLOs. Tracing transforms performance optimization from guesswork into science.</p> <p>Without tracing, performance issues are mysteries: users complain about slowness, but you don't know if it's the API, database, external service, or network. With tracing, you see exactly where time is spent: \"95% of request time is waiting for external credit API\" leads directly to caching solution.</p>"},{"location":"atomic/observability/tracing/performance-monitoring/#performance-analysis-workflow","title":"Performance Analysis Workflow","text":""},{"location":"atomic/observability/tracing/performance-monitoring/#step-1-identify-slow-endpoints","title":"Step 1: Identify Slow Endpoints","text":"<pre><code># Query Jaeger for P95 latency by endpoint\n# Filter: service=finance_lending_api duration&gt;1s\n# Sort by: duration desc\n\n# Results show:\n# POST /api/loans           [2.5s avg] \u2190 SLOW\n# GET /api/loans/:id/details [1.8s avg] \u2190 SLOW\n# GET /api/loans            [0.2s avg] \u2190 FAST\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#step-2-analyze-trace-waterfall","title":"Step 2: Analyze Trace Waterfall","text":"<pre><code>Trace: POST /api/loans [2500ms]\n\u251c\u2500 validate_user [50ms]\n\u2502  \u2514\u2500 GET /api/users/:id [45ms]\n\u251c\u2500 credit_check [2300ms] \u2190 BOTTLENECK (92% of total time)\n\u2502  \u2514\u2500 POST /external-credit-api [2250ms] \u2190 External API slow\n\u251c\u2500 save_loan [100ms]\n\u2502  \u2514\u2500 INSERT INTO loans [85ms]\n\u2514\u2500 publish_event [20ms]\n\nDIAGNOSIS: External API is the bottleneck\nSOLUTION: Add caching + timeout + circuit breaker\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#step-3-implement-optimization","title":"Step 3: Implement Optimization","text":"<pre><code># Before: Always call external API (2250ms)\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    with tracer.start_as_current_span(\"credit_check\") as span:\n        credit_score = await credit_api.get_score(loan.user_id)  # 2250ms\n        span.set_attribute(\"credit.score\", credit_score)\n\n\n# After: Cache credit scores (45ms cache hit, 2250ms cache miss)\n@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate):\n    with tracer.start_as_current_span(\"credit_check\") as span:\n        # Check Redis cache first\n        cached_score = await redis.get(f\"credit:{loan.user_id}\")\n\n        if cached_score:\n            span.add_event(\"cache_hit\")\n            credit_score = int(cached_score)\n            # 45ms (Redis latency)\n        else:\n            span.add_event(\"cache_miss\")\n            credit_score = await credit_api.get_score(loan.user_id)  # 2250ms\n            await redis.setex(f\"credit:{loan.user_id}\", 3600, credit_score)\n\n        span.set_attribute(\"credit.score\", credit_score)\n\n\n# Result: 90% cache hit rate \u2192 avg latency 250ms (was 2500ms)\n# Improvement: 10x faster\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#step-4-verify-improvement","title":"Step 4: Verify Improvement","text":"<pre><code># Query Jaeger after optimization\n# Filter: service=finance_lending_api operation=POST /api/loans\n# Time range: Last 1 hour\n\n# Before:  P50=2.0s P95=2.5s P99=3.0s\n# After:   P50=0.2s P95=0.5s P99=2.5s (cache misses)\n\n# Cache hit rate from metrics\nrate(cache_operations_total{result=\"hit\"}[1h]) / rate(cache_operations_total[1h])\n# Result: 0.90 (90% hit rate)\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#common-performance-issues","title":"Common Performance Issues","text":""},{"location":"atomic/observability/tracing/performance-monitoring/#n1-query-problem","title":"N+1 Query Problem","text":"<pre><code># PROBLEM: N+1 queries (1 + N database roundtrips)\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Fetch loans with N+1 query anti-pattern.\"\"\"\n    with tracer.start_as_current_span(\"get_loans\") as span:\n        # Query 1: Fetch all loans\n        loans = await db.execute(\"SELECT * FROM loans\")  # 50ms\n\n        # Query N: Fetch user for each loan (N separate queries)\n        for loan in loans:  # 100 loans\n            with tracer.start_as_current_span(\"get_user\") as user_span:\n                user = await db.execute(\n                    \"SELECT * FROM users WHERE id = ?\", loan.user_id\n                )  # 10ms \u00d7 100 = 1000ms\n                loan.user = user\n\n        span.set_attribute(\"loan.count\", len(loans))\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [1050ms]\n# \u251c\u2500 SELECT * FROM loans [50ms]\n# \u251c\u2500 SELECT * FROM users [10ms] \u2190 Repeated 100 times\n# \u251c\u2500 SELECT * FROM users [10ms]\n# \u251c\u2500 SELECT * FROM users [10ms]\n# ... (97 more identical spans)\n# \u2514\u2500 SELECT * FROM users [10ms]\n\n# DIAGNOSIS: 100 separate database queries for users\n# SOLUTION: Use JOIN or batch query\n</code></pre> <pre><code># SOLUTION 1: SQL JOIN (single query)\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Fetch loans with JOIN (optimized).\"\"\"\n    with tracer.start_as_current_span(\"get_loans\") as span:\n        loans = await db.execute(\"\"\"\n            SELECT loans.*, users.*\n            FROM loans\n            JOIN users ON loans.user_id = users.id\n        \"\"\")  # 60ms (single query)\n\n        span.set_attribute(\"loan.count\", len(loans))\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [60ms]  \u2190 17x faster\n# \u2514\u2500 SELECT loans JOIN users [60ms]\n\n# Improvement: 1050ms \u2192 60ms\n</code></pre> <pre><code># SOLUTION 2: Batch query (when JOIN not possible)\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Fetch loans with batch user query.\"\"\"\n    with tracer.start_as_current_span(\"get_loans\") as span:\n        # Query 1: Fetch loans\n        loans = await db.execute(\"SELECT * FROM loans\")  # 50ms\n\n        # Query 2: Batch fetch all users\n        user_ids = [loan.user_id for loan in loans]\n        users = await db.execute(\n            \"SELECT * FROM users WHERE id IN (?)\",\n            user_ids\n        )  # 25ms (single query for all users)\n\n        # Map users to loans\n        user_map = {user.id: user for user in users}\n        for loan in loans:\n            loan.user = user_map[loan.user_id]\n\n        span.set_attribute(\"loan.count\", len(loans))\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [75ms]  \u2190 14x faster\n# \u251c\u2500 SELECT * FROM loans [50ms]\n# \u2514\u2500 SELECT * FROM users WHERE id IN (...) [25ms]\n\n# Improvement: 1050ms \u2192 75ms\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#sequential-vs-parallel-execution","title":"Sequential vs Parallel Execution","text":"<pre><code># PROBLEM: Sequential external calls (300ms total)\n@app.get(\"/api/loans/{loan_id}/details\")\nasync def get_loan_details(loan_id: str):\n    \"\"\"Fetch loan details sequentially.\"\"\"\n    with tracer.start_as_current_span(\"get_loan_details\") as span:\n        # Sequential calls\n        loan = await get_loan(loan_id)         # 100ms\n        user = await get_user(loan.user_id)    # 100ms\n        documents = await get_documents(loan_id)  # 100ms\n\n        span.set_attribute(\"loan.id\", loan_id)\n        return {\"loan\": loan, \"user\": user, \"documents\": documents}\n\n\n# Trace shows:\n# GET /api/loans/:id/details [300ms]\n# \u251c\u2500 get_loan [100ms]\n# \u251c\u2500 get_user [100ms]  \u2190 Wait for get_loan to finish\n# \u2514\u2500 get_documents [100ms]  \u2190 Wait for get_user to finish\n\n# DIAGNOSIS: Calls are independent but executed sequentially\n# SOLUTION: Parallel execution with asyncio.gather\n</code></pre> <pre><code># SOLUTION: Parallel execution (100ms total)\n@app.get(\"/api/loans/{loan_id}/details\")\nasync def get_loan_details(loan_id: str):\n    \"\"\"Fetch loan details in parallel.\"\"\"\n    with tracer.start_as_current_span(\"get_loan_details\") as span:\n        # Parallel calls (all 3 start simultaneously)\n        loan, user, documents = await asyncio.gather(\n            get_loan(loan_id),\n            get_user_by_loan(loan_id),  # Can start before loan completes\n            get_documents(loan_id)\n        )\n\n        span.set_attribute(\"loan.id\", loan_id)\n        return {\"loan\": loan, \"user\": user, \"documents\": documents}\n\n\n# Trace shows:\n# GET /api/loans/:id/details [100ms]  \u2190 3x faster\n# \u251c\u2500 get_loan [100ms]\n# \u251c\u2500 get_user [100ms]  \u2190 Runs in parallel with get_loan\n# \u2514\u2500 get_documents [100ms]  \u2190 Runs in parallel with both\n\n# Improvement: 300ms \u2192 100ms\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#inefficient-database-queries","title":"Inefficient Database Queries","text":"<pre><code># PROBLEM: Missing database index (500ms query)\n@app.get(\"/api/loans\")\nasync def get_loans(user_id: str):\n    \"\"\"Fetch loans by user (slow without index).\"\"\"\n    with tracer.start_as_current_span(\"get_loans_by_user\") as span:\n        loans = await db.execute(\n            \"SELECT * FROM loans WHERE user_id = ?\",\n            user_id\n        )  # 500ms (full table scan)\n\n        span.set_attribute(\"user.id\", user_id)\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [500ms]\n# \u2514\u2500 SELECT * FROM loans WHERE user_id = ? [500ms]\n\n# Jaeger span attributes show:\n# db.statement: SELECT * FROM loans WHERE user_id = ?\n# db.rows_examined: 1000000 \u2190 Full table scan!\n# db.rows_returned: 10\n\n# DIAGNOSIS: No index on user_id column\n# SOLUTION: Add database index\n</code></pre> <pre><code>-- SOLUTION: Create index on user_id\nCREATE INDEX idx_loans_user_id ON loans(user_id);\n</code></pre> <pre><code># After adding index:\n# Trace shows:\n# GET /api/loans [15ms]  \u2190 33x faster\n# \u2514\u2500 SELECT * FROM loans WHERE user_id = ? [15ms]\n\n# Span attributes show:\n# db.rows_examined: 10 \u2190 Index used, no full scan\n# db.rows_returned: 10\n\n# Improvement: 500ms \u2192 15ms\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#excessive-data-transfer","title":"Excessive Data Transfer","text":"<pre><code># PROBLEM: Fetching too much data (2000ms)\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Fetch all loan data including large documents.\"\"\"\n    with tracer.start_as_current_span(\"get_loans\") as span:\n        loans = await db.execute(\"\"\"\n            SELECT loans.*, documents.content\n            FROM loans\n            JOIN documents ON loans.id = documents.loan_id\n        \"\"\")  # 2000ms (documents.content is large BLOB)\n\n        span.set_attribute(\"loan.count\", len(loans))\n        span.set_attribute(\"response.size_bytes\", len(json.dumps(loans)))\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [2000ms]\n# \u2514\u2500 SELECT loans, documents.content [2000ms]\n\n# Span attributes show:\n# response.size_bytes: 50000000 (50MB response)\n\n# DIAGNOSIS: Returning large document content unnecessarily\n# SOLUTION: Return only required fields\n</code></pre> <pre><code># SOLUTION: Select only needed columns (150ms)\n@app.get(\"/api/loans\")\nasync def get_loans():\n    \"\"\"Fetch only required loan fields.\"\"\"\n    with tracer.start_as_current_span(\"get_loans\") as span:\n        loans = await db.execute(\"\"\"\n            SELECT loans.id, loans.amount, loans.status, loans.user_id\n            FROM loans\n        \"\"\")  # 150ms (no large BLOBs)\n\n        span.set_attribute(\"loan.count\", len(loans))\n        span.set_attribute(\"response.size_bytes\", len(json.dumps(loans)))\n        return loans\n\n\n# Trace shows:\n# GET /api/loans [150ms]  \u2190 13x faster\n# \u2514\u2500 SELECT loans.id, loans.amount, loans.status [150ms]\n\n# Span attributes show:\n# response.size_bytes: 50000 (50KB response)\n\n# Improvement: 2000ms \u2192 150ms, 50MB \u2192 50KB\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#performance-baseline-and-slos","title":"Performance Baseline and SLOs","text":""},{"location":"atomic/observability/tracing/performance-monitoring/#establishing-baseline","title":"Establishing Baseline","text":"<pre><code># Query Jaeger for current performance (baseline)\n# Time range: Last 7 days\n# Service: finance_lending_api\n\n# Results:\n# POST /api/loans:\n#   P50: 200ms\n#   P95: 500ms\n#   P99: 1000ms\n\n# GET /api/loans/:id:\n#   P50: 50ms\n#   P95: 100ms\n#   P99: 200ms\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#defining-slos","title":"Defining SLOs","text":"<pre><code># SLO definition based on baseline\nslos:\n  - service: finance_lending_api\n    endpoint: POST /api/loans\n    slo_target:\n      p95_latency_ms: 500  # 95% of requests &lt; 500ms\n      availability: 99.9   # 99.9% success rate\n\n  - service: finance_lending_api\n    endpoint: GET /api/loans/:id\n    slo_target:\n      p95_latency_ms: 100\n      availability: 99.95\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#slo-monitoring","title":"SLO Monitoring","text":"<pre><code># Query: Is POST /api/loans meeting SLO?\n# Target: P95 &lt; 500ms\n\nhistogram_quantile(0.95,\n  rate(http_request_duration_seconds_bucket{\n    service=\"finance_lending_api\",\n    endpoint=\"/api/loans\"\n  }[1h])\n) &lt; 0.5  # 0.5 seconds = 500ms\n\n# If result = 1: SLO met\n# If result = 0: SLO violated (investigate slow traces)\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#jaeger-query-patterns","title":"Jaeger Query Patterns","text":""},{"location":"atomic/observability/tracing/performance-monitoring/#find-slowest-traces","title":"Find Slowest Traces","text":"<pre><code># Jaeger UI search:\nService: finance_lending_api\nOperation: POST /api/loans\nMin Duration: 1s\nLimit: 100\n\n# Returns: Top 100 slowest traces\n# Click trace \u2192 See waterfall \u2192 Identify bottleneck\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#find-traces-with-errors","title":"Find Traces with Errors","text":"<pre><code># Jaeger UI search:\nService: finance_lending_api\nTags: error=true\nLimit: 100\n\n# Returns: All traces with errors\n# Analyze error patterns (same endpoint? same user?)\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#compare-beforeafter-optimization","title":"Compare Before/After Optimization","text":"<pre><code># Query 1: Before optimization (baseline)\nService: finance_lending_api\nLookback: 1d\nTime Range: 2024-01-10 00:00 - 2024-01-10 23:59\n\n# Result: P95 = 2500ms\n\n# Query 2: After optimization\nService: finance_lending_api\nLookback: 1d\nTime Range: 2024-01-11 00:00 - 2024-01-11 23:59\n\n# Result: P95 = 250ms\n\n# Improvement: 10x faster\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#best-practices","title":"Best Practices","text":""},{"location":"atomic/observability/tracing/performance-monitoring/#do-add-span-attributes-for-analysis","title":"DO: Add Span Attributes for Analysis","text":"<pre><code># CORRECT: Rich span attributes enable analysis\nwith tracer.start_as_current_span(\"database_query\") as span:\n    span.set_attribute(\"db.statement\", \"SELECT * FROM loans WHERE user_id = ?\")\n    span.set_attribute(\"db.rows_examined\", 1000000)\n    span.set_attribute(\"db.rows_returned\", 10)\n    span.set_attribute(\"db.index_used\", False)  # \u2190 Key insight\n\n    result = await db.execute(query)\n\n\n# INCORRECT: No attributes (can't analyze)\nwith tracer.start_as_current_span(\"database_query\"):  # \u274c No attributes\n    result = await db.execute(query)\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#do-measure-before-and-after","title":"DO: Measure Before and After","text":"<pre><code># CORRECT: Baseline \u2192 Optimize \u2192 Measure improvement\n# 1. Query Jaeger for baseline P95\n# 2. Implement optimization\n# 3. Query Jaeger for new P95\n# 4. Calculate improvement %\n\nbaseline_p95 = 2500  # ms\noptimized_p95 = 250  # ms\nimprovement = (baseline_p95 - optimized_p95) / baseline_p95 * 100\n# Result: 90% improvement\n\n\n# INCORRECT: Optimize without measuring\n# \u274c Don't know if optimization worked\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#dont-ignore-cache-miss-performance","title":"DON'T: Ignore Cache Miss Performance","text":"<pre><code># INCORRECT: Only optimizing cache hits\n# Cache hit: 45ms (fast)\n# Cache miss: 2250ms (still slow) \u2190 Ignored\n\n# Users with cache misses still suffer\n\n\n# CORRECT: Optimize both paths\n# Cache hit: 45ms (fast)\n# Cache miss: 350ms (added timeout + circuit breaker + fallback)\n\n# All users experience acceptable performance\n</code></pre>"},{"location":"atomic/observability/tracing/performance-monitoring/#checklist","title":"Checklist","text":"<ul> <li> Query Jaeger for P95/P99 latency by endpoint</li> <li> Identify endpoints violating SLOs</li> <li> Analyze slow trace waterfalls in Jaeger</li> <li> Detect N+1 query patterns (many identical child spans)</li> <li> Find sequential calls that can be parallelized</li> <li> Check for missing database indexes (high rows_examined)</li> <li> Identify excessive data transfer (large response sizes)</li> <li> Implement caching for frequently accessed data</li> <li> Add timeouts to external service calls</li> <li> Measure performance before and after optimizations</li> <li> Update SLOs based on achievable performance</li> <li> Create alerts for SLO violations</li> </ul>"},{"location":"atomic/observability/tracing/performance-monitoring/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code> \u2014 OpenTelemetry instrumentation</li> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing patterns</li> <li><code>docs/atomic/observability/tracing/jaeger-configuration.md</code> \u2014 Jaeger backend setup</li> <li><code>docs/atomic/observability/metrics/golden-signals.md</code> \u2014 Latency SLOs</li> </ul>"},{"location":"atomic/observability/tracing/trace-correlation/","title":"Trace Correlation","text":"<p>Correlate traces with logs and metrics to achieve unified observability across distributed systems. Trace correlation enables jumping from a slow trace to related logs, linking error logs to traces for root cause analysis, and correlating performance metrics with specific requests, creating a complete operational picture.</p> <p>This document covers correlation ID propagation patterns, linking traces to structured logs, associating metrics with trace context, unified observability dashboards in Grafana, debugging workflows that leverage all three signals (traces/logs/metrics), and exemplar-based correlation. Correlation transforms isolated observability signals into a cohesive narrative.</p> <p>Without correlation, engineers waste hours jumping between tools: finding a slow trace in Jaeger, manually searching for request IDs in Kibana logs, then checking Grafana metrics for the same timeframe. With correlation, you click a trace span \u2192 see related logs \u2192 view associated metrics \u2192 identify root cause in seconds, not hours.</p>"},{"location":"atomic/observability/tracing/trace-correlation/#correlation-ids","title":"Correlation IDs","text":""},{"location":"atomic/observability/tracing/trace-correlation/#request-id-propagation","title":"Request ID Propagation","text":"<pre><code># src/middleware/correlation.py\nfrom opentelemetry import trace\nimport structlog\nimport uuid\n\n@app.middleware(\"http\")\nasync def correlation_middleware(request: Request, call_next):\n    \"\"\"Propagate correlation IDs across all signals.\"\"\"\n    # Get or generate request ID\n    request_id = request.headers.get(\"X-Request-ID\")\n    if not request_id:\n        request_id = f\"req-{uuid.uuid4()}\"\n\n    # Get trace context\n    span = trace.get_current_span()\n    trace_id = format(span.get_span_context().trace_id, '032x')\n    span_id = format(span.get_span_context().span_id, '016x')\n\n    # Bind all IDs to logger\n    logger = structlog.get_logger().bind(\n        request_id=request_id,\n        trace_id=trace_id,\n        span_id=span_id,\n        service=\"finance_lending_api\"\n    )\n\n    # Add IDs to span attributes\n    span.set_attribute(\"request.id\", request_id)\n\n    # Store in request state\n    request.state.request_id = request_id\n    request.state.trace_id = trace_id\n    request.state.span_id = span_id\n    request.state.logger = logger\n\n    # Log request with all IDs\n    logger.info(\n        \"http_request_started\",\n        method=request.method,\n        path=request.url.path\n    )\n\n    response = await call_next(request)\n\n    # Add IDs to response headers\n    response.headers[\"X-Request-ID\"] = request_id\n    response.headers[\"X-Trace-ID\"] = trace_id\n\n    logger.info(\n        \"http_request_completed\",\n        status_code=response.status_code,\n        duration_ms=compute_duration()\n    )\n\n    return response\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#correlation-in-logs","title":"Correlation in Logs","text":"<pre><code># Result: Every log has request_id, trace_id, span_id\n{\n    \"timestamp\": \"2024-01-10T10:30:45.123Z\",\n    \"level\": \"info\",\n    \"event\": \"http_request_started\",\n    \"service\": \"finance_lending_api\",\n    \"request_id\": \"req-abc-123\",\n    \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n    \"span_id\": \"00f067aa0ba902b7\",\n    \"method\": \"POST\",\n    \"path\": \"/api/loans\"\n}\n\n# Query logs by trace ID:\n# Kibana: trace_id:\"4bf92f3577b34da6a3ce929d0e0e4736\"\n# Shows all logs from all services in this trace\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#trace-to-log-correlation","title":"Trace to Log Correlation","text":""},{"location":"atomic/observability/tracing/trace-correlation/#link-trace-spans-to-logs","title":"Link Trace Spans to Logs","text":"<pre><code>@app.post(\"/api/loans\")\nasync def create_loan(loan: LoanCreate, request: Request):\n    \"\"\"Create loan with correlated logs.\"\"\"\n    logger = request.state.logger\n\n    with tracer.start_as_current_span(\"create_loan\") as span:\n        span.set_attribute(\"loan.amount\", loan.amount)\n        span.set_attribute(\"user.id\", loan.user_id)\n\n        # Log with trace context\n        logger.info(\n            \"loan_creation_started\",\n            loan_amount=loan.amount,\n            user_id=loan.user_id\n        )\n\n        try:\n            # Check credit\n            with tracer.start_as_current_span(\"credit_check\") as credit_span:\n                credit_score = await check_credit(loan.user_id)\n\n                # Log result with span context\n                logger.info(\n                    \"credit_check_completed\",\n                    credit_score=credit_score,\n                    span_name=credit_span.name\n                )\n\n                if credit_score &lt; 650:\n                    logger.warning(\n                        \"loan_rejected_low_credit\",\n                        credit_score=credit_score,\n                        threshold=650\n                    )\n                    span.set_attribute(\"loan.status\", \"rejected\")\n                    raise HTTPException(\n                        status_code=400,\n                        detail=\"Insufficient credit score\"\n                    )\n\n            # Save loan\n            loan_record = await db.create_loan(loan)\n\n            logger.info(\n                \"loan_created\",\n                loan_id=loan_record.id,\n                status=\"approved\"\n            )\n\n            return {\"id\": loan_record.id}\n\n        except Exception as e:\n            logger.error(\n                \"loan_creation_failed\",\n                error=str(e),\n                error_type=type(e).__name__\n            )\n            span.record_exception(e)\n            raise\n\n\n# Result: Click trace span in Jaeger \u2192 copy trace_id \u2192 paste in Kibana\n# Instantly see all logs from this request across all services\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#jaeger-to-kibana-integration","title":"Jaeger to Kibana Integration","text":"<pre><code># Jaeger UI configuration\njaeger:\n  query:\n    base-path: /\n    ui-config: |\n      {\n        \"linkPatterns\": [\n          {\n            \"type\": \"logs\",\n            \"key\": \"trace_id\",\n            \"url\": \"https://kibana.example.com/app/kibana#/discover?_a=(query:(query_string:(query:'trace_id:#{trace_id}')))\",\n            \"text\": \"View Logs in Kibana\"\n          }\n        ]\n      }\n\n# Result: \"View Logs\" button in Jaeger UI opens Kibana with trace logs\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#trace-to-metrics-correlation","title":"Trace to Metrics Correlation","text":""},{"location":"atomic/observability/tracing/trace-correlation/#exemplars-prometheus-grafana","title":"Exemplars (Prometheus + Grafana)","text":"<pre><code>from prometheus_client import Histogram\nfrom opentelemetry import trace\n\n# Create histogram with exemplar support\nrequest_duration = Histogram(\n    'http_request_duration_seconds',\n    'Request duration',\n    ['method', 'endpoint'],\n    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]\n)\n\n\n@app.middleware(\"http\")\nasync def metrics_with_exemplars(request: Request, call_next):\n    \"\"\"Record metrics with trace exemplars.\"\"\"\n    start_time = time.time()\n\n    response = await call_next(request)\n\n    duration = time.time() - start_time\n\n    # Get trace context for exemplar\n    span = trace.get_current_span()\n    trace_id = format(span.get_span_context().trace_id, '032x')\n\n    # Record metric with exemplar (trace ID)\n    request_duration.labels(\n        method=request.method,\n        endpoint=request.url.path\n    ).observe(\n        duration,\n        exemplar={'trace_id': trace_id}  # Link to trace\n    )\n\n    return response\n\n\n# Result: Grafana shows high latency spike \u2192 click spike \u2192 see trace ID\n# Click \"View Trace\" \u2192 opens Jaeger with exact slow request\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#metrics-dashboard-with-trace-links","title":"Metrics Dashboard with Trace Links","text":"<pre><code># Grafana dashboard with trace links\npanels:\n  - title: \"Request Latency (P95)\"\n    targets:\n      - expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n    options:\n      dataLinks:\n        - title: \"View Traces\"\n          url: \"https://jaeger.example.com/search?service=${__field.labels.service}&amp;start=${__from}&amp;end=${__to}\"\n\n  - title: \"Error Rate\"\n    targets:\n      - expr: rate(http_requests_total{status_code=~\"5..\"}[5m])\n    options:\n      dataLinks:\n        - title: \"View Error Traces\"\n          url: \"https://jaeger.example.com/search?service=${__field.labels.service}&amp;tags={\\\"error\\\":\\\"true\\\"}\"\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#unified-observability-dashboard","title":"Unified Observability Dashboard","text":""},{"location":"atomic/observability/tracing/trace-correlation/#grafana-unified-view","title":"Grafana Unified View","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Finance Lending API - Unified Observability\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\"expr\": \"rate(http_requests_total[5m])\"}\n        ],\n        \"dataLinks\": [\n          {\n            \"title\": \"View Traces\",\n            \"url\": \"https://jaeger.example.com/search?service=finance_lending_api&amp;start=${__from}&amp;end=${__to}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Logs (Last 100)\",\n        \"type\": \"logs\",\n        \"targets\": [\n          {\n            \"query\": \"level:error AND service:finance_lending_api\",\n            \"datasource\": \"Elasticsearch\"\n          }\n        ],\n        \"options\": {\n          \"showTime\": true,\n          \"showLabels\": true\n        }\n      },\n      {\n        \"title\": \"Slow Traces (&gt; 1s)\",\n        \"type\": \"table\",\n        \"targets\": [\n          {\n            \"datasource\": \"Jaeger\",\n            \"query\": \"service=finance_lending_api duration&gt;1s\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#debugging-workflows","title":"Debugging Workflows","text":""},{"location":"atomic/observability/tracing/trace-correlation/#scenario-1-high-latency-investigation","title":"Scenario 1: High Latency Investigation","text":"<pre><code># Step 1: Grafana shows P95 latency spike at 10:30 AM\n# Query: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n# Result: P95 = 2.5 seconds (normally 200ms)\n\n# Step 2: Click exemplar \u2192 opens Jaeger with trace ID\n# Trace: POST /api/loans [2500ms]\n# \u251c\u2500 credit_check [2300ms] \u2190 BOTTLENECK\n# \u2502  \u2514\u2500 POST /credit-score [2250ms]\n\n# Step 3: Copy trace_id from Jaeger \u2192 search in Kibana\n# Kibana query: trace_id:\"4bf92f3577b34da6a3ce929d0e0e4736\"\n# Logs show:\n{\n    \"event\": \"credit_check_timeout\",\n    \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n    \"error\": \"External API timeout after 2000ms\",\n    \"upstream_service\": \"credit_bureau_api\"\n}\n\n# Root cause identified: External API timeout\n# Solution: Add timeout + circuit breaker + caching\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#scenario-2-error-rate-investigation","title":"Scenario 2: Error Rate Investigation","text":"<pre><code># Step 1: Grafana shows error rate spike\n# Query: rate(http_requests_total{status_code=~\"5..\"}[5m])\n# Result: 50 errors/sec (normally 0)\n\n# Step 2: Click \"View Error Traces\" \u2192 Jaeger filtered by error=true\n# Multiple traces show:\n# POST /api/loans [ERROR 500]\n# \u2514\u2500 database_query [ERROR] \"Connection pool exhausted\"\n\n# Step 3: Search logs by trace_id in Kibana\n# Logs reveal:\n{\n    \"event\": \"database_connection_failed\",\n    \"error\": \"FATAL: remaining connection slots reserved\",\n    \"active_connections\": 100,\n    \"max_connections\": 100\n}\n\n# Root cause: Database connection pool exhaustion\n# Solution: Increase pool size, add connection timeout\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#scenario-3-user-reported-issue","title":"Scenario 3: User-Reported Issue","text":"<pre><code># User reports: \"My loan application failed\"\n\n# Step 1: Get request_id from user's screenshot/email\n# request_id: \"req-abc-123\"\n\n# Step 2: Search logs in Kibana\n# Query: request_id:\"req-abc-123\"\n# Logs show:\n{\n    \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n    \"event\": \"loan_creation_failed\",\n    \"error\": \"User verification failed\",\n    \"user_id\": \"user-456\"\n}\n\n# Step 3: Open trace in Jaeger\n# URL: https://jaeger/trace/4bf92f3577b34da6a3ce929d0e0e4736\n# Trace shows:\n# POST /api/loans [500ms]\n# \u2514\u2500 verify_user [ERROR 404]\n#    \u2514\u2500 GET /api/users/456 [ERROR 404] \"User not found\"\n\n# Step 4: Check user service metrics in Grafana\n# Query: rate(http_requests_total{service=\"data_api\",endpoint=\"/api/users/:id\",status_code=\"404\"}[1h])\n# Result: 404 rate spiked at 9:00 AM (during user migration)\n\n# Root cause: User not migrated to new database\n# Solution: Complete user migration, sync user data\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#correlation-best-practices","title":"Correlation Best Practices","text":""},{"location":"atomic/observability/tracing/trace-correlation/#do-always-propagate-ids","title":"DO: Always Propagate IDs","text":"<pre><code># CORRECT: Propagate request_id, trace_id everywhere\nheaders = {\n    \"X-Request-ID\": request_id,\n    \"X-Trace-ID\": trace_id\n}\ninject(headers)  # OpenTelemetry trace context\n\nasync with httpx.AsyncClient() as client:\n    await client.post(url, headers=headers)\n\n# Publish to RabbitMQ\nmessage = aio_pika.Message(\n    body=body,\n    headers={\n        \"request_id\": request_id,\n        \"trace_id\": trace_id\n    }\n)\n\n\n# INCORRECT: Missing correlation IDs\nawait client.post(url)  # \u274c No request_id, no trace_id\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#do-include-ids-in-all-logs","title":"DO: Include IDs in All Logs","text":"<pre><code># CORRECT: Bind IDs to logger\nlogger = structlog.get_logger().bind(\n    request_id=request_id,\n    trace_id=trace_id,\n    span_id=span_id,\n    service=\"finance_lending_api\"\n)\n\nlogger.info(\"operation_completed\", result=\"success\")\n\n\n# INCORRECT: Missing IDs\nlogger.info(\"operation completed\")  # \u274c Can't correlate\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#do-add-trace-links-to-dashboards","title":"DO: Add Trace Links to Dashboards","text":"<pre><code># CORRECT: Enable click-through from metrics to traces\npanels:\n  - title: \"Error Rate\"\n    dataLinks:\n      - title: \"View Error Traces\"\n        url: \"https://jaeger/search?tags={\\\"error\\\":\\\"true\\\"}&amp;start=${__from}\"\n\n\n# INCORRECT: No navigation between tools\n# Users manually copy timestamps and search\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#dont-use-different-id-formats","title":"DON'T: Use Different ID Formats","text":"<pre><code># INCORRECT: Inconsistent ID formats\napi_service:    request_id = \"req-abc-123\"\ndata_service:   request_id = \"ABC123\"      # \u274c Different format\nworker_service: request_id = \"req_abc_123\" # \u274c Underscore vs hyphen\n\n\n# CORRECT: Consistent format across all services\nrequest_id = f\"req-{uuid.uuid4()}\"  # \u2705 Always \"req-{uuid}\"\n</code></pre>"},{"location":"atomic/observability/tracing/trace-correlation/#implementation-checklist","title":"Implementation Checklist","text":"<ul> <li> Add correlation middleware to all services</li> <li> Generate or extract request_id in API gateway/first service</li> <li> Propagate request_id in all HTTP headers (X-Request-ID)</li> <li> Propagate trace context with OpenTelemetry (traceparent header)</li> <li> Include request_id in all RabbitMQ message headers</li> <li> Bind request_id, trace_id, span_id to structured logger</li> <li> Add trace_id to all log entries</li> <li> Return request_id in API responses (X-Request-ID header)</li> <li> Configure Jaeger \u2192 Kibana integration (link patterns)</li> <li> Add exemplars to Prometheus metrics</li> <li> Configure Grafana \u2192 Jaeger integration (data links)</li> <li> Create unified observability dashboard</li> <li> Document debugging workflows for common scenarios</li> <li> Test correlation: trace \u2192 logs \u2192 metrics \u2192 back to trace</li> </ul>"},{"location":"atomic/observability/tracing/trace-correlation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/tracing/opentelemetry-setup.md</code> \u2014 OpenTelemetry configuration</li> <li><code>docs/atomic/observability/tracing/distributed-tracing.md</code> \u2014 Distributed tracing patterns</li> <li><code>docs/atomic/observability/logging/structured-logging.md</code> \u2014 Structured logging</li> <li><code>docs/atomic/observability/logging/log-correlation.md</code> \u2014 Log correlation techniques</li> <li><code>docs/atomic/observability/metrics/custom-metrics.md</code> \u2014 Metrics with exemplars</li> </ul>"},{"location":"atomic/real-time/push-notifications/","title":"Push Notifications Implementation","text":"<p>Comprehensive guide for implementing push notifications across multiple platforms including FCM, APNs, web push, email, and SMS with queue management and delivery tracking.</p>"},{"location":"atomic/real-time/push-notifications/#prerequisites","title":"Prerequisites","text":"<ul> <li>FastAPI Basic Setup</li> <li>Redis Integration</li> <li>RabbitMQ Integration</li> <li>Communication APIs</li> </ul>"},{"location":"atomic/real-time/push-notifications/#core-push-notification-system","title":"Core Push Notification System","text":""},{"location":"atomic/real-time/push-notifications/#notification-service-architecture","title":"Notification Service Architecture","text":"<pre><code>from typing import Dict, List, Optional, Any, Union\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nimport asyncio\nimport json\nimport uuid\nimport logging\nfrom abc import ABC, abstractmethod\n\nlogger = logging.getLogger(__name__)\n\nclass NotificationChannel(Enum):\n    PUSH_MOBILE = \"push_mobile\"\n    PUSH_WEB = \"push_web\"\n    EMAIL = \"email\"\n    SMS = \"sms\"\n    IN_APP = \"in_app\"\n    SLACK = \"slack\"\n    WEBHOOK = \"webhook\"\n\nclass NotificationPriority(Enum):\n    LOW = \"low\"\n    NORMAL = \"normal\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\nclass NotificationStatus(Enum):\n    PENDING = \"pending\"\n    SENT = \"sent\"\n    DELIVERED = \"delivered\"\n    FAILED = \"failed\"\n    EXPIRED = \"expired\"\n    CLICKED = \"clicked\"\n\n@dataclass\nclass NotificationPayload:\n    title: str\n    body: str\n    data: Dict[str, Any] = field(default_factory=dict)\n    image_url: Optional[str] = None\n    action_url: Optional[str] = None\n    actions: List[Dict[str, str]] = field(default_factory=list)\n\n@dataclass\nclass NotificationTarget:\n    user_id: str\n    device_tokens: List[str] = field(default_factory=list)\n    email: Optional[str] = None\n    phone_number: Optional[str] = None\n    preferences: Dict[str, Any] = field(default_factory=dict)\n\n@dataclass\nclass NotificationRequest:\n    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    payload: NotificationPayload = None\n    targets: List[NotificationTarget] = field(default_factory=list)\n    channels: List[NotificationChannel] = field(default_factory=list)\n    priority: NotificationPriority = NotificationPriority.NORMAL\n    schedule_at: Optional[datetime] = None\n    expires_at: Optional[datetime] = None\n    retry_config: Dict[str, Any] = field(default_factory=dict)\n    tracking_enabled: bool = True\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n@dataclass\nclass NotificationResult:\n    notification_id: str\n    channel: NotificationChannel\n    target_id: str\n    status: NotificationStatus\n    provider_response: Optional[Dict[str, Any]] = None\n    error_message: Optional[str] = None\n    sent_at: Optional[datetime] = None\n    delivered_at: Optional[datetime] = None\n    clicked_at: Optional[datetime] = None\n\nclass NotificationProvider(ABC):\n    \"\"\"Abstract base class for notification providers\"\"\"\n\n    @abstractmethod\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send notification via this provider\"\"\"\n        pass\n\n    @abstractmethod\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate if target is valid for this provider\"\"\"\n        pass\n\nclass NotificationService:\n    \"\"\"Main notification service orchestrator\"\"\"\n\n    def __init__(self, redis_client, message_queue, db_session):\n        self.redis = redis_client\n        self.message_queue = message_queue\n        self.db_session = db_session\n        self.providers: Dict[NotificationChannel, NotificationProvider] = {}\n        self.templates = {}\n        self.user_preferences = {}\n\n    def register_provider(self, channel: NotificationChannel, provider: NotificationProvider):\n        \"\"\"Register notification provider for specific channel\"\"\"\n        self.providers[channel] = provider\n        logger.info(f\"Registered provider for {channel.value}\")\n\n    async def send_notification(self, request: NotificationRequest) -&gt; List[NotificationResult]:\n        \"\"\"Send notification through specified channels\"\"\"\n        results = []\n\n        # Validate request\n        if not request.payload or not request.targets:\n            raise ValueError(\"Notification payload and targets are required\")\n\n        # Process each target\n        for target in request.targets:\n            # Get user preferences\n            user_prefs = await self._get_user_preferences(target.user_id)\n\n            # Filter channels based on user preferences\n            allowed_channels = self._filter_channels_by_preferences(\n                request.channels, user_prefs, request.priority\n            )\n\n            # Send through each allowed channel\n            for channel in allowed_channels:\n                if channel not in self.providers:\n                    logger.warning(f\"No provider registered for {channel.value}\")\n                    continue\n\n                try:\n                    # Check if immediate send or schedule\n                    if request.schedule_at and request.schedule_at &gt; datetime.utcnow():\n                        # Schedule for later\n                        await self._schedule_notification(request, target, channel)\n                        result = NotificationResult(\n                            notification_id=request.id,\n                            channel=channel,\n                            target_id=target.user_id,\n                            status=NotificationStatus.PENDING\n                        )\n                    else:\n                        # Send immediately\n                        result = await self._send_immediate(request, target, channel)\n\n                    results.append(result)\n\n                except Exception as e:\n                    logger.error(f\"Failed to send notification via {channel.value}: {e}\")\n                    result = NotificationResult(\n                        notification_id=request.id,\n                        channel=channel,\n                        target_id=target.user_id,\n                        status=NotificationStatus.FAILED,\n                        error_message=str(e)\n                    )\n                    results.append(result)\n\n        # Store results\n        await self._store_notification_results(request, results)\n\n        return results\n\n    async def _send_immediate(\n        self,\n        request: NotificationRequest,\n        target: NotificationTarget,\n        channel: NotificationChannel\n    ) -&gt; NotificationResult:\n        \"\"\"Send notification immediately\"\"\"\n        provider = self.providers[channel]\n\n        # Validate target for this channel\n        if not await provider.validate_target(target):\n            return NotificationResult(\n                notification_id=request.id,\n                channel=channel,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=\"Invalid target for channel\"\n            )\n\n        # Send notification\n        result = await provider.send_notification(\n            request.payload,\n            target,\n            {\n                \"priority\": request.priority,\n                \"tracking_enabled\": request.tracking_enabled,\n                \"retry_config\": request.retry_config\n            }\n        )\n\n        return result\n\n    async def _schedule_notification(\n        self,\n        request: NotificationRequest,\n        target: NotificationTarget,\n        channel: NotificationChannel\n    ):\n        \"\"\"Schedule notification for later delivery\"\"\"\n        task_data = {\n            \"notification_id\": request.id,\n            \"payload\": request.payload.__dict__,\n            \"target\": target.__dict__,\n            \"channel\": channel.value,\n            \"options\": {\n                \"priority\": request.priority.value,\n                \"tracking_enabled\": request.tracking_enabled,\n                \"retry_config\": request.retry_config\n            }\n        }\n\n        # Schedule in message queue\n        await self.message_queue.schedule_task(\n            \"send_notification\",\n            task_data,\n            schedule_at=request.schedule_at\n        )\n\n    def _filter_channels_by_preferences(\n        self,\n        channels: List[NotificationChannel],\n        user_prefs: Dict[str, Any],\n        priority: NotificationPriority\n    ) -&gt; List[NotificationChannel]:\n        \"\"\"Filter channels based on user preferences\"\"\"\n        allowed_channels = []\n\n        for channel in channels:\n            channel_key = f\"allow_{channel.value}\"\n\n            # Check if user allows this channel\n            if user_prefs.get(channel_key, True):\n                allowed_channels.append(channel)\n            elif priority == NotificationPriority.CRITICAL:\n                # Critical notifications override preferences\n                allowed_channels.append(channel)\n\n        return allowed_channels\n\n    async def _get_user_preferences(self, user_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get user notification preferences\"\"\"\n        # Try cache first\n        cache_key = f\"user_prefs:{user_id}\"\n        cached_prefs = await self.redis.get(cache_key)\n\n        if cached_prefs:\n            return json.loads(cached_prefs)\n\n        # Get from database\n        # Implementation depends on your database structure\n        prefs = await self._fetch_user_preferences_from_db(user_id)\n\n        # Cache for 1 hour\n        await self.redis.setex(cache_key, 3600, json.dumps(prefs))\n\n        return prefs\n\n    async def _fetch_user_preferences_from_db(self, user_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Fetch user preferences from database\"\"\"\n        # Default preferences\n        return {\n            \"allow_push_mobile\": True,\n            \"allow_push_web\": True,\n            \"allow_email\": True,\n            \"allow_sms\": False,\n            \"allow_in_app\": True,\n            \"quiet_hours_start\": \"22:00\",\n            \"quiet_hours_end\": \"08:00\",\n            \"timezone\": \"UTC\"\n        }\n\n    async def _store_notification_results(\n        self,\n        request: NotificationRequest,\n        results: List[NotificationResult]\n    ):\n        \"\"\"Store notification results for tracking\"\"\"\n        # Store in database for analytics and tracking\n        # Implementation depends on your database structure\n        pass\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#firebase-cloud-messaging-fcm-provider","title":"Firebase Cloud Messaging (FCM) Provider","text":""},{"location":"atomic/real-time/push-notifications/#fcm-implementation","title":"FCM Implementation","text":"<pre><code>import aiohttp\nimport json\nfrom google.oauth2 import service_account\nfrom google.auth.transport.requests import Request\n\nclass FCMProvider(NotificationProvider):\n    \"\"\"Firebase Cloud Messaging provider\"\"\"\n\n    def __init__(self, service_account_file: str, project_id: str):\n        self.project_id = project_id\n        self.credentials = service_account.Credentials.from_service_account_file(\n            service_account_file,\n            scopes=['https://www.googleapis.com/auth/cloud-platform']\n        )\n        self.fcm_url = f\"https://fcm.googleapis.com/v1/projects/{project_id}/messages:send\"\n\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send FCM notification\"\"\"\n        options = options or {}\n\n        try:\n            # Get access token\n            access_token = await self._get_access_token()\n\n            # Send to each device token\n            results = []\n            for device_token in target.device_tokens:\n                result = await self._send_to_device(\n                    device_token, payload, target, access_token, options\n                )\n                results.append(result)\n\n            # Return result for the first device (or aggregate results)\n            return results[0] if results else NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_MOBILE,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=\"No device tokens\"\n            )\n\n        except Exception as e:\n            logger.error(f\"FCM send error: {e}\")\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_MOBILE,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=str(e)\n            )\n\n    async def _send_to_device(\n        self,\n        device_token: str,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        access_token: str,\n        options: Dict[str, Any]\n    ) -&gt; NotificationResult:\n        \"\"\"Send FCM message to specific device\"\"\"\n\n        # Build FCM message\n        message = {\n            \"message\": {\n                \"token\": device_token,\n                \"notification\": {\n                    \"title\": payload.title,\n                    \"body\": payload.body\n                },\n                \"data\": {\n                    **payload.data,\n                    \"click_action\": payload.action_url or \"\",\n                    \"user_id\": target.user_id\n                },\n                \"android\": {\n                    \"priority\": self._get_android_priority(options.get(\"priority\")),\n                    \"notification\": {\n                        \"channel_id\": \"default\",\n                        \"sound\": \"default\",\n                        \"click_action\": payload.action_url\n                    }\n                },\n                \"apns\": {\n                    \"payload\": {\n                        \"aps\": {\n                            \"alert\": {\n                                \"title\": payload.title,\n                                \"body\": payload.body\n                            },\n                            \"sound\": \"default\",\n                            \"badge\": 1\n                        }\n                    }\n                },\n                \"webpush\": {\n                    \"notification\": {\n                        \"title\": payload.title,\n                        \"body\": payload.body,\n                        \"icon\": payload.image_url,\n                        \"data\": payload.data\n                    }\n                }\n            }\n        }\n\n        # Add image if provided\n        if payload.image_url:\n            message[\"message\"][\"notification\"][\"image\"] = payload.image_url\n\n        # Send request\n        headers = {\n            \"Authorization\": f\"Bearer {access_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                self.fcm_url,\n                headers=headers,\n                json=message\n            ) as response:\n\n                response_data = await response.json()\n\n                if response.status == 200:\n                    return NotificationResult(\n                        notification_id=response_data.get(\"name\", \"\"),\n                        channel=NotificationChannel.PUSH_MOBILE,\n                        target_id=target.user_id,\n                        status=NotificationStatus.SENT,\n                        provider_response=response_data,\n                        sent_at=datetime.utcnow()\n                    )\n                else:\n                    error_msg = response_data.get(\"error\", {}).get(\"message\", \"Unknown error\")\n                    return NotificationResult(\n                        notification_id=\"\",\n                        channel=NotificationChannel.PUSH_MOBILE,\n                        target_id=target.user_id,\n                        status=NotificationStatus.FAILED,\n                        error_message=error_msg,\n                        provider_response=response_data\n                    )\n\n    async def _get_access_token(self) -&gt; str:\n        \"\"\"Get OAuth2 access token for FCM\"\"\"\n        # Refresh credentials if needed\n        if not self.credentials.valid:\n            self.credentials.refresh(Request())\n\n        return self.credentials.token\n\n    def _get_android_priority(self, priority: NotificationPriority) -&gt; str:\n        \"\"\"Convert priority to Android priority\"\"\"\n        if priority == NotificationPriority.CRITICAL:\n            return \"high\"\n        elif priority == NotificationPriority.HIGH:\n            return \"high\"\n        else:\n            return \"normal\"\n\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate FCM target\"\"\"\n        return bool(target.device_tokens)\n\nclass APNsProvider(NotificationProvider):\n    \"\"\"Apple Push Notification service provider\"\"\"\n\n    def __init__(self, key_file: str, key_id: str, team_id: str, bundle_id: str, production: bool = False):\n        self.key_file = key_file\n        self.key_id = key_id\n        self.team_id = team_id\n        self.bundle_id = bundle_id\n        self.apns_url = \"https://api.push.apple.com\" if production else \"https://api.development.push.apple.com\"\n\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send APNs notification\"\"\"\n        options = options or {}\n\n        try:\n            # Generate JWT token\n            jwt_token = self._generate_jwt_token()\n\n            # Build APNs payload\n            apns_payload = {\n                \"aps\": {\n                    \"alert\": {\n                        \"title\": payload.title,\n                        \"body\": payload.body\n                    },\n                    \"sound\": \"default\",\n                    \"badge\": 1\n                },\n                **payload.data\n            }\n\n            # Add category for actions\n            if payload.actions:\n                apns_payload[\"aps\"][\"category\"] = \"ACTION_CATEGORY\"\n\n            # Send to each device token\n            results = []\n            for device_token in target.device_tokens:\n                result = await self._send_to_apns_device(\n                    device_token, apns_payload, target, jwt_token, options\n                )\n                results.append(result)\n\n            return results[0] if results else NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_MOBILE,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=\"No device tokens\"\n            )\n\n        except Exception as e:\n            logger.error(f\"APNs send error: {e}\")\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_MOBILE,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=str(e)\n            )\n\n    async def _send_to_apns_device(\n        self,\n        device_token: str,\n        payload: Dict[str, Any],\n        target: NotificationTarget,\n        jwt_token: str,\n        options: Dict[str, Any]\n    ) -&gt; NotificationResult:\n        \"\"\"Send to specific APNs device\"\"\"\n\n        url = f\"{self.apns_url}/3/device/{device_token}\"\n\n        headers = {\n            \"Authorization\": f\"bearer {jwt_token}\",\n            \"apns-topic\": self.bundle_id,\n            \"apns-priority\": \"10\" if options.get(\"priority\") == NotificationPriority.HIGH else \"5\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(url, headers=headers, json=payload) as response:\n\n                if response.status == 200:\n                    apns_id = response.headers.get(\"apns-id\", \"\")\n                    return NotificationResult(\n                        notification_id=apns_id,\n                        channel=NotificationChannel.PUSH_MOBILE,\n                        target_id=target.user_id,\n                        status=NotificationStatus.SENT,\n                        sent_at=datetime.utcnow()\n                    )\n                else:\n                    error_data = await response.json() if response.content_type == 'application/json' else {}\n                    return NotificationResult(\n                        notification_id=\"\",\n                        channel=NotificationChannel.PUSH_MOBILE,\n                        target_id=target.user_id,\n                        status=NotificationStatus.FAILED,\n                        error_message=error_data.get(\"reason\", f\"HTTP {response.status}\"),\n                        provider_response=error_data\n                    )\n\n    def _generate_jwt_token(self) -&gt; str:\n        \"\"\"Generate JWT token for APNs authentication\"\"\"\n        import jwt\n        from datetime import datetime, timedelta\n\n        # Read private key\n        with open(self.key_file, 'rb') as f:\n            private_key = f.read()\n\n        # Create JWT payload\n        payload = {\n            \"iss\": self.team_id,\n            \"iat\": datetime.utcnow(),\n            \"exp\": datetime.utcnow() + timedelta(hours=1)\n        }\n\n        headers = {\n            \"alg\": \"ES256\",\n            \"kid\": self.key_id\n        }\n\n        return jwt.encode(payload, private_key, algorithm=\"ES256\", headers=headers)\n\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate APNs target\"\"\"\n        return bool(target.device_tokens)\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#web-push-provider","title":"Web Push Provider","text":""},{"location":"atomic/real-time/push-notifications/#web-push-implementation","title":"Web Push Implementation","text":"<pre><code>from pywebpush import webpush, WebPushException\n\nclass WebPushProvider(NotificationProvider):\n    \"\"\"Web Push notification provider\"\"\"\n\n    def __init__(self, vapid_private_key: str, vapid_claims: Dict[str, str]):\n        self.vapid_private_key = vapid_private_key\n        self.vapid_claims = vapid_claims  # {\"sub\": \"mailto:admin@example.com\"}\n\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send Web Push notification\"\"\"\n        options = options or {}\n\n        try:\n            # Build web push payload\n            push_payload = {\n                \"title\": payload.title,\n                \"body\": payload.body,\n                \"icon\": payload.image_url or \"/default-icon.png\",\n                \"badge\": \"/badge-icon.png\",\n                \"data\": {\n                    **payload.data,\n                    \"url\": payload.action_url\n                },\n                \"actions\": payload.actions,\n                \"requireInteraction\": options.get(\"priority\") == NotificationPriority.HIGH,\n                \"tag\": f\"notification-{target.user_id}\",\n                \"timestamp\": int(datetime.utcnow().timestamp() * 1000)\n            }\n\n            # Send to each subscription\n            results = []\n            for subscription_info in target.device_tokens:  # Web push subscriptions stored as device tokens\n                try:\n                    subscription = json.loads(subscription_info)\n                    result = await self._send_to_subscription(\n                        subscription, push_payload, target, options\n                    )\n                    results.append(result)\n\n                except json.JSONDecodeError:\n                    logger.error(f\"Invalid subscription format: {subscription_info}\")\n                    continue\n\n            return results[0] if results else NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_WEB,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=\"No valid subscriptions\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Web Push send error: {e}\")\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_WEB,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=str(e)\n            )\n\n    async def _send_to_subscription(\n        self,\n        subscription: Dict[str, Any],\n        payload: Dict[str, Any],\n        target: NotificationTarget,\n        options: Dict[str, Any]\n    ) -&gt; NotificationResult:\n        \"\"\"Send to specific web push subscription\"\"\"\n\n        try:\n            # Send web push\n            response = webpush(\n                subscription_info=subscription,\n                data=json.dumps(payload),\n                vapid_private_key=self.vapid_private_key,\n                vapid_claims=self.vapid_claims,\n                timeout=10\n            )\n\n            return NotificationResult(\n                notification_id=str(uuid.uuid4()),\n                channel=NotificationChannel.PUSH_WEB,\n                target_id=target.user_id,\n                status=NotificationStatus.SENT,\n                provider_response={\"status_code\": response.status_code},\n                sent_at=datetime.utcnow()\n            )\n\n        except WebPushException as e:\n            # Handle specific web push errors\n            error_msg = str(e)\n            if \"410\" in error_msg:  # Gone - subscription expired\n                # Mark subscription as invalid\n                await self._mark_subscription_invalid(subscription, target.user_id)\n\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.PUSH_WEB,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=error_msg\n            )\n\n    async def _mark_subscription_invalid(self, subscription: Dict[str, Any], user_id: str):\n        \"\"\"Mark web push subscription as invalid\"\"\"\n        # Implementation to remove invalid subscription from database\n        pass\n\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate web push target\"\"\"\n        if not target.device_tokens:\n            return False\n\n        # Validate subscription format\n        for subscription_info in target.device_tokens:\n            try:\n                subscription = json.loads(subscription_info)\n                required_keys = [\"endpoint\", \"keys\"]\n                if not all(key in subscription for key in required_keys):\n                    return False\n            except json.JSONDecodeError:\n                return False\n\n        return True\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#email-and-sms-providers","title":"Email and SMS Providers","text":""},{"location":"atomic/real-time/push-notifications/#email-provider","title":"Email Provider","text":"<pre><code>import aiosmtplib\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.image import MIMEImage\n\nclass EmailProvider(NotificationProvider):\n    \"\"\"Email notification provider\"\"\"\n\n    def __init__(self, smtp_config: Dict[str, Any], templates_dir: str = None):\n        self.smtp_config = smtp_config\n        self.templates_dir = templates_dir\n\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send email notification\"\"\"\n        options = options or {}\n\n        try:\n            if not target.email:\n                return NotificationResult(\n                    notification_id=\"\",\n                    channel=NotificationChannel.EMAIL,\n                    target_id=target.user_id,\n                    status=NotificationStatus.FAILED,\n                    error_message=\"No email address\"\n                )\n\n            # Build email message\n            message = await self._build_email_message(payload, target, options)\n\n            # Send email\n            await self._send_email(message, target.email)\n\n            return NotificationResult(\n                notification_id=str(uuid.uuid4()),\n                channel=NotificationChannel.EMAIL,\n                target_id=target.user_id,\n                status=NotificationStatus.SENT,\n                sent_at=datetime.utcnow()\n            )\n\n        except Exception as e:\n            logger.error(f\"Email send error: {e}\")\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.EMAIL,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=str(e)\n            )\n\n    async def _build_email_message(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any]\n    ) -&gt; MIMEMultipart:\n        \"\"\"Build email message\"\"\"\n        message = MIMEMultipart(\"alternative\")\n        message[\"Subject\"] = payload.title\n        message[\"From\"] = self.smtp_config[\"from_email\"]\n        message[\"To\"] = target.email\n\n        # Create text version\n        text_content = payload.body\n        if payload.action_url:\n            text_content += f\"\\n\\nClick here: {payload.action_url}\"\n\n        text_part = MIMEText(text_content, \"plain\")\n        message.attach(text_part)\n\n        # Create HTML version\n        html_content = await self._build_html_content(payload, target, options)\n        html_part = MIMEText(html_content, \"html\")\n        message.attach(html_part)\n\n        return message\n\n    async def _build_html_content(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any]\n    ) -&gt; str:\n        \"\"\"Build HTML email content\"\"\"\n        # Simple HTML template\n        html_template = f\"\"\"\n        &lt;!DOCTYPE html&gt;\n        &lt;html&gt;\n        &lt;head&gt;\n            &lt;meta charset=\"utf-8\"&gt;\n            &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n            &lt;title&gt;{payload.title}&lt;/title&gt;\n        &lt;/head&gt;\n        &lt;body style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;\"&gt;\n            &lt;div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px;\"&gt;\n                &lt;h2 style=\"color: #333; margin-top: 0;\"&gt;{payload.title}&lt;/h2&gt;\n                &lt;p style=\"color: #666; line-height: 1.6;\"&gt;{payload.body}&lt;/p&gt;\n\n                {f'&lt;img src=\"{payload.image_url}\" alt=\"Notification Image\" style=\"max-width: 100%; height: auto; border-radius: 4px;\"&gt;' if payload.image_url else ''}\n\n                {f'&lt;a href=\"{payload.action_url}\" style=\"background-color: #007bff; color: white; padding: 12px 24px; text-decoration: none; border-radius: 4px; display: inline-block; margin-top: 20px;\"&gt;View Details&lt;/a&gt;' if payload.action_url else ''}\n            &lt;/div&gt;\n\n            &lt;p style=\"color: #999; font-size: 12px; margin-top: 20px;\"&gt;\n                This email was sent to {target.email}.\n                &lt;a href=\"#\" style=\"color: #007bff;\"&gt;Unsubscribe&lt;/a&gt;\n            &lt;/p&gt;\n        &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\"\n        return html_template\n\n    async def _send_email(self, message: MIMEMultipart, to_email: str):\n        \"\"\"Send email via SMTP\"\"\"\n        smtp = aiosmtplib.SMTP(\n            hostname=self.smtp_config[\"host\"],\n            port=self.smtp_config[\"port\"],\n            use_tls=self.smtp_config.get(\"use_tls\", True)\n        )\n\n        await smtp.connect()\n\n        if self.smtp_config.get(\"username\"):\n            await smtp.login(\n                self.smtp_config[\"username\"],\n                self.smtp_config[\"password\"]\n            )\n\n        await smtp.send_message(message)\n        await smtp.quit()\n\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate email target\"\"\"\n        return bool(target.email and \"@\" in target.email)\n\nclass SMSProvider(NotificationProvider):\n    \"\"\"SMS notification provider using Twilio\"\"\"\n\n    def __init__(self, twilio_account_sid: str, twilio_auth_token: str, from_number: str):\n        self.account_sid = twilio_account_sid\n        self.auth_token = twilio_auth_token\n        self.from_number = from_number\n\n    async def send_notification(\n        self,\n        payload: NotificationPayload,\n        target: NotificationTarget,\n        options: Dict[str, Any] = None\n    ) -&gt; NotificationResult:\n        \"\"\"Send SMS notification\"\"\"\n        try:\n            from twilio.rest import Client\n\n            if not target.phone_number:\n                return NotificationResult(\n                    notification_id=\"\",\n                    channel=NotificationChannel.SMS,\n                    target_id=target.user_id,\n                    status=NotificationStatus.FAILED,\n                    error_message=\"No phone number\"\n                )\n\n            # Create Twilio client\n            client = Client(self.account_sid, self.auth_token)\n\n            # Build SMS content\n            sms_content = f\"{payload.title}\\n\\n{payload.body}\"\n            if payload.action_url:\n                sms_content += f\"\\n\\n{payload.action_url}\"\n\n            # Send SMS\n            message = client.messages.create(\n                body=sms_content,\n                from_=self.from_number,\n                to=target.phone_number\n            )\n\n            return NotificationResult(\n                notification_id=message.sid,\n                channel=NotificationChannel.SMS,\n                target_id=target.user_id,\n                status=NotificationStatus.SENT,\n                provider_response={\"sid\": message.sid},\n                sent_at=datetime.utcnow()\n            )\n\n        except Exception as e:\n            logger.error(f\"SMS send error: {e}\")\n            return NotificationResult(\n                notification_id=\"\",\n                channel=NotificationChannel.SMS,\n                target_id=target.user_id,\n                status=NotificationStatus.FAILED,\n                error_message=str(e)\n            )\n\n    async def validate_target(self, target: NotificationTarget) -&gt; bool:\n        \"\"\"Validate SMS target\"\"\"\n        return bool(target.phone_number and len(target.phone_number) &gt; 5)\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#notification-templates-and-personalization","title":"Notification Templates and Personalization","text":""},{"location":"atomic/real-time/push-notifications/#template-engine","title":"Template Engine","text":"<pre><code>from jinja2 import Environment, FileSystemLoader, Template\n\nclass NotificationTemplateEngine:\n    \"\"\"Template engine for notification personalization\"\"\"\n\n    def __init__(self, templates_dir: str):\n        self.env = Environment(loader=FileSystemLoader(templates_dir))\n        self.templates = {}\n\n    def register_template(self, template_id: str, template_data: Dict[str, str]):\n        \"\"\"Register notification template\"\"\"\n        self.templates[template_id] = {\n            \"title\": Template(template_data[\"title\"]),\n            \"body\": Template(template_data[\"body\"]),\n            \"html_body\": Template(template_data.get(\"html_body\", \"\")),\n            \"data\": template_data.get(\"data\", {})\n        }\n\n    async def render_notification(\n        self,\n        template_id: str,\n        context: Dict[str, Any],\n        target: NotificationTarget\n    ) -&gt; NotificationPayload:\n        \"\"\"Render notification from template\"\"\"\n        if template_id not in self.templates:\n            raise ValueError(f\"Template {template_id} not found\")\n\n        template = self.templates[template_id]\n\n        # Add user context\n        full_context = {\n            **context,\n            \"user_id\": target.user_id,\n            \"email\": target.email,\n            \"phone_number\": target.phone_number,\n            \"preferences\": target.preferences\n        }\n\n        # Render template\n        title = template[\"title\"].render(**full_context)\n        body = template[\"body\"].render(**full_context)\n        html_body = template[\"html_body\"].render(**full_context) if template[\"html_body\"] else None\n\n        return NotificationPayload(\n            title=title,\n            body=body,\n            data={\n                **template[\"data\"],\n                \"html_body\": html_body\n            }\n        )\n\nclass PersonalizationService:\n    \"\"\"Service for personalizing notifications\"\"\"\n\n    def __init__(self, template_engine: NotificationTemplateEngine, db_session):\n        self.template_engine = template_engine\n        self.db_session = db_session\n\n    async def create_personalized_notification(\n        self,\n        template_id: str,\n        user_ids: List[str],\n        context: Dict[str, Any],\n        channels: List[NotificationChannel],\n        priority: NotificationPriority = NotificationPriority.NORMAL\n    ) -&gt; List[NotificationRequest]:\n        \"\"\"Create personalized notifications for multiple users\"\"\"\n        requests = []\n\n        for user_id in user_ids:\n            # Get user data for personalization\n            user_data = await self._get_user_data(user_id)\n            target = NotificationTarget(\n                user_id=user_id,\n                device_tokens=user_data.get(\"device_tokens\", []),\n                email=user_data.get(\"email\"),\n                phone_number=user_data.get(\"phone_number\"),\n                preferences=user_data.get(\"preferences\", {})\n            )\n\n            # Render personalized content\n            personalized_context = {\n                **context,\n                **user_data\n            }\n\n            payload = await self.template_engine.render_notification(\n                template_id, personalized_context, target\n            )\n\n            # Create notification request\n            request = NotificationRequest(\n                payload=payload,\n                targets=[target],\n                channels=channels,\n                priority=priority\n            )\n\n            requests.append(request)\n\n        return requests\n\n    async def _get_user_data(self, user_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get user data for personalization\"\"\"\n        # Implementation depends on your database structure\n        return {\n            \"name\": f\"User {user_id}\",\n            \"email\": f\"user{user_id}@example.com\",\n            \"device_tokens\": [],\n            \"preferences\": {}\n        }\n\n# Example template registration\ntemplate_engine = NotificationTemplateEngine(\"templates/\")\n\n# Welcome notification template\ntemplate_engine.register_template(\"user_welcome\", {\n    \"title\": \"Welcome to {{ app_name }}, {{ name }}!\",\n    \"body\": \"Hi {{ name }}, welcome to {{ app_name }}. We're excited to have you on board!\",\n    \"html_body\": \"\"\"\n    &lt;h2&gt;Welcome to {{ app_name }}, {{ name }}!&lt;/h2&gt;\n    &lt;p&gt;Hi {{ name }},&lt;/p&gt;\n    &lt;p&gt;Welcome to {{ app_name }}. We're excited to have you on board!&lt;/p&gt;\n    &lt;p&gt;Get started by exploring our features:&lt;/p&gt;\n    &lt;ul&gt;\n        &lt;li&gt;Feature 1&lt;/li&gt;\n        &lt;li&gt;Feature 2&lt;/li&gt;\n        &lt;li&gt;Feature 3&lt;/li&gt;\n    &lt;/ul&gt;\n    \"\"\",\n    \"data\": {\n        \"category\": \"welcome\",\n        \"action_url\": \"/onboarding\"\n    }\n})\n\n# Order notification template\ntemplate_engine.register_template(\"order_confirmed\", {\n    \"title\": \"Order #{{ order_number }} Confirmed\",\n    \"body\": \"Your order for {{ item_count }} items totaling ${{ total_amount }} has been confirmed.\",\n    \"html_body\": \"\"\"\n    &lt;h2&gt;Order Confirmed!&lt;/h2&gt;\n    &lt;p&gt;Hi {{ name }},&lt;/p&gt;\n    &lt;p&gt;Your order #{{ order_number }} has been confirmed.&lt;/p&gt;\n    &lt;p&gt;&lt;strong&gt;Order Details:&lt;/strong&gt;&lt;/p&gt;\n    &lt;ul&gt;\n        &lt;li&gt;Items: {{ item_count }}&lt;/li&gt;\n        &lt;li&gt;Total: ${{ total_amount }}&lt;/li&gt;\n        &lt;li&gt;Delivery: {{ delivery_date }}&lt;/li&gt;\n    &lt;/ul&gt;\n    \"\"\",\n    \"data\": {\n        \"category\": \"order\",\n        \"order_id\": \"{{ order_id }}\"\n    }\n})\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#queue-management-and-retry-logic","title":"Queue Management and Retry Logic","text":""},{"location":"atomic/real-time/push-notifications/#message-queue-integration","title":"Message Queue Integration","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\nfrom typing import Dict, Any, Optional\n\nclass NotificationQueue:\n    \"\"\"Message queue for notification processing\"\"\"\n\n    def __init__(self, redis_client, max_retries: int = 3):\n        self.redis = redis_client\n        self.max_retries = max_retries\n        self.workers = {}\n\n    async def start_workers(self, worker_count: int = 5):\n        \"\"\"Start notification processing workers\"\"\"\n        for i in range(worker_count):\n            worker = asyncio.create_task(self._worker(f\"worker_{i}\"))\n            self.workers[f\"worker_{i}\"] = worker\n\n        logger.info(f\"Started {worker_count} notification workers\")\n\n    async def stop_workers(self):\n        \"\"\"Stop all notification workers\"\"\"\n        for worker_id, worker in self.workers.items():\n            worker.cancel()\n\n        await asyncio.gather(*self.workers.values(), return_exceptions=True)\n        self.workers.clear()\n\n    async def enqueue_notification(\n        self,\n        request: NotificationRequest,\n        delay_seconds: int = 0,\n        priority: int = 1\n    ):\n        \"\"\"Enqueue notification for processing\"\"\"\n        task_data = {\n            \"id\": request.id,\n            \"request\": self._serialize_request(request),\n            \"retry_count\": 0,\n            \"enqueued_at\": datetime.utcnow().isoformat(),\n            \"priority\": priority\n        }\n\n        if delay_seconds &gt; 0:\n            # Schedule for later\n            execute_at = datetime.utcnow() + timedelta(seconds=delay_seconds)\n            await self.redis.zadd(\n                \"notification_scheduled\",\n                {json.dumps(task_data): execute_at.timestamp()}\n            )\n        else:\n            # Add to immediate queue\n            await self.redis.lpush(\"notification_queue\", json.dumps(task_data))\n\n    async def _worker(self, worker_id: str):\n        \"\"\"Worker process for handling notifications\"\"\"\n        logger.info(f\"Notification worker {worker_id} started\")\n\n        while True:\n            try:\n                # Check for scheduled notifications\n                await self._process_scheduled_notifications()\n\n                # Process immediate queue\n                task_data = await self.redis.brpop(\"notification_queue\", timeout=1)\n\n                if task_data:\n                    queue_name, task_json = task_data\n                    await self._process_notification_task(task_json, worker_id)\n\n            except asyncio.CancelledError:\n                logger.info(f\"Notification worker {worker_id} cancelled\")\n                break\n            except Exception as e:\n                logger.error(f\"Worker {worker_id} error: {e}\")\n                await asyncio.sleep(1)\n\n    async def _process_scheduled_notifications(self):\n        \"\"\"Move scheduled notifications to immediate queue\"\"\"\n        current_time = datetime.utcnow().timestamp()\n\n        # Get notifications ready for processing\n        ready_notifications = await self.redis.zrangebyscore(\n            \"notification_scheduled\",\n            0,\n            current_time,\n            withscores=True\n        )\n\n        for notification_data, score in ready_notifications:\n            # Move to immediate queue\n            await self.redis.lpush(\"notification_queue\", notification_data)\n\n            # Remove from scheduled queue\n            await self.redis.zrem(\"notification_scheduled\", notification_data)\n\n    async def _process_notification_task(self, task_json: str, worker_id: str):\n        \"\"\"Process individual notification task\"\"\"\n        try:\n            task_data = json.loads(task_json)\n            request = self._deserialize_request(task_data[\"request\"])\n\n            logger.info(f\"Worker {worker_id} processing notification {request.id}\")\n\n            # Process notification through notification service\n            notification_service = NotificationService(self.redis, self, None)\n            results = await notification_service.send_notification(request)\n\n            # Check for failures and retry if needed\n            failed_results = [r for r in results if r.status == NotificationStatus.FAILED]\n\n            if failed_results and task_data[\"retry_count\"] &lt; self.max_retries:\n                await self._retry_notification(task_data, failed_results)\n            else:\n                # Store final results\n                await self._store_final_results(request.id, results)\n\n        except Exception as e:\n            logger.error(f\"Error processing notification task: {e}\")\n\n    async def _retry_notification(self, task_data: Dict[str, Any], failed_results: List[NotificationResult]):\n        \"\"\"Retry failed notification\"\"\"\n        retry_count = task_data[\"retry_count\"] + 1\n        delay_seconds = 2 ** retry_count  # Exponential backoff\n\n        # Update task data\n        task_data[\"retry_count\"] = retry_count\n        task_data[\"retry_at\"] = (datetime.utcnow() + timedelta(seconds=delay_seconds)).isoformat()\n\n        # Schedule retry\n        execute_at = datetime.utcnow() + timedelta(seconds=delay_seconds)\n        await self.redis.zadd(\n            \"notification_scheduled\",\n            {json.dumps(task_data): execute_at.timestamp()}\n        )\n\n        logger.info(f\"Scheduled retry {retry_count} for notification {task_data['id']} in {delay_seconds}s\")\n\n    def _serialize_request(self, request: NotificationRequest) -&gt; Dict[str, Any]:\n        \"\"\"Serialize notification request for storage\"\"\"\n        return {\n            \"id\": request.id,\n            \"payload\": {\n                \"title\": request.payload.title,\n                \"body\": request.payload.body,\n                \"data\": request.payload.data,\n                \"image_url\": request.payload.image_url,\n                \"action_url\": request.payload.action_url,\n                \"actions\": request.payload.actions\n            },\n            \"targets\": [\n                {\n                    \"user_id\": t.user_id,\n                    \"device_tokens\": t.device_tokens,\n                    \"email\": t.email,\n                    \"phone_number\": t.phone_number,\n                    \"preferences\": t.preferences\n                }\n                for t in request.targets\n            ],\n            \"channels\": [c.value for c in request.channels],\n            \"priority\": request.priority.value,\n            \"schedule_at\": request.schedule_at.isoformat() if request.schedule_at else None,\n            \"expires_at\": request.expires_at.isoformat() if request.expires_at else None,\n            \"retry_config\": request.retry_config,\n            \"tracking_enabled\": request.tracking_enabled,\n            \"created_at\": request.created_at.isoformat()\n        }\n\n    def _deserialize_request(self, data: Dict[str, Any]) -&gt; NotificationRequest:\n        \"\"\"Deserialize notification request from storage\"\"\"\n        payload = NotificationPayload(\n            title=data[\"payload\"][\"title\"],\n            body=data[\"payload\"][\"body\"],\n            data=data[\"payload\"][\"data\"],\n            image_url=data[\"payload\"][\"image_url\"],\n            action_url=data[\"payload\"][\"action_url\"],\n            actions=data[\"payload\"][\"actions\"]\n        )\n\n        targets = [\n            NotificationTarget(\n                user_id=t[\"user_id\"],\n                device_tokens=t[\"device_tokens\"],\n                email=t[\"email\"],\n                phone_number=t[\"phone_number\"],\n                preferences=t[\"preferences\"]\n            )\n            for t in data[\"targets\"]\n        ]\n\n        return NotificationRequest(\n            id=data[\"id\"],\n            payload=payload,\n            targets=targets,\n            channels=[NotificationChannel(c) for c in data[\"channels\"]],\n            priority=NotificationPriority(data[\"priority\"]),\n            schedule_at=datetime.fromisoformat(data[\"schedule_at\"]) if data[\"schedule_at\"] else None,\n            expires_at=datetime.fromisoformat(data[\"expires_at\"]) if data[\"expires_at\"] else None,\n            retry_config=data[\"retry_config\"],\n            tracking_enabled=data[\"tracking_enabled\"],\n            created_at=datetime.fromisoformat(data[\"created_at\"])\n        )\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#testing-push-notifications","title":"Testing Push Notifications","text":""},{"location":"atomic/real-time/push-notifications/#notification-testing-framework","title":"Notification Testing Framework","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\n\nclass NotificationTester:\n    \"\"\"Testing utilities for notification system\"\"\"\n\n    def __init__(self, notification_service: NotificationService):\n        self.notification_service = notification_service\n\n    async def test_fcm_notification(self):\n        \"\"\"Test FCM notification sending\"\"\"\n        # Mock FCM provider\n        mock_fcm = AsyncMock(spec=FCMProvider)\n        mock_fcm.send_notification.return_value = NotificationResult(\n            notification_id=\"test_fcm_id\",\n            channel=NotificationChannel.PUSH_MOBILE,\n            target_id=\"user123\",\n            status=NotificationStatus.SENT,\n            sent_at=datetime.utcnow()\n        )\n        mock_fcm.validate_target.return_value = True\n\n        self.notification_service.register_provider(NotificationChannel.PUSH_MOBILE, mock_fcm)\n\n        # Create test notification\n        payload = NotificationPayload(\n            title=\"Test Notification\",\n            body=\"This is a test notification\",\n            data={\"key\": \"value\"}\n        )\n\n        target = NotificationTarget(\n            user_id=\"user123\",\n            device_tokens=[\"test_device_token\"]\n        )\n\n        request = NotificationRequest(\n            payload=payload,\n            targets=[target],\n            channels=[NotificationChannel.PUSH_MOBILE]\n        )\n\n        # Send notification\n        results = await self.notification_service.send_notification(request)\n\n        # Verify results\n        assert len(results) == 1\n        assert results[0].status == NotificationStatus.SENT\n        assert results[0].notification_id == \"test_fcm_id\"\n\n        # Verify provider was called correctly\n        mock_fcm.send_notification.assert_called_once()\n\n    async def test_multi_channel_notification(self):\n        \"\"\"Test sending notification through multiple channels\"\"\"\n        # Mock providers\n        mock_fcm = AsyncMock(spec=FCMProvider)\n        mock_fcm.send_notification.return_value = NotificationResult(\n            notification_id=\"fcm_id\",\n            channel=NotificationChannel.PUSH_MOBILE,\n            target_id=\"user123\",\n            status=NotificationStatus.SENT\n        )\n        mock_fcm.validate_target.return_value = True\n\n        mock_email = AsyncMock(spec=EmailProvider)\n        mock_email.send_notification.return_value = NotificationResult(\n            notification_id=\"email_id\",\n            channel=NotificationChannel.EMAIL,\n            target_id=\"user123\",\n            status=NotificationStatus.SENT\n        )\n        mock_email.validate_target.return_value = True\n\n        self.notification_service.register_provider(NotificationChannel.PUSH_MOBILE, mock_fcm)\n        self.notification_service.register_provider(NotificationChannel.EMAIL, mock_email)\n\n        # Create test notification\n        payload = NotificationPayload(\n            title=\"Multi-channel Test\",\n            body=\"This should be sent via multiple channels\"\n        )\n\n        target = NotificationTarget(\n            user_id=\"user123\",\n            device_tokens=[\"test_token\"],\n            email=\"test@example.com\"\n        )\n\n        request = NotificationRequest(\n            payload=payload,\n            targets=[target],\n            channels=[NotificationChannel.PUSH_MOBILE, NotificationChannel.EMAIL]\n        )\n\n        # Send notification\n        results = await self.notification_service.send_notification(request)\n\n        # Verify results\n        assert len(results) == 2\n        assert all(r.status == NotificationStatus.SENT for r in results)\n\n        # Verify both providers were called\n        mock_fcm.send_notification.assert_called_once()\n        mock_email.send_notification.assert_called_once()\n\n    async def test_notification_with_user_preferences(self):\n        \"\"\"Test notification filtering based on user preferences\"\"\"\n        # Mock user preferences\n        user_prefs = {\n            \"allow_push_mobile\": True,\n            \"allow_email\": False,  # User disabled email notifications\n            \"allow_sms\": True\n        }\n\n        with patch.object(\n            self.notification_service,\n            '_get_user_preferences',\n            return_value=user_prefs\n        ):\n            # Mock providers\n            mock_fcm = AsyncMock(spec=FCMProvider)\n            mock_fcm.validate_target.return_value = True\n            mock_fcm.send_notification.return_value = NotificationResult(\n                notification_id=\"fcm_id\",\n                channel=NotificationChannel.PUSH_MOBILE,\n                target_id=\"user123\",\n                status=NotificationStatus.SENT\n            )\n\n            mock_email = AsyncMock(spec=EmailProvider)\n            mock_sms = AsyncMock(spec=SMSProvider)\n\n            self.notification_service.register_provider(NotificationChannel.PUSH_MOBILE, mock_fcm)\n            self.notification_service.register_provider(NotificationChannel.EMAIL, mock_email)\n            self.notification_service.register_provider(NotificationChannel.SMS, mock_sms)\n\n            # Create test notification\n            payload = NotificationPayload(title=\"Test\", body=\"Test message\")\n            target = NotificationTarget(\n                user_id=\"user123\",\n                device_tokens=[\"token\"],\n                email=\"test@example.com\",\n                phone_number=\"+1234567890\"\n            )\n\n            request = NotificationRequest(\n                payload=payload,\n                targets=[target],\n                channels=[\n                    NotificationChannel.PUSH_MOBILE,\n                    NotificationChannel.EMAIL,\n                    NotificationChannel.SMS\n                ]\n            )\n\n            # Send notification\n            results = await self.notification_service.send_notification(request)\n\n            # Verify only allowed channels were used\n            # Email should be filtered out due to user preferences\n            channels_used = {r.channel for r in results}\n            assert NotificationChannel.PUSH_MOBILE in channels_used\n            assert NotificationChannel.EMAIL not in channels_used\n\n            # Verify only FCM was called (email should be skipped)\n            mock_fcm.send_notification.assert_called_once()\n            mock_email.send_notification.assert_not_called()\n\n@pytest.fixture\ndef notification_service():\n    \"\"\"Create notification service for testing\"\"\"\n    redis_client = AsyncMock()\n    message_queue = AsyncMock()\n    db_session = AsyncMock()\n\n    return NotificationService(redis_client, message_queue, db_session)\n\n@pytest.fixture\ndef notification_tester(notification_service):\n    \"\"\"Create notification tester\"\"\"\n    return NotificationTester(notification_service)\n\n@pytest.mark.asyncio\nasync def test_fcm_notification_sending(notification_tester):\n    await notification_tester.test_fcm_notification()\n\n@pytest.mark.asyncio\nasync def test_multi_channel_notifications(notification_tester):\n    await notification_tester.test_multi_channel_notification()\n\n@pytest.mark.asyncio\nasync def test_user_preference_filtering(notification_tester):\n    await notification_tester.test_notification_with_user_preferences()\n</code></pre>"},{"location":"atomic/real-time/push-notifications/#related-documentation","title":"Related Documentation","text":"<ul> <li>WebSocket Patterns</li> <li>Server-Sent Events Implementation</li> <li>Real-time Sync Patterns</li> <li>Communication APIs</li> </ul>"},{"location":"atomic/real-time/push-notifications/#best-practices","title":"Best Practices","text":"<ol> <li>Provider Selection:</li> <li>Use FCM for Android and cross-platform mobile</li> <li>Use APNs for iOS native applications</li> <li>Use Web Push for browser notifications</li> <li> <p>Implement fallback mechanisms</p> </li> <li> <p>Message Design:</p> </li> <li>Keep messages concise and actionable</li> <li>Use rich media appropriately</li> <li>Implement proper deep linking</li> <li> <p>Test across different devices</p> </li> <li> <p>Delivery Reliability:</p> </li> <li>Implement retry mechanisms with exponential backoff</li> <li>Use message queues for scalability</li> <li>Track delivery status and user engagement</li> <li> <p>Handle provider-specific errors</p> </li> <li> <p>User Experience:</p> </li> <li>Respect user notification preferences</li> <li>Implement quiet hours</li> <li>Provide unsubscribe options</li> <li> <p>Use appropriate notification priority</p> </li> <li> <p>Performance:</p> </li> <li>Batch notifications where possible</li> <li>Use background processing</li> <li>Implement rate limiting</li> <li>Monitor provider quotas and limits</li> </ol>"},{"location":"atomic/real-time/push-notifications/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/real-time/websocket-patterns.md</code> \u2014 WebSocket notifications</li> <li><code>docs/atomic/services/aiogram/bot-api-features.md</code> \u2014 Telegram notifications</li> <li><code>docs/atomic/rabbitmq/message-consuming.md</code> \u2014 Notification queues</li> <li><code>docs/atomic/services/asyncio/task-scheduling.md</code> \u2014 Notification scheduling</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/","title":"Real-Time Synchronization Patterns","text":"<p>Comprehensive patterns for maintaining data consistency across clients and services in real-time environments, including conflict resolution, offline support, and monitoring strategies.</p>"},{"location":"atomic/real-time/real-time-sync-patterns/#synchronization-architecture","title":"Synchronization Architecture","text":""},{"location":"atomic/real-time/real-time-sync-patterns/#core-components","title":"Core Components","text":"<ol> <li>Change Event Producer \u2014 emits domain events for each mutation (CRUD, state transitions).</li> <li>Event Bus \u2014 Kafka, NATS, or Redis Streams delivering events with ordering guarantees.</li> <li>Presence &amp; State Service \u2014 tracks active sessions, device metadata, and version vectors.</li> <li>Sync Gateways \u2014 WebSocket/SSE workers delivering delta updates to clients.</li> <li>Conflict Resolver \u2014 service responsible for deterministic merge policies.</li> </ol>"},{"location":"atomic/real-time/real-time-sync-patterns/#data-flow-overview","title":"Data Flow Overview","text":"<pre><code>sequenceDiagram\n    participant Client A\n    participant Gateway\n    participant Sync Service\n    participant Event Bus\n    participant Client B\n\n    Client A-&gt;&gt;Gateway: Mutation request\n    Gateway-&gt;&gt;Sync Service: Persist + publish event\n    Sync Service-&gt;&gt;Event Bus: emit item.updated (version, payload)\n    Event Bus-&gt;&gt;Client B: Push delta via subscription\n    Client B-&gt;&gt;Gateway: ACK version + apply\n    Gateway-&gt;&gt;Client A: Confirmation + new version vector</code></pre>"},{"location":"atomic/real-time/real-time-sync-patterns/#versioning-strategies","title":"Versioning Strategies","text":""},{"location":"atomic/real-time/real-time-sync-patterns/#vector-clocks","title":"Vector Clocks","text":"<ul> <li>Maintain per-entity vector clock with <code>{device_id: counter}</code> pairs.</li> <li>Detect concurrent updates when vectors are incomparable.</li> <li>Resolve via server-side merge or client prompt.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#lamport-timestamps","title":"Lamport Timestamps","text":"<ul> <li>Suitable for single-writer flows (e.g., collaborative cursors).</li> <li>Increment global counter per mutation; break ties with writer ID.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#crdt-structures","title":"CRDT Structures","text":"<p>Use Conflict-free Replicated Data Types for collaborative data models:</p> <ul> <li>GCounter / PN-Counter \u2014 aggregated counters.</li> <li>LWW-Element-Set \u2014 presence/absence with last-write-wins timestamps.</li> <li>RGA / LSEQ \u2014 ordered collaborative text editing.</li> </ul> <pre><code>from dataclasses import dataclass, field\nfrom typing import Dict, Tuple\nfrom enum import Enum\nimport time\n\nclass Operation(Enum):\n    ADD = \"add\"\n    REMOVE = \"remove\"\n\n@dataclass\nclass LWWElementSet:\n    add_set: Dict[str, Tuple[float, dict]] = field(default_factory=dict)\n    remove_set: Dict[str, float] = field(default_factory=dict)\n\n    def add(self, element_id: str, payload: dict) -&gt; None:\n        self.add_set[element_id] = (time.time(), payload)\n\n    def remove(self, element_id: str) -&gt; None:\n        self.remove_set[element_id] = time.time()\n\n    def lookup(self, element_id: str) -&gt; bool:\n        add_ts, _ = self.add_set.get(element_id, (0, {}))\n        remove_ts = self.remove_set.get(element_id, 0)\n        return add_ts &gt; remove_ts\n\n    def values(self) -&gt; dict:\n        return {\n            element_id: payload\n            for element_id, (timestamp, payload) in self.add_set.items()\n            if timestamp &gt; self.remove_set.get(element_id, 0)\n        }\n</code></pre>"},{"location":"atomic/real-time/real-time-sync-patterns/#offline-first-synchronization","title":"Offline-First Synchronization","text":""},{"location":"atomic/real-time/real-time-sync-patterns/#client-side-strategies","title":"Client-Side Strategies","text":"<ul> <li>Persist pending mutations in local queue (IndexedDB, SQLite).</li> <li>Assign temporary IDs and map to server IDs post-sync.</li> <li>Implement exponential backoff with jitter for retries.</li> <li>Display optimistic UI state with reconciliation indicators.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#server-reconciliation-endpoint","title":"Server Reconciliation Endpoint","text":"<pre><code>from fastapi import APIRouter, Depends\nfrom pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import List\n\nrouter = APIRouter(prefix=\"/sync\", tags=[\"sync\"])\n\nclass Mutation(BaseModel):\n    temp_id: str\n    entity_id: str | None\n    operation: str\n    payload: dict\n    version: str\n    occurred_at: datetime\n\nclass SyncRequest(BaseModel):\n    device_id: str\n    last_ack_version: str | None\n    mutations: List[Mutation]\n\n@router.post(\"/reconcile\")\nasync def reconcile_changes(request: SyncRequest):\n    # 1. Validate device + auth context\n    # 2. Apply mutations sequentially, capturing conflicts\n    # 3. Generate authoritative versions\n    # 4. Return resolved state + new checkpoints\n    return {\n        \"applied\": [],\n        \"conflicts\": [],\n        \"checkpoint\": \"2024-03-01T12:00:00Z\"\n    }\n</code></pre>"},{"location":"atomic/real-time/real-time-sync-patterns/#conflict-resolution-policies","title":"Conflict Resolution Policies","text":"<ul> <li>Last write wins \u2014 default for idempotent fields (timestamps, statuses).</li> <li>Merge by intent \u2014 combine list modifications, dedupe unique IDs.</li> <li>Domain-specific resolution \u2014 use business rules (e.g., higher priority role assignments win).</li> <li>Human-in-the-loop \u2014 queue unresolved conflicts for manual review.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#observability-monitoring","title":"Observability &amp; Monitoring","text":"<ul> <li>Emit <code>sync.latency</code> and <code>sync.backlog</code> metrics per tenant/device.</li> <li>Track reconciliation failure rate; alert when &gt;2%.</li> <li>Log version vectors and conflict reasons for root-cause analysis.</li> <li>Use synthetic clients to test end-to-end sync under packet loss.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit test CRDT operations with randomized property-based tests.</li> <li>Replay production traffic in staging to validate determinism.</li> <li>Chaos testing: introduce artificial latency, dropped packets, and partitioned networks.</li> <li>Contract tests for client SDK (Android/iOS/Web) to ensure protocol compatibility.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#runbook-checklist","title":"Runbook Checklist","text":"<ul> <li> Document sync protocol versioning and backward compatibility.</li> <li> Automate client upgrade prompts when protocol changes.</li> <li> Maintain idempotent mutation handlers with dedupe keys.</li> <li> Backup event logs for rehydration and auditing.</li> <li> Synthetic monitoring covering cold start and reconnect scenarios.</li> </ul>"},{"location":"atomic/real-time/real-time-sync-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/real-time/websocket-patterns.md</code> \u2014 WebSocket transport</li> <li><code>docs/atomic/real-time/sse-implementation.md</code> \u2014 SSE alternative</li> <li><code>docs/atomic/infrastructure/redis.md</code> \u2014 Redis pub/sub</li> <li><code>docs/atomic/rabbitmq/message-consuming.md</code> \u2014 Event streaming</li> </ul>"},{"location":"atomic/real-time/sse-implementation/","title":"Server-Sent Events (SSE) Implementation","text":"<p>Comprehensive guide for implementing Server-Sent Events with FastAPI, event streaming, connection management, and real-time data delivery patterns.</p>"},{"location":"atomic/real-time/sse-implementation/#prerequisites","title":"Prerequisites","text":"<ul> <li>FastAPI Basic Setup</li> <li>WebSocket Patterns</li> <li>Authentication &amp; Authorization Guide</li> <li>Understanding of HTTP streaming and SSE protocol</li> </ul>"},{"location":"atomic/real-time/sse-implementation/#core-sse-implementation","title":"Core SSE Implementation","text":""},{"location":"atomic/real-time/sse-implementation/#fastapi-sse-service","title":"FastAPI SSE Service","text":"<pre><code>from fastapi import FastAPI, Request, Depends, HTTPException, BackgroundTasks\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.security import HTTPBearer\nfrom typing import Dict, List, Optional, Any, AsyncGenerator, Callable\nimport asyncio\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport redis.asyncio as redis\n\nlogger = logging.getLogger(__name__)\n\nclass EventType(Enum):\n    MESSAGE = \"message\"\n    NOTIFICATION = \"notification\"\n    UPDATE = \"update\"\n    HEARTBEAT = \"heartbeat\"\n    ERROR = \"error\"\n    CUSTOM = \"custom\"\n\n@dataclass\nclass SSEEvent:\n    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    event: str = \"message\"\n    data: Any = None\n    retry: Optional[int] = None\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n\n    def format(self) -&gt; str:\n        \"\"\"Format event for SSE protocol\"\"\"\n        lines = []\n\n        if self.id:\n            lines.append(f\"id: {self.id}\")\n\n        if self.event:\n            lines.append(f\"event: {self.event}\")\n\n        if self.retry is not None:\n            lines.append(f\"retry: {self.retry}\")\n\n        if self.data is not None:\n            if isinstance(self.data, (dict, list)):\n                data_str = json.dumps(self.data)\n            else:\n                data_str = str(self.data)\n\n            # Handle multiline data\n            for line in data_str.split('\\n'):\n                lines.append(f\"data: {line}\")\n\n        lines.append(\"\")  # Empty line to end event\n        return \"\\n\".join(lines) + \"\\n\"\n\n@dataclass\nclass SSEConnection:\n    connection_id: str\n    user_id: Optional[str]\n    channels: set = field(default_factory=set)\n    connected_at: datetime = field(default_factory=datetime.utcnow)\n    last_event_id: Optional[str] = None\n    filters: Dict[str, Any] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\nclass SSEManager:\n    \"\"\"Manage Server-Sent Events connections and streaming\"\"\"\n\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.active_connections: Dict[str, SSEConnection] = {}\n        self.event_queues: Dict[str, asyncio.Queue] = {}\n        self.channel_subscribers: Dict[str, set] = {}\n        self.heartbeat_interval = 30  # seconds\n\n    async def create_event_stream(\n        self,\n        connection_id: str,\n        user_id: Optional[str] = None,\n        channels: List[str] = None,\n        filters: Dict[str, Any] = None,\n        last_event_id: Optional[str] = None\n    ) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Create SSE event stream for client\"\"\"\n\n        # Create connection\n        connection = SSEConnection(\n            connection_id=connection_id,\n            user_id=user_id,\n            channels=set(channels or []),\n            last_event_id=last_event_id,\n            filters=filters or {}\n        )\n\n        self.active_connections[connection_id] = connection\n        self.event_queues[connection_id] = asyncio.Queue()\n\n        # Subscribe to channels\n        for channel in connection.channels:\n            await self._subscribe_to_channel(connection_id, channel)\n\n        # Store connection in Redis for distributed support\n        await self._store_connection_in_redis(connection)\n\n        try:\n            # Send initial connection event\n            initial_event = SSEEvent(\n                event=\"connected\",\n                data={\n                    \"connection_id\": connection_id,\n                    \"timestamp\": datetime.utcnow().isoformat(),\n                    \"channels\": list(connection.channels)\n                }\n            )\n            yield initial_event.format()\n\n            # Replay missed events if last_event_id provided\n            if last_event_id:\n                async for missed_event in self._replay_missed_events(connection_id, last_event_id):\n                    yield missed_event\n\n            # Start heartbeat task\n            heartbeat_task = asyncio.create_task(self._heartbeat_sender(connection_id))\n\n            # Stream events\n            while connection_id in self.active_connections:\n                try:\n                    # Wait for event with timeout\n                    event_data = await asyncio.wait_for(\n                        self.event_queues[connection_id].get(),\n                        timeout=1.0\n                    )\n\n                    if event_data:\n                        yield event_data\n\n                        # Update last event ID\n                        if isinstance(event_data, str) and \"id:\" in event_data:\n                            lines = event_data.split('\\n')\n                            for line in lines:\n                                if line.startswith(\"id:\"):\n                                    self.active_connections[connection_id].last_event_id = line[3:].strip()\n                                    break\n\n                except asyncio.TimeoutError:\n                    # Timeout is normal, continue loop\n                    continue\n                except Exception as e:\n                    logger.error(f\"Error in SSE stream for {connection_id}: {e}\")\n                    break\n\n        finally:\n            # Clean up connection\n            heartbeat_task.cancel()\n            await self._cleanup_connection(connection_id)\n\n    async def send_event_to_connection(self, connection_id: str, event: SSEEvent):\n        \"\"\"Send event to specific connection\"\"\"\n        if connection_id in self.event_queues:\n            await self.event_queues[connection_id].put(event.format())\n        else:\n            # Try to send via Redis for distributed setup\n            await self._send_event_via_redis(connection_id, event)\n\n    async def send_event_to_user(self, user_id: str, event: SSEEvent):\n        \"\"\"Send event to all connections of a user\"\"\"\n        user_connections = [\n            conn_id for conn_id, conn in self.active_connections.items()\n            if conn.user_id == user_id\n        ]\n\n        for connection_id in user_connections:\n            await self.send_event_to_connection(connection_id, event)\n\n        # Also send via Redis for distributed setup\n        await self._send_event_to_user_via_redis(user_id, event)\n\n    async def broadcast_to_channel(self, channel: str, event: SSEEvent, exclude: set = None):\n        \"\"\"Broadcast event to all subscribers of a channel\"\"\"\n        exclude = exclude or set()\n        subscribers = self.channel_subscribers.get(channel, set())\n\n        # Apply channel-specific filtering\n        filtered_subscribers = await self._apply_channel_filters(channel, subscribers, event)\n\n        for connection_id in filtered_subscribers:\n            if connection_id not in exclude:\n                await self.send_event_to_connection(connection_id, event)\n\n        # Store event for replay\n        await self._store_event_for_replay(channel, event)\n\n        # Broadcast via Redis for distributed setup\n        await self._broadcast_via_redis(channel, event, exclude)\n\n    async def _subscribe_to_channel(self, connection_id: str, channel: str):\n        \"\"\"Subscribe connection to channel\"\"\"\n        if channel not in self.channel_subscribers:\n            self.channel_subscribers[channel] = set()\n\n        self.channel_subscribers[channel].add(connection_id)\n\n        # Store subscription in Redis\n        await self.redis.sadd(f\"sse:channel:{channel}\", connection_id)\n        await self.redis.expire(f\"sse:channel:{channel}\", 3600)\n\n    async def _apply_channel_filters(self, channel: str, subscribers: set, event: SSEEvent) -&gt; set:\n        \"\"\"Apply event filters for channel subscribers\"\"\"\n        filtered_subscribers = set()\n\n        for connection_id in subscribers:\n            connection = self.active_connections.get(connection_id)\n            if connection and self._event_matches_filters(event, connection.filters):\n                filtered_subscribers.add(connection_id)\n\n        return filtered_subscribers\n\n    def _event_matches_filters(self, event: SSEEvent, filters: Dict[str, Any]) -&gt; bool:\n        \"\"\"Check if event matches connection filters\"\"\"\n        if not filters:\n            return True\n\n        event_data = event.data if isinstance(event.data, dict) else {}\n\n        for filter_key, filter_value in filters.items():\n            if filter_key in event_data:\n                if isinstance(filter_value, list):\n                    if event_data[filter_key] not in filter_value:\n                        return False\n                else:\n                    if event_data[filter_key] != filter_value:\n                        return False\n\n        return True\n\n    async def _heartbeat_sender(self, connection_id: str):\n        \"\"\"Send periodic heartbeat events\"\"\"\n        while connection_id in self.active_connections:\n            try:\n                await asyncio.sleep(self.heartbeat_interval)\n\n                if connection_id not in self.active_connections:\n                    break\n\n                heartbeat_event = SSEEvent(\n                    event=\"heartbeat\",\n                    data={\"timestamp\": datetime.utcnow().isoformat()}\n                )\n\n                await self.send_event_to_connection(connection_id, heartbeat_event)\n\n            except Exception as e:\n                logger.error(f\"Heartbeat error for {connection_id}: {e}\")\n                break\n\n    async def _replay_missed_events(self, connection_id: str, last_event_id: str) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Replay events missed since last_event_id\"\"\"\n        connection = self.active_connections.get(connection_id)\n        if not connection:\n            return\n\n        for channel in connection.channels:\n            # Get stored events from Redis\n            events = await self.redis.lrange(f\"sse:events:{channel}\", 0, -1)\n\n            found_last_event = False\n            for event_data in reversed(events):\n                try:\n                    event_info = json.loads(event_data)\n\n                    if not found_last_event:\n                        if event_info.get(\"id\") == last_event_id:\n                            found_last_event = True\n                        continue\n\n                    # Reconstruct and yield event\n                    event = SSEEvent(\n                        id=event_info.get(\"id\"),\n                        event=event_info.get(\"event\", \"message\"),\n                        data=event_info.get(\"data\")\n                    )\n\n                    if self._event_matches_filters(event, connection.filters):\n                        yield event.format()\n\n                except json.JSONDecodeError:\n                    continue\n\n    async def _store_event_for_replay(self, channel: str, event: SSEEvent):\n        \"\"\"Store event for replay functionality\"\"\"\n        event_data = {\n            \"id\": event.id,\n            \"event\": event.event,\n            \"data\": event.data,\n            \"timestamp\": event.timestamp.isoformat()\n        }\n\n        # Store in Redis list (keep last 1000 events)\n        await self.redis.lpush(f\"sse:events:{channel}\", json.dumps(event_data))\n        await self.redis.ltrim(f\"sse:events:{channel}\", 0, 999)\n        await self.redis.expire(f\"sse:events:{channel}\", 86400)  # 24 hours\n\n    async def _cleanup_connection(self, connection_id: str):\n        \"\"\"Clean up connection resources\"\"\"\n        connection = self.active_connections.get(connection_id)\n        if connection:\n            # Remove from channels\n            for channel in connection.channels:\n                if channel in self.channel_subscribers:\n                    self.channel_subscribers[channel].discard(connection_id)\n                    if not self.channel_subscribers[channel]:\n                        del self.channel_subscribers[channel]\n\n            # Clean up local state\n            del self.active_connections[connection_id]\n\n            if connection_id in self.event_queues:\n                del self.event_queues[connection_id]\n\n        # Remove from Redis\n        await self._remove_connection_from_redis(connection_id)\n\n        logger.info(f\"SSE connection cleaned up: {connection_id}\")\n\n    # Redis integration methods for distributed SSE\n    async def _store_connection_in_redis(self, connection: SSEConnection):\n        \"\"\"Store connection info in Redis\"\"\"\n        await self.redis.hset(\n            f\"sse:connections:{connection.connection_id}\",\n            mapping={\n                \"user_id\": connection.user_id or \"\",\n                \"channels\": json.dumps(list(connection.channels)),\n                \"connected_at\": connection.connected_at.isoformat(),\n                \"server_id\": self._get_server_id(),\n                \"last_event_id\": connection.last_event_id or \"\",\n                \"filters\": json.dumps(connection.filters),\n                \"metadata\": json.dumps(connection.metadata)\n            }\n        )\n        await self.redis.expire(f\"sse:connections:{connection.connection_id}\", 3600)\n\n    async def _remove_connection_from_redis(self, connection_id: str):\n        \"\"\"Remove connection info from Redis\"\"\"\n        await self.redis.delete(f\"sse:connections:{connection_id}\")\n\n    def _get_server_id(self) -&gt; str:\n        \"\"\"Get unique server identifier\"\"\"\n        import socket\n        return f\"{socket.gethostname()}:{id(self)}\"\n\n# FastAPI SSE endpoints\napp = FastAPI()\nsecurity = HTTPBearer(auto_error=False)\n\n# Initialize SSE manager\nredis_client = redis.from_url(\"redis://localhost:6379\")\nsse_manager = SSEManager(redis_client)\n\n@app.get(\"/events\")\nasync def sse_endpoint(\n    request: Request,\n    channels: str = \"\",\n    filters: str = \"{}\",\n    last_event_id: Optional[str] = None\n):\n    \"\"\"Public SSE endpoint\"\"\"\n    connection_id = str(uuid.uuid4())\n\n    # Parse channels and filters\n    channel_list = [ch.strip() for ch in channels.split(\",\") if ch.strip()]\n    try:\n        filter_dict = json.loads(filters) if filters else {}\n    except json.JSONDecodeError:\n        filter_dict = {}\n\n    # Get last event ID from headers if not in query\n    if not last_event_id:\n        last_event_id = request.headers.get(\"Last-Event-ID\")\n\n    return StreamingResponse(\n        sse_manager.create_event_stream(\n            connection_id=connection_id,\n            channels=channel_list,\n            filters=filter_dict,\n            last_event_id=last_event_id\n        ),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"Cache-Control,Last-Event-ID\",\n        }\n    )\n\n@app.get(\"/events/authenticated\")\nasync def authenticated_sse_endpoint(\n    request: Request,\n    channels: str = \"\",\n    filters: str = \"{}\",\n    last_event_id: Optional[str] = None,\n    token: str = Depends(security)\n):\n    \"\"\"Authenticated SSE endpoint\"\"\"\n    # Authenticate user\n    try:\n        user = await authenticate_token(token.credentials if token else None)\n    except Exception:\n        raise HTTPException(status_code=401, detail=\"Invalid authentication\")\n\n    connection_id = str(uuid.uuid4())\n\n    # Parse channels and filters\n    channel_list = [ch.strip() for ch in channels.split(\",\") if ch.strip()]\n    try:\n        filter_dict = json.loads(filters) if filters else {}\n    except json.JSONDecodeError:\n        filter_dict = {}\n\n    # Get last event ID from headers if not in query\n    if not last_event_id:\n        last_event_id = request.headers.get(\"Last-Event-ID\")\n\n    return StreamingResponse(\n        sse_manager.create_event_stream(\n            connection_id=connection_id,\n            user_id=user.id,\n            channels=channel_list,\n            filters=filter_dict,\n            last_event_id=last_event_id\n        ),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"Cache-Control,Last-Event-ID\",\n        }\n    )\n\nasync def authenticate_token(token: str):\n    \"\"\"Authenticate JWT token\"\"\"\n    # Implementation depends on your auth system\n    pass\n</code></pre>"},{"location":"atomic/real-time/sse-implementation/#advanced-sse-patterns","title":"Advanced SSE Patterns","text":""},{"location":"atomic/real-time/sse-implementation/#real-time-dashboard-updates","title":"Real-time Dashboard Updates","text":"<pre><code>class DashboardSSEService:\n    \"\"\"SSE service for real-time dashboard updates\"\"\"\n\n    def __init__(self, sse_manager: SSEManager, db_session):\n        self.sse_manager = sse_manager\n        self.db_session = db_session\n        self.metric_cache = {}\n\n    async def start_dashboard_updates(self):\n        \"\"\"Start periodic dashboard metric updates\"\"\"\n        asyncio.create_task(self._update_metrics_loop())\n\n    async def _update_metrics_loop(self):\n        \"\"\"Periodically update and broadcast dashboard metrics\"\"\"\n        while True:\n            try:\n                # Collect current metrics\n                metrics = await self._collect_dashboard_metrics()\n\n                # Check for changes\n                if self._metrics_changed(metrics):\n                    # Broadcast updates to dashboard subscribers\n                    await self.sse_manager.broadcast_to_channel(\n                        \"dashboard\",\n                        SSEEvent(\n                            event=\"metrics_update\",\n                            data={\n                                \"metrics\": metrics,\n                                \"timestamp\": datetime.utcnow().isoformat()\n                            }\n                        )\n                    )\n\n                    self.metric_cache = metrics\n\n                await asyncio.sleep(5)  # Update every 5 seconds\n\n            except Exception as e:\n                logger.error(f\"Dashboard metrics update error: {e}\")\n                await asyncio.sleep(10)  # Wait longer on error\n\n    async def _collect_dashboard_metrics(self) -&gt; Dict[str, Any]:\n        \"\"\"Collect dashboard metrics from various sources\"\"\"\n        return {\n            \"active_users\": await self._get_active_users_count(),\n            \"orders_today\": await self._get_orders_today_count(),\n            \"revenue_today\": await self._get_revenue_today(),\n            \"system_health\": await self._get_system_health(),\n            \"recent_activities\": await self._get_recent_activities()\n        }\n\n    def _metrics_changed(self, new_metrics: Dict[str, Any]) -&gt; bool:\n        \"\"\"Check if metrics have changed significantly\"\"\"\n        if not self.metric_cache:\n            return True\n\n        # Check for significant changes (you can customize thresholds)\n        for key, value in new_metrics.items():\n            if key not in self.metric_cache:\n                return True\n\n            old_value = self.metric_cache[key]\n            if isinstance(value, (int, float)) and isinstance(old_value, (int, float)):\n                # Check for 5% change or absolute difference &gt; 10\n                if abs(value - old_value) &gt; max(old_value * 0.05, 10):\n                    return True\n            elif value != old_value:\n                return True\n\n        return False\n\n    async def send_alert(self, alert_type: str, message: str, severity: str = \"info\"):\n        \"\"\"Send alert to dashboard subscribers\"\"\"\n        await self.sse_manager.broadcast_to_channel(\n            \"dashboard\",\n            SSEEvent(\n                event=\"alert\",\n                data={\n                    \"type\": alert_type,\n                    \"message\": message,\n                    \"severity\": severity,\n                    \"timestamp\": datetime.utcnow().isoformat()\n                }\n            )\n        )\n\nclass NotificationSSEService:\n    \"\"\"SSE service for user notifications\"\"\"\n\n    def __init__(self, sse_manager: SSEManager):\n        self.sse_manager = sse_manager\n\n    async def send_notification(\n        self,\n        user_id: str,\n        title: str,\n        message: str,\n        notification_type: str = \"info\",\n        data: Dict[str, Any] = None\n    ):\n        \"\"\"Send notification to specific user\"\"\"\n        notification_event = SSEEvent(\n            event=\"notification\",\n            data={\n                \"title\": title,\n                \"message\": message,\n                \"type\": notification_type,\n                \"data\": data or {},\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n        )\n\n        await self.sse_manager.send_event_to_user(user_id, notification_event)\n\n    async def send_bulk_notification(\n        self,\n        user_ids: List[str],\n        title: str,\n        message: str,\n        notification_type: str = \"info\"\n    ):\n        \"\"\"Send notification to multiple users\"\"\"\n        notification_event = SSEEvent(\n            event=\"notification\",\n            data={\n                \"title\": title,\n                \"message\": message,\n                \"type\": notification_type,\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n        )\n\n        for user_id in user_ids:\n            await self.sse_manager.send_event_to_user(user_id, notification_event)\n\nclass LiveDataStreamService:\n    \"\"\"SSE service for live data streaming\"\"\"\n\n    def __init__(self, sse_manager: SSEManager):\n        self.sse_manager = sse_manager\n        self.data_sources = {}\n\n    async def register_data_source(\n        self,\n        source_id: str,\n        data_generator: Callable,\n        interval: int = 1,\n        channel: str = None\n    ):\n        \"\"\"Register a data source for live streaming\"\"\"\n        channel = channel or f\"data:{source_id}\"\n\n        self.data_sources[source_id] = {\n            \"generator\": data_generator,\n            \"interval\": interval,\n            \"channel\": channel,\n            \"task\": None\n        }\n\n        # Start streaming task\n        self.data_sources[source_id][\"task\"] = asyncio.create_task(\n            self._stream_data_source(source_id)\n        )\n\n    async def _stream_data_source(self, source_id: str):\n        \"\"\"Stream data from registered source\"\"\"\n        source_config = self.data_sources[source_id]\n\n        while source_id in self.data_sources:\n            try:\n                # Generate data\n                data = await source_config[\"generator\"]()\n\n                # Stream to subscribers\n                await self.sse_manager.broadcast_to_channel(\n                    source_config[\"channel\"],\n                    SSEEvent(\n                        event=\"data_update\",\n                        data={\n                            \"source_id\": source_id,\n                            \"data\": data,\n                            \"timestamp\": datetime.utcnow().isoformat()\n                        }\n                    )\n                )\n\n                await asyncio.sleep(source_config[\"interval\"])\n\n            except Exception as e:\n                logger.error(f\"Data streaming error for {source_id}: {e}\")\n                await asyncio.sleep(source_config[\"interval\"] * 2)\n\n    async def unregister_data_source(self, source_id: str):\n        \"\"\"Unregister data source\"\"\"\n        if source_id in self.data_sources:\n            task = self.data_sources[source_id].get(\"task\")\n            if task:\n                task.cancel()\n\n            del self.data_sources[source_id]\n\n# Example data generators\nasync def stock_price_generator():\n    \"\"\"Generate mock stock price data\"\"\"\n    import random\n    return {\n        \"symbol\": \"AAPL\",\n        \"price\": round(150 + random.uniform(-5, 5), 2),\n        \"change\": round(random.uniform(-2, 2), 2),\n        \"volume\": random.randint(1000000, 5000000)\n    }\n\nasync def system_metrics_generator():\n    \"\"\"Generate system metrics data\"\"\"\n    import psutil\n    return {\n        \"cpu_percent\": psutil.cpu_percent(),\n        \"memory_percent\": psutil.virtual_memory().percent,\n        \"disk_usage\": psutil.disk_usage('/').percent,\n        \"active_connections\": len(sse_manager.active_connections)\n    }\n</code></pre>"},{"location":"atomic/real-time/sse-implementation/#sse-client-integration","title":"SSE Client Integration","text":""},{"location":"atomic/real-time/sse-implementation/#javascript-client","title":"JavaScript Client","text":"<pre><code>class SSEClient {\n    constructor(url, options = {}) {\n        this.url = url;\n        this.options = {\n            retry: 3000,\n            maxRetries: 5,\n            reconnectDelay: 1000,\n            ...options\n        };\n\n        this.eventSource = null;\n        this.retryCount = 0;\n        this.lastEventId = null;\n        this.listeners = new Map();\n        this.connectionState = 'disconnected';\n    }\n\n    connect() {\n        if (this.eventSource) {\n            this.disconnect();\n        }\n\n        const url = this.buildUrl();\n        this.eventSource = new EventSource(url);\n\n        this.eventSource.onopen = (event) =&gt; {\n            this.connectionState = 'connected';\n            this.retryCount = 0;\n            this.emit('connected', { event });\n            console.log('SSE connected');\n        };\n\n        this.eventSource.onmessage = (event) =&gt; {\n            this.handleMessage(event);\n        };\n\n        this.eventSource.onerror = (event) =&gt; {\n            this.connectionState = 'error';\n            this.emit('error', { event });\n\n            if (this.retryCount &lt; this.options.maxRetries) {\n                this.scheduleReconnect();\n            } else {\n                console.error('SSE max retries exceeded');\n                this.emit('maxRetriesExceeded', { retryCount: this.retryCount });\n            }\n        };\n\n        // Handle custom event types\n        this.setupCustomEventHandlers();\n    }\n\n    buildUrl() {\n        let url = this.url;\n        const params = new URLSearchParams();\n\n        if (this.options.channels) {\n            params.append('channels', this.options.channels.join(','));\n        }\n\n        if (this.options.filters) {\n            params.append('filters', JSON.stringify(this.options.filters));\n        }\n\n        if (this.lastEventId) {\n            params.append('last_event_id', this.lastEventId);\n        }\n\n        if (params.toString()) {\n            url += '?' + params.toString();\n        }\n\n        return url;\n    }\n\n    setupCustomEventHandlers() {\n        const customEvents = [\n            'connected', 'notification', 'metrics_update',\n            'alert', 'data_update', 'heartbeat'\n        ];\n\n        customEvents.forEach(eventType =&gt; {\n            this.eventSource.addEventListener(eventType, (event) =&gt; {\n                this.handleMessage(event);\n            });\n        });\n    }\n\n    handleMessage(event) {\n        try {\n            // Update last event ID\n            if (event.lastEventId) {\n                this.lastEventId = event.lastEventId;\n                localStorage.setItem('sse_last_event_id', this.lastEventId);\n            }\n\n            // Parse data\n            let data;\n            try {\n                data = JSON.parse(event.data);\n            } catch {\n                data = event.data;\n            }\n\n            // Emit to listeners\n            this.emit(event.type, {\n                id: event.lastEventId,\n                type: event.type,\n                data: data,\n                timestamp: new Date()\n            });\n\n        } catch (error) {\n            console.error('Error handling SSE message:', error);\n        }\n    }\n\n    scheduleReconnect() {\n        this.retryCount++;\n        const delay = this.options.reconnectDelay * Math.pow(2, this.retryCount - 1);\n\n        console.log(`SSE reconnecting in ${delay}ms (attempt ${this.retryCount})`);\n\n        setTimeout(() =&gt; {\n            if (this.connectionState === 'error') {\n                this.connect();\n            }\n        }, delay);\n    }\n\n    disconnect() {\n        if (this.eventSource) {\n            this.eventSource.close();\n            this.eventSource = null;\n        }\n        this.connectionState = 'disconnected';\n        this.emit('disconnected');\n    }\n\n    // Event listener management\n    on(eventType, callback) {\n        if (!this.listeners.has(eventType)) {\n            this.listeners.set(eventType, []);\n        }\n        this.listeners.get(eventType).push(callback);\n    }\n\n    off(eventType, callback) {\n        if (this.listeners.has(eventType)) {\n            const callbacks = this.listeners.get(eventType);\n            const index = callbacks.indexOf(callback);\n            if (index &gt; -1) {\n                callbacks.splice(index, 1);\n            }\n        }\n    }\n\n    emit(eventType, data) {\n        if (this.listeners.has(eventType)) {\n            this.listeners.get(eventType).forEach(callback =&gt; {\n                try {\n                    callback(data);\n                } catch (error) {\n                    console.error(`Error in SSE event listener for ${eventType}:`, error);\n                }\n            });\n        }\n    }\n\n    // Utility methods\n    getConnectionState() {\n        return this.connectionState;\n    }\n\n    getLastEventId() {\n        return this.lastEventId;\n    }\n\n    updateChannels(channels) {\n        this.options.channels = channels;\n        if (this.connectionState === 'connected') {\n            this.connect(); // Reconnect with new channels\n        }\n    }\n\n    updateFilters(filters) {\n        this.options.filters = filters;\n        if (this.connectionState === 'connected') {\n            this.connect(); // Reconnect with new filters\n        }\n    }\n}\n\n// Usage examples\nconst sseClient = new SSEClient('/events/authenticated', {\n    channels: ['dashboard', 'notifications'],\n    filters: { user_id: '123' },\n    retry: 3000,\n    maxRetries: 5\n});\n\n// Listen for events\nsseClient.on('notification', (event) =&gt; {\n    console.log('Received notification:', event.data);\n    showNotification(event.data.title, event.data.message);\n});\n\nsseClient.on('metrics_update', (event) =&gt; {\n    console.log('Metrics updated:', event.data.metrics);\n    updateDashboard(event.data.metrics);\n});\n\nsseClient.on('alert', (event) =&gt; {\n    console.log('Alert received:', event.data);\n    showAlert(event.data.message, event.data.severity);\n});\n\nsseClient.on('connected', () =&gt; {\n    console.log('SSE connection established');\n});\n\nsseClient.on('error', (error) =&gt; {\n    console.error('SSE connection error:', error);\n});\n\n// Connect\nsseClient.connect();\n\n// Utility functions\nfunction showNotification(title, message) {\n    // Implementation for showing notifications\n    if (Notification.permission === 'granted') {\n        new Notification(title, { body: message });\n    }\n}\n\nfunction updateDashboard(metrics) {\n    // Implementation for updating dashboard\n    document.getElementById('active-users').textContent = metrics.active_users;\n    document.getElementById('orders-today').textContent = metrics.orders_today;\n    // ... update other metrics\n}\n\nfunction showAlert(message, severity) {\n    // Implementation for showing alerts\n    const alertClass = severity === 'error' ? 'alert-danger' :\n                      severity === 'warning' ? 'alert-warning' : 'alert-info';\n\n    const alertDiv = document.createElement('div');\n    alertDiv.className = `alert ${alertClass}`;\n    alertDiv.textContent = message;\n\n    document.getElementById('alerts-container').appendChild(alertDiv);\n\n    // Auto-remove after 5 seconds\n    setTimeout(() =&gt; {\n        alertDiv.remove();\n    }, 5000);\n}\n</code></pre>"},{"location":"atomic/real-time/sse-implementation/#testing-sse-implementation","title":"Testing SSE Implementation","text":""},{"location":"atomic/real-time/sse-implementation/#sse-testing-framework","title":"SSE Testing Framework","text":"<pre><code>import pytest\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\n\nclass SSETester:\n    \"\"\"Testing utilities for SSE functionality\"\"\"\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url\n\n    async def test_sse_connection(self):\n        \"\"\"Test basic SSE connection\"\"\"\n        async with aiohttp.ClientSession() as session:\n            async with session.get(f\"{self.base_url}/events\") as response:\n                assert response.status == 200\n                assert response.headers['content-type'] == 'text/event-stream'\n\n                # Read first event (connection confirmation)\n                line = await response.content.readline()\n                assert line.startswith(b'event: connected')\n\n    async def test_event_streaming(self):\n        \"\"\"Test receiving events via SSE\"\"\"\n        events_received = []\n\n        async with aiohttp.ClientSession() as session:\n            async with session.get(\n                f\"{self.base_url}/events?channels=test_channel\"\n            ) as response:\n\n                # Create task to collect events\n                async def collect_events():\n                    try:\n                        async for line in response.content:\n                            line_str = line.decode().strip()\n                            if line_str.startswith('data: '):\n                                events_received.append(line_str[6:])\n                            if len(events_received) &gt;= 2:  # Stop after 2 events\n                                break\n                    except asyncio.CancelledError:\n                        pass\n\n                collect_task = asyncio.create_task(collect_events())\n\n                # Wait a bit for connection\n                await asyncio.sleep(0.1)\n\n                # Send test event via API\n                await self._trigger_test_event(\"test_channel\")\n\n                # Wait for events\n                try:\n                    await asyncio.wait_for(collect_task, timeout=5.0)\n                except asyncio.TimeoutError:\n                    collect_task.cancel()\n\n        assert len(events_received) &gt;= 1\n\n    async def test_event_replay(self):\n        \"\"\"Test event replay functionality\"\"\"\n        # First, send some events\n        for i in range(3):\n            await self._trigger_test_event(\"replay_test\", f\"Event {i}\")\n\n        # Get events with replay\n        events = await self._get_events_with_replay(\"replay_test\")\n\n        assert len(events) &gt;= 3\n\n    async def test_filtered_events(self):\n        \"\"\"Test event filtering\"\"\"\n        filters = {\"user_id\": \"123\"}\n\n        async with aiohttp.ClientSession() as session:\n            url = f\"{self.base_url}/events?channels=filter_test&amp;filters={json.dumps(filters)}\"\n\n            async with session.get(url) as response:\n                # Implementation for testing filtered events\n                pass\n\n    async def _trigger_test_event(self, channel: str, data: str = \"test data\"):\n        \"\"\"Trigger a test event via internal API\"\"\"\n        # This would call your internal API to trigger an SSE event\n        # Implementation depends on your application structure\n        pass\n\n    async def _get_events_with_replay(self, channel: str) -&gt; List[str]:\n        \"\"\"Get events with replay functionality\"\"\"\n        events = []\n\n        async with aiohttp.ClientSession() as session:\n            # Set last event ID to trigger replay\n            headers = {\"Last-Event-ID\": \"some-old-event-id\"}\n\n            async with session.get(\n                f\"{self.base_url}/events?channels={channel}\",\n                headers=headers\n            ) as response:\n\n                async for line in response.content:\n                    line_str = line.decode().strip()\n                    if line_str.startswith('data: '):\n                        events.append(line_str[6:])\n                    if len(events) &gt;= 5:  # Limit for test\n                        break\n\n        return events\n\nclass SSEPerformanceTester:\n    \"\"\"Performance testing for SSE implementation\"\"\"\n\n    async def test_concurrent_connections(self, connection_count: int = 100):\n        \"\"\"Test multiple concurrent SSE connections\"\"\"\n        connections = []\n        start_time = asyncio.get_event_loop().time()\n\n        try:\n            async with aiohttp.ClientSession() as session:\n                # Create concurrent connections\n                tasks = []\n                for i in range(connection_count):\n                    task = asyncio.create_task(\n                        self._create_sse_connection(session, f\"connection_{i}\")\n                    )\n                    tasks.append(task)\n\n                # Wait for all connections\n                connections = await asyncio.gather(*tasks, return_exceptions=True)\n\n                connection_time = asyncio.get_event_loop().time() - start_time\n\n                # Test broadcasting to all connections\n                start_time = asyncio.get_event_loop().time()\n                await self._broadcast_test_event()\n                broadcast_time = asyncio.get_event_loop().time() - start_time\n\n                return {\n                    \"concurrent_connections\": connection_count,\n                    \"successful_connections\": len([c for c in connections if not isinstance(c, Exception)]),\n                    \"connection_time\": connection_time,\n                    \"broadcast_time\": broadcast_time\n                }\n\n        finally:\n            # Clean up connections\n            for connection in connections:\n                if hasattr(connection, 'close'):\n                    connection.close()\n\n    async def _create_sse_connection(self, session: aiohttp.ClientSession, connection_id: str):\n        \"\"\"Create individual SSE connection for testing\"\"\"\n        try:\n            response = await session.get(f\"{self.base_url}/events?channels=performance_test\")\n            return response\n        except Exception as e:\n            return e\n\n    async def _broadcast_test_event(self):\n        \"\"\"Broadcast test event for performance testing\"\"\"\n        # Implementation for triggering broadcast event\n        pass\n\n# pytest fixtures and test cases\n@pytest.fixture\ndef sse_tester():\n    return SSETester(\"http://localhost:8000\")\n\n@pytest.mark.asyncio\nasync def test_basic_sse_functionality(sse_tester):\n    await sse_tester.test_sse_connection()\n\n@pytest.mark.asyncio\nasync def test_sse_event_streaming(sse_tester):\n    await sse_tester.test_event_streaming()\n\n@pytest.mark.asyncio\nasync def test_sse_event_replay(sse_tester):\n    await sse_tester.test_event_replay()\n</code></pre>"},{"location":"atomic/real-time/sse-implementation/#related-documentation","title":"Related Documentation","text":"<ul> <li>WebSocket Patterns</li> <li>Push Notifications</li> <li>Real-time Sync Patterns</li> <li>FastAPI Basic Setup</li> </ul>"},{"location":"atomic/real-time/sse-implementation/#best-practices","title":"Best Practices","text":"<ol> <li>Connection Management:</li> <li>Implement proper connection cleanup</li> <li>Use heartbeats to detect stale connections</li> <li> <p>Handle reconnection gracefully</p> </li> <li> <p>Event Design:</p> </li> <li>Use structured event formats</li> <li>Implement event replay for reliability</li> <li> <p>Apply filtering to reduce bandwidth</p> </li> <li> <p>Performance:</p> </li> <li>Monitor active connection count</li> <li>Implement connection limits</li> <li> <p>Use efficient event serialization</p> </li> <li> <p>Reliability:</p> </li> <li>Store events for replay</li> <li>Implement proper error handling</li> <li> <p>Use Redis for distributed coordination</p> </li> <li> <p>Security:</p> </li> <li>Authenticate connections when needed</li> <li>Validate event permissions</li> <li>Implement rate limiting</li> </ol>"},{"location":"atomic/real-time/sse-implementation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/real-time/websocket-patterns.md</code> \u2014 WebSocket alternative</li> <li><code>docs/atomic/real-time/real-time-sync-patterns.md</code> \u2014 Sync strategies</li> <li><code>docs/atomic/services/fastapi/streaming-responses.md</code> \u2014 SSE with FastAPI</li> <li><code>docs/atomic/infrastructure/nginx.md</code> \u2014 SSE proxy configuration</li> </ul>"},{"location":"atomic/real-time/websocket-patterns/","title":"WebSocket Integration Patterns","text":"<p>Comprehensive guide for implementing WebSocket connections with FastAPI, connection management, authentication, scaling, and real-time communication patterns.</p>"},{"location":"atomic/real-time/websocket-patterns/#prerequisites","title":"Prerequisites","text":"<ul> <li>FastAPI Basic Setup</li> <li>Authentication &amp; Authorization Guide</li> <li>Redis Integration</li> <li>Understanding of WebSocket protocol</li> </ul>"},{"location":"atomic/real-time/websocket-patterns/#core-websocket-service","title":"Core WebSocket Service","text":""},{"location":"atomic/real-time/websocket-patterns/#fastapi-websocket-implementation","title":"FastAPI WebSocket Implementation","text":"<pre><code>from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer\nfrom typing import Dict, List, Optional, Any, Set\nimport asyncio\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport redis.asyncio as redis\n\nlogger = logging.getLogger(__name__)\n\nclass MessageType(Enum):\n    CONNECT = \"connect\"\n    DISCONNECT = \"disconnect\"\n    MESSAGE = \"message\"\n    BROADCAST = \"broadcast\"\n    PRIVATE = \"private\"\n    TYPING = \"typing\"\n    PRESENCE = \"presence\"\n    ERROR = \"error\"\n    HEARTBEAT = \"heartbeat\"\n\n@dataclass\nclass WebSocketMessage:\n    type: MessageType\n    data: Dict[str, Any]\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    sender_id: Optional[str] = None\n    recipient_id: Optional[str] = None\n    channel: Optional[str] = None\n\n@dataclass\nclass ConnectionInfo:\n    connection_id: str\n    user_id: Optional[str]\n    username: Optional[str]\n    channels: Set[str] = field(default_factory=set)\n    connected_at: datetime = field(default_factory=datetime.utcnow)\n    last_heartbeat: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\nclass WebSocketManager:\n    \"\"\"Manage WebSocket connections and messaging\"\"\"\n\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.active_connections: Dict[str, WebSocket] = {}\n        self.connection_info: Dict[str, ConnectionInfo] = {}\n        self.channel_subscribers: Dict[str, Set[str]] = {}\n        self.heartbeat_interval = 30  # seconds\n\n    async def connect(\n        self,\n        websocket: WebSocket,\n        connection_id: str,\n        user_id: Optional[str] = None,\n        username: Optional[str] = None,\n        metadata: Dict[str, Any] = None\n    ):\n        \"\"\"Accept WebSocket connection and register it\"\"\"\n        await websocket.accept()\n\n        # Store connection\n        self.active_connections[connection_id] = websocket\n        self.connection_info[connection_id] = ConnectionInfo(\n            connection_id=connection_id,\n            user_id=user_id,\n            username=username,\n            metadata=metadata or {}\n        )\n\n        # Store connection info in Redis for distributed scaling\n        await self._store_connection_in_redis(connection_id)\n\n        # Send connection confirmation\n        await self._send_message(connection_id, WebSocketMessage(\n            type=MessageType.CONNECT,\n            data={\n                \"connection_id\": connection_id,\n                \"status\": \"connected\",\n                \"server_time\": datetime.utcnow().isoformat()\n            }\n        ))\n\n        # Start heartbeat task\n        asyncio.create_task(self._heartbeat_monitor(connection_id))\n\n        logger.info(f\"WebSocket connected: {connection_id} (user: {user_id})\")\n\n    async def disconnect(self, connection_id: str, code: int = 1000):\n        \"\"\"Handle WebSocket disconnection\"\"\"\n        if connection_id in self.active_connections:\n            # Remove from all channels\n            connection = self.connection_info.get(connection_id)\n            if connection:\n                for channel in connection.channels.copy():\n                    await self.leave_channel(connection_id, channel)\n\n            # Clean up local state\n            del self.active_connections[connection_id]\n            del self.connection_info[connection_id]\n\n            # Remove from Redis\n            await self._remove_connection_from_redis(connection_id)\n\n            logger.info(f\"WebSocket disconnected: {connection_id} (code: {code})\")\n\n    async def send_to_connection(self, connection_id: str, message: WebSocketMessage):\n        \"\"\"Send message to specific connection\"\"\"\n        if connection_id in self.active_connections:\n            await self._send_message(connection_id, message)\n        else:\n            # Try to send via Redis for distributed setup\n            await self._send_via_redis(connection_id, message)\n\n    async def send_to_user(self, user_id: str, message: WebSocketMessage):\n        \"\"\"Send message to all connections of a user\"\"\"\n        user_connections = [\n            conn_id for conn_id, info in self.connection_info.items()\n            if info.user_id == user_id\n        ]\n\n        for connection_id in user_connections:\n            await self.send_to_connection(connection_id, message)\n\n        # Also send via Redis for distributed setup\n        await self._send_to_user_via_redis(user_id, message)\n\n    async def broadcast_to_channel(self, channel: str, message: WebSocketMessage, exclude: Set[str] = None):\n        \"\"\"Broadcast message to all subscribers of a channel\"\"\"\n        exclude = exclude or set()\n        subscribers = self.channel_subscribers.get(channel, set())\n\n        for connection_id in subscribers:\n            if connection_id not in exclude:\n                await self.send_to_connection(connection_id, message)\n\n        # Broadcast via Redis for distributed setup\n        await self._broadcast_via_redis(channel, message, exclude)\n\n    async def join_channel(self, connection_id: str, channel: str) -&gt; bool:\n        \"\"\"Add connection to channel\"\"\"\n        if connection_id not in self.connection_info:\n            return False\n\n        # Add to local channel\n        if channel not in self.channel_subscribers:\n            self.channel_subscribers[channel] = set()\n        self.channel_subscribers[channel].add(connection_id)\n\n        # Update connection info\n        self.connection_info[connection_id].channels.add(channel)\n\n        # Store in Redis\n        await self._join_channel_in_redis(connection_id, channel)\n\n        # Notify channel about new subscriber\n        await self.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.PRESENCE,\n            data={\n                \"action\": \"joined\",\n                \"connection_id\": connection_id,\n                \"user_id\": self.connection_info[connection_id].user_id,\n                \"channel\": channel\n            }\n        ), exclude={connection_id})\n\n        logger.info(f\"Connection {connection_id} joined channel {channel}\")\n        return True\n\n    async def leave_channel(self, connection_id: str, channel: str) -&gt; bool:\n        \"\"\"Remove connection from channel\"\"\"\n        if connection_id not in self.connection_info:\n            return False\n\n        # Remove from local channel\n        if channel in self.channel_subscribers:\n            self.channel_subscribers[channel].discard(connection_id)\n            if not self.channel_subscribers[channel]:\n                del self.channel_subscribers[channel]\n\n        # Update connection info\n        self.connection_info[connection_id].channels.discard(channel)\n\n        # Remove from Redis\n        await self._leave_channel_in_redis(connection_id, channel)\n\n        # Notify channel about subscriber leaving\n        await self.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.PRESENCE,\n            data={\n                \"action\": \"left\",\n                \"connection_id\": connection_id,\n                \"user_id\": self.connection_info[connection_id].user_id,\n                \"channel\": channel\n            }\n        ))\n\n        logger.info(f\"Connection {connection_id} left channel {channel}\")\n        return True\n\n    async def _send_message(self, connection_id: str, message: WebSocketMessage):\n        \"\"\"Send message to WebSocket connection\"\"\"\n        websocket = self.active_connections.get(connection_id)\n        if websocket:\n            try:\n                await websocket.send_text(json.dumps({\n                    \"type\": message.type.value,\n                    \"data\": message.data,\n                    \"timestamp\": message.timestamp.isoformat(),\n                    \"message_id\": message.message_id,\n                    \"sender_id\": message.sender_id,\n                    \"recipient_id\": message.recipient_id,\n                    \"channel\": message.channel\n                }))\n            except Exception as e:\n                logger.error(f\"Failed to send message to {connection_id}: {e}\")\n                await self.disconnect(connection_id, code=1011)\n\n    async def _heartbeat_monitor(self, connection_id: str):\n        \"\"\"Monitor connection heartbeat\"\"\"\n        while connection_id in self.active_connections:\n            try:\n                await asyncio.sleep(self.heartbeat_interval)\n\n                if connection_id not in self.active_connections:\n                    break\n\n                # Send heartbeat\n                await self._send_message(connection_id, WebSocketMessage(\n                    type=MessageType.HEARTBEAT,\n                    data={\"timestamp\": datetime.utcnow().isoformat()}\n                ))\n\n                # Update last heartbeat\n                if connection_id in self.connection_info:\n                    self.connection_info[connection_id].last_heartbeat = datetime.utcnow()\n\n            except Exception as e:\n                logger.error(f\"Heartbeat failed for {connection_id}: {e}\")\n                await self.disconnect(connection_id, code=1011)\n                break\n\n    # Redis integration methods for distributed WebSocket support\n    async def _store_connection_in_redis(self, connection_id: str):\n        \"\"\"Store connection info in Redis\"\"\"\n        connection = self.connection_info[connection_id]\n        await self.redis.hset(\n            f\"ws:connections:{connection_id}\",\n            mapping={\n                \"user_id\": connection.user_id or \"\",\n                \"username\": connection.username or \"\",\n                \"connected_at\": connection.connected_at.isoformat(),\n                \"server_id\": self._get_server_id(),\n                \"metadata\": json.dumps(connection.metadata)\n            }\n        )\n        await self.redis.expire(f\"ws:connections:{connection_id}\", 3600)\n\n    async def _remove_connection_from_redis(self, connection_id: str):\n        \"\"\"Remove connection info from Redis\"\"\"\n        await self.redis.delete(f\"ws:connections:{connection_id}\")\n\n    async def _send_via_redis(self, connection_id: str, message: WebSocketMessage):\n        \"\"\"Send message via Redis pub/sub for distributed setup\"\"\"\n        await self.redis.publish(\n            f\"ws:direct:{connection_id}\",\n            json.dumps({\n                \"type\": message.type.value,\n                \"data\": message.data,\n                \"timestamp\": message.timestamp.isoformat(),\n                \"message_id\": message.message_id,\n                \"sender_id\": message.sender_id,\n                \"recipient_id\": message.recipient_id,\n                \"channel\": message.channel\n            })\n        )\n\n    def _get_server_id(self) -&gt; str:\n        \"\"\"Get unique server identifier\"\"\"\n        import socket\n        return f\"{socket.gethostname()}:{id(self)}\"\n\n# FastAPI WebSocket endpoints\napp = FastAPI()\nsecurity = HTTPBearer(auto_error=False)\n\n# Initialize WebSocket manager\nredis_client = redis.from_url(\"redis://localhost:6379\")\nws_manager = WebSocketManager(redis_client)\n\n@app.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket):\n    \"\"\"Public WebSocket endpoint\"\"\"\n    connection_id = str(uuid.uuid4())\n\n    try:\n        await ws_manager.connect(websocket, connection_id)\n\n        while True:\n            # Receive message from client\n            data = await websocket.receive_text()\n            try:\n                message_data = json.loads(data)\n                await handle_websocket_message(connection_id, message_data)\n            except json.JSONDecodeError:\n                await ws_manager.send_to_connection(connection_id, WebSocketMessage(\n                    type=MessageType.ERROR,\n                    data={\"error\": \"Invalid JSON format\"}\n                ))\n\n    except WebSocketDisconnect:\n        await ws_manager.disconnect(connection_id)\n    except Exception as e:\n        logger.error(f\"WebSocket error for {connection_id}: {e}\")\n        await ws_manager.disconnect(connection_id, code=1011)\n\n@app.websocket(\"/ws/authenticated\")\nasync def authenticated_websocket_endpoint(websocket: WebSocket, token: str = None):\n    \"\"\"Authenticated WebSocket endpoint\"\"\"\n    connection_id = str(uuid.uuid4())\n\n    # Authenticate user\n    user = None\n    if token:\n        try:\n            user = await authenticate_token(token)\n        except Exception:\n            await websocket.close(code=1008, reason=\"Authentication failed\")\n            return\n\n    try:\n        await ws_manager.connect(\n            websocket,\n            connection_id,\n            user_id=user.id if user else None,\n            username=user.username if user else None,\n            metadata={\"authenticated\": user is not None}\n        )\n\n        while True:\n            data = await websocket.receive_text()\n            try:\n                message_data = json.loads(data)\n                await handle_authenticated_message(connection_id, message_data, user)\n            except json.JSONDecodeError:\n                await ws_manager.send_to_connection(connection_id, WebSocketMessage(\n                    type=MessageType.ERROR,\n                    data={\"error\": \"Invalid JSON format\"}\n                ))\n\n    except WebSocketDisconnect:\n        await ws_manager.disconnect(connection_id)\n    except Exception as e:\n        logger.error(f\"Authenticated WebSocket error for {connection_id}: {e}\")\n        await ws_manager.disconnect(connection_id, code=1011)\n\nasync def handle_websocket_message(connection_id: str, message_data: Dict[str, Any]):\n    \"\"\"Handle incoming WebSocket message\"\"\"\n    message_type = message_data.get(\"type\")\n    data = message_data.get(\"data\", {})\n\n    if message_type == \"join_channel\":\n        channel = data.get(\"channel\")\n        if channel:\n            await ws_manager.join_channel(connection_id, channel)\n\n    elif message_type == \"leave_channel\":\n        channel = data.get(\"channel\")\n        if channel:\n            await ws_manager.leave_channel(connection_id, channel)\n\n    elif message_type == \"message\":\n        channel = data.get(\"channel\")\n        if channel:\n            await ws_manager.broadcast_to_channel(channel, WebSocketMessage(\n                type=MessageType.MESSAGE,\n                data=data,\n                sender_id=connection_id,\n                channel=channel\n            ))\n\n    elif message_type == \"heartbeat\":\n        # Update heartbeat timestamp\n        if connection_id in ws_manager.connection_info:\n            ws_manager.connection_info[connection_id].last_heartbeat = datetime.utcnow()\n\nasync def handle_authenticated_message(connection_id: str, message_data: Dict[str, Any], user):\n    \"\"\"Handle incoming authenticated WebSocket message\"\"\"\n    message_type = message_data.get(\"type\")\n    data = message_data.get(\"data\", {})\n\n    if message_type == \"private_message\":\n        recipient_id = data.get(\"recipient_id\")\n        if recipient_id:\n            await ws_manager.send_to_user(recipient_id, WebSocketMessage(\n                type=MessageType.PRIVATE,\n                data=data,\n                sender_id=user.id if user else connection_id,\n                recipient_id=recipient_id\n            ))\n\n    else:\n        # Handle regular message with user context\n        data[\"user_id\"] = user.id if user else None\n        data[\"username\"] = user.username if user else None\n        await handle_websocket_message(connection_id, message_data)\n\nasync def authenticate_token(token: str):\n    \"\"\"Authenticate JWT token\"\"\"\n    # Implementation depends on your auth system\n    # Return user object or raise exception\n    pass\n</code></pre>"},{"location":"atomic/real-time/websocket-patterns/#advanced-websocket-patterns","title":"Advanced WebSocket Patterns","text":""},{"location":"atomic/real-time/websocket-patterns/#chat-application-pattern","title":"Chat Application Pattern","text":"<pre><code>class ChatService:\n    \"\"\"Real-time chat service using WebSockets\"\"\"\n\n    def __init__(self, ws_manager: WebSocketManager, db_session):\n        self.ws_manager = ws_manager\n        self.db_session = db_session\n        self.typing_users: Dict[str, Set[str]] = {}  # channel -&gt; set of typing users\n\n    async def send_chat_message(\n        self,\n        sender_id: str,\n        channel: str,\n        content: str,\n        message_type: str = \"text\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Send chat message to channel\"\"\"\n\n        # Store message in database\n        message_record = await self._store_message(sender_id, channel, content, message_type)\n\n        # Broadcast to channel subscribers\n        await self.ws_manager.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.MESSAGE,\n            data={\n                \"message_id\": message_record[\"id\"],\n                \"sender_id\": sender_id,\n                \"sender_username\": message_record[\"sender_username\"],\n                \"content\": content,\n                \"message_type\": message_type,\n                \"timestamp\": message_record[\"created_at\"]\n            },\n            sender_id=sender_id,\n            channel=channel\n        ))\n\n        return message_record\n\n    async def handle_typing_indicator(self, user_id: str, channel: str, is_typing: bool):\n        \"\"\"Handle typing indicators\"\"\"\n        if channel not in self.typing_users:\n            self.typing_users[channel] = set()\n\n        if is_typing:\n            self.typing_users[channel].add(user_id)\n        else:\n            self.typing_users[channel].discard(user_id)\n\n        # Broadcast typing status\n        await self.ws_manager.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.TYPING,\n            data={\n                \"user_id\": user_id,\n                \"is_typing\": is_typing,\n                \"typing_users\": list(self.typing_users[channel])\n            },\n            channel=channel\n        ))\n\n        # Auto-stop typing after timeout\n        if is_typing:\n            asyncio.create_task(self._auto_stop_typing(user_id, channel))\n\n    async def _auto_stop_typing(self, user_id: str, channel: str):\n        \"\"\"Automatically stop typing indicator after timeout\"\"\"\n        await asyncio.sleep(5)  # 5 seconds timeout\n\n        if channel in self.typing_users and user_id in self.typing_users[channel]:\n            await self.handle_typing_indicator(user_id, channel, False)\n\n    async def get_chat_history(self, channel: str, limit: int = 50, offset: int = 0) -&gt; List[Dict]:\n        \"\"\"Get chat message history\"\"\"\n        # Implementation would query database for chat history\n        return []\n\n    async def _store_message(self, sender_id: str, channel: str, content: str, message_type: str) -&gt; Dict:\n        \"\"\"Store chat message in database\"\"\"\n        # Implementation would store in database and return message record\n        return {\n            \"id\": str(uuid.uuid4()),\n            \"sender_id\": sender_id,\n            \"sender_username\": \"user\",  # Get from database\n            \"channel\": channel,\n            \"content\": content,\n            \"message_type\": message_type,\n            \"created_at\": datetime.utcnow().isoformat()\n        }\n\nclass CollaborativeEditingService:\n    \"\"\"Real-time collaborative editing using WebSockets\"\"\"\n\n    def __init__(self, ws_manager: WebSocketManager, redis_client: redis.Redis):\n        self.ws_manager = ws_manager\n        self.redis = redis_client\n\n    async def handle_document_operation(\n        self,\n        user_id: str,\n        document_id: str,\n        operation: Dict[str, Any]\n    ):\n        \"\"\"Handle collaborative editing operation\"\"\"\n\n        # Apply operational transformation\n        transformed_operation = await self._transform_operation(document_id, operation)\n\n        # Store operation in Redis for conflict resolution\n        await self._store_operation(document_id, transformed_operation)\n\n        # Broadcast to all document collaborators\n        channel = f\"document:{document_id}\"\n        await self.ws_manager.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.MESSAGE,\n            data={\n                \"operation_type\": \"document_operation\",\n                \"document_id\": document_id,\n                \"operation\": transformed_operation,\n                \"user_id\": user_id\n            },\n            sender_id=user_id,\n            channel=channel\n        ))\n\n    async def handle_cursor_position(self, user_id: str, document_id: str, position: Dict[str, int]):\n        \"\"\"Handle cursor position updates\"\"\"\n        channel = f\"document:{document_id}\"\n\n        await self.ws_manager.broadcast_to_channel(channel, WebSocketMessage(\n            type=MessageType.MESSAGE,\n            data={\n                \"operation_type\": \"cursor_position\",\n                \"document_id\": document_id,\n                \"user_id\": user_id,\n                \"position\": position\n            },\n            sender_id=user_id,\n            channel=channel\n        ))\n\n    async def _transform_operation(self, document_id: str, operation: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Apply operational transformation for conflict resolution\"\"\"\n        # Simplified OT implementation\n        # In production, use a library like ShareJS or Yjs\n        return operation\n\n    async def _store_operation(self, document_id: str, operation: Dict[str, Any]):\n        \"\"\"Store operation for replay and conflict resolution\"\"\"\n        operation_id = str(uuid.uuid4())\n        await self.redis.lpush(\n            f\"document_operations:{document_id}\",\n            json.dumps({\n                \"id\": operation_id,\n                \"operation\": operation,\n                \"timestamp\": datetime.utcnow().isoformat()\n            })\n        )\n\n        # Keep only last 1000 operations\n        await self.redis.ltrim(f\"document_operations:{document_id}\", 0, 999)\n</code></pre>"},{"location":"atomic/real-time/websocket-patterns/#websocket-scaling-and-load-balancing","title":"WebSocket Scaling and Load Balancing","text":""},{"location":"atomic/real-time/websocket-patterns/#redis-based-scaling","title":"Redis-based Scaling","text":"<pre><code>class DistributedWebSocketManager:\n    \"\"\"WebSocket manager with Redis-based distributed scaling\"\"\"\n\n    def __init__(self, redis_client: redis.Redis, server_id: str):\n        self.redis = redis_client\n        self.server_id = server_id\n        self.local_manager = WebSocketManager(redis_client)\n        self.pubsub = None\n\n    async def start_distributed_mode(self):\n        \"\"\"Start listening to Redis pub/sub for distributed messages\"\"\"\n        self.pubsub = self.redis.pubsub()\n\n        # Subscribe to relevant channels\n        await self.pubsub.subscribe(\n            f\"ws:server:{self.server_id}\",\n            \"ws:broadcast:*\",\n            \"ws:user:*\"\n        )\n\n        # Start message processing task\n        asyncio.create_task(self._process_distributed_messages())\n\n    async def _process_distributed_messages(self):\n        \"\"\"Process messages from other WebSocket servers\"\"\"\n        async for message in self.pubsub.listen():\n            if message[\"type\"] == \"message\":\n                try:\n                    data = json.loads(message[\"data\"])\n                    await self._handle_distributed_message(message[\"channel\"], data)\n                except Exception as e:\n                    logger.error(f\"Error processing distributed message: {e}\")\n\n    async def _handle_distributed_message(self, channel: str, data: Dict[str, Any]):\n        \"\"\"Handle message from other WebSocket servers\"\"\"\n        if channel.startswith(\"ws:broadcast:\"):\n            # Handle broadcast message\n            target_channel = channel.replace(\"ws:broadcast:\", \"\")\n            message = WebSocketMessage(\n                type=MessageType(data[\"type\"]),\n                data=data[\"data\"],\n                sender_id=data.get(\"sender_id\"),\n                channel=target_channel\n            )\n            await self.local_manager.broadcast_to_channel(target_channel, message)\n\n        elif channel.startswith(\"ws:user:\"):\n            # Handle user-specific message\n            user_id = channel.replace(\"ws:user:\", \"\")\n            message = WebSocketMessage(\n                type=MessageType(data[\"type\"]),\n                data=data[\"data\"],\n                sender_id=data.get(\"sender_id\"),\n                recipient_id=user_id\n            )\n            await self.local_manager.send_to_user(user_id, message)\n\n        elif channel == f\"ws:server:{self.server_id}\":\n            # Handle server-specific message\n            connection_id = data.get(\"connection_id\")\n            if connection_id:\n                message = WebSocketMessage(\n                    type=MessageType(data[\"type\"]),\n                    data=data[\"data\"],\n                    sender_id=data.get(\"sender_id\")\n                )\n                await self.local_manager.send_to_connection(connection_id, message)\n\n    async def broadcast_across_servers(self, channel: str, message: WebSocketMessage):\n        \"\"\"Broadcast message across all WebSocket servers\"\"\"\n        await self.redis.publish(\n            f\"ws:broadcast:{channel}\",\n            json.dumps({\n                \"type\": message.type.value,\n                \"data\": message.data,\n                \"sender_id\": message.sender_id,\n                \"timestamp\": message.timestamp.isoformat()\n            })\n        )\n\n    async def send_to_user_across_servers(self, user_id: str, message: WebSocketMessage):\n        \"\"\"Send message to user across all servers\"\"\"\n        await self.redis.publish(\n            f\"ws:user:{user_id}\",\n            json.dumps({\n                \"type\": message.type.value,\n                \"data\": message.data,\n                \"sender_id\": message.sender_id,\n                \"timestamp\": message.timestamp.isoformat()\n            })\n        )\n\nclass WebSocketLoadBalancer:\n    \"\"\"Load balancer for WebSocket connections\"\"\"\n\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.server_stats = {}\n\n    async def get_best_server(self) -&gt; str:\n        \"\"\"Get the best server for new WebSocket connection\"\"\"\n        servers = await self._get_active_servers()\n\n        if not servers:\n            raise Exception(\"No active WebSocket servers available\")\n\n        # Simple round-robin or least connections algorithm\n        best_server = min(servers, key=lambda s: s[\"connection_count\"])\n        return best_server[\"server_id\"]\n\n    async def _get_active_servers(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get list of active WebSocket servers\"\"\"\n        servers = []\n        server_keys = await self.redis.keys(\"ws:server:*:stats\")\n\n        for key in server_keys:\n            stats = await self.redis.hgetall(key)\n            if stats:\n                servers.append({\n                    \"server_id\": key.split(\":\")[2],\n                    \"connection_count\": int(stats.get(\"connections\", 0)),\n                    \"last_heartbeat\": stats.get(\"last_heartbeat\"),\n                    \"cpu_usage\": float(stats.get(\"cpu_usage\", 0)),\n                    \"memory_usage\": float(stats.get(\"memory_usage\", 0))\n                })\n\n        # Filter out stale servers\n        current_time = datetime.utcnow()\n        active_servers = []\n\n        for server in servers:\n            try:\n                last_heartbeat = datetime.fromisoformat(server[\"last_heartbeat\"])\n                if (current_time - last_heartbeat).seconds &lt; 60:  # 1 minute threshold\n                    active_servers.append(server)\n            except (ValueError, TypeError):\n                continue\n\n        return active_servers\n\n    async def update_server_stats(self, server_id: str, stats: Dict[str, Any]):\n        \"\"\"Update server statistics\"\"\"\n        await self.redis.hset(\n            f\"ws:server:{server_id}:stats\",\n            mapping={\n                \"connections\": stats.get(\"connections\", 0),\n                \"cpu_usage\": stats.get(\"cpu_usage\", 0),\n                \"memory_usage\": stats.get(\"memory_usage\", 0),\n                \"last_heartbeat\": datetime.utcnow().isoformat()\n            }\n        )\n        await self.redis.expire(f\"ws:server:{server_id}:stats\", 120)  # 2 minutes TTL\n</code></pre>"},{"location":"atomic/real-time/websocket-patterns/#testing-websocket-implementation","title":"Testing WebSocket Implementation","text":""},{"location":"atomic/real-time/websocket-patterns/#websocket-testing-framework","title":"WebSocket Testing Framework","text":"<pre><code>import pytest\nimport asyncio\nfrom fastapi.testclient import TestClient\nfrom fastapi.websockets import WebSocketDisconnect\n\nclass WebSocketTester:\n    \"\"\"Testing utilities for WebSocket functionality\"\"\"\n\n    def __init__(self, app):\n        self.app = app\n        self.client = TestClient(app)\n\n    async def test_websocket_connection(self):\n        \"\"\"Test basic WebSocket connection\"\"\"\n        with self.client.websocket_connect(\"/ws\") as websocket:\n            # Test connection established\n            data = websocket.receive_json()\n            assert data[\"type\"] == \"connect\"\n            assert \"connection_id\" in data[\"data\"]\n\n    async def test_channel_join_leave(self):\n        \"\"\"Test joining and leaving channels\"\"\"\n        with self.client.websocket_connect(\"/ws\") as websocket:\n            # Receive connection message\n            websocket.receive_json()\n\n            # Join channel\n            websocket.send_json({\n                \"type\": \"join_channel\",\n                \"data\": {\"channel\": \"test_channel\"}\n            })\n\n            # Send message to channel\n            websocket.send_json({\n                \"type\": \"message\",\n                \"data\": {\n                    \"channel\": \"test_channel\",\n                    \"content\": \"Hello, channel!\"\n                }\n            })\n\n            # Receive echoed message\n            message = websocket.receive_json()\n            assert message[\"type\"] == \"message\"\n            assert message[\"data\"][\"content\"] == \"Hello, channel!\"\n\n    async def test_multiple_connections(self):\n        \"\"\"Test multiple WebSocket connections\"\"\"\n        async def client_handler(client_id: str, messages: List):\n            with self.client.websocket_connect(\"/ws\") as websocket:\n                websocket.receive_json()  # Connection message\n\n                # Join test channel\n                websocket.send_json({\n                    \"type\": \"join_channel\",\n                    \"data\": {\"channel\": \"multi_test\"}\n                })\n\n                # Send message\n                websocket.send_json({\n                    \"type\": \"message\",\n                    \"data\": {\n                        \"channel\": \"multi_test\",\n                        \"content\": f\"Message from {client_id}\"\n                    }\n                })\n\n                # Collect messages\n                for _ in range(2):  # Expect 2 messages (one from each client)\n                    msg = websocket.receive_json()\n                    if msg[\"type\"] == \"message\":\n                        messages.append(msg)\n\n        messages1 = []\n        messages2 = []\n\n        # Run both clients concurrently\n        await asyncio.gather(\n            client_handler(\"client1\", messages1),\n            client_handler(\"client2\", messages2)\n        )\n\n        # Verify both clients received messages\n        assert len(messages1) &gt;= 1\n        assert len(messages2) &gt;= 1\n\n    async def test_authentication_required(self):\n        \"\"\"Test authenticated WebSocket endpoint\"\"\"\n        # Test without token (should fail)\n        with pytest.raises(WebSocketDisconnect):\n            with self.client.websocket_connect(\"/ws/authenticated\"):\n                pass\n\n        # Test with valid token\n        valid_token = \"valid_jwt_token\"  # Generate valid token for test\n        with self.client.websocket_connect(\n            f\"/ws/authenticated?token={valid_token}\"\n        ) as websocket:\n            data = websocket.receive_json()\n            assert data[\"type\"] == \"connect\"\n\nclass WebSocketPerformanceTester:\n    \"\"\"Performance testing for WebSocket implementation\"\"\"\n\n    async def test_connection_throughput(self, concurrent_connections: int = 100):\n        \"\"\"Test handling multiple concurrent connections\"\"\"\n        connections = []\n        start_time = asyncio.get_event_loop().time()\n\n        try:\n            # Create concurrent connections\n            for i in range(concurrent_connections):\n                websocket = self.client.websocket_connect(\"/ws\")\n                connections.append(websocket)\n                await asyncio.sleep(0.01)  # Small delay between connections\n\n            connection_time = asyncio.get_event_loop().time() - start_time\n\n            # Test message broadcasting\n            start_time = asyncio.get_event_loop().time()\n\n            # Send messages from each connection\n            for i, websocket in enumerate(connections):\n                websocket.send_json({\n                    \"type\": \"join_channel\",\n                    \"data\": {\"channel\": \"performance_test\"}\n                })\n\n                websocket.send_json({\n                    \"type\": \"message\",\n                    \"data\": {\n                        \"channel\": \"performance_test\",\n                        \"content\": f\"Message {i}\"\n                    }\n                })\n\n            broadcast_time = asyncio.get_event_loop().time() - start_time\n\n            return {\n                \"concurrent_connections\": concurrent_connections,\n                \"connection_time\": connection_time,\n                \"broadcast_time\": broadcast_time,\n                \"avg_connection_time\": connection_time / concurrent_connections,\n                \"messages_per_second\": concurrent_connections / broadcast_time\n            }\n\n        finally:\n            # Clean up connections\n            for websocket in connections:\n                try:\n                    websocket.close()\n                except:\n                    pass\n\n# pytest fixtures and test cases\n@pytest.fixture\ndef websocket_tester():\n    return WebSocketTester(app)\n\n@pytest.mark.asyncio\nasync def test_basic_websocket_functionality(websocket_tester):\n    await websocket_tester.test_websocket_connection()\n\n@pytest.mark.asyncio\nasync def test_channel_operations(websocket_tester):\n    await websocket_tester.test_channel_join_leave()\n\n@pytest.mark.asyncio\nasync def test_concurrent_connections(websocket_tester):\n    await websocket_tester.test_multiple_connections()\n</code></pre>"},{"location":"atomic/real-time/websocket-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Server-Sent Events Implementation</li> <li>Push Notifications</li> <li>Real-time Sync Patterns</li> <li>FastAPI Basic Setup</li> </ul>"},{"location":"atomic/real-time/websocket-patterns/#best-practices","title":"Best Practices","text":"<ol> <li>Connection Management:</li> <li>Implement proper heartbeat mechanisms</li> <li>Handle disconnections gracefully</li> <li> <p>Use connection pooling for scaling</p> </li> <li> <p>Message Handling:</p> </li> <li>Validate all incoming messages</li> <li>Implement message queuing for reliability</li> <li> <p>Use structured message formats</p> </li> <li> <p>Security:</p> </li> <li>Authenticate WebSocket connections</li> <li>Validate user permissions for channels</li> <li> <p>Implement rate limiting</p> </li> <li> <p>Scaling:</p> </li> <li>Use Redis for distributed WebSocket coordination</li> <li>Implement load balancing strategies</li> <li> <p>Monitor connection metrics</p> </li> <li> <p>Performance:</p> </li> <li>Optimize message serialization</li> <li>Use efficient data structures</li> <li>Implement proper error handling</li> </ol>"},{"location":"atomic/real-time/websocket-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/real-time/real-time-sync-patterns.md</code> \u2014 Sync patterns</li> <li><code>docs/atomic/real-time/sse-implementation.md</code> \u2014 SSE alternative</li> <li><code>docs/atomic/services/fastapi/websocket-support.md</code> \u2014 FastAPI WebSocket</li> <li><code>docs/atomic/infrastructure/nginx.md</code> \u2014 WebSocket proxy</li> </ul>"},{"location":"atomic/security/authentication-authorization-guide/","title":"Authentication &amp; Authorization Guide","text":"<p>Comprehensive guide for implementing authentication and authorization in microservices using FastAPI, JWT tokens, and Redis.</p>"},{"location":"atomic/security/authentication-authorization-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>FastAPI service setup (FastAPI Basic Setup)</li> <li>Redis integration (Redis Connection Management)</li> <li>Understanding of JWT concepts</li> </ul>"},{"location":"atomic/security/authentication-authorization-guide/#jwt-implementation-with-fastapi","title":"JWT Implementation with FastAPI","text":""},{"location":"atomic/security/authentication-authorization-guide/#token-structure","title":"Token Structure","text":"<pre><code>from datetime import datetime, timedelta\nfrom typing import Optional\nimport jwt\nfrom pydantic import BaseModel\n\nclass TokenData(BaseModel):\n    user_id: str\n    username: str\n    roles: list[str]\n    exp: datetime\n    iat: datetime\n    jti: str  # JWT ID for blacklisting\n\nclass AuthConfig:\n    SECRET_KEY: str = \"your-secret-key\"\n    ALGORITHM: str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n    REFRESH_TOKEN_EXPIRE_DAYS: int = 7\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#token-generation-service","title":"Token Generation Service","text":"<pre><code>import uuid\nfrom datetime import datetime, timedelta\nimport jwt\nimport redis.asyncio as redis\n\nclass TokenService:\n    def __init__(self, redis_client: redis.Redis, config: AuthConfig):\n        self.redis = redis_client\n        self.config = config\n\n    async def create_access_token(\n        self,\n        user_id: str,\n        username: str,\n        roles: list[str]\n    ) -&gt; str:\n        now = datetime.utcnow()\n        jti = str(uuid.uuid4())\n\n        payload = {\n            \"user_id\": user_id,\n            \"username\": username,\n            \"roles\": roles,\n            \"exp\": now + timedelta(minutes=self.config.ACCESS_TOKEN_EXPIRE_MINUTES),\n            \"iat\": now,\n            \"jti\": jti,\n            \"type\": \"access\"\n        }\n\n        token = jwt.encode(payload, self.config.SECRET_KEY, algorithm=self.config.ALGORITHM)\n\n        # Store in Redis for tracking\n        await self.redis.setex(\n            f\"token:access:{jti}\",\n            self.config.ACCESS_TOKEN_EXPIRE_MINUTES * 60,\n            user_id\n        )\n\n        return token\n\n    async def create_refresh_token(self, user_id: str) -&gt; str:\n        now = datetime.utcnow()\n        jti = str(uuid.uuid4())\n\n        payload = {\n            \"user_id\": user_id,\n            \"exp\": now + timedelta(days=self.config.REFRESH_TOKEN_EXPIRE_DAYS),\n            \"iat\": now,\n            \"jti\": jti,\n            \"type\": \"refresh\"\n        }\n\n        token = jwt.encode(payload, self.config.SECRET_KEY, algorithm=self.config.ALGORITHM)\n\n        # Store in Redis\n        await self.redis.setex(\n            f\"token:refresh:{jti}\",\n            self.config.REFRESH_TOKEN_EXPIRE_DAYS * 24 * 60 * 60,\n            user_id\n        )\n\n        return token\n\n    async def verify_token(self, token: str, token_type: str = \"access\") -&gt; Optional[dict]:\n        try:\n            payload = jwt.decode(\n                token,\n                self.config.SECRET_KEY,\n                algorithms=[self.config.ALGORITHM]\n            )\n\n            if payload.get(\"type\") != token_type:\n                return None\n\n            jti = payload.get(\"jti\")\n            if not jti:\n                return None\n\n            # Check if token is blacklisted\n            if await self.redis.get(f\"blacklist:{jti}\"):\n                return None\n\n            # Check if token exists in Redis\n            stored_user_id = await self.redis.get(f\"token:{token_type}:{jti}\")\n            if not stored_user_id:\n                return None\n\n            return payload\n\n        except jwt.ExpiredSignatureError:\n            return None\n        except jwt.InvalidTokenError:\n            return None\n\n    async def blacklist_token(self, token: str):\n        try:\n            payload = jwt.decode(\n                token,\n                self.config.SECRET_KEY,\n                algorithms=[self.config.ALGORITHM],\n                options={\"verify_exp\": False}\n            )\n\n            jti = payload.get(\"jti\")\n            if jti:\n                # Add to blacklist with remaining TTL\n                exp = payload.get(\"exp\", 0)\n                current_time = datetime.utcnow().timestamp()\n                ttl = max(int(exp - current_time), 1)\n\n                await self.redis.setex(f\"blacklist:{jti}\", ttl, \"1\")\n\n        except jwt.InvalidTokenError:\n            pass\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#rbac-patterns-and-examples","title":"RBAC Patterns and Examples","text":""},{"location":"atomic/security/authentication-authorization-guide/#role-definition","title":"Role Definition","text":"<pre><code>from enum import Enum\nfrom typing import Set\n\nclass Permission(Enum):\n    READ_USERS = \"read:users\"\n    WRITE_USERS = \"write:users\"\n    DELETE_USERS = \"delete:users\"\n    READ_ORDERS = \"read:orders\"\n    WRITE_ORDERS = \"write:orders\"\n    ADMIN_ACCESS = \"admin:access\"\n\nclass Role(Enum):\n    GUEST = \"guest\"\n    USER = \"user\"\n    MODERATOR = \"moderator\"\n    ADMIN = \"admin\"\n\nROLE_PERMISSIONS = {\n    Role.GUEST: {Permission.READ_ORDERS},\n    Role.USER: {\n        Permission.READ_USERS,\n        Permission.READ_ORDERS,\n        Permission.WRITE_ORDERS\n    },\n    Role.MODERATOR: {\n        Permission.READ_USERS,\n        Permission.WRITE_USERS,\n        Permission.READ_ORDERS,\n        Permission.WRITE_ORDERS,\n    },\n    Role.ADMIN: {\n        Permission.READ_USERS,\n        Permission.WRITE_USERS,\n        Permission.DELETE_USERS,\n        Permission.READ_ORDERS,\n        Permission.WRITE_ORDERS,\n        Permission.ADMIN_ACCESS,\n    }\n}\n\ndef get_permissions_for_roles(roles: list[str]) -&gt; Set[Permission]:\n    permissions = set()\n    for role_str in roles:\n        try:\n            role = Role(role_str)\n            permissions.update(ROLE_PERMISSIONS.get(role, set()))\n        except ValueError:\n            continue\n    return permissions\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#authorization-dependency","title":"Authorization Dependency","text":"<pre><code>from fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n\nsecurity = HTTPBearer()\n\nclass AuthDependency:\n    def __init__(self, token_service: TokenService):\n        self.token_service = token_service\n\n    async def get_current_user(\n        self,\n        credentials: HTTPAuthorizationCredentials = Depends(security)\n    ) -&gt; dict:\n        token = credentials.credentials\n        payload = await self.token_service.verify_token(token)\n\n        if not payload:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Invalid authentication credentials\",\n                headers={\"WWW-Authenticate\": \"Bearer\"},\n            )\n\n        return payload\n\n    def require_permissions(self, required_permissions: Set[Permission]):\n        async def permission_checker(\n            current_user: dict = Depends(self.get_current_user)\n        ):\n            user_roles = current_user.get(\"roles\", [])\n            user_permissions = get_permissions_for_roles(user_roles)\n\n            if not required_permissions.issubset(user_permissions):\n                raise HTTPException(\n                    status_code=status.HTTP_403_FORBIDDEN,\n                    detail=\"Insufficient permissions\"\n                )\n\n            return current_user\n\n        return permission_checker\n\n    def require_roles(self, required_roles: Set[Role]):\n        async def role_checker(\n            current_user: dict = Depends(self.get_current_user)\n        ):\n            user_roles = {Role(role) for role in current_user.get(\"roles\", []) if role in [r.value for r in Role]}\n\n            if not required_roles.intersection(user_roles):\n                raise HTTPException(\n                    status_code=status.HTTP_403_FORBIDDEN,\n                    detail=\"Insufficient role privileges\"\n                )\n\n            return current_user\n\n        return role_checker\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#session-management-with-redis","title":"Session Management with Redis","text":""},{"location":"atomic/security/authentication-authorization-guide/#session-storage","title":"Session Storage","text":"<pre><code>import json\nfrom datetime import timedelta\n\nclass SessionManager:\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.session_ttl = timedelta(hours=24)\n\n    async def create_session(self, user_id: str, session_data: dict) -&gt; str:\n        session_id = str(uuid.uuid4())\n        session_key = f\"session:{session_id}\"\n\n        session_payload = {\n            \"user_id\": user_id,\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"last_activity\": datetime.utcnow().isoformat(),\n            **session_data\n        }\n\n        await self.redis.setex(\n            session_key,\n            int(self.session_ttl.total_seconds()),\n            json.dumps(session_payload)\n        )\n\n        # Track active sessions for user\n        await self.redis.sadd(f\"user_sessions:{user_id}\", session_id)\n        await self.redis.expire(f\"user_sessions:{user_id}\", int(self.session_ttl.total_seconds()))\n\n        return session_id\n\n    async def get_session(self, session_id: str) -&gt; Optional[dict]:\n        session_data = await self.redis.get(f\"session:{session_id}\")\n\n        if not session_data:\n            return None\n\n        session = json.loads(session_data)\n\n        # Update last activity\n        session[\"last_activity\"] = datetime.utcnow().isoformat()\n        await self.redis.setex(\n            f\"session:{session_id}\",\n            int(self.session_ttl.total_seconds()),\n            json.dumps(session)\n        )\n\n        return session\n\n    async def invalidate_session(self, session_id: str):\n        session_data = await self.redis.get(f\"session:{session_id}\")\n        if session_data:\n            session = json.loads(session_data)\n            user_id = session.get(\"user_id\")\n\n            if user_id:\n                await self.redis.srem(f\"user_sessions:{user_id}\", session_id)\n\n        await self.redis.delete(f\"session:{session_id}\")\n\n    async def invalidate_all_user_sessions(self, user_id: str):\n        session_ids = await self.redis.smembers(f\"user_sessions:{user_id}\")\n\n        for session_id in session_ids:\n            await self.redis.delete(f\"session:{session_id}\")\n\n        await self.redis.delete(f\"user_sessions:{user_id}\")\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#mfa-integration-examples","title":"MFA Integration Examples","text":""},{"location":"atomic/security/authentication-authorization-guide/#totp-implementation","title":"TOTP Implementation","text":"<pre><code>import pyotp\nimport qrcode\nfrom io import BytesIO\nimport base64\n\nclass MFAService:\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n\n    def generate_secret(self, user_id: str) -&gt; str:\n        secret = pyotp.random_base32()\n        return secret\n\n    async def setup_totp(self, user_id: str, app_name: str = \"YourApp\") -&gt; dict:\n        secret = self.generate_secret(user_id)\n\n        # Store temporary secret (not confirmed yet)\n        await self.redis.setex(\n            f\"mfa_setup:{user_id}\",\n            300,  # 5 minutes\n            secret\n        )\n\n        # Generate QR code\n        totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(\n            name=user_id,\n            issuer_name=app_name\n        )\n\n        qr = qrcode.QRCode(version=1, box_size=10, border=5)\n        qr.add_data(totp_uri)\n        qr.make(fit=True)\n\n        img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n        buffer = BytesIO()\n        img.save(buffer, format='PNG')\n        qr_code_base64 = base64.b64encode(buffer.getvalue()).decode()\n\n        return {\n            \"secret\": secret,\n            \"qr_code\": qr_code_base64,\n            \"totp_uri\": totp_uri\n        }\n\n    async def confirm_totp_setup(self, user_id: str, verification_code: str) -&gt; bool:\n        secret = await self.redis.get(f\"mfa_setup:{user_id}\")\n\n        if not secret:\n            return False\n\n        totp = pyotp.TOTP(secret)\n\n        if totp.verify(verification_code, valid_window=1):\n            # Save confirmed secret\n            await self.redis.set(f\"mfa_secret:{user_id}\", secret)\n            # Remove setup secret\n            await self.redis.delete(f\"mfa_setup:{user_id}\")\n            return True\n\n        return False\n\n    async def verify_totp(self, user_id: str, verification_code: str) -&gt; bool:\n        secret = await self.redis.get(f\"mfa_secret:{user_id}\")\n\n        if not secret:\n            return False\n\n        totp = pyotp.TOTP(secret)\n        return totp.verify(verification_code, valid_window=1)\n\n    async def is_mfa_enabled(self, user_id: str) -&gt; bool:\n        secret = await self.redis.get(f\"mfa_secret:{user_id}\")\n        return secret is not None\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"atomic/security/authentication-authorization-guide/#complete-authentication-setup","title":"Complete Authentication Setup","text":"<pre><code>from fastapi import FastAPI, Depends, HTTPException, status\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(title=\"Secure Microservice\")\n\n# Initialize services\nauth_config = AuthConfig()\nredis_client = redis.from_url(\"redis://localhost:6379/0\")\ntoken_service = TokenService(redis_client, auth_config)\nsession_manager = SessionManager(redis_client)\nmfa_service = MFAService(redis_client)\nauth_dependency = AuthDependency(token_service)\n\n# Authentication endpoints\n@app.post(\"/auth/login\")\nasync def login(credentials: LoginRequest):\n    # Validate user credentials (implement your user validation)\n    user = await validate_user_credentials(credentials.username, credentials.password)\n\n    if not user:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid credentials\"\n        )\n\n    # Check if MFA is enabled\n    if await mfa_service.is_mfa_enabled(user.id):\n        # Return temporary token for MFA verification\n        temp_token = await token_service.create_access_token(\n            user_id=user.id,\n            username=user.username,\n            roles=[\"mfa_pending\"]\n        )\n        return {\"requires_mfa\": True, \"temp_token\": temp_token}\n\n    # Create full access tokens\n    access_token = await token_service.create_access_token(\n        user_id=user.id,\n        username=user.username,\n        roles=user.roles\n    )\n    refresh_token = await token_service.create_refresh_token(user.id)\n\n    # Create session\n    session_id = await session_manager.create_session(\n        user_id=user.id,\n        session_data={\"ip\": \"request.client.host\", \"user_agent\": \"request.headers.get('user-agent')\"}\n    )\n\n    return {\n        \"access_token\": access_token,\n        \"refresh_token\": refresh_token,\n        \"session_id\": session_id,\n        \"token_type\": \"bearer\"\n    }\n\n@app.post(\"/auth/verify-mfa\")\nasync def verify_mfa(\n    mfa_request: MFAVerificationRequest,\n    temp_user: dict = Depends(auth_dependency.require_roles({Role.GUEST}))\n):\n    user_id = temp_user[\"user_id\"]\n\n    if not await mfa_service.verify_totp(user_id, mfa_request.code):\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid MFA code\"\n        )\n\n    # Get full user data and create proper tokens\n    user = await get_user_by_id(user_id)\n\n    access_token = await token_service.create_access_token(\n        user_id=user.id,\n        username=user.username,\n        roles=user.roles\n    )\n    refresh_token = await token_service.create_refresh_token(user.id)\n\n    return {\n        \"access_token\": access_token,\n        \"refresh_token\": refresh_token,\n        \"token_type\": \"bearer\"\n    }\n\n# Protected endpoint example\n@app.get(\"/users/profile\")\nasync def get_profile(\n    current_user: dict = Depends(auth_dependency.require_permissions({Permission.READ_USERS}))\n):\n    return {\"user_id\": current_user[\"user_id\"], \"username\": current_user[\"username\"]}\n\n@app.delete(\"/admin/users/{user_id}\")\nasync def delete_user(\n    user_id: str,\n    current_user: dict = Depends(auth_dependency.require_permissions({Permission.DELETE_USERS}))\n):\n    # Implement user deletion\n    return {\"message\": f\"User {user_id} deleted by {current_user['username']}\"}\n</code></pre>"},{"location":"atomic/security/authentication-authorization-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>FastAPI Security Patterns</li> <li>Redis Integration Guide</li> <li>Session Management Patterns</li> <li>Security Testing Guide</li> </ul>"},{"location":"atomic/security/authentication-authorization-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Token Security:</li> <li>Use strong, randomly generated secrets</li> <li>Implement proper token rotation</li> <li> <p>Store tokens securely in Redis with appropriate TTL</p> </li> <li> <p>Role-Based Access:</p> </li> <li>Design granular permissions</li> <li>Use principle of least privilege</li> <li> <p>Implement role inheritance when appropriate</p> </li> <li> <p>Session Management:</p> </li> <li>Track active sessions per user</li> <li>Implement session invalidation on security events</li> <li> <p>Monitor for concurrent sessions</p> </li> <li> <p>MFA Implementation:</p> </li> <li>Provide backup codes for recovery</li> <li>Implement rate limiting for MFA attempts</li> <li> <p>Use secure secret storage</p> </li> <li> <p>Monitoring and Logging:</p> </li> <li>Log all authentication attempts</li> <li>Monitor for brute force attacks</li> <li>Track session anomalies</li> </ol>"},{"location":"atomic/security/authentication-authorization-guide/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/security/session-management-patterns.md</code> \u2014 Session handling</li> <li><code>docs/atomic/services/fastapi/security-patterns.md</code> \u2014 FastAPI security</li> <li><code>docs/atomic/infrastructure/secrets-management.md</code> \u2014 Secret storage</li> <li><code>docs/atomic/security/security-testing-guide.md</code> \u2014 Security testing</li> </ul>"},{"location":"atomic/security/authorization-patterns/","title":"Authorization Patterns","text":"<p>Advanced authorization patterns and implementations for microservices architecture following the Improved Hybrid Approach.</p>"},{"location":"atomic/security/authorization-patterns/#overview","title":"Overview","text":"<p>Authorization patterns define how permissions and access control are implemented across business and data services. This document covers advanced RBAC, ABAC, and resource-based authorization patterns.</p>"},{"location":"atomic/security/authorization-patterns/#advanced-rbac-patterns","title":"Advanced RBAC Patterns","text":""},{"location":"atomic/security/authorization-patterns/#1-hierarchical-roles","title":"1. Hierarchical Roles","text":"<pre><code># src/core/rbac.py\nfrom typing import Dict, Set, List\nfrom enum import Enum\n\nclass RoleHierarchy:\n    \"\"\"Hierarchical role management with inheritance.\"\"\"\n\n    def __init__(self):\n        self.hierarchy = {\n            \"super_admin\": [\"admin\", \"moderator\", \"user\"],\n            \"admin\": [\"moderator\", \"user\"],\n            \"moderator\": [\"user\"],\n            \"user\": []\n        }\n\n        self.role_permissions = {\n            \"super_admin\": {\"*\"},  # All permissions\n            \"admin\": {\n                \"user:create\", \"user:read\", \"user:update\", \"user:delete\",\n                \"content:manage\", \"reports:view\", \"system:configure\"\n            },\n            \"moderator\": {\n                \"user:read\", \"content:manage\", \"content:moderate\"\n            },\n            \"user\": {\n                \"user:read_own\", \"content:create\", \"content:read\"\n            }\n        }\n\n    def get_effective_permissions(self, roles: List[str]) -&gt; Set[str]:\n        \"\"\"Get all permissions including inherited from role hierarchy.\"\"\"\n        effective_permissions = set()\n\n        for role in roles:\n            # Add direct permissions\n            if role in self.role_permissions:\n                effective_permissions.update(self.role_permissions[role])\n\n            # Add inherited permissions\n            inherited_roles = self.hierarchy.get(role, [])\n            for inherited_role in inherited_roles:\n                if inherited_role in self.role_permissions:\n                    effective_permissions.update(self.role_permissions[inherited_role])\n\n        return effective_permissions\n\n    def has_permission(self, user_roles: List[str], required_permission: str) -&gt; bool:\n        \"\"\"Check if user has required permission through roles.\"\"\"\n        effective_permissions = self.get_effective_permissions(user_roles)\n\n        # Check for wildcard permission\n        if \"*\" in effective_permissions:\n            return True\n\n        # Check for exact permission\n        if required_permission in effective_permissions:\n            return True\n\n        # Check for wildcard patterns\n        for permission in effective_permissions:\n            if permission.endswith(\":*\"):\n                permission_prefix = permission[:-2]\n                if required_permission.startswith(permission_prefix + \":\"):\n                    return True\n\n        return False\n\n# Dependency injection for role hierarchy\nrole_hierarchy = RoleHierarchy()\n\ndef get_role_hierarchy() -&gt; RoleHierarchy:\n    return role_hierarchy\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#2-context-aware-authorization","title":"2. Context-Aware Authorization","text":"<pre><code># src/core/context_auth.py\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass\nfrom fastapi import Request, Depends\nfrom src.core.auth import get_current_user\nfrom src.core.models import CurrentUser\n\n@dataclass\nclass AuthorizationContext:\n    \"\"\"Authorization context with request and resource information.\"\"\"\n    user: CurrentUser\n    resource_type: Optional[str] = None\n    resource_id: Optional[str] = None\n    action: Optional[str] = None\n    request: Optional[Request] = None\n    additional_context: Optional[Dict[str, Any]] = None\n\nclass ContextualAuthorizer:\n    \"\"\"Context-aware authorization engine.\"\"\"\n\n    def __init__(self, role_hierarchy: RoleHierarchy):\n        self.role_hierarchy = role_hierarchy\n        self.resource_policies = {}\n        self.register_default_policies()\n\n    def register_default_policies(self):\n        \"\"\"Register default resource-based policies.\"\"\"\n\n        # User resource policies\n        self.resource_policies[\"user\"] = {\n            \"read\": self._user_read_policy,\n            \"update\": self._user_update_policy,\n            \"delete\": self._user_delete_policy\n        }\n\n        # Content resource policies\n        self.resource_policies[\"content\"] = {\n            \"read\": self._content_read_policy,\n            \"update\": self._content_update_policy,\n            \"delete\": self._content_delete_policy\n        }\n\n    async def authorize(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"Main authorization method.\"\"\"\n\n        # Check role-based permissions first\n        permission = f\"{context.resource_type}:{context.action}\"\n        if self.role_hierarchy.has_permission(context.user.roles, permission):\n            return True\n\n        # Check resource-specific policies\n        if context.resource_type in self.resource_policies:\n            resource_policies = self.resource_policies[context.resource_type]\n            if context.action in resource_policies:\n                policy_func = resource_policies[context.action]\n                return await policy_func(context)\n\n        return False\n\n    async def _user_read_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"User read policy - can read own profile or with user:read permission.\"\"\"\n        if context.resource_id == context.user.id:\n            return True\n        return self.role_hierarchy.has_permission(context.user.roles, \"user:read\")\n\n    async def _user_update_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"User update policy - can update own profile or with user:update permission.\"\"\"\n        if context.resource_id == context.user.id:\n            return True\n        return self.role_hierarchy.has_permission(context.user.roles, \"user:update\")\n\n    async def _user_delete_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"User delete policy - only with user:delete permission.\"\"\"\n        return self.role_hierarchy.has_permission(context.user.roles, \"user:delete\")\n\n    async def _content_read_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"Content read policy - public content or own content.\"\"\"\n        # Get content metadata (implement based on your data service)\n        content_data = await self._get_content_metadata(context.resource_id)\n\n        if content_data.get(\"is_public\"):\n            return True\n\n        if content_data.get(\"owner_id\") == context.user.id:\n            return True\n\n        return self.role_hierarchy.has_permission(context.user.roles, \"content:read_all\")\n\n    async def _content_update_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"Content update policy - owner or content:manage permission.\"\"\"\n        content_data = await self._get_content_metadata(context.resource_id)\n\n        if content_data.get(\"owner_id\") == context.user.id:\n            return True\n\n        return self.role_hierarchy.has_permission(context.user.roles, \"content:manage\")\n\n    async def _content_delete_policy(self, context: AuthorizationContext) -&gt; bool:\n        \"\"\"Content delete policy - owner or content:manage permission.\"\"\"\n        return await self._content_update_policy(context)\n\n    async def _get_content_metadata(self, content_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get content metadata from data service.\"\"\"\n        # Implement call to data service\n        # This is a placeholder - implement according to your data service API\n        return {\n            \"id\": content_id,\n            \"owner_id\": \"some-user-id\",\n            \"is_public\": False\n        }\n\n# Dependency for contextual authorizer\ndef get_contextual_authorizer(\n    role_hierarchy: RoleHierarchy = Depends(get_role_hierarchy)\n) -&gt; ContextualAuthorizer:\n    return ContextualAuthorizer(role_hierarchy)\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#3-resource-based-authorization-decorator","title":"3. Resource-Based Authorization Decorator","text":"<pre><code># src/core/decorators.py\nfrom functools import wraps\nfrom typing import Callable, Optional\nfrom fastapi import Depends, HTTPException, status, Request\nfrom src.core.context_auth import AuthorizationContext, ContextualAuthorizer, get_contextual_authorizer\nfrom src.core.auth import get_current_user\nfrom src.core.models import CurrentUser\n\ndef authorize_resource(\n    resource_type: str,\n    action: str,\n    resource_id_param: str = \"resource_id\"\n):\n    \"\"\"Decorator for resource-based authorization.\"\"\"\n\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Extract dependencies from kwargs\n            current_user = None\n            authorizer = None\n            request = None\n\n            for key, value in kwargs.items():\n                if isinstance(value, CurrentUser):\n                    current_user = value\n                elif isinstance(value, ContextualAuthorizer):\n                    authorizer = value\n                elif isinstance(value, Request):\n                    request = value\n\n            if not current_user or not authorizer:\n                raise HTTPException(\n                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                    detail=\"Authorization dependencies not found\"\n                )\n\n            # Get resource ID from path parameters\n            resource_id = kwargs.get(resource_id_param)\n\n            # Create authorization context\n            context = AuthorizationContext(\n                user=current_user,\n                resource_type=resource_type,\n                resource_id=resource_id,\n                action=action,\n                request=request\n            )\n\n            # Check authorization\n            if not await authorizer.authorize(context):\n                raise HTTPException(\n                    status_code=status.HTTP_403_FORBIDDEN,\n                    detail=f\"Insufficient permissions for {action} on {resource_type}\"\n                )\n\n            return await func(*args, **kwargs)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#attribute-based-access-control-abac","title":"Attribute-Based Access Control (ABAC)","text":""},{"location":"atomic/security/authorization-patterns/#1-policy-engine","title":"1. Policy Engine","text":"<pre><code># src/core/abac.py\nfrom typing import Dict, Any, List, Callable\nfrom dataclasses import dataclass\nimport json\nfrom datetime import datetime\n\n@dataclass\nclass ABACAttribute:\n    \"\"\"ABAC attribute definition.\"\"\"\n    name: str\n    value: Any\n    type: str  # \"user\", \"resource\", \"environment\", \"action\"\n\n@dataclass\nclass ABACPolicy:\n    \"\"\"ABAC policy definition.\"\"\"\n    id: str\n    name: str\n    description: str\n    conditions: List[Dict[str, Any]]\n    effect: str  # \"allow\" or \"deny\"\n    priority: int = 0\n\nclass ABACEngine:\n    \"\"\"Attribute-Based Access Control engine.\"\"\"\n\n    def __init__(self):\n        self.policies: List[ABACPolicy] = []\n        self.attribute_providers = {}\n        self.register_default_providers()\n\n    def register_default_providers(self):\n        \"\"\"Register default attribute providers.\"\"\"\n        self.attribute_providers.update({\n            \"user.roles\": self._get_user_roles,\n            \"user.department\": self._get_user_department,\n            \"user.clearance_level\": self._get_user_clearance,\n            \"resource.owner\": self._get_resource_owner,\n            \"resource.classification\": self._get_resource_classification,\n            \"environment.time\": self._get_current_time,\n            \"environment.location\": self._get_user_location,\n            \"environment.network\": self._get_network_info\n        })\n\n    def add_policy(self, policy: ABACPolicy):\n        \"\"\"Add ABAC policy.\"\"\"\n        self.policies.append(policy)\n        # Sort by priority (higher priority first)\n        self.policies.sort(key=lambda p: p.priority, reverse=True)\n\n    async def evaluate(\n        self,\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        context: Dict[str, Any] = None\n    ) -&gt; bool:\n        \"\"\"Evaluate ABAC policies.\"\"\"\n\n        # Collect all attributes\n        attributes = await self._collect_attributes(\n            user, resource_type, resource_id, action, context or {}\n        )\n\n        # Evaluate policies in priority order\n        for policy in self.policies:\n            result = await self._evaluate_policy(policy, attributes)\n            if result is not None:\n                return result == \"allow\"\n\n        # Default deny\n        return False\n\n    async def _collect_attributes(\n        self,\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        context: Dict[str, Any]\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Collect all attributes from providers.\"\"\"\n\n        attributes = {\n            # User attributes\n            \"user.id\": user.id,\n            \"user.email\": user.email,\n            \"user.roles\": user.roles,\n\n            # Resource attributes\n            \"resource.type\": resource_type,\n            \"resource.id\": resource_id,\n\n            # Action attributes\n            \"action.name\": action,\n\n            # Environment attributes\n            \"environment.timestamp\": datetime.utcnow().isoformat(),\n\n            # Context attributes\n            **{f\"context.{k}\": v for k, v in context.items()}\n        }\n\n        # Call attribute providers\n        for attr_name, provider in self.attribute_providers.items():\n            try:\n                attributes[attr_name] = await provider(user, resource_id, context)\n            except Exception as e:\n                # Log error but continue\n                attributes[attr_name] = None\n\n        return attributes\n\n    async def _evaluate_policy(\n        self,\n        policy: ABACPolicy,\n        attributes: Dict[str, Any]\n    ) -&gt; Optional[str]:\n        \"\"\"Evaluate single policy against attributes.\"\"\"\n\n        for condition in policy.conditions:\n            if not await self._evaluate_condition(condition, attributes):\n                return None  # Policy doesn't match\n\n        return policy.effect\n\n    async def _evaluate_condition(\n        self,\n        condition: Dict[str, Any],\n        attributes: Dict[str, Any]\n    ) -&gt; bool:\n        \"\"\"Evaluate single condition.\"\"\"\n\n        operator = condition.get(\"operator\")\n        attribute = condition.get(\"attribute\")\n        value = condition.get(\"value\")\n\n        if attribute not in attributes:\n            return False\n\n        attr_value = attributes[attribute]\n\n        if operator == \"equals\":\n            return attr_value == value\n        elif operator == \"not_equals\":\n            return attr_value != value\n        elif operator == \"in\":\n            return attr_value in value\n        elif operator == \"not_in\":\n            return attr_value not in value\n        elif operator == \"contains\":\n            return value in attr_value if attr_value else False\n        elif operator == \"greater_than\":\n            return attr_value &gt; value\n        elif operator == \"less_than\":\n            return attr_value &lt; value\n        elif operator == \"regex\":\n            import re\n            return bool(re.match(value, str(attr_value)))\n        elif operator == \"time_range\":\n            current_hour = datetime.utcnow().hour\n            start_hour, end_hour = value\n            if start_hour &lt;= end_hour:\n                return start_hour &lt;= current_hour &lt;= end_hour\n            else:  # Overnight range\n                return current_hour &gt;= start_hour or current_hour &lt;= end_hour\n\n        return False\n\n    # Attribute provider methods\n    async def _get_user_roles(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; List[str]:\n        return user.roles\n\n    async def _get_user_department(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; str:\n        # Get from user service or user attributes\n        return getattr(user, 'department', 'unknown')\n\n    async def _get_user_clearance(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; int:\n        # Get security clearance level\n        return getattr(user, 'clearance_level', 0)\n\n    async def _get_resource_owner(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; str:\n        # Get resource owner from data service\n        return \"resource-owner-id\"  # Placeholder\n\n    async def _get_resource_classification(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; str:\n        # Get resource classification level\n        return \"public\"  # Placeholder\n\n    async def _get_current_time(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; int:\n        return datetime.utcnow().hour\n\n    async def _get_user_location(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; str:\n        # Get user location from request or user profile\n        return context.get(\"location\", \"unknown\")\n\n    async def _get_network_info(self, user: CurrentUser, resource_id: str, context: Dict) -&gt; Dict[str, str]:\n        # Get network information\n        return {\n            \"ip\": context.get(\"client_ip\", \"unknown\"),\n            \"network_type\": \"internal\" if context.get(\"client_ip\", \"\").startswith(\"192.168.\") else \"external\"\n        }\n\n# Example ABAC policies\ndef create_example_policies() -&gt; List[ABACPolicy]:\n    \"\"\"Create example ABAC policies.\"\"\"\n\n    policies = [\n        # High-priority policy: Super admins can do anything\n        ABACPolicy(\n            id=\"super_admin_all\",\n            name=\"Super Admin Full Access\",\n            description=\"Super admins have access to everything\",\n            conditions=[\n                {\n                    \"operator\": \"in\",\n                    \"attribute\": \"user.roles\",\n                    \"value\": [\"super_admin\"]\n                }\n            ],\n            effect=\"allow\",\n            priority=100\n        ),\n\n        # Time-based access policy\n        ABACPolicy(\n            id=\"business_hours_only\",\n            name=\"Business Hours Access\",\n            description=\"Certain actions only during business hours\",\n            conditions=[\n                {\n                    \"operator\": \"in\",\n                    \"attribute\": \"action.name\",\n                    \"value\": [\"create\", \"update\", \"delete\"]\n                },\n                {\n                    \"operator\": \"time_range\",\n                    \"attribute\": \"environment.time\",\n                    \"value\": [9, 17]  # 9 AM to 5 PM\n                }\n            ],\n            effect=\"allow\",\n            priority=50\n        ),\n\n        # Department-based access\n        ABACPolicy(\n            id=\"hr_employee_data\",\n            name=\"HR Employee Data Access\",\n            description=\"HR department can access employee data\",\n            conditions=[\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"user.department\",\n                    \"value\": \"hr\"\n                },\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"resource.type\",\n                    \"value\": \"employee\"\n                }\n            ],\n            effect=\"allow\",\n            priority=30\n        ),\n\n        # Resource ownership policy\n        ABACPolicy(\n            id=\"resource_owner_access\",\n            name=\"Resource Owner Access\",\n            description=\"Users can access their own resources\",\n            conditions=[\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"user.id\",\n                    \"value\": \"{resource.owner}\"  # Dynamic reference\n                }\n            ],\n            effect=\"allow\",\n            priority=20\n        ),\n\n        # Location-based restriction\n        ABACPolicy(\n            id=\"sensitive_data_location\",\n            name=\"Sensitive Data Location Restriction\",\n            description=\"Sensitive data only accessible from internal network\",\n            conditions=[\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"resource.classification\",\n                    \"value\": \"sensitive\"\n                },\n                {\n                    \"operator\": \"not_equals\",\n                    \"attribute\": \"environment.network.network_type\",\n                    \"value\": \"internal\"\n                }\n            ],\n            effect=\"deny\",\n            priority=80  # High priority for security\n        )\n    ]\n\n    return policies\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#2-abac-integration-with-fastapi","title":"2. ABAC Integration with FastAPI","text":"<pre><code># src/core/abac_middleware.py\nfrom fastapi import Depends, HTTPException, status, Request\nfrom src.core.abac import ABACEngine\nfrom src.core.auth import get_current_user\nfrom src.core.models import CurrentUser\n\nclass ABACAuthorizer:\n    \"\"\"ABAC authorizer for FastAPI integration.\"\"\"\n\n    def __init__(self):\n        self.engine = ABACEngine()\n        # Load policies from configuration or database\n        policies = create_example_policies()\n        for policy in policies:\n            self.engine.add_policy(policy)\n\n    async def authorize(\n        self,\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        request: Request\n    ) -&gt; bool:\n        \"\"\"Authorize request using ABAC.\"\"\"\n\n        context = {\n            \"client_ip\": request.client.host,\n            \"user_agent\": request.headers.get(\"user-agent\", \"\"),\n            \"path\": str(request.url.path),\n            \"method\": request.method\n        }\n\n        return await self.engine.evaluate(\n            user, resource_type, resource_id, action, context\n        )\n\n# Global ABAC authorizer instance\nabac_authorizer = ABACAuthorizer()\n\ndef get_abac_authorizer() -&gt; ABACAuthorizer:\n    return abac_authorizer\n\ndef require_abac_authorization(\n    resource_type: str,\n    action: str,\n    resource_id_param: str = \"resource_id\"\n):\n    \"\"\"Decorator for ABAC authorization.\"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Extract dependencies\n            current_user = None\n            request = None\n\n            for key, value in kwargs.items():\n                if isinstance(value, CurrentUser):\n                    current_user = value\n                elif isinstance(value, Request):\n                    request = value\n\n            if not current_user:\n                raise HTTPException(\n                    status_code=status.HTTP_401_UNAUTHORIZED,\n                    detail=\"Authentication required\"\n                )\n\n            # Get resource ID\n            resource_id = kwargs.get(resource_id_param, \"\")\n\n            # Check ABAC authorization\n            authorized = await abac_authorizer.authorize(\n                current_user, resource_type, resource_id, action, request\n            )\n\n            if not authorized:\n                raise HTTPException(\n                    status_code=status.HTTP_403_FORBIDDEN,\n                    detail=\"Access denied by policy\"\n                )\n\n            return await func(*args, **kwargs)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#dynamic-authorization","title":"Dynamic Authorization","text":""},{"location":"atomic/security/authorization-patterns/#1-policy-management-api","title":"1. Policy Management API","text":"<pre><code># src/api/policies.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom typing import List\nfrom src.core.auth import get_current_user\nfrom src.core.permissions import require_permission, Permission\nfrom src.core.abac import ABACPolicy\nfrom src.core.schemas import PolicyCreate, PolicyUpdate, PolicyResponse\nfrom src.core.models import CurrentUser\n\nrouter = APIRouter(prefix=\"/policies\", tags=[\"authorization-policies\"])\n\n@router.get(\"/\", response_model=List[PolicyResponse])\n@require_permission(Permission.ADMIN_ACCESS)\nasync def list_policies(\n    current_user: CurrentUser = Depends(get_current_user)\n):\n    \"\"\"List all authorization policies.\"\"\"\n    policies = abac_authorizer.engine.policies\n    return [PolicyResponse.from_policy(p) for p in policies]\n\n@router.post(\"/\", response_model=PolicyResponse)\n@require_permission(Permission.ADMIN_ACCESS)\nasync def create_policy(\n    policy_data: PolicyCreate,\n    current_user: CurrentUser = Depends(get_current_user)\n):\n    \"\"\"Create new authorization policy.\"\"\"\n\n    policy = ABACPolicy(\n        id=policy_data.id,\n        name=policy_data.name,\n        description=policy_data.description,\n        conditions=policy_data.conditions,\n        effect=policy_data.effect,\n        priority=policy_data.priority\n    )\n\n    abac_authorizer.engine.add_policy(policy)\n\n    # Save to persistent storage (database/config)\n    await save_policy_to_storage(policy)\n\n    return PolicyResponse.from_policy(policy)\n\n@router.put(\"/{policy_id}\", response_model=PolicyResponse)\n@require_permission(Permission.ADMIN_ACCESS)\nasync def update_policy(\n    policy_id: str,\n    policy_update: PolicyUpdate,\n    current_user: CurrentUser = Depends(get_current_user)\n):\n    \"\"\"Update authorization policy.\"\"\"\n\n    # Find existing policy\n    existing_policy = None\n    for policy in abac_authorizer.engine.policies:\n        if policy.id == policy_id:\n            existing_policy = policy\n            break\n\n    if not existing_policy:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Policy not found\"\n        )\n\n    # Update policy\n    updated_policy = ABACPolicy(\n        id=existing_policy.id,\n        name=policy_update.name or existing_policy.name,\n        description=policy_update.description or existing_policy.description,\n        conditions=policy_update.conditions or existing_policy.conditions,\n        effect=policy_update.effect or existing_policy.effect,\n        priority=policy_update.priority or existing_policy.priority\n    )\n\n    # Remove old policy and add updated one\n    abac_authorizer.engine.policies.remove(existing_policy)\n    abac_authorizer.engine.add_policy(updated_policy)\n\n    # Save to persistent storage\n    await update_policy_in_storage(updated_policy)\n\n    return PolicyResponse.from_policy(updated_policy)\n\n@router.delete(\"/{policy_id}\")\n@require_permission(Permission.ADMIN_ACCESS)\nasync def delete_policy(\n    policy_id: str,\n    current_user: CurrentUser = Depends(get_current_user)\n):\n    \"\"\"Delete authorization policy.\"\"\"\n\n    # Find and remove policy\n    for policy in abac_authorizer.engine.policies[:]:  # Create copy for iteration\n        if policy.id == policy_id:\n            abac_authorizer.engine.policies.remove(policy)\n            await delete_policy_from_storage(policy_id)\n            return {\"message\": \"Policy deleted successfully\"}\n\n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=\"Policy not found\"\n    )\n\n@router.post(\"/test\")\n@require_permission(Permission.ADMIN_ACCESS)\nasync def test_authorization(\n    test_request: AuthorizationTestRequest,\n    current_user: CurrentUser = Depends(get_current_user)\n):\n    \"\"\"Test authorization for given parameters.\"\"\"\n\n    # Create mock user for testing\n    mock_user = CurrentUser(\n        id=test_request.user_id,\n        email=\"test@example.com\",\n        username=\"testuser\",\n        is_active=True,\n        roles=test_request.user_roles,\n        scopes=[]\n    )\n\n    # Test authorization\n    result = await abac_authorizer.engine.evaluate(\n        mock_user,\n        test_request.resource_type,\n        test_request.resource_id,\n        test_request.action,\n        test_request.context\n    )\n\n    return {\n        \"authorized\": result,\n        \"user_id\": test_request.user_id,\n        \"resource_type\": test_request.resource_type,\n        \"resource_id\": test_request.resource_id,\n        \"action\": test_request.action,\n        \"context\": test_request.context\n    }\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#performance-optimization","title":"Performance Optimization","text":""},{"location":"atomic/security/authorization-patterns/#1-authorization-caching","title":"1. Authorization Caching","text":"<pre><code># src/core/auth_cache.py\nimport redis.asyncio as redis\nimport json\nfrom typing import Optional\nfrom datetime import timedelta\nfrom src.core.config import settings\n\nclass AuthorizationCache:\n    \"\"\"Cache for authorization decisions.\"\"\"\n\n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.cache_ttl = timedelta(minutes=15)\n        self.cache_prefix = \"auth:\"\n\n    def _make_cache_key(\n        self,\n        user_id: str,\n        resource_type: str,\n        resource_id: str,\n        action: str\n    ) -&gt; str:\n        \"\"\"Create cache key for authorization decision.\"\"\"\n        return f\"{self.cache_prefix}{user_id}:{resource_type}:{resource_id}:{action}\"\n\n    async def get_authorization(\n        self,\n        user_id: str,\n        resource_type: str,\n        resource_id: str,\n        action: str\n    ) -&gt; Optional[bool]:\n        \"\"\"Get cached authorization decision.\"\"\"\n        cache_key = self._make_cache_key(user_id, resource_type, resource_id, action)\n\n        cached_result = await self.redis.get(cache_key)\n        if cached_result:\n            return json.loads(cached_result)\n\n        return None\n\n    async def set_authorization(\n        self,\n        user_id: str,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        authorized: bool\n    ) -&gt; None:\n        \"\"\"Cache authorization decision.\"\"\"\n        cache_key = self._make_cache_key(user_id, resource_type, resource_id, action)\n\n        await self.redis.setex(\n            cache_key,\n            self.cache_ttl,\n            json.dumps(authorized)\n        )\n\n    async def invalidate_user_cache(self, user_id: str) -&gt; None:\n        \"\"\"Invalidate all cached decisions for a user.\"\"\"\n        pattern = f\"{self.cache_prefix}{user_id}:*\"\n        keys = await self.redis.keys(pattern)\n        if keys:\n            await self.redis.delete(*keys)\n\n    async def invalidate_resource_cache(self, resource_type: str, resource_id: str) -&gt; None:\n        \"\"\"Invalidate all cached decisions for a resource.\"\"\"\n        pattern = f\"{self.cache_prefix}*:{resource_type}:{resource_id}:*\"\n        keys = await self.redis.keys(pattern)\n        if keys:\n            await self.redis.delete(*keys)\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#2-optimized-authorization-flow","title":"2. Optimized Authorization Flow","text":"<pre><code># src/core/optimized_auth.py\nfrom typing import Optional\nfrom src.core.auth_cache import AuthorizationCache\nfrom src.core.abac import ABACEngine\nfrom src.core.models import CurrentUser\n\nclass OptimizedAuthorizer:\n    \"\"\"Optimized authorizer with caching and short-circuits.\"\"\"\n\n    def __init__(self, abac_engine: ABACEngine, cache: AuthorizationCache):\n        self.abac_engine = abac_engine\n        self.cache = cache\n\n    async def authorize(\n        self,\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        context: dict = None,\n        use_cache: bool = True\n    ) -&gt; bool:\n        \"\"\"Optimized authorization with caching.\"\"\"\n\n        # Check cache first\n        if use_cache:\n            cached_result = await self.cache.get_authorization(\n                user.id, resource_type, resource_id, action\n            )\n            if cached_result is not None:\n                return cached_result\n\n        # Short-circuit for super admin\n        if \"super_admin\" in user.roles:\n            if use_cache:\n                await self.cache.set_authorization(\n                    user.id, resource_type, resource_id, action, True\n                )\n            return True\n\n        # Check basic RBAC first (faster than ABAC)\n        permission = f\"{resource_type}:{action}\"\n        if self.role_hierarchy.has_permission(user.roles, permission):\n            if use_cache:\n                await self.cache.set_authorization(\n                    user.id, resource_type, resource_id, action, True\n                )\n            return True\n\n        # Fall back to full ABAC evaluation\n        result = await self.abac_engine.evaluate(\n            user, resource_type, resource_id, action, context or {}\n        )\n\n        # Cache the result\n        if use_cache:\n            await self.cache.set_authorization(\n                user.id, resource_type, resource_id, action, result\n            )\n\n        return result\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#audit-and-compliance","title":"Audit and Compliance","text":""},{"location":"atomic/security/authorization-patterns/#1-authorization-audit-trail","title":"1. Authorization Audit Trail","text":"<pre><code># src/core/auth_audit.py\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\nfrom src.core.models import CurrentUser\nfrom src.clients.data_service import AuditDataClient\n\nclass AuthorizationAuditor:\n    \"\"\"Audit trail for authorization decisions.\"\"\"\n\n    def __init__(self, audit_client: AuditDataClient):\n        self.audit_client = audit_client\n\n    async def log_authorization_attempt(\n        self,\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        authorized: bool,\n        policy_matched: Optional[str] = None,\n        context: Dict[str, Any] = None\n    ) -&gt; None:\n        \"\"\"Log authorization attempt for audit trail.\"\"\"\n\n        audit_record = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event_type\": \"authorization_attempt\",\n            \"user_id\": user.id,\n            \"user_email\": user.email,\n            \"user_roles\": user.roles,\n            \"resource_type\": resource_type,\n            \"resource_id\": resource_id,\n            \"action\": action,\n            \"authorized\": authorized,\n            \"policy_matched\": policy_matched,\n            \"context\": context or {},\n            \"ip_address\": context.get(\"client_ip\") if context else None,\n            \"user_agent\": context.get(\"user_agent\") if context else None\n        }\n\n        await self.audit_client.create_audit_record(audit_record)\n\n    async def log_permission_change(\n        self,\n        admin_user: CurrentUser,\n        target_user_id: str,\n        old_permissions: list,\n        new_permissions: list,\n        reason: str\n    ) -&gt; None:\n        \"\"\"Log permission changes for compliance.\"\"\"\n\n        audit_record = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event_type\": \"permission_change\",\n            \"admin_user_id\": admin_user.id,\n            \"admin_email\": admin_user.email,\n            \"target_user_id\": target_user_id,\n            \"old_permissions\": old_permissions,\n            \"new_permissions\": new_permissions,\n            \"reason\": reason\n        }\n\n        await self.audit_client.create_audit_record(audit_record)\n\n    async def log_policy_change(\n        self,\n        admin_user: CurrentUser,\n        policy_id: str,\n        change_type: str,  # \"created\", \"updated\", \"deleted\"\n        old_policy: Optional[Dict] = None,\n        new_policy: Optional[Dict] = None\n    ) -&gt; None:\n        \"\"\"Log policy changes for compliance.\"\"\"\n\n        audit_record = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"event_type\": \"policy_change\",\n            \"admin_user_id\": admin_user.id,\n            \"admin_email\": admin_user.email,\n            \"policy_id\": policy_id,\n            \"change_type\": change_type,\n            \"old_policy\": old_policy,\n            \"new_policy\": new_policy\n        }\n\n        await self.audit_client.create_audit_record(audit_record)\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#testing-authorization","title":"Testing Authorization","text":""},{"location":"atomic/security/authorization-patterns/#1-authorization-test-utilities","title":"1. Authorization Test Utilities","text":"<pre><code># tests/auth_test_utils.py\nfrom typing import List, Dict, Any\nfrom src.core.models import CurrentUser\nfrom src.core.abac import ABACEngine, ABACPolicy\n\nclass AuthorizationTestHelper:\n    \"\"\"Helper class for testing authorization.\"\"\"\n\n    def create_test_user(\n        self,\n        user_id: str = \"test-user\",\n        roles: List[str] = None,\n        attributes: Dict[str, Any] = None\n    ) -&gt; CurrentUser:\n        \"\"\"Create test user with specified roles and attributes.\"\"\"\n        user = CurrentUser(\n            id=user_id,\n            email=f\"{user_id}@example.com\",\n            username=user_id,\n            is_active=True,\n            roles=roles or [\"user\"],\n            scopes=[]\n        )\n\n        # Add custom attributes\n        if attributes:\n            for key, value in attributes.items():\n                setattr(user, key, value)\n\n        return user\n\n    def create_test_policy(\n        self,\n        policy_id: str,\n        conditions: List[Dict[str, Any]],\n        effect: str = \"allow\",\n        priority: int = 0\n    ) -&gt; ABACPolicy:\n        \"\"\"Create test ABAC policy.\"\"\"\n        return ABACPolicy(\n            id=policy_id,\n            name=f\"Test Policy {policy_id}\",\n            description=f\"Test policy for {policy_id}\",\n            conditions=conditions,\n            effect=effect,\n            priority=priority\n        )\n\n    async def assert_authorized(\n        self,\n        authorizer: 'OptimizedAuthorizer',\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        context: Dict[str, Any] = None\n    ) -&gt; None:\n        \"\"\"Assert that authorization succeeds.\"\"\"\n        result = await authorizer.authorize(\n            user, resource_type, resource_id, action, context\n        )\n        assert result, f\"Expected authorization to succeed for {user.id}:{resource_type}:{action}\"\n\n    async def assert_not_authorized(\n        self,\n        authorizer: 'OptimizedAuthorizer',\n        user: CurrentUser,\n        resource_type: str,\n        resource_id: str,\n        action: str,\n        context: Dict[str, Any] = None\n    ) -&gt; None:\n        \"\"\"Assert that authorization fails.\"\"\"\n        result = await authorizer.authorize(\n            user, resource_type, resource_id, action, context\n        )\n        assert not result, f\"Expected authorization to fail for {user.id}:{resource_type}:{action}\"\n\n# Test fixture\n@pytest.fixture\ndef auth_test_helper():\n    return AuthorizationTestHelper()\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#2-authorization-test-examples","title":"2. Authorization Test Examples","text":"<pre><code># tests/test_authorization.py\nimport pytest\nfrom src.core.abac import ABACEngine\nfrom src.core.optimized_auth import OptimizedAuthorizer\nfrom tests.auth_test_utils import AuthorizationTestHelper\n\nclass TestRBACAuthorization:\n    \"\"\"Test Role-Based Access Control.\"\"\"\n\n    async def test_admin_full_access(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test that admin users have full access.\"\"\"\n        # Create admin user\n        admin_user = auth_test_helper.create_test_user(\"admin\", [\"admin\"])\n\n        # Create authorizer\n        engine = ABACEngine()\n        authorizer = OptimizedAuthorizer(engine, None)\n\n        # Test various actions\n        await auth_test_helper.assert_authorized(\n            authorizer, admin_user, \"user\", \"any-user\", \"read\"\n        )\n        await auth_test_helper.assert_authorized(\n            authorizer, admin_user, \"user\", \"any-user\", \"update\"\n        )\n        await auth_test_helper.assert_authorized(\n            authorizer, admin_user, \"content\", \"any-content\", \"delete\"\n        )\n\n    async def test_user_limited_access(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test that regular users have limited access.\"\"\"\n        # Create regular user\n        user = auth_test_helper.create_test_user(\"user\", [\"user\"])\n\n        # Create authorizer\n        engine = ABACEngine()\n        authorizer = OptimizedAuthorizer(engine, None)\n\n        # Test read access (should work)\n        await auth_test_helper.assert_authorized(\n            authorizer, user, \"content\", \"public-content\", \"read\"\n        )\n\n        # Test admin action (should fail)\n        await auth_test_helper.assert_not_authorized(\n            authorizer, user, \"user\", \"other-user\", \"delete\"\n        )\n\nclass TestABACAuthorization:\n    \"\"\"Test Attribute-Based Access Control.\"\"\"\n\n    async def test_time_based_access(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test time-based access control.\"\"\"\n        # Create user\n        user = auth_test_helper.create_test_user(\"user\", [\"user\"])\n\n        # Create time-based policy\n        policy = auth_test_helper.create_test_policy(\n            \"business_hours\",\n            conditions=[\n                {\n                    \"operator\": \"time_range\",\n                    \"attribute\": \"environment.time\",\n                    \"value\": [9, 17]\n                }\n            ],\n            effect=\"allow\"\n        )\n\n        # Create engine with policy\n        engine = ABACEngine()\n        engine.add_policy(policy)\n        authorizer = OptimizedAuthorizer(engine, None)\n\n        # Mock business hours context\n        business_hours_context = {\"current_hour\": 10}\n\n        # Test during business hours\n        await auth_test_helper.assert_authorized(\n            authorizer, user, \"document\", \"doc-1\", \"create\", business_hours_context\n        )\n\n        # Mock after hours context\n        after_hours_context = {\"current_hour\": 20}\n\n        # Test after hours\n        await auth_test_helper.assert_not_authorized(\n            authorizer, user, \"document\", \"doc-1\", \"create\", after_hours_context\n        )\n\n    async def test_department_based_access(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test department-based access control.\"\"\"\n        # Create HR user\n        hr_user = auth_test_helper.create_test_user(\n            \"hr_user\",\n            [\"user\"],\n            {\"department\": \"hr\"}\n        )\n\n        # Create non-HR user\n        dev_user = auth_test_helper.create_test_user(\n            \"dev_user\",\n            [\"user\"],\n            {\"department\": \"development\"}\n        )\n\n        # Create department-based policy\n        policy = auth_test_helper.create_test_policy(\n            \"hr_access\",\n            conditions=[\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"user.department\",\n                    \"value\": \"hr\"\n                },\n                {\n                    \"operator\": \"equals\",\n                    \"attribute\": \"resource.type\",\n                    \"value\": \"employee\"\n                }\n            ],\n            effect=\"allow\"\n        )\n\n        # Create engine with policy\n        engine = ABACEngine()\n        engine.add_policy(policy)\n        authorizer = OptimizedAuthorizer(engine, None)\n\n        # Test HR user access to employee data\n        await auth_test_helper.assert_authorized(\n            authorizer, hr_user, \"employee\", \"emp-123\", \"read\"\n        )\n\n        # Test non-HR user access to employee data\n        await auth_test_helper.assert_not_authorized(\n            authorizer, dev_user, \"employee\", \"emp-123\", \"read\"\n        )\n\nclass TestAuthorizationPerformance:\n    \"\"\"Test authorization performance and caching.\"\"\"\n\n    async def test_authorization_caching(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test that authorization results are properly cached.\"\"\"\n        # This test would require a real Redis instance or mock\n        # Implementation depends on your testing setup\n        pass\n\n    async def test_authorization_performance(self, auth_test_helper: AuthorizationTestHelper):\n        \"\"\"Test authorization performance under load.\"\"\"\n        import time\n\n        user = auth_test_helper.create_test_user(\"user\", [\"user\"])\n        engine = ABACEngine()\n        authorizer = OptimizedAuthorizer(engine, None)\n\n        # Measure authorization time\n        start_time = time.time()\n\n        for i in range(100):\n            await authorizer.authorize(user, \"content\", f\"content-{i}\", \"read\")\n\n        end_time = time.time()\n        avg_time = (end_time - start_time) / 100\n\n        # Assert reasonable performance (adjust threshold as needed)\n        assert avg_time &lt; 0.01, f\"Authorization too slow: {avg_time}s per call\"\n</code></pre>"},{"location":"atomic/security/authorization-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> - Authentication implementation</li> <li><code>docs/atomic/security/security-testing-guide.md</code> - Security testing patterns</li> <li><code>docs/atomic/services/fastapi/security-patterns.md</code> - FastAPI security basics</li> <li><code>docs/atomic/integrations/redis/fastapi-integration.md</code> - Redis caching integration</li> <li><code>docs/atomic/architecture/data-access-architecture.md</code> - Data service patterns</li> </ul>"},{"location":"atomic/security/authorization-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/security/authorization-patterns/#implementation-checklist","title":"Implementation Checklist","text":"<ul> <li> Implement hierarchical RBAC with clear role inheritance</li> <li> Use context-aware authorization for resource access</li> <li> Implement ABAC for complex business rules</li> <li> Cache authorization decisions for performance</li> <li> Audit all authorization attempts for compliance</li> <li> Test authorization logic thoroughly</li> <li> Use policy management APIs for dynamic updates</li> <li> Implement proper error handling and logging</li> <li> Follow principle of least privilege</li> <li> Regular review and update of authorization policies</li> </ul>"},{"location":"atomic/security/authorization-patterns/#security-considerations","title":"Security Considerations","text":"<ul> <li> Default deny policy for all resources</li> <li> Secure policy storage and management</li> <li> Regular audit of permissions and roles</li> <li> Protection against privilege escalation</li> <li> Secure attribute collection and validation</li> <li> Rate limiting for authorization checks</li> <li> Monitoring for authorization bypasses</li> <li> Secure policy update mechanisms</li> <li> Separation of authorization and authentication</li> <li> Regular security testing and penetration testing</li> </ul>"},{"location":"atomic/security/security-testing-guide/","title":"Security Testing Guide","text":"<p>Comprehensive guide for testing authentication, authorization, and security features in microservices.</p>"},{"location":"atomic/security/security-testing-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Authentication &amp; Authorization Guide</li> <li>Session Management Patterns</li> <li>Pytest Setup</li> <li>Integration Testing</li> </ul>"},{"location":"atomic/security/security-testing-guide/#authentication-testing","title":"Authentication Testing","text":""},{"location":"atomic/security/security-testing-guide/#jwt-token-testing","title":"JWT Token Testing","text":"<pre><code>import pytest\nimport jwt\nfrom datetime import datetime, timedelta\nfrom unittest.mock import AsyncMock, MagicMock\n\nfrom your_app.security.token_service import TokenService, AuthConfig\n\n@pytest.fixture\ndef auth_config():\n    return AuthConfig(\n        SECRET_KEY=\"test-secret-key\",\n        ALGORITHM=\"HS256\",\n        ACCESS_TOKEN_EXPIRE_MINUTES=30,\n        REFRESH_TOKEN_EXPIRE_DAYS=7\n    )\n\n@pytest.fixture\ndef mock_redis():\n    redis_mock = AsyncMock()\n    redis_mock.setex = AsyncMock()\n    redis_mock.get = AsyncMock()\n    redis_mock.delete = AsyncMock()\n    return redis_mock\n\n@pytest.fixture\ndef token_service(mock_redis, auth_config):\n    return TokenService(mock_redis, auth_config)\n\nclass TestTokenService:\n    @pytest.mark.asyncio\n    async def test_create_access_token(self, token_service, mock_redis):\n        user_id = \"user123\"\n        username = \"testuser\"\n        roles = [\"user\", \"admin\"]\n\n        token = await token_service.create_access_token(user_id, username, roles)\n\n        # Verify token structure\n        assert isinstance(token, str)\n        assert len(token) &gt; 0\n\n        # Decode and verify payload\n        payload = jwt.decode(\n            token,\n            token_service.config.SECRET_KEY,\n            algorithms=[token_service.config.ALGORITHM]\n        )\n\n        assert payload[\"user_id\"] == user_id\n        assert payload[\"username\"] == username\n        assert payload[\"roles\"] == roles\n        assert payload[\"type\"] == \"access\"\n        assert \"jti\" in payload\n        assert \"exp\" in payload\n        assert \"iat\" in payload\n\n        # Verify Redis call\n        mock_redis.setex.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_verify_valid_token(self, token_service, mock_redis):\n        user_id = \"user123\"\n        username = \"testuser\"\n        roles = [\"user\"]\n\n        # Create token\n        token = await token_service.create_access_token(user_id, username, roles)\n\n        # Mock Redis responses\n        payload = jwt.decode(\n            token,\n            token_service.config.SECRET_KEY,\n            algorithms=[token_service.config.ALGORITHM]\n        )\n        jti = payload[\"jti\"]\n\n        mock_redis.get.side_effect = [\n            None,  # blacklist check\n            user_id.encode()  # token exists check\n        ]\n\n        # Verify token\n        result = await token_service.verify_token(token)\n\n        assert result is not None\n        assert result[\"user_id\"] == user_id\n        assert result[\"username\"] == username\n        assert result[\"roles\"] == roles\n\n    @pytest.mark.asyncio\n    async def test_verify_expired_token(self, token_service, auth_config):\n        # Create expired token\n        now = datetime.utcnow()\n        expired_payload = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"user\"],\n            \"exp\": now - timedelta(minutes=1),  # Expired\n            \"iat\": now - timedelta(minutes=31),\n            \"jti\": \"test-jti\",\n            \"type\": \"access\"\n        }\n\n        expired_token = jwt.encode(\n            expired_payload,\n            auth_config.SECRET_KEY,\n            algorithm=auth_config.ALGORITHM\n        )\n\n        result = await token_service.verify_token(expired_token)\n        assert result is None\n\n    @pytest.mark.asyncio\n    async def test_verify_blacklisted_token(self, token_service, mock_redis):\n        user_id = \"user123\"\n        username = \"testuser\"\n        roles = [\"user\"]\n\n        token = await token_service.create_access_token(user_id, username, roles)\n\n        # Mock blacklisted token\n        mock_redis.get.side_effect = [\n            \"1\".encode(),  # blacklist check returns value\n        ]\n\n        result = await token_service.verify_token(token)\n        assert result is None\n\n    @pytest.mark.asyncio\n    async def test_blacklist_token(self, token_service, mock_redis):\n        user_id = \"user123\"\n        username = \"testuser\"\n        roles = [\"user\"]\n\n        token = await token_service.create_access_token(user_id, username, roles)\n\n        await token_service.blacklist_token(token)\n\n        # Verify Redis setex was called for blacklisting\n        assert mock_redis.setex.call_count &gt;= 2  # Create + blacklist calls\n\n    @pytest.mark.asyncio\n    async def test_invalid_token_format(self, token_service):\n        invalid_token = \"invalid.token.format\"\n\n        result = await token_service.verify_token(invalid_token)\n        assert result is None\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#authorization-testing","title":"Authorization Testing","text":"<pre><code>import pytest\nfrom fastapi import HTTPException\nfrom unittest.mock import AsyncMock\n\nfrom your_app.security.auth_dependency import AuthDependency, Permission, Role\nfrom your_app.security.token_service import TokenService\n\nclass TestAuthDependency:\n    @pytest.fixture\n    def mock_token_service(self):\n        return AsyncMock(spec=TokenService)\n\n    @pytest.fixture\n    def auth_dependency(self, mock_token_service):\n        return AuthDependency(mock_token_service)\n\n    @pytest.mark.asyncio\n    async def test_get_current_user_valid_token(self, auth_dependency, mock_token_service):\n        mock_credentials = MagicMock()\n        mock_credentials.credentials = \"valid.jwt.token\"\n\n        expected_payload = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"user\", \"admin\"]\n        }\n\n        mock_token_service.verify_token.return_value = expected_payload\n\n        result = await auth_dependency.get_current_user(mock_credentials)\n\n        assert result == expected_payload\n        mock_token_service.verify_token.assert_called_once_with(\"valid.jwt.token\")\n\n    @pytest.mark.asyncio\n    async def test_get_current_user_invalid_token(self, auth_dependency, mock_token_service):\n        mock_credentials = MagicMock()\n        mock_credentials.credentials = \"invalid.token\"\n\n        mock_token_service.verify_token.return_value = None\n\n        with pytest.raises(HTTPException) as exc_info:\n            await auth_dependency.get_current_user(mock_credentials)\n\n        assert exc_info.value.status_code == 401\n        assert \"Invalid authentication credentials\" in str(exc_info.value.detail)\n\n    @pytest.mark.asyncio\n    async def test_require_permissions_sufficient(self, auth_dependency):\n        required_permissions = {Permission.READ_USERS}\n\n        permission_checker = auth_dependency.require_permissions(required_permissions)\n\n        current_user = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"admin\"]  # Admin has READ_USERS permission\n        }\n\n        result = await permission_checker(current_user)\n        assert result == current_user\n\n    @pytest.mark.asyncio\n    async def test_require_permissions_insufficient(self, auth_dependency):\n        required_permissions = {Permission.DELETE_USERS}\n\n        permission_checker = auth_dependency.require_permissions(required_permissions)\n\n        current_user = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"user\"]  # User doesn't have DELETE_USERS permission\n        }\n\n        with pytest.raises(HTTPException) as exc_info:\n            await permission_checker(current_user)\n\n        assert exc_info.value.status_code == 403\n        assert \"Insufficient permissions\" in str(exc_info.value.detail)\n\n    @pytest.mark.asyncio\n    async def test_require_roles_valid(self, auth_dependency):\n        required_roles = {Role.ADMIN}\n\n        role_checker = auth_dependency.require_roles(required_roles)\n\n        current_user = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"admin\", \"user\"]\n        }\n\n        result = await role_checker(current_user)\n        assert result == current_user\n\n    @pytest.mark.asyncio\n    async def test_require_roles_invalid(self, auth_dependency):\n        required_roles = {Role.ADMIN}\n\n        role_checker = auth_dependency.require_roles(required_roles)\n\n        current_user = {\n            \"user_id\": \"user123\",\n            \"username\": \"testuser\",\n            \"roles\": [\"user\"]\n        }\n\n        with pytest.raises(HTTPException) as exc_info:\n            await role_checker(current_user)\n\n        assert exc_info.value.status_code == 403\n        assert \"Insufficient role privileges\" in str(exc_info.value.detail)\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#session-management-testing","title":"Session Management Testing","text":""},{"location":"atomic/security/security-testing-guide/#session-storage-testing","title":"Session Storage Testing","text":"<pre><code>import pytest\nimport json\nfrom datetime import datetime, timedelta\nfrom unittest.mock import AsyncMock\n\nfrom your_app.security.session_manager import DistributedSessionManager\n\nclass TestDistributedSessionManager:\n    @pytest.fixture\n    def mock_redis(self):\n        redis_mock = AsyncMock()\n        redis_mock.setex = AsyncMock()\n        redis_mock.get = AsyncMock()\n        redis_mock.delete = AsyncMock()\n        redis_mock.sadd = AsyncMock()\n        redis_mock.srem = AsyncMock()\n        redis_mock.smembers = AsyncMock()\n        redis_mock.expire = AsyncMock()\n        redis_mock.lpush = AsyncMock()\n        return redis_mock\n\n    @pytest.fixture\n    def session_manager(self, mock_redis):\n        return DistributedSessionManager(\n            redis_client=mock_redis,\n            default_ttl=timedelta(hours=24),\n            max_sessions_per_user=5\n        )\n\n    @pytest.mark.asyncio\n    async def test_create_session(self, session_manager, mock_redis):\n        user_id = \"user123\"\n        session_data = {\n            \"ip_address\": \"192.168.1.1\",\n            \"user_agent\": \"TestAgent/1.0\",\n            \"metadata\": {\"device\": \"mobile\"}\n        }\n\n        # Mock existing sessions check\n        mock_redis.smembers.return_value = []\n\n        session_id = await session_manager.create_session(user_id, session_data)\n\n        assert isinstance(session_id, str)\n        assert len(session_id) &gt; 0\n\n        # Verify Redis calls\n        mock_redis.setex.assert_called()\n        mock_redis.sadd.assert_called_with(f\"user_sessions:{user_id}\", session_id)\n        mock_redis.expire.assert_called()\n        mock_redis.lpush.assert_called()  # Audit log\n\n    @pytest.mark.asyncio\n    async def test_get_session_valid(self, session_manager, mock_redis):\n        session_id = \"test-session-id\"\n        user_id = \"user123\"\n\n        session_data = {\n            \"session_id\": session_id,\n            \"user_id\": user_id,\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"last_activity\": datetime.utcnow().isoformat(),\n            \"expires_at\": (datetime.utcnow() + timedelta(hours=1)).isoformat(),\n            \"ip_address\": \"192.168.1.1\",\n            \"metadata\": {}\n        }\n\n        mock_redis.get.return_value = json.dumps(session_data)\n\n        result = await session_manager.get_session(session_id)\n\n        assert result is not None\n        assert result[\"session_id\"] == session_id\n        assert result[\"user_id\"] == user_id\n\n        # Verify activity update\n        mock_redis.setex.assert_called()\n\n    @pytest.mark.asyncio\n    async def test_get_session_expired(self, session_manager, mock_redis):\n        session_id = \"test-session-id\"\n\n        expired_session_data = {\n            \"session_id\": session_id,\n            \"user_id\": \"user123\",\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"last_activity\": datetime.utcnow().isoformat(),\n            \"expires_at\": (datetime.utcnow() - timedelta(hours=1)).isoformat(),  # Expired\n            \"metadata\": {}\n        }\n\n        mock_redis.get.return_value = json.dumps(expired_session_data)\n\n        result = await session_manager.get_session(session_id)\n\n        assert result is None\n\n        # Verify session was invalidated\n        mock_redis.delete.assert_called()\n\n    @pytest.mark.asyncio\n    async def test_invalidate_session(self, session_manager, mock_redis):\n        session_id = \"test-session-id\"\n        user_id = \"user123\"\n\n        session_data = {\n            \"session_id\": session_id,\n            \"user_id\": user_id,\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"last_activity\": datetime.utcnow().isoformat(),\n            \"expires_at\": (datetime.utcnow() + timedelta(hours=1)).isoformat(),\n            \"metadata\": {}\n        }\n\n        mock_redis.get.return_value = json.dumps(session_data)\n\n        result = await session_manager.invalidate_session(session_id)\n\n        assert result is True\n\n        # Verify Redis calls\n        mock_redis.srem.assert_called_with(f\"user_sessions:{user_id}\", session_id)\n        mock_redis.delete.assert_called_with(f\"session:{session_id}\")\n\n    @pytest.mark.asyncio\n    async def test_session_limit_enforcement(self, session_manager, mock_redis):\n        user_id = \"user123\"\n\n        # Mock 5 existing sessions (at limit)\n        existing_sessions = [f\"session_{i}\" for i in range(5)]\n        mock_redis.smembers.return_value = existing_sessions\n\n        # Mock session data for cleanup\n        for i, session_id in enumerate(existing_sessions):\n            session_data = {\n                \"session_id\": session_id,\n                \"user_id\": user_id,\n                \"created_at\": datetime.utcnow().isoformat(),\n                \"last_activity\": (datetime.utcnow() - timedelta(minutes=i)).isoformat(),\n                \"expires_at\": (datetime.utcnow() + timedelta(hours=1)).isoformat(),\n                \"metadata\": {}\n            }\n\n            if i == 0:  # First call for enforcement check\n                mock_redis.get.return_value = json.dumps(session_data)\n            else:\n                # Additional calls for get_user_sessions\n                mock_redis.get.return_value = json.dumps(session_data)\n\n        session_data = {\n            \"ip_address\": \"192.168.1.1\",\n            \"user_agent\": \"TestAgent/1.0\"\n        }\n\n        await session_manager.create_session(user_id, session_data)\n\n        # Should have invalidated the oldest session\n        assert mock_redis.delete.call_count &gt;= 1\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#mfa-testing","title":"MFA Testing","text":""},{"location":"atomic/security/security-testing-guide/#totp-testing","title":"TOTP Testing","text":"<pre><code>import pytest\nimport pyotp\nfrom unittest.mock import AsyncMock, patch\n\nfrom your_app.security.mfa_service import MFAService\n\nclass TestMFAService:\n    @pytest.fixture\n    def mock_redis(self):\n        redis_mock = AsyncMock()\n        redis_mock.setex = AsyncMock()\n        redis_mock.get = AsyncMock()\n        redis_mock.set = AsyncMock()\n        redis_mock.delete = AsyncMock()\n        return redis_mock\n\n    @pytest.fixture\n    def mfa_service(self, mock_redis):\n        return MFAService(mock_redis)\n\n    @pytest.mark.asyncio\n    async def test_setup_totp(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n        app_name = \"TestApp\"\n\n        with patch('pyotp.random_base32') as mock_random:\n            mock_random.return_value = \"JBSWY3DPEHPK3PXP\"\n\n            result = await mfa_service.setup_totp(user_id, app_name)\n\n            assert \"secret\" in result\n            assert \"qr_code\" in result\n            assert \"totp_uri\" in result\n\n            # Verify Redis call\n            mock_redis.setex.assert_called_with(\n                f\"mfa_setup:{user_id}\",\n                300,\n                \"JBSWY3DPEHPK3PXP\"\n            )\n\n    @pytest.mark.asyncio\n    async def test_confirm_totp_setup_valid(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n        secret = \"JBSWY3DPEHPK3PXP\"\n\n        mock_redis.get.return_value = secret.encode()\n\n        # Generate valid TOTP code\n        totp = pyotp.TOTP(secret)\n        valid_code = totp.now()\n\n        result = await mfa_service.confirm_totp_setup(user_id, valid_code)\n\n        assert result is True\n\n        # Verify Redis calls\n        mock_redis.set.assert_called_with(f\"mfa_secret:{user_id}\", secret)\n        mock_redis.delete.assert_called_with(f\"mfa_setup:{user_id}\")\n\n    @pytest.mark.asyncio\n    async def test_confirm_totp_setup_invalid_code(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n        secret = \"JBSWY3DPEHPK3PXP\"\n\n        mock_redis.get.return_value = secret.encode()\n\n        invalid_code = \"000000\"\n\n        result = await mfa_service.confirm_totp_setup(user_id, invalid_code)\n\n        assert result is False\n\n        # Verify secret was not saved\n        mock_redis.set.assert_not_called()\n\n    @pytest.mark.asyncio\n    async def test_verify_totp_valid(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n        secret = \"JBSWY3DPEHPK3PXP\"\n\n        mock_redis.get.return_value = secret.encode()\n\n        # Generate valid TOTP code\n        totp = pyotp.TOTP(secret)\n        valid_code = totp.now()\n\n        result = await mfa_service.verify_totp(user_id, valid_code)\n\n        assert result is True\n\n    @pytest.mark.asyncio\n    async def test_verify_totp_no_secret(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n\n        mock_redis.get.return_value = None\n\n        result = await mfa_service.verify_totp(user_id, \"123456\")\n\n        assert result is False\n\n    @pytest.mark.asyncio\n    async def test_is_mfa_enabled(self, mfa_service, mock_redis):\n        user_id = \"user123\"\n\n        # Test enabled\n        mock_redis.get.return_value = \"secret\".encode()\n        result = await mfa_service.is_mfa_enabled(user_id)\n        assert result is True\n\n        # Test disabled\n        mock_redis.get.return_value = None\n        result = await mfa_service.is_mfa_enabled(user_id)\n        assert result is False\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#fastapi-integration-testing","title":"FastAPI Integration Testing","text":""},{"location":"atomic/security/security-testing-guide/#authentication-endpoints-testing","title":"Authentication Endpoints Testing","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom unittest.mock import AsyncMock, patch\n\nfrom your_app.main import app\nfrom your_app.security.token_service import TokenService\n\n@pytest.fixture\ndef client():\n    return TestClient(app)\n\n@pytest.fixture\ndef mock_token_service():\n    return AsyncMock(spec=TokenService)\n\nclass TestAuthenticationEndpoints:\n    def test_login_valid_credentials(self, client):\n        with patch('your_app.main.validate_user_credentials') as mock_validate, \\\n             patch('your_app.main.token_service') as mock_token_service, \\\n             patch('your_app.main.mfa_service') as mock_mfa_service, \\\n             patch('your_app.main.session_manager') as mock_session_manager:\n\n            # Mock user validation\n            mock_user = MagicMock()\n            mock_user.id = \"user123\"\n            mock_user.username = \"testuser\"\n            mock_user.roles = [\"user\"]\n            mock_validate.return_value = mock_user\n\n            # Mock MFA disabled\n            mock_mfa_service.is_mfa_enabled.return_value = False\n\n            # Mock token creation\n            mock_token_service.create_access_token.return_value = \"access_token\"\n            mock_token_service.create_refresh_token.return_value = \"refresh_token\"\n\n            # Mock session creation\n            mock_session_manager.create_session.return_value = \"session_id\"\n\n            response = client.post(\"/auth/login\", json={\n                \"username\": \"testuser\",\n                \"password\": \"testpass\"\n            })\n\n            assert response.status_code == 200\n            data = response.json()\n\n            assert \"access_token\" in data\n            assert \"refresh_token\" in data\n            assert \"session_id\" in data\n            assert data[\"token_type\"] == \"bearer\"\n\n    def test_login_invalid_credentials(self, client):\n        with patch('your_app.main.validate_user_credentials') as mock_validate:\n            mock_validate.return_value = None\n\n            response = client.post(\"/auth/login\", json={\n                \"username\": \"invalid\",\n                \"password\": \"invalid\"\n            })\n\n            assert response.status_code == 401\n            assert \"Invalid credentials\" in response.json()[\"detail\"]\n\n    def test_login_with_mfa_required(self, client):\n        with patch('your_app.main.validate_user_credentials') as mock_validate, \\\n             patch('your_app.main.token_service') as mock_token_service, \\\n             patch('your_app.main.mfa_service') as mock_mfa_service:\n\n            # Mock user validation\n            mock_user = MagicMock()\n            mock_user.id = \"user123\"\n            mock_user.username = \"testuser\"\n            mock_user.roles = [\"user\"]\n            mock_validate.return_value = mock_user\n\n            # Mock MFA enabled\n            mock_mfa_service.is_mfa_enabled.return_value = True\n\n            # Mock temporary token creation\n            mock_token_service.create_access_token.return_value = \"temp_token\"\n\n            response = client.post(\"/auth/login\", json={\n                \"username\": \"testuser\",\n                \"password\": \"testpass\"\n            })\n\n            assert response.status_code == 200\n            data = response.json()\n\n            assert data[\"requires_mfa\"] is True\n            assert \"temp_token\" in data\n\n    def test_protected_endpoint_with_valid_token(self, client):\n        with patch('your_app.main.auth_dependency.get_current_user') as mock_get_user:\n            mock_get_user.return_value = {\n                \"user_id\": \"user123\",\n                \"username\": \"testuser\",\n                \"roles\": [\"user\"]\n            }\n\n            response = client.get(\n                \"/users/profile\",\n                headers={\"Authorization\": \"Bearer valid_token\"}\n            )\n\n            assert response.status_code == 200\n            data = response.json()\n\n            assert data[\"user_id\"] == \"user123\"\n            assert data[\"username\"] == \"testuser\"\n\n    def test_protected_endpoint_without_token(self, client):\n        response = client.get(\"/users/profile\")\n\n        assert response.status_code == 403  # No Authorization header\n\n    def test_protected_endpoint_invalid_token(self, client):\n        with patch('your_app.main.auth_dependency.get_current_user') as mock_get_user:\n            mock_get_user.side_effect = HTTPException(\n                status_code=401,\n                detail=\"Invalid authentication credentials\"\n            )\n\n            response = client.get(\n                \"/users/profile\",\n                headers={\"Authorization\": \"Bearer invalid_token\"}\n            )\n\n            assert response.status_code == 401\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#security-load-testing","title":"Security Load Testing","text":""},{"location":"atomic/security/security-testing-guide/#authentication-load-testing","title":"Authentication Load Testing","text":"<pre><code>import asyncio\nimport aiohttp\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass SecurityLoadTester:\n    def __init__(self, base_url: str, max_concurrent: int = 100):\n        self.base_url = base_url\n        self.max_concurrent = max_concurrent\n\n    async def test_login_performance(self, credentials_list: list, duration_seconds: int = 60):\n        \"\"\"Test login endpoint performance under load.\"\"\"\n\n        results = {\n            \"total_requests\": 0,\n            \"successful_requests\": 0,\n            \"failed_requests\": 0,\n            \"avg_response_time\": 0,\n            \"errors\": []\n        }\n\n        start_time = time.time()\n        response_times = []\n\n        semaphore = asyncio.Semaphore(self.max_concurrent)\n\n        async def make_request(session, credentials):\n            async with semaphore:\n                try:\n                    start = time.time()\n                    async with session.post(\n                        f\"{self.base_url}/auth/login\",\n                        json=credentials,\n                        timeout=aiohttp.ClientTimeout(total=30)\n                    ) as response:\n                        await response.text()\n                        response_time = time.time() - start\n                        response_times.append(response_time)\n\n                        results[\"total_requests\"] += 1\n\n                        if response.status == 200:\n                            results[\"successful_requests\"] += 1\n                        else:\n                            results[\"failed_requests\"] += 1\n\n                except Exception as e:\n                    results[\"total_requests\"] += 1\n                    results[\"failed_requests\"] += 1\n                    results[\"errors\"].append(str(e))\n\n        async with aiohttp.ClientSession() as session:\n            tasks = []\n\n            while time.time() - start_time &lt; duration_seconds:\n                for credentials in credentials_list:\n                    if time.time() - start_time &gt;= duration_seconds:\n                        break\n\n                    task = asyncio.create_task(make_request(session, credentials))\n                    tasks.append(task)\n\n                    # Small delay to prevent overwhelming\n                    await asyncio.sleep(0.01)\n\n            # Wait for all tasks to complete\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n        if response_times:\n            results[\"avg_response_time\"] = sum(response_times) / len(response_times)\n\n        return results\n\n    async def test_token_verification_performance(self, tokens: list, duration_seconds: int = 60):\n        \"\"\"Test token verification performance.\"\"\"\n\n        results = {\"total_requests\": 0, \"successful_requests\": 0, \"failed_requests\": 0}\n\n        start_time = time.time()\n        semaphore = asyncio.Semaphore(self.max_concurrent)\n\n        async def verify_token(session, token):\n            async with semaphore:\n                try:\n                    headers = {\"Authorization\": f\"Bearer {token}\"}\n                    async with session.get(\n                        f\"{self.base_url}/users/profile\",\n                        headers=headers,\n                        timeout=aiohttp.ClientTimeout(total=10)\n                    ) as response:\n                        results[\"total_requests\"] += 1\n\n                        if response.status == 200:\n                            results[\"successful_requests\"] += 1\n                        else:\n                            results[\"failed_requests\"] += 1\n\n                except Exception:\n                    results[\"total_requests\"] += 1\n                    results[\"failed_requests\"] += 1\n\n        async with aiohttp.ClientSession() as session:\n            tasks = []\n\n            while time.time() - start_time &lt; duration_seconds:\n                for token in tokens:\n                    if time.time() - start_time &gt;= duration_seconds:\n                        break\n\n                    task = asyncio.create_task(verify_token(session, token))\n                    tasks.append(task)\n\n                    await asyncio.sleep(0.001)\n\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n        return results\n\n# Usage example\nasync def run_security_load_tests():\n    tester = SecurityLoadTester(\"http://localhost:8000\")\n\n    credentials = [\n        {\"username\": f\"user{i}\", \"password\": \"password\"}\n        for i in range(10)\n    ]\n\n    print(\"Testing login performance...\")\n    login_results = await tester.test_login_performance(credentials, 30)\n    print(f\"Login test results: {login_results}\")\n\n    # Create some valid tokens for testing\n    # (In real tests, you'd get these from actual login requests)\n    tokens = [\"valid_token_1\", \"valid_token_2\", \"valid_token_3\"]\n\n    print(\"Testing token verification performance...\")\n    token_results = await tester.test_token_verification_performance(tokens, 30)\n    print(f\"Token verification results: {token_results}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(run_security_load_tests())\n</code></pre>"},{"location":"atomic/security/security-testing-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication &amp; Authorization Guide</li> <li>Session Management Patterns</li> <li>Pytest Setup</li> <li>Integration Testing</li> </ul>"},{"location":"atomic/security/security-testing-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Test Coverage:</li> <li>Test all authentication flows</li> <li>Test authorization scenarios</li> <li>Test token lifecycle</li> <li> <p>Test session management</p> </li> <li> <p>Security Scenarios:</p> </li> <li>Test with expired tokens</li> <li>Test with malformed tokens</li> <li>Test concurrent sessions</li> <li> <p>Test MFA flows</p> </li> <li> <p>Performance Testing:</p> </li> <li>Load test authentication endpoints</li> <li>Test token verification performance</li> <li> <p>Monitor response times under load</p> </li> <li> <p>Integration Testing:</p> </li> <li>Test with real Redis instances</li> <li>Test cross-service authentication</li> <li>Test security middleware</li> </ol>"},{"location":"atomic/security/security-testing-guide/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> \u2014 Auth testing</li> <li><code>docs/atomic/testing/security-testing.md</code> \u2014 Security test patterns</li> <li><code>docs/atomic/testing/integration-testing.md</code> \u2014 Integration security tests</li> <li><code>docs/atomic/infrastructure/ci-cd-pipeline.md</code> \u2014 Security scans in CI</li> </ul>"},{"location":"atomic/security/session-management-patterns/","title":"Session Management Patterns","text":"<p>Advanced session management strategies for microservices with Redis and distributed environments.</p>"},{"location":"atomic/security/session-management-patterns/#prerequisites","title":"Prerequisites","text":"<ul> <li>Redis Connection Management</li> <li>Authentication &amp; Authorization Guide</li> <li>Understanding of distributed systems concepts</li> </ul>"},{"location":"atomic/security/session-management-patterns/#session-storage-strategies","title":"Session Storage Strategies","text":""},{"location":"atomic/security/session-management-patterns/#redis-based-session-store","title":"Redis-Based Session Store","text":"<pre><code>import json\nimport uuid\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, List\nimport redis.asyncio as redis\n\nclass DistributedSessionManager:\n    def __init__(\n        self,\n        redis_client: redis.Redis,\n        default_ttl: timedelta = timedelta(hours=24),\n        max_sessions_per_user: int = 5\n    ):\n        self.redis = redis_client\n        self.default_ttl = default_ttl\n        self.max_sessions_per_user = max_sessions_per_user\n\n    async def create_session(\n        self,\n        user_id: str,\n        session_data: Dict,\n        ttl: Optional[timedelta] = None\n    ) -&gt; str:\n        session_id = str(uuid.uuid4())\n        session_ttl = ttl or self.default_ttl\n\n        # Enforce session limit\n        await self._enforce_session_limit(user_id)\n\n        session_payload = {\n            \"session_id\": session_id,\n            \"user_id\": user_id,\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"last_activity\": datetime.utcnow().isoformat(),\n            \"expires_at\": (datetime.utcnow() + session_ttl).isoformat(),\n            \"ip_address\": session_data.get(\"ip_address\"),\n            \"user_agent\": session_data.get(\"user_agent\"),\n            \"device_fingerprint\": session_data.get(\"device_fingerprint\"),\n            \"metadata\": session_data.get(\"metadata\", {})\n        }\n\n        # Store session data\n        session_key = f\"session:{session_id}\"\n        await self.redis.setex(\n            session_key,\n            int(session_ttl.total_seconds()),\n            json.dumps(session_payload)\n        )\n\n        # Add to user's active sessions\n        user_sessions_key = f\"user_sessions:{user_id}\"\n        await self.redis.sadd(user_sessions_key, session_id)\n        await self.redis.expire(user_sessions_key, int(session_ttl.total_seconds()))\n\n        # Track session creation\n        await self._track_session_event(session_id, \"created\", session_data)\n\n        return session_id\n\n    async def get_session(\n        self,\n        session_id: str,\n        update_activity: bool = True\n    ) -&gt; Optional[Dict]:\n        session_key = f\"session:{session_id}\"\n        session_data = await self.redis.get(session_key)\n\n        if not session_data:\n            return None\n\n        session = json.loads(session_data)\n\n        # Check if session is expired\n        expires_at = datetime.fromisoformat(session[\"expires_at\"])\n        if datetime.utcnow() &gt; expires_at:\n            await self.invalidate_session(session_id)\n            return None\n\n        if update_activity:\n            # Update last activity\n            session[\"last_activity\"] = datetime.utcnow().isoformat()\n            await self.redis.setex(\n                session_key,\n                int(self.default_ttl.total_seconds()),\n                json.dumps(session)\n            )\n\n            await self._track_session_event(session_id, \"activity_updated\")\n\n        return session\n\n    async def update_session(\n        self,\n        session_id: str,\n        updates: Dict\n    ) -&gt; bool:\n        session = await self.get_session(session_id, update_activity=False)\n\n        if not session:\n            return False\n\n        # Update session data\n        session[\"metadata\"].update(updates.get(\"metadata\", {}))\n\n        # Update other allowed fields\n        allowed_updates = [\"ip_address\", \"user_agent\", \"device_fingerprint\"]\n        for field in allowed_updates:\n            if field in updates:\n                session[field] = updates[field]\n\n        session[\"last_activity\"] = datetime.utcnow().isoformat()\n\n        session_key = f\"session:{session_id}\"\n        await self.redis.setex(\n            session_key,\n            int(self.default_ttl.total_seconds()),\n            json.dumps(session)\n        )\n\n        await self._track_session_event(session_id, \"updated\", updates)\n        return True\n\n    async def invalidate_session(self, session_id: str) -&gt; bool:\n        session = await self.get_session(session_id, update_activity=False)\n\n        if not session:\n            return False\n\n        user_id = session[\"user_id\"]\n\n        # Remove from user's active sessions\n        await self.redis.srem(f\"user_sessions:{user_id}\", session_id)\n\n        # Delete session data\n        await self.redis.delete(f\"session:{session_id}\")\n\n        await self._track_session_event(session_id, \"invalidated\")\n        return True\n\n    async def invalidate_all_user_sessions(self, user_id: str) -&gt; int:\n        user_sessions_key = f\"user_sessions:{user_id}\"\n        session_ids = await self.redis.smembers(user_sessions_key)\n\n        count = 0\n        for session_id in session_ids:\n            if await self.invalidate_session(session_id):\n                count += 1\n\n        await self.redis.delete(user_sessions_key)\n        await self._track_session_event(None, \"all_user_sessions_invalidated\", {\"user_id\": user_id})\n\n        return count\n\n    async def get_user_sessions(self, user_id: str) -&gt; List[Dict]:\n        user_sessions_key = f\"user_sessions:{user_id}\"\n        session_ids = await self.redis.smembers(user_sessions_key)\n\n        sessions = []\n        for session_id in session_ids:\n            session = await self.get_session(session_id, update_activity=False)\n            if session:\n                sessions.append(session)\n\n        return sorted(sessions, key=lambda x: x[\"last_activity\"], reverse=True)\n\n    async def _enforce_session_limit(self, user_id: str):\n        sessions = await self.get_user_sessions(user_id)\n\n        if len(sessions) &gt;= self.max_sessions_per_user:\n            # Remove oldest sessions\n            sessions_to_remove = len(sessions) - self.max_sessions_per_user + 1\n            oldest_sessions = sorted(sessions, key=lambda x: x[\"last_activity\"])\n\n            for session in oldest_sessions[:sessions_to_remove]:\n                await self.invalidate_session(session[\"session_id\"])\n\n    async def _track_session_event(\n        self,\n        session_id: Optional[str],\n        event_type: str,\n        event_data: Optional[Dict] = None\n    ):\n        event = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"session_id\": session_id,\n            \"event_type\": event_type,\n            \"data\": event_data or {}\n        }\n\n        # Store in audit log (implement according to your logging strategy)\n        audit_key = f\"session_audit:{datetime.utcnow().strftime('%Y-%m-%d')}\"\n        await self.redis.lpush(audit_key, json.dumps(event))\n        await self.redis.expire(audit_key, 7 * 24 * 60 * 60)  # Keep for 7 days\n</code></pre>"},{"location":"atomic/security/session-management-patterns/#session-security-patterns","title":"Session Security Patterns","text":""},{"location":"atomic/security/session-management-patterns/#concurrent-session-detection","title":"Concurrent Session Detection","text":"<pre><code>class SessionSecurityManager:\n    def __init__(self, session_manager: DistributedSessionManager):\n        self.session_manager = session_manager\n\n    async def detect_concurrent_sessions(\n        self,\n        user_id: str,\n        current_session_id: str\n    ) -&gt; Dict:\n        sessions = await self.session_manager.get_user_sessions(user_id)\n\n        other_sessions = [s for s in sessions if s[\"session_id\"] != current_session_id]\n        concurrent_count = len(other_sessions)\n\n        if concurrent_count &gt; 0:\n            # Check for suspicious patterns\n            suspicious_patterns = await self._analyze_session_patterns(other_sessions)\n\n            return {\n                \"concurrent_sessions\": concurrent_count,\n                \"suspicious_activity\": suspicious_patterns,\n                \"sessions\": other_sessions\n            }\n\n        return {\"concurrent_sessions\": 0, \"suspicious_activity\": False}\n\n    async def _analyze_session_patterns(self, sessions: List[Dict]) -&gt; bool:\n        # Check for multiple different IP addresses\n        ip_addresses = set(s.get(\"ip_address\") for s in sessions if s.get(\"ip_address\"))\n\n        # Check for multiple different user agents\n        user_agents = set(s.get(\"user_agent\") for s in sessions if s.get(\"user_agent\"))\n\n        # Check for rapid session creation\n        creation_times = [\n            datetime.fromisoformat(s[\"created_at\"])\n            for s in sessions\n        ]\n\n        if len(creation_times) &gt; 1:\n            time_diff = max(creation_times) - min(creation_times)\n            rapid_creation = time_diff &lt; timedelta(minutes=5)\n        else:\n            rapid_creation = False\n\n        # Define suspicious criteria\n        return (\n            len(ip_addresses) &gt; 2 or  # More than 2 different IPs\n            len(user_agents) &gt; 3 or   # More than 3 different user agents\n            rapid_creation             # Rapid session creation\n        )\n\n    async def force_reauthentication(self, user_id: str, reason: str) -&gt; bool:\n        # Invalidate all sessions except current\n        count = await self.session_manager.invalidate_all_user_sessions(user_id)\n\n        # Log security event\n        await self._log_security_event(user_id, \"force_reauthentication\", {\n            \"reason\": reason,\n            \"sessions_invalidated\": count\n        })\n\n        return count &gt; 0\n\n    async def _log_security_event(self, user_id: str, event_type: str, data: Dict):\n        # Implement according to your security logging strategy\n        pass\n</code></pre>"},{"location":"atomic/security/session-management-patterns/#session-fingerprinting","title":"Session Fingerprinting","text":"<pre><code>import hashlib\nfrom typing import Dict\n\nclass SessionFingerprinting:\n    @staticmethod\n    def generate_device_fingerprint(request_data: Dict) -&gt; str:\n        \"\"\"Generate a device fingerprint from request headers and metadata.\"\"\"\n\n        fingerprint_data = {\n            \"user_agent\": request_data.get(\"user_agent\", \"\"),\n            \"accept_language\": request_data.get(\"accept_language\", \"\"),\n            \"accept_encoding\": request_data.get(\"accept_encoding\", \"\"),\n            \"screen_resolution\": request_data.get(\"screen_resolution\", \"\"),\n            \"timezone\": request_data.get(\"timezone\", \"\"),\n            \"platform\": request_data.get(\"platform\", \"\")\n        }\n\n        # Create a consistent string representation\n        fingerprint_string = \"|\".join(\n            f\"{k}:{v}\" for k, v in sorted(fingerprint_data.items())\n        )\n\n        # Hash the fingerprint\n        return hashlib.sha256(fingerprint_string.encode()).hexdigest()\n\n    @staticmethod\n    def validate_fingerprint(\n        stored_fingerprint: str,\n        current_fingerprint: str,\n        tolerance: float = 0.8\n    ) -&gt; bool:\n        \"\"\"Validate if current fingerprint matches stored one with tolerance.\"\"\"\n\n        if stored_fingerprint == current_fingerprint:\n            return True\n\n        # Calculate similarity (simple example)\n        # In practice, you might want more sophisticated comparison\n        return SessionFingerprinting._calculate_similarity(\n            stored_fingerprint,\n            current_fingerprint\n        ) &gt;= tolerance\n\n    @staticmethod\n    def _calculate_similarity(fp1: str, fp2: str) -&gt; float:\n        \"\"\"Calculate similarity between two fingerprints.\"\"\"\n        # Simple character-based similarity\n        if not fp1 or not fp2:\n            return 0.0\n\n        max_len = max(len(fp1), len(fp2))\n        matches = sum(c1 == c2 for c1, c2 in zip(fp1, fp2))\n\n        return matches / max_len\n</code></pre>"},{"location":"atomic/security/session-management-patterns/#session-cleanup-and-maintenance","title":"Session Cleanup and Maintenance","text":""},{"location":"atomic/security/session-management-patterns/#automatic-session-cleanup","title":"Automatic Session Cleanup","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\n\nclass SessionCleanupService:\n    def __init__(\n        self,\n        session_manager: DistributedSessionManager,\n        cleanup_interval: timedelta = timedelta(hours=1)\n    ):\n        self.session_manager = session_manager\n        self.cleanup_interval = cleanup_interval\n        self.running = False\n\n    async def start_cleanup_service(self):\n        \"\"\"Start the background cleanup service.\"\"\"\n        self.running = True\n\n        while self.running:\n            try:\n                await self._cleanup_expired_sessions()\n                await asyncio.sleep(self.cleanup_interval.total_seconds())\n            except Exception as e:\n                # Log error but continue running\n                print(f\"Session cleanup error: {e}\")\n                await asyncio.sleep(60)  # Wait 1 minute before retry\n\n    async def stop_cleanup_service(self):\n        \"\"\"Stop the background cleanup service.\"\"\"\n        self.running = False\n\n    async def _cleanup_expired_sessions(self):\n        \"\"\"Clean up expired sessions and orphaned data.\"\"\"\n\n        # Find all session keys\n        session_keys = []\n        cursor = 0\n\n        while True:\n            cursor, keys = await self.session_manager.redis.scan(\n                cursor=cursor,\n                match=\"session:*\",\n                count=100\n            )\n            session_keys.extend(keys)\n\n            if cursor == 0:\n                break\n\n        expired_count = 0\n        orphaned_count = 0\n\n        for key in session_keys:\n            session_data = await self.session_manager.redis.get(key)\n\n            if not session_data:\n                continue\n\n            try:\n                session = json.loads(session_data)\n                expires_at = datetime.fromisoformat(session[\"expires_at\"])\n\n                if datetime.utcnow() &gt; expires_at:\n                    session_id = session[\"session_id\"]\n                    await self.session_manager.invalidate_session(session_id)\n                    expired_count += 1\n\n            except (json.JSONDecodeError, KeyError, ValueError):\n                # Malformed session data, remove it\n                await self.session_manager.redis.delete(key)\n                orphaned_count += 1\n\n        if expired_count &gt; 0 or orphaned_count &gt; 0:\n            print(f\"Cleaned up {expired_count} expired and {orphaned_count} orphaned sessions\")\n\n    async def cleanup_user_session_sets(self):\n        \"\"\"Clean up user session sets that may have orphaned session IDs.\"\"\"\n\n        cursor = 0\n        while True:\n            cursor, keys = await self.session_manager.redis.scan(\n                cursor=cursor,\n                match=\"user_sessions:*\",\n                count=100\n            )\n\n            for key in keys:\n                session_ids = await self.session_manager.redis.smembers(key)\n                valid_sessions = []\n\n                for session_id in session_ids:\n                    session_exists = await self.session_manager.redis.exists(f\"session:{session_id}\")\n                    if session_exists:\n                        valid_sessions.append(session_id)\n                    else:\n                        # Remove orphaned session ID\n                        await self.session_manager.redis.srem(key, session_id)\n\n                # If no valid sessions remain, delete the set\n                if not valid_sessions:\n                    await self.session_manager.redis.delete(key)\n\n            if cursor == 0:\n                break\n</code></pre>"},{"location":"atomic/security/session-management-patterns/#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"atomic/security/session-management-patterns/#session-middleware","title":"Session Middleware","text":"<pre><code>from fastapi import Request, HTTPException, status\nfrom fastapi.middleware.base import BaseHTTPMiddleware\n\nclass SessionMiddleware(BaseHTTPMiddleware):\n    def __init__(\n        self,\n        app,\n        session_manager: DistributedSessionManager,\n        security_manager: SessionSecurityManager\n    ):\n        super().__init__(app)\n        self.session_manager = session_manager\n        self.security_manager = security_manager\n\n    async def dispatch(self, request: Request, call_next):\n        # Extract session ID from header or cookie\n        session_id = request.headers.get(\"X-Session-ID\") or request.cookies.get(\"session_id\")\n\n        if session_id:\n            session = await self.session_manager.get_session(session_id)\n\n            if session:\n                request.state.session = session\n                request.state.user_id = session[\"user_id\"]\n\n                # Check for suspicious activity\n                security_check = await self.security_manager.detect_concurrent_sessions(\n                    session[\"user_id\"],\n                    session_id\n                )\n\n                if security_check[\"suspicious_activity\"]:\n                    # Log and potentially require re-authentication\n                    request.state.requires_security_check = True\n            else:\n                request.state.session = None\n        else:\n            request.state.session = None\n\n        response = await call_next(request)\n        return response\n\n# Usage in FastAPI app\nfrom fastapi import FastAPI, Depends\n\napp = FastAPI()\n\n# Initialize services\nsession_manager = DistributedSessionManager(redis_client)\nsecurity_manager = SessionSecurityManager(session_manager)\n\n# Add middleware\napp.add_middleware(SessionMiddleware, session_manager, security_manager)\n\ndef get_current_session(request: Request) -&gt; Optional[Dict]:\n    return getattr(request.state, \"session\", None)\n\ndef require_session(request: Request) -&gt; Dict:\n    session = get_current_session(request)\n    if not session:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Valid session required\"\n        )\n    return session\n\n@app.get(\"/profile\")\nasync def get_profile(session: Dict = Depends(require_session)):\n    return {\"user_id\": session[\"user_id\"], \"session_id\": session[\"session_id\"]}\n\n@app.post(\"/logout\")\nasync def logout(session: Dict = Depends(require_session)):\n    await session_manager.invalidate_session(session[\"session_id\"])\n    return {\"message\": \"Successfully logged out\"}\n\n@app.get(\"/sessions\")\nasync def get_user_sessions(session: Dict = Depends(require_session)):\n    sessions = await session_manager.get_user_sessions(session[\"user_id\"])\n    return {\"sessions\": sessions}\n</code></pre>"},{"location":"atomic/security/session-management-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication &amp; Authorization Guide</li> <li>Redis Integration Guide</li> <li>Security Testing Guide</li> </ul>"},{"location":"atomic/security/session-management-patterns/#best-practices","title":"Best Practices","text":"<ol> <li>Session Storage:</li> <li>Use Redis for distributed session storage</li> <li>Implement proper TTL management</li> <li> <p>Store minimal session data</p> </li> <li> <p>Security:</p> </li> <li>Generate unique session IDs</li> <li>Implement session fingerprinting</li> <li> <p>Monitor for concurrent sessions</p> </li> <li> <p>Performance:</p> </li> <li>Use connection pooling for Redis</li> <li>Implement efficient cleanup processes</li> <li> <p>Cache frequently accessed session data</p> </li> <li> <p>Monitoring:</p> </li> <li>Track session creation and invalidation</li> <li>Monitor for suspicious patterns</li> <li>Log security-related events</li> </ol>"},{"location":"atomic/security/session-management-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/security/authentication-authorization-guide.md</code> \u2014 Auth patterns</li> <li><code>docs/atomic/infrastructure/redis.md</code> \u2014 Redis session storage</li> <li><code>docs/atomic/services/fastapi/security-patterns.md</code> \u2014 FastAPI sessions</li> <li><code>docs/atomic/security/security-testing-guide.md</code> \u2014 Session testing</li> </ul>"},{"location":"atomic/services/aiogram/basic-setup/","title":"Aiogram Basic Setup","text":"<p>This file captures the minimal scaffold for an Aiogram-based Telegram bot service operating within the Improved Hybrid Approach.</p>"},{"location":"atomic/services/aiogram/basic-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+</li> <li><code>aiogram&gt;=3.4</code></li> <li>Access to Telegram bot token (stored in secrets, not in code)</li> <li>Redis and RabbitMQ endpoints provided via settings</li> </ul>"},{"location":"atomic/services/aiogram/basic-setup/#project-skeleton","title":"Project Skeleton","text":"<pre><code>src/\n\u251c\u2500\u2500 bot/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 handlers/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 photos.py\n\u2502   \u251c\u2500\u2500 middlewares/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 request_id.py\n\u2502   \u2514\u2500\u2500 services/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 photo_service.py\n\u251c\u2500\u2500 shared/\n\u2502   \u2514\u2500\u2500 dtos/\n\u2502       \u2514\u2500\u2500 photo_payload.py\n\u2514\u2500\u2500 tests/\n</code></pre>"},{"location":"atomic/services/aiogram/basic-setup/#dependencies","title":"Dependencies","text":"<pre><code>[project.dependencies]\naiogram = \"^3.4\"\nredis = \"^5.0\"\naio-pika = \"^9.4\"\nhttpx = \"^0.27\"\n</code></pre>"},{"location":"atomic/services/aiogram/basic-setup/#entry-point","title":"Entry Point","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nfrom aiogram import Bot, Dispatcher\nfrom src.bot.config import get_settings\nfrom src.bot.handlers import register_handlers\nfrom src.bot.lifespan import build_lifespan\n\n\ndef main() -&gt; None:\n    settings = get_settings()\n    bot = Bot(token=settings.telegram_token)\n    dp = Dispatcher()\n\n    register_handlers(dp)\n\n    lifespan = build_lifespan(settings, dp)\n\n    asyncio.run(lifespan(bot, dp))\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"atomic/services/aiogram/basic-setup/#checklist","title":"Checklist","text":"<ul> <li> Bot token sourced from configuration, never hard-coded.</li> <li> Dispatcher and Bot initialised exactly once.</li> <li> Handlers are registered via dedicated function to maintain clarity.</li> <li> Lifespan handles Redis/RabbitMQ setup (see <code>bot-initialization.md</code>).</li> </ul>"},{"location":"atomic/services/aiogram/basic-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/bot-initialization.md</code></li> <li><code>docs/atomic/architecture/service-separation-principles.md</code></li> </ul>"},{"location":"atomic/services/aiogram/bot-initialization/","title":"Bot Initialization","text":"<p>Correct bot and dispatcher setup ensures single event loop ownership and predictable lifecycle management.</p>"},{"location":"atomic/services/aiogram/bot-initialization/#lifespan-pattern","title":"Lifespan Pattern","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nfrom contextlib import asynccontextmanager\nfrom aiogram import Bot, Dispatcher\nfrom src.bot.config import Settings\nfrom src.bot.dependencies import RedisClient, RabbitMQClient\n\n\ndef build_lifespan(settings: Settings, dp: Dispatcher):\n    @asynccontextmanager\n    async def lifespan(bot: Bot):\n        redis = RedisClient(settings.redis_url)\n        rabbit = RabbitMQClient(settings.rabbitmq_url)\n\n        await redis.connect()\n        await rabbit.connect()\n\n        dp.startup.register(lambda: {\"redis\": redis, \"rabbitmq\": rabbit})\n        dp.shutdown.register(redis.close)\n        dp.shutdown.register(rabbit.close)\n\n        try:\n            await dp.start_polling(bot)\n            yield\n        finally:\n            await dp.storage.close()  # if storage is used\n\n    return lifespan\n</code></pre>"},{"location":"atomic/services/aiogram/bot-initialization/#guidelines","title":"Guidelines","text":"<ul> <li>Initialise Bot with connection pooling (<code>session=ClientSession()</code> when using custom HTTP settings).</li> <li>Configure logging before starting polling to capture early failures.</li> <li>Use <code>asyncio.run()</code> only in the main module.</li> <li>Register signal handlers to cancel polling gracefully (Aiogram handles this internally, but explicit logging helps).</li> </ul>"},{"location":"atomic/services/aiogram/bot-initialization/#webhook-mode","title":"Webhook Mode","text":"<p>See <code>webhook-configuration.md</code> for production webhook setups when polling is not acceptable.</p>"},{"location":"atomic/services/aiogram/bot-initialization/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/dependency-injection.md</code></li> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> </ul>"},{"location":"atomic/services/aiogram/dependency-injection/","title":"Dependency Injection","text":"<p>Aiogram exposes simple DI hooks via dispatcher startup/shutdown callbacks. Use them to provide infrastructure clients to handlers.</p>"},{"location":"atomic/services/aiogram/dependency-injection/#startup-registration","title":"Startup Registration","text":"<pre><code>from __future__ import annotations\n\nfrom aiogram import Dispatcher\nfrom src.bot.dependencies import RedisClient, RabbitMQClient\n\n\ndef register_dependencies(dp: Dispatcher, redis: RedisClient, rabbit: RabbitMQClient) -&gt; None:\n    async def on_startup() -&gt; dict[str, object]:\n        return {\n            \"redis\": redis,\n            \"rabbitmq\": rabbit,\n        }\n\n    dp.startup.register(on_startup)\n\n    async def on_shutdown() -&gt; None:\n        await redis.close()\n        await rabbit.close()\n\n    dp.shutdown.register(on_shutdown)\n</code></pre>"},{"location":"atomic/services/aiogram/dependency-injection/#handler-signature","title":"Handler Signature","text":"<pre><code>from aiogram.types import Message\nfrom src.bot.dependencies import RedisClient, RabbitMQClient\n\n\nasync def handle_photo(\n    message: Message,\n    redis: RedisClient,\n    rabbitmq: RabbitMQClient,\n) -&gt; None:\n    ...\n</code></pre> <p>Aiogram injects dependency values into handler parameters using the keys returned from startup.</p>"},{"location":"atomic/services/aiogram/dependency-injection/#guidelines","title":"Guidelines","text":"<ul> <li>Instantiate clients once during lifespan, not per handler.</li> <li>Add typing aliases for clarity (<code>type Redis = RedisClient</code> if needed).</li> <li>Compose services in factories (<code>get_photo_service(redis, rabbitmq)</code>) when handlers require higher-level abstractions.</li> </ul>"},{"location":"atomic/services/aiogram/dependency-injection/#testing","title":"Testing","text":"<ul> <li>Provide fakes directly in unit tests (handlers accept parameters explicitly).</li> <li>For integration tests, reuse real clients from Testcontainers and register them via the same mechanism.</li> </ul>"},{"location":"atomic/services/aiogram/dependency-injection/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/middleware-setup.md</code></li> <li><code>docs/atomic/services/aiogram/testing-strategies.md</code></li> </ul>"},{"location":"atomic/services/aiogram/handler-patterns/","title":"Handler Patterns","text":"<p>Handlers orchestrate domain services in response to Telegram updates. Keep them concise, deterministic, and idempotent.</p>"},{"location":"atomic/services/aiogram/handler-patterns/#basic-handler-structure","title":"Basic Handler Structure","text":"<pre><code>from __future__ import annotations\n\nfrom aiogram import Router\nfrom aiogram.types import Message\nfrom aiogram.filters import Command\nfrom src.bot.services.photo_service import PhotoService\nfrom src.bot.dependencies import get_photo_service\n\nrouter = Router()\n\n\n@router.message(Command(\"start\"))\nasync def cmd_start(message: Message) -&gt; None:\n    await message.answer(\"Hi! Send me a photo.\")\n\n\n@router.message()\nasync def handle_photo(\n    message: Message,\n    photo_service: PhotoService,\n) -&gt; None:\n    await photo_service.process_photo(message)\n</code></pre>"},{"location":"atomic/services/aiogram/handler-patterns/#principles","title":"Principles","text":"<ul> <li>Register handlers via routers, not directly on the dispatcher.</li> <li>Filter aggressively: use <code>F.photo</code>, <code>F.text</code>, or custom filters to avoid expensive branching inside handlers.</li> <li>Delegate domain logic to services (e.g., <code>PhotoService</code>).</li> <li>Propagate Request IDs via middleware; handlers should rely on context rather than generating their own IDs unless necessary.</li> </ul>"},{"location":"atomic/services/aiogram/handler-patterns/#error-handling","title":"Error Handling","text":"<ul> <li>Wrap domain/service exceptions and provide user-friendly Telegram responses.</li> <li>Log exceptions with context; avoid leaking secrets or internal IDs.</li> <li>Use fallback handlers (<code>router.errors.register</code>) for unhandled exceptions to notify users gracefully.</li> </ul>"},{"location":"atomic/services/aiogram/handler-patterns/#idempotency","title":"Idempotency","text":"<ul> <li>Use Redis to prevent duplicate processing (store message IDs keyed by user/chat).</li> <li>Check idempotency before downloading large files or publishing events.</li> </ul>"},{"location":"atomic/services/aiogram/handler-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/dependency-injection.md</code></li> <li><code>docs/atomic/services/aiogram/testing-strategies.md</code></li> </ul>"},{"location":"atomic/services/aiogram/middleware-setup/","title":"Middleware Setup","text":"<p>Middleware is the right place to inject cross-cutting concerns such as request IDs, tracing, and dependency context.</p>"},{"location":"atomic/services/aiogram/middleware-setup/#request-id-middleware","title":"Request ID Middleware","text":"<pre><code>from __future__ import annotations\n\nfrom aiogram import BaseMiddleware\nfrom aiogram.types import Update\nfrom typing import Any, Awaitable, Callable\nfrom src.core.logging import generate_request_id, set_request_id\n\n\nclass RequestIDMiddleware(BaseMiddleware):\n    async def __call__(\n        self,\n        handler: Callable[[Update, dict[str, Any]], Awaitable[Any]],\n        event: Update,\n        data: dict[str, Any],\n    ) -&gt; Any:\n        request_id = generate_request_id(\n            \"tg\",\n            user_id=getattr(event.message.from_user, \"id\", None),\n            chat_id=getattr(event.message.chat, \"id\", None),\n        )\n        set_request_id(request_id)\n        data[\"request_id\"] = request_id\n\n        return await handler(event, data)\n</code></pre> <p>Register during startup:</p> <pre><code>from src.bot.middlewares.request_id import RequestIDMiddleware\n\ndp.update.middleware(RequestIDMiddleware())\n</code></pre>"},{"location":"atomic/services/aiogram/middleware-setup/#dependency-middleware","title":"Dependency Middleware","text":"<ul> <li>Use startup hooks (<code>dp.startup.register</code>) to inject Redis/RabbitMQ clients into handler data.</li> <li>Optionally use middleware to fetch contextual data (user profile, feature flags) in a cached manner.</li> </ul>"},{"location":"atomic/services/aiogram/middleware-setup/#ordering","title":"Ordering","text":"<ul> <li>Request ID middleware should run first.</li> <li>Authentication middleware (if any) should precede handlers that depend on user context.</li> <li>Rate limiting middleware should run after request ID to reuse correlation IDs in logs.</li> </ul>"},{"location":"atomic/services/aiogram/middleware-setup/#testing","title":"Testing","text":"<ul> <li>Use Aiogram test utilities to assert middleware attaches <code>request_id</code>.</li> <li>Ensure middleware is excluded or adjusted in unit tests to keep them deterministic.</li> </ul>"},{"location":"atomic/services/aiogram/middleware-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/handler-patterns.md</code></li> <li><code>docs/atomic/observability/logging/request-id-tracking.md</code></li> </ul>"},{"location":"atomic/services/aiogram/state-management/","title":"State Management","text":"<p>Aiogram's FSM helps track conversational state. Use it sparingly and persist state externally when resilience is required.</p>"},{"location":"atomic/services/aiogram/state-management/#setup","title":"Setup","text":"<pre><code>from __future__ import annotations\n\nfrom aiogram.fsm.storage.redis import RedisStorage\nfrom aiogram.fsm.state import State, StatesGroup\nfrom aiogram import Dispatcher\n\n\nclass PhotoFlow(StatesGroup):\n    waiting_for_caption = State()\n\n\ndef configure_state(dp: Dispatcher, redis_url: str) -&gt; None:\n    storage = RedisStorage.from_url(redis_url)\n    dp.storage = storage\n</code></pre>"},{"location":"atomic/services/aiogram/state-management/#usage","title":"Usage","text":"<pre><code>from aiogram import Router\nfrom aiogram.types import Message\nfrom aiogram.fsm.context import FSMContext\nfrom src.bot.states import PhotoFlow\n\nrouter = Router()\n\n\n@router.message(F.photo)\nasync def ask_for_caption(message: Message, state: FSMContext) -&gt; None:\n    await state.set_state(PhotoFlow.waiting_for_caption)\n    await message.answer(\"Please provide a caption.\")\n\n\n@router.message(PhotoFlow.waiting_for_caption)\nasync def receive_caption(message: Message, state: FSMContext) -&gt; None:\n    caption = message.text or \"\"\n    await state.clear()\n    await message.answer(f\"Received caption: {caption}\")\n</code></pre>"},{"location":"atomic/services/aiogram/state-management/#guidelines","title":"Guidelines","text":"<ul> <li>Store minimal data in the FSM; large payloads belong in Redis or database services.</li> <li>Clean up state transitions (<code>await state.clear()</code>) to prevent stale sessions.</li> <li>Combine state with idempotency checks to avoid repeated processing after restarts.</li> <li>Persist FSM storage in Redis or database to survive restarts; in-memory storage is acceptable only for development.</li> </ul>"},{"location":"atomic/services/aiogram/state-management/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/services/aiogram/state-management/#global-fsm-storage-never-closed","title":"\u274c Global FSM Storage Never Closed","text":"<p>Problem: Memory leaks and connection pool exhaustion from unclosed Redis connections in FSM storage</p> <p>Symptom: Bot crashes after 3-7 days uptime with \"too many open files\" error or memory exhaustion</p> <p>Impact: Production crashes, requires frequent restarts, data loss on abrupt termination</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: Global storage that is never closed\n# src/api/handlers/poll.py\nfrom aiogram.fsm.storage.redis import RedisStorage\n\n_fsm_storage: RedisStorage | None = None\n\ndef get_fsm_storage() -&gt; RedisStorage:\n    \"\"\"Get or create FSM storage instance for state checking.\"\"\"\n    global _fsm_storage\n    if _fsm_storage is None:\n        _fsm_storage = RedisStorage.from_url(settings.redis_url)\n    return _fsm_storage  # \u26a0\ufe0f NEVER CLOSED \u2192 Memory and connection leaks!\n\n# Usage in handler\nasync def check_poll_handler(message: Message) -&gt; None:\n    storage = get_fsm_storage()  # Creates new connections indefinitely\n    state_data = await storage.get_data(...)\n</code></pre></p> <p>Why This Matters: - Redis connection pool is NEVER closed, accumulating over bot lifetime - Each connection holds memory, file descriptors, and network sockets - Over days/weeks \u2192 memory exhaustion \u2192 \"too many open files\" \u2192 crash - No graceful shutdown means in-flight state updates may be lost</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Proper lifecycle management with cleanup\nfrom aiogram.fsm.storage.redis import RedisStorage\n\n_fsm_storage: RedisStorage | None = None\n\ndef get_fsm_storage() -&gt; RedisStorage:\n    \"\"\"\n    Get shared FSM storage instance.\n\n    Returns:\n        Shared FSM storage instance for state management\n    \"\"\"\n    global _fsm_storage\n    if _fsm_storage is None:\n        _fsm_storage = RedisStorage.from_url(settings.redis_url)\n    return _fsm_storage\n\nasync def close_fsm_storage() -&gt; None:\n    \"\"\"Close FSM storage and release resources.\"\"\"\n    global _fsm_storage\n    if _fsm_storage is not None:\n        await _fsm_storage.close()\n        _fsm_storage = None\n        logger.info(\"fsm_storage_closed\", event=\"cleanup\")\n\n# In main bot entry point\nasync def main() -&gt; None:\n    \"\"\"Main bot entry point with proper cleanup.\"\"\"\n    try:\n        await dp.start_polling(bot)\n    finally:\n        # \u2705 Proper cleanup on shutdown\n        await close_fsm_storage()\n        await bot.session.close()\n        await storage.close()\n</code></pre></p> <p>Architecture Rule:</p> <p>All stateful resources (Redis clients, FSM storage, HTTP clients, database connections) MUST have explicit cleanup in application lifecycle hooks.</p> <p>Monitoring: <pre><code># Monitor memory growth over time\ndocker stats --no-stream bot_service\n\n# Check file descriptor leak (should be &lt; 100 for healthy bot)\ndocker exec bot_service sh -c 'ls /proc/$$/fd | wc -l'\n\n# Monitor Redis connections (should be stable, not growing)\ndocker exec redis redis-cli CLIENT LIST | wc -l\n</code></pre></p> <p>Related Anti-Patterns: - HTTP Client Proliferation \u2192 <code>docs/atomic/integrations/http-communication/http-client-patterns.md#http-client-proliferation</code> - Connection Pool Misuse \u2192 <code>docs/atomic/integrations/redis/connection-management.md#connection-pool-misuse</code></p>"},{"location":"atomic/services/aiogram/state-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/dependency-injection.md</code></li> <li><code>docs/atomic/integrations/redis/key-naming-conventions.md</code></li> <li><code>docs/atomic/integrations/cross-service/graceful-shutdown.md</code></li> </ul>"},{"location":"atomic/services/aiogram/testing-strategies/","title":"Testing Strategies","text":"<p>Telegram bots require the same rigour as HTTP services. Cover handlers, integration with Telegram API, and messaging side effects.</p>"},{"location":"atomic/services/aiogram/testing-strategies/#unit-tests","title":"Unit Tests","text":"<ul> <li>Use Aiogram's testing utilities (<code>aiogram.test</code>) or plain async tests with fakes.</li> <li>Call handlers directly with mocked <code>Message</code>/<code>CallbackQuery</code> objects.</li> <li>Provide fake Redis/RabbitMQ clients implementing the same interface.</li> </ul> <pre><code>@pytest.mark.asyncio\nasync def test_handle_photo_publishes_event(fake_message, fake_redis, fake_rabbit, photo_service):\n    await handle_photo(fake_message, rabbitmq=fake_rabbit, redis=fake_redis, service=photo_service)\n\n    fake_rabbit.assert_published(\"photo.received\")\n</code></pre>"},{"location":"atomic/services/aiogram/testing-strategies/#integration-tests","title":"Integration Tests","text":"<ul> <li>Use Testcontainers to start Redis and RabbitMQ.</li> <li>Spin up dispatcher via the real <code>build_lifespan</code> function and send synthetic updates.</li> <li>Verify published events, cached values, and Telegram responses (mock <code>Bot</code> HTTP calls).</li> </ul>"},{"location":"atomic/services/aiogram/testing-strategies/#end-to-end-tests","title":"End-to-End Tests","text":"<ul> <li>Optional but encouraged: send real updates via Telegram sandbox bots in staging.</li> <li>Ensure webhook endpoints respond with <code>200</code> quickly; tests should assert idempotency behaviour.</li> </ul>"},{"location":"atomic/services/aiogram/testing-strategies/#ci-requirements","title":"CI Requirements","text":"<ul> <li>Include bot tests in the standard pipeline (unit + integration).</li> <li>Validate that request ID middleware sets context for every update.</li> <li>Enforce coverage thresholds identical to API services.</li> </ul>"},{"location":"atomic/services/aiogram/testing-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/service-testing/aiogram-testing-patterns.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/services/aiogram/webhook-configuration/","title":"Webhook Configuration","text":"<p>Webhook mode is recommended for production deployments behind HTTPS. The bot receives updates via FastAPI or another HTTP server.</p>"},{"location":"atomic/services/aiogram/webhook-configuration/#architecture","title":"Architecture","text":"<pre><code>Telegram \u2192 HTTPS \u2192 Webhook endpoint \u2192 Aiogram Dispatcher \u2192 Handlers\n</code></pre> <p>Use a lightweight FastAPI app to receive webhooks and forward them to the dispatcher running in the same process.</p>"},{"location":"atomic/services/aiogram/webhook-configuration/#setup-steps","title":"Setup Steps","text":"<ol> <li>Expose a public HTTPS endpoint (NGINX, Cloudflare, AWS API Gateway).</li> <li>Generate a secret path (<code>/webhook/&lt;token-hash&gt;</code>).</li> <li>Register webhook with Telegram using <code>setWebhook</code>.</li> <li>Verify SSL/TLS configuration.</li> </ol>"},{"location":"atomic/services/aiogram/webhook-configuration/#example","title":"Example","text":"<pre><code>from __future__ import annotations\n\nfrom fastapi import FastAPI, Request\nfrom aiogram import Bot, Dispatcher\nfrom aiogram.types import Update\nfrom src.bot.factory import create_dispatcher\n\n\nbot = Bot(token=settings.telegram_token)\ndp = create_dispatcher(settings)\napp = FastAPI()\n\n\n@app.post(f\"/webhook/{settings.webhook_secret}\")\nasync def telegram_webhook(request: Request) -&gt; dict[str, str]:\n    update = Update.model_validate(await request.json(), context={\"bot\": bot})\n    await dp.feed_update(bot, update)\n    return {\"status\": \"ok\"}\n</code></pre> <p>Run webhook server with Uvicorn; polling must be disabled.</p>"},{"location":"atomic/services/aiogram/webhook-configuration/#operational-considerations","title":"Operational Considerations","text":"<ul> <li>Keep webhook endpoint stateless; rely on Redis/RabbitMQ for stateful operations.</li> <li>Validate the secret path to reject unauthorised requests.</li> <li>Gracefully handle retries by making handlers idempotent.</li> <li>Monitor delivery by inspecting Telegram webhook status (<code>getWebhookInfo</code>).</li> </ul>"},{"location":"atomic/services/aiogram/webhook-configuration/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/aiogram/bot-initialization.md</code></li> <li><code>docs/atomic/services/aiogram/handler-patterns.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/basic-setup/","title":"AsyncIO Worker Basic Setup","text":"<p>AsyncIO worker services run background jobs outside of HTTP request cycles. This guide covers the minimum bootstrap.</p>"},{"location":"atomic/services/asyncio-workers/basic-setup/#directory-layout","title":"Directory Layout","text":"<pre><code>src/\n\u251c\u2500\u2500 worker/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 tasks/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 photo_consumer.py\n\u2502   \u2514\u2500\u2500 services/\n\u2502       \u2514\u2500\u2500 photo_processor.py\n\u2514\u2500\u2500 shared/\n    \u2514\u2500\u2500 events/\n        \u2514\u2500\u2500 photo_received.py\n</code></pre>"},{"location":"atomic/services/asyncio-workers/basic-setup/#dependencies","title":"Dependencies","text":"<pre><code>[project.dependencies]\naio-pika = \"^9.4\"\nredis = \"^5.0\"\nasyncpg = \"^0.29\"  # optional\npydantic = \"^2.8\"\n</code></pre>"},{"location":"atomic/services/asyncio-workers/basic-setup/#entry-point-mainpy","title":"Entry Point (<code>main.py</code>)","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nfrom contextlib import suppress\nfrom src.worker.bootstrap import bootstrap\n\n\nasync def main() -&gt; None:\n    await bootstrap()\n\n\nif __name__ == \"__main__\":\n    with suppress(asyncio.CancelledError):\n        asyncio.run(main())\n</code></pre> <p><code>bootstrap()</code> connects to Redis/RabbitMQ, configures logging, and launches consumer tasks (see <code>task-management.md</code>).</p>"},{"location":"atomic/services/asyncio-workers/basic-setup/#checklist","title":"Checklist","text":"<ul> <li> <code>asyncio.run(main())</code> invoked only in <code>__main__</code> guard.</li> <li> Configuration loaded before logging.</li> <li> External clients instantiated once and passed to tasks.</li> <li> Signal handlers registered to stop gracefully.</li> </ul>"},{"location":"atomic/services/asyncio-workers/basic-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/main-function-patterns.md</code></li> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/dependency-management/","title":"Dependency Management","text":"<p>Workers depend on asynchronous clients (RabbitMQ, Redis, databases). Instantiate them once and share via lightweight containers.</p>"},{"location":"atomic/services/asyncio-workers/dependency-management/#building-dependencies","title":"Building Dependencies","text":"<pre><code>from __future__ import annotations\n\nfrom contextlib import AsyncExitStack\nfrom dataclasses import dataclass\nfrom src.worker.adapters.rabbitmq import RabbitMQClient\nfrom src.worker.adapters.redis import RedisClient\nfrom src.worker.config import Settings\n\n\n@dataclass\nclass Dependencies:\n    rabbitmq: RabbitMQClient\n    redis: RedisClient\n\n\nasync def build_dependencies(settings: Settings, stack: AsyncExitStack) -&gt; Dependencies:\n    rabbitmq = RabbitMQClient(settings.rabbitmq_url)\n    redis = RedisClient(settings.redis_url)\n\n    await stack.enter_async_context(rabbitmq.connect())\n    await stack.enter_async_context(redis.connect())\n\n    return Dependencies(rabbitmq=rabbitmq, redis=redis)\n</code></pre> <p><code>AsyncExitStack</code> ensures resources close automatically on exit.</p>"},{"location":"atomic/services/asyncio-workers/dependency-management/#guidelines","title":"Guidelines","text":"<ul> <li>Load configuration once in <code>main()</code> and pass to builders.</li> <li>Reuse the same dependencies across all tasks; do not create new connections in loops.</li> <li>Wrap third-party clients that lack async context managers to provide one yourself.</li> <li>Expose typed helpers (<code>deps.rabbitmq.channel</code>) but hide low-level connection details from tasks where possible.</li> </ul>"},{"location":"atomic/services/asyncio-workers/dependency-management/#testing","title":"Testing","text":"<ul> <li>Provide fake dependency objects with the same interface for unit tests.</li> <li>Integration tests can spin up real brokers via Testcontainers and call <code>build_dependencies()</code> with overridden URLs.</li> </ul>"},{"location":"atomic/services/asyncio-workers/dependency-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/task-management.md</code></li> <li><code>docs/atomic/services/asyncio-workers/error-handling.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/error-handling/","title":"Error Handling","text":"<p>Workers process asynchronous jobs where failure semantics differ from HTTP services. Handle exceptions thoughtfully to preserve message guarantees.</p>"},{"location":"atomic/services/asyncio-workers/error-handling/#principles","title":"Principles","text":"<ul> <li>Treat expected business errors separately from infrastructure failures.</li> <li>Log errors with structured metadata (request ID, message ID, retry count).</li> <li>Decide on retry vs. dead-letter behaviour per queue.</li> </ul>"},{"location":"atomic/services/asyncio-workers/error-handling/#pattern","title":"Pattern","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nfrom src.worker.metrics import WorkerMetrics\nfrom src.worker.exceptions import RecoverableError, FatalError\n\n\nclass PhotoConsumer:\n    async def run(self) -&gt; None:\n        async for message in self.queue.consume():\n            request_id = message.headers.get(\"x-request-id\")\n            try:\n                await self.handle_message(message, request_id)\n            except RecoverableError as exc:\n                await message.nack(requeue=True)\n                WorkerMetrics.retries.inc()\n            except FatalError as exc:\n                await message.reject(requeue=False)\n                WorkerMetrics.dead_letters.inc()\n            except Exception:\n                await message.reject(requeue=False)\n                raise\n            else:\n                await message.ack()\n</code></pre>"},{"location":"atomic/services/asyncio-workers/error-handling/#guidelines","title":"Guidelines","text":"<ul> <li>Use idempotency keys to avoid duplicate processing when requeueing.</li> <li>Wrap external calls with retries/backoff; raise <code>RecoverableError</code> for transient issues.</li> <li>Convert unexpected exceptions into alerts; allow orchestrator to restart worker if necessary.</li> <li>Ensure <code>CancelledError</code> is propagated during shutdown (do not swallow it).</li> </ul>"},{"location":"atomic/services/asyncio-workers/error-handling/#monitoring","title":"Monitoring","text":"<ul> <li>Emit metrics for processed/failed/retried messages.</li> <li>Add structured logs with <code>reason=...</code> to speed up post-incident analysis.</li> </ul>"},{"location":"atomic/services/asyncio-workers/error-handling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/task-management.md</code></li> <li><code>docs/atomic/observability/logging/log-correlation.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/main-function-patterns/","title":"Main Function Patterns","text":"<p>Workers own their event loop. The <code>main()</code> coroutine orchestrates configuration, dependency setup, task orchestration, and shutdown.</p>"},{"location":"atomic/services/asyncio-workers/main-function-patterns/#boilerplate","title":"Boilerplate","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nimport signal\nfrom contextlib import AsyncExitStack\nfrom src.worker.config import get_settings\nfrom src.worker.dependencies import build_dependencies\nfrom src.worker.task_runner import start_tasks, stop_tasks\n\n\nasync def main() -&gt; None:\n    settings = get_settings()\n    stack = AsyncExitStack()\n\n    async with stack:\n        deps = await build_dependencies(settings, stack)\n        stop_event = asyncio.Event()\n\n        for sig in (signal.SIGTERM, signal.SIGINT):\n            asyncio.get_running_loop().add_signal_handler(sig, stop_event.set)\n\n        tasks = await start_tasks(deps)\n\n        await stop_event.wait()\n        await stop_tasks(tasks)\n</code></pre>"},{"location":"atomic/services/asyncio-workers/main-function-patterns/#guidelines","title":"Guidelines","text":"<ul> <li>Use <code>AsyncExitStack</code> to manage resources (redis connections, RabbitMQ channels).</li> <li>Register signal handlers once per process.</li> <li>Wrap main body with structured logging context to include request IDs for emitted events.</li> <li>Add health check hooks if the worker exposes metrics or status endpoints.</li> </ul>"},{"location":"atomic/services/asyncio-workers/main-function-patterns/#testing","title":"Testing","text":"<ul> <li>Unit-test <code>build_dependencies</code> with fakes.</li> <li>Integration-test <code>main()</code> via <code>asyncio.run(main())</code> in controlled environment; assert cleanup occurs when stop event is triggered.</li> </ul>"},{"location":"atomic/services/asyncio-workers/main-function-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/signal-handling.md</code></li> <li><code>docs/atomic/services/asyncio-workers/task-management.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/signal-handling/","title":"Signal Handling","text":"<p>Graceful shutdown prevents data loss and avoids orphaned tasks. Workers must listen for POSIX signals and stop cleanly.</p>"},{"location":"atomic/services/asyncio-workers/signal-handling/#implementation","title":"Implementation","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nimport signal\nfrom typing import Iterable\n\n\ndef register_signal_handlers(loop: asyncio.AbstractEventLoop, stop_event: asyncio.Event) -&gt; None:\n    for sig in (signal.SIGTERM, signal.SIGINT):\n        loop.add_signal_handler(sig, stop_event.set)\n\n\ndef unregister_signal_handlers(loop: asyncio.AbstractEventLoop) -&gt; None:\n    for sig in (signal.SIGTERM, signal.SIGINT):\n        loop.remove_signal_handler(sig)\n</code></pre> <p>Usage in <code>main()</code>:</p> <pre><code>stop_event = asyncio.Event()\nloop = asyncio.get_running_loop()\nregister_signal_handlers(loop, stop_event)\n\ntry:\n    await stop_event.wait()\nfinally:\n    unregister_signal_handlers(loop)\n</code></pre>"},{"location":"atomic/services/asyncio-workers/signal-handling/#shutdown-workflow","title":"Shutdown Workflow","text":"<ol> <li>Signal handler sets <code>stop_event</code>.</li> <li>Long-running tasks check <code>stop_event.is_set()</code> and exit loops.</li> <li>Consumers acknowledge in-flight messages and close connections.</li> <li>Resources disposed (RabbitMQ, Redis, DB) via <code>AsyncExitStack</code> or explicit closures.</li> <li>Log <code>worker_shutdown_completed</code> with context for observability.</li> </ol>"},{"location":"atomic/services/asyncio-workers/signal-handling/#testing","title":"Testing","text":"<ul> <li>Simulate signals in integration tests (<code>os.kill(os.getpid(), signal.SIGTERM)</code> inside subprocess).</li> <li>Assert tasks cancel gracefully without raising unhandled exceptions.</li> </ul>"},{"location":"atomic/services/asyncio-workers/signal-handling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/task-management.md</code></li> <li><code>docs/atomic/observability/logging/structured-logging.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/task-management/","title":"Task Management","text":"<p>Manage background tasks explicitly to avoid orphaned coroutines and to ensure proper shutdown.</p>"},{"location":"atomic/services/asyncio-workers/task-management/#launching-tasks","title":"Launching Tasks","text":"<pre><code>from __future__ import annotations\n\nimport asyncio\nfrom typing import Iterable\nfrom src.worker.consumers import PhotoConsumer\n\n\nasync def start_tasks(deps) -&gt; list[asyncio.Task[None]]:\n    consumer = PhotoConsumer(deps.rabbitmq, deps.redis)\n    task = asyncio.create_task(consumer.run(), name=\"photo-consumer\")\n    return [task]\n</code></pre>"},{"location":"atomic/services/asyncio-workers/task-management/#coordinating-shutdown","title":"Coordinating Shutdown","text":"<pre><code>async def stop_tasks(tasks: Iterable[asyncio.Task[None]]) -&gt; None:\n    for task in tasks:\n        task.cancel()\n\n    for task in tasks:\n        try:\n            await task\n        except asyncio.CancelledError:\n            continue\n</code></pre>"},{"location":"atomic/services/asyncio-workers/task-management/#supervising-loops","title":"Supervising Loops","text":"<ul> <li>Use <code>asyncio.TaskGroup</code> (Python 3.12+) to supervise multiple consumers.</li> <li>Ensure tasks periodically check <code>asyncio.current_task().cancelled()</code> or a shared <code>stop_event</code>.</li> <li>Log task lifecycle events (<code>task_started</code>, <code>task_cancelled</code>, <code>task_failed</code>).</li> </ul>"},{"location":"atomic/services/asyncio-workers/task-management/#backpressure-concurrency","title":"Backpressure &amp; Concurrency","text":"<ul> <li>Limit concurrency via worker pools or semaphores when processing heavy workloads.</li> <li>Implement retry/backoff inside consumers for transient failures.</li> <li>For RabbitMQ, use QoS to control message prefetch.</li> </ul>"},{"location":"atomic/services/asyncio-workers/task-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/asyncio-workers/error-handling.md</code></li> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> </ul>"},{"location":"atomic/services/asyncio-workers/testing-strategies/","title":"Testing Strategies","text":"<p>AsyncIO workers require rigorous tests to prevent regressions in long-running processes.</p>"},{"location":"atomic/services/asyncio-workers/testing-strategies/#unit-tests","title":"Unit Tests","text":"<ul> <li>Test task functions in isolation using fakes for Redis/RabbitMQ.</li> <li>Use <code>pytest.mark.asyncio</code> and manually create event loops where needed.</li> <li>Mock time/clock functions when testing retries or backoff.</li> </ul> <pre><code>@pytest.mark.asyncio\nasync def test_process_photo_retries_on_recoverable_error(fake_deps, photo_consumer):\n    fake_deps.rabbitmq.raise_on_publish(RecoverableError())\n\n    await photo_consumer.handle_message(fake_message, request_id=\"req-123\")\n\n    assert fake_message.nacked\n</code></pre>"},{"location":"atomic/services/asyncio-workers/testing-strategies/#integration-tests","title":"Integration Tests","text":"<ul> <li>Launch Testcontainers for RabbitMQ/Redis, run consumer logic against real queues.</li> <li>Trigger stop events to ensure graceful shutdown path is covered.</li> <li>Verify that messages are acknowledged or requeued as expected.</li> </ul>"},{"location":"atomic/services/asyncio-workers/testing-strategies/#end-to-end-tests","title":"End-to-End Tests","text":"<ul> <li>Optional but valuable: run workers together with producers in staging, send real events, and assert downstream effects (database writes, HTTP callbacks).</li> </ul>"},{"location":"atomic/services/asyncio-workers/testing-strategies/#ci-expectations","title":"CI Expectations","text":"<ul> <li>Workers share the same CI pipeline as other services: linting, typing, tests, security scans.</li> <li>Coverage thresholds apply; critical paths must be 100% covered.</li> <li>Publish logs from integration tests for debugging intermittent failures.</li> </ul>"},{"location":"atomic/services/asyncio-workers/testing-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/service-testing/asyncio-testing-patterns.md</code></li> <li><code>docs/atomic/services/asyncio-workers/error-handling.md</code></li> </ul>"},{"location":"atomic/services/data-services/http-api-design/","title":"HTTP API Design for Data Services","text":"<p>Data services expose HTTP endpoints consumed by business services. Contracts must be stable, well-documented, and domain-aware.</p>"},{"location":"atomic/services/data-services/http-api-design/#endpoint-structure","title":"Endpoint Structure","text":"<ul> <li>Prefix all routes with <code>/api/v1</code> (bump version on breaking changes).</li> <li>Use nouns for resource endpoints (<code>/users</code>, <code>/orders/{id}</code>) and verbs for commands when needed (<code>/orders/{id}/cancel</code>).</li> <li>Provide domain-level operations (aggregations, projections) in addition to CRUD.</li> </ul>"},{"location":"atomic/services/data-services/http-api-design/#response-format","title":"Response Format","text":"<ul> <li>Return DTOs defined in <code>src/schemas/</code> with descriptive fields.</li> <li>Use cursor-based pagination for large collections (<code>next_cursor</code>, <code>limit</code>).</li> <li>Include consistent metadata (e.g., <code>total_items</code> if available) without leaking internal IDs.</li> </ul>"},{"location":"atomic/services/data-services/http-api-design/#error-semantics","title":"Error Semantics","text":"<ul> <li>400 \u2013 validation errors (missing/invalid data).</li> <li>404 \u2013 resource not found.</li> <li>409 \u2013 conflict (duplicate keys, version mismatch).</li> <li>422 \u2013 domain constraint violations when input is syntactically valid but semantically incorrect.</li> <li>500 \u2013 unexpected errors (should be rare; log and alert).</li> </ul> <p>Error responses follow Problem Details (<code>error-handling.md</code>).</p>"},{"location":"atomic/services/data-services/http-api-design/#idempotency","title":"Idempotency","text":"<ul> <li>Require <code>Idempotency-Key</code> header for non-idempotent POST/PUT when clients might retry.</li> <li>Store keys in Redis with TTL; reject duplicates with 409/Problem Details.</li> </ul>"},{"location":"atomic/services/data-services/http-api-design/#observability","title":"Observability","text":"<ul> <li>Propagate request IDs from headers; generate if absent.</li> <li>Emit metrics per endpoint (throughput, latency, error rate).</li> <li>Log payload sizes for heavy endpoints to monitor traffic growth.</li> </ul>"},{"location":"atomic/services/data-services/http-api-design/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/testing-strategies.md</code></li> <li><code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code></li> </ul>"},{"location":"atomic/services/data-services/mongo-service-setup/","title":"MongoDB Service Setup","text":"<p>MongoDB data services handle document-centric workloads via async Motor clients.</p>"},{"location":"atomic/services/data-services/mongo-service-setup/#dependencies","title":"Dependencies","text":"<pre><code>[project.dependencies]\nmotor = \"^3.5\"\nfastapi = \"^0.111\"\npydantic = \"^2.8\"\n</code></pre>"},{"location":"atomic/services/data-services/mongo-service-setup/#client-initialization","title":"Client Initialization","text":"<pre><code>from __future__ import annotations\n\nfrom motor.motor_asyncio import AsyncIOMotorClient\nfrom src.core.config import Settings\n\n\ndef build_client(settings: Settings) -&gt; AsyncIOMotorClient:\n    client = AsyncIOMotorClient(\n        settings.mongo_url,\n        maxPoolSize=settings.mongo_max_pool,\n        minPoolSize=settings.mongo_min_pool,\n        serverSelectionTimeoutMS=5000,\n    )\n    return client\n</code></pre> <p>Use lifespan to connect/disconnect the client. Expose specific databases/collections via repositories.</p>"},{"location":"atomic/services/data-services/mongo-service-setup/#schema-validation","title":"Schema Validation","text":"<ul> <li>Define Pydantic models for documents and enforce them before inserts.</li> <li>Configure MongoDB JSON schema validators where appropriate.</li> <li>Maintain indexes in code or migrations and apply them during startup.</li> </ul>"},{"location":"atomic/services/data-services/mongo-service-setup/#aggregations","title":"Aggregations","text":"<ul> <li>Store aggregation pipelines close to repositories; keep them deterministic and documented.</li> <li>Test pipelines with realistic datasets.</li> </ul>"},{"location":"atomic/services/data-services/mongo-service-setup/#health-checks","title":"Health Checks","text":"<ul> <li>Ping the database (<code>await client.admin.command(\"ping\")</code>) in readiness probes.</li> <li>Monitor pool utilisation and slow queries via MongoDB profiler (production only with caution).</li> </ul>"},{"location":"atomic/services/data-services/mongo-service-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/repository-patterns.md</code></li> <li><code>docs/atomic/services/data-services/http-api-design.md</code></li> </ul>"},{"location":"atomic/services/data-services/postgres-service-setup/","title":"PostgreSQL Service Setup","text":"<p>PostgreSQL data services expose HTTP APIs that encapsulate relational data access. They use async SQLAlchemy and follow the Improved Hybrid separation.</p>"},{"location":"atomic/services/data-services/postgres-service-setup/#dependencies","title":"Dependencies","text":"<pre><code>[project.dependencies]\nfastapi = \"^0.111\"\nsqlalchemy = \"^2.0\"\nasyncpg = \"^0.29\"\nalembic = \"^1.13\"\nuvicorn = \"^0.30\"\npydantic = \"^2.8\"\n</code></pre>"},{"location":"atomic/services/data-services/postgres-service-setup/#engine-and-session","title":"Engine and Session","text":"<pre><code>from __future__ import annotations\n\nfrom sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine, async_sessionmaker\nfrom sqlalchemy.orm import sessionmaker\nfrom src.core.config import Settings\n\n\ndef build_engine(settings: Settings) -&gt; AsyncEngine:\n    return create_async_engine(\n        settings.database_url,\n        pool_size=settings.db_pool_size,\n        max_overflow=settings.db_max_overflow,\n        pool_timeout=30,\n        pool_recycle=1800,\n    )\n\n\ndef build_session_factory(engine: AsyncEngine) -&gt; async_sessionmaker:\n    return async_sessionmaker(engine, expire_on_commit=False)\n</code></pre> <p>Use lifespan to create engine/session factory once and inject sessions per request.</p>"},{"location":"atomic/services/data-services/postgres-service-setup/#migrations","title":"Migrations","text":"<ul> <li>Manage schema changes with Alembic; run migrations during deployment before starting the API.</li> <li>Store migration scripts in <code>migrations/</code> with sequential revisions.</li> <li>Use <code>alembic.ini</code> configured for async engines (<code>sqlalchemy.url = postgresql+asyncpg://...</code>).</li> </ul>"},{"location":"atomic/services/data-services/postgres-service-setup/#health-checks","title":"Health Checks","text":"<ul> <li>Expose <code>/ready</code> that verifies DB connectivity (<code>SELECT 1</code>).</li> <li>Monitor connection pool metrics (borrowed connections, wait time).</li> </ul>"},{"location":"atomic/services/data-services/postgres-service-setup/#performance","title":"Performance","text":"<ul> <li>Tune indexes for common query patterns; review with <code>EXPLAIN ANALYZE</code>.</li> <li>Use prepared statements or SQLAlchemy compiled cache for hot queries.</li> <li>Avoid loading entire result sets; rely on pagination.</li> </ul>"},{"location":"atomic/services/data-services/postgres-service-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/repository-patterns.md</code></li> <li><code>docs/atomic/services/data-services/transaction-management.md</code></li> </ul>"},{"location":"atomic/services/data-services/repository-patterns/","title":"Repository Patterns","text":"<p>Repositories encapsulate persistence logic and expose domain-aware operations to application services.</p>"},{"location":"atomic/services/data-services/repository-patterns/#sqlalchemy-example","title":"SQLAlchemy Example","text":"<pre><code>from __future__ import annotations\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\nfrom src.domain.users import User\nfrom src.schemas.users import UserCreate\n\n\nclass UserRepository:\n    def __init__(self, session: AsyncSession) -&gt; None:\n        self._session = session\n\n    async def create(self, payload: UserCreate) -&gt; User:\n        user = User(**payload.model_dump())\n        self._session.add(user)\n        await self._session.flush()\n        await self._session.refresh(user)\n        return user\n\n    async def get_by_email(self, email: str) -&gt; User | None:\n        stmt = select(User).where(User.email == email)\n        result = await self._session.execute(stmt)\n        return result.scalar_one_or_none()\n</code></pre>"},{"location":"atomic/services/data-services/repository-patterns/#mongodb-example","title":"MongoDB Example","text":"<pre><code>from __future__ import annotations\n\nfrom motor.motor_asyncio import AsyncIOMotorCollection\nfrom src.schemas.analytics import EventCreate\n\n\nclass AnalyticsRepository:\n    def __init__(self, collection: AsyncIOMotorCollection) -&gt; None:\n        self._collection = collection\n\n    async def insert_event(self, payload: EventCreate) -&gt; str:\n        document = payload.model_dump()\n        result = await self._collection.insert_one(document)\n        return str(result.inserted_id)\n</code></pre>"},{"location":"atomic/services/data-services/repository-patterns/#guidelines","title":"Guidelines","text":"<ul> <li>Define interfaces/protocols for repositories in the domain layer to decouple implementation.</li> <li>Keep each repository focused on a single aggregate or bounded context.</li> <li>Avoid returning ORM/ODM-specific objects to callers; map to domain models or DTOs.</li> <li>Implement pagination helpers returning <code>items</code> + <code>next_cursor</code>.</li> <li>Encapsulate caching logic within repositories if it relates to data access; otherwise move it to application services.</li> </ul>"},{"location":"atomic/services/data-services/repository-patterns/#testing","title":"Testing","text":"<ul> <li>Unit-test repositories with in-memory or fake clients for simple logic.</li> <li>Integration-test against real databases using Testcontainers and run migrations beforehand.</li> </ul>"},{"location":"atomic/services/data-services/repository-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/transaction-management.md</code></li> <li><code>docs/atomic/architecture/ddd-hexagonal-principles.md</code></li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/","title":"Testing Strategies","text":"<p>Data services must prove correctness across repositories, HTTP endpoints, and integration scenarios.</p>"},{"location":"atomic/services/data-services/testing-strategies/#unit-tests","title":"Unit Tests","text":"<ul> <li>Validate repositories against in-memory fakes or mocks for simple logic.</li> <li>Assert DTO validation catches schema violations before hitting the database.</li> <li>Ensure units of work commit/rollback as expected.</li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/#integration-tests","title":"Integration Tests","text":"<ul> <li>Use Testcontainers to run PostgreSQL and MongoDB.</li> <li>Apply migrations before tests (Alembic, custom scripts).</li> <li>Exercise HTTP endpoints via <code>httpx.AsyncClient</code>; verify status codes and payload shapes.</li> <li>Validate transactional behaviour (rollback on failure, unique constraint handling).</li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/#contract-tests","title":"Contract Tests","text":"<ul> <li>Snapshot OpenAPI schema and repository interfaces.</li> <li>Perform consumer-driven tests with business services to ensure response fields remain stable.</li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/#performanceload-tests","title":"Performance/Load Tests","text":"<ul> <li>Benchmark heavy aggregate endpoints and large batch operations.</li> <li>Identify slow queries (EXPLAIN) and ensure indexes cover key paths.</li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/#ci-expectations","title":"CI Expectations","text":"<ul> <li>Coverage thresholds identical to other services (100% for touched code).</li> <li>Security scanners run against dependencies (<code>trivy</code>, <code>pip-audit</code>).</li> <li>Publish SQL logs for failing integration tests to aid diagnosis.</li> </ul>"},{"location":"atomic/services/data-services/testing-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/database-testing.md</code></li> <li><code>docs/atomic/services/data-services/http-api-design.md</code></li> </ul>"},{"location":"atomic/services/data-services/transaction-management/","title":"Transaction Management","text":"<p>Data services must guarantee consistent writes and avoid leaking half-committed state to callers.</p>"},{"location":"atomic/services/data-services/transaction-management/#sqlalchemy-transactions","title":"SQLAlchemy Transactions","text":"<pre><code>from __future__ import annotations\n\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker\n\n\n@asynccontextmanager\nasync def unit_of_work(session_factory: async_sessionmaker[AsyncSession]) -&gt; AsyncSession:\n    session = session_factory()\n    try:\n        yield session\n        await session.commit()\n    except Exception:\n        await session.rollback()\n        raise\n    finally:\n        await session.close()\n</code></pre> <p>Usage in endpoints:</p> <pre><code>async with unit_of_work(session_factory) as session:\n    repo = UserRepository(session)\n    user = await repo.create(payload)\n</code></pre>"},{"location":"atomic/services/data-services/transaction-management/#mongodb-transactions","title":"MongoDB Transactions","text":"<ul> <li>Use multi-document transactions only when necessary (requires replica set).</li> <li>For single-document operations, rely on atomic updates and idempotency.</li> </ul> <pre><code>async with await client.start_session() as session:\n    async with session.start_transaction():\n        await collection.insert_one(doc, session=session)\n</code></pre>"},{"location":"atomic/services/data-services/transaction-management/#patterns","title":"Patterns","text":"<ul> <li>One transaction per request; avoid nested commits.</li> <li>Wrap domain services with units of work to ensure consistency across repositories.</li> <li>For eventual consistency, use transactional outbox patterns (write to DB + outbox table within the same transaction, then publish via worker).</li> </ul>"},{"location":"atomic/services/data-services/transaction-management/#observability","title":"Observability","text":"<ul> <li>Log transaction boundaries (<code>transaction_started</code>, <code>transaction_committed</code>, <code>transaction_rolled_back</code>).</li> <li>Monitor rollback rates; spikes indicate upstream issues or validation gaps.</li> </ul>"},{"location":"atomic/services/data-services/transaction-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/data-services/repository-patterns.md</code></li> <li><code>docs/atomic/services/data-services/testing-strategies.md</code></li> </ul>"},{"location":"atomic/services/fastapi/application-factory/","title":"FastAPI Application Factory","text":"<p>Use an application factory to keep side effects out of module scope, enable dependency overrides in tests, and wire integrations explicitly.</p>"},{"location":"atomic/services/fastapi/application-factory/#factory-pattern","title":"Factory Pattern","text":"<pre><code>from __future__ import annotations\n\nfrom fastapi import FastAPI\nfrom src.core.config import Settings, get_settings\nfrom src.core.logging import configure_logging\nfrom src.core.di import Container\nfrom src.api.routes import register_routes\n\n\ndef create_app(settings: Settings | None = None) -&gt; FastAPI:\n    settings = settings or get_settings()\n    configure_logging(settings)\n\n    container = Container(settings=settings)\n\n    app = FastAPI(\n        title=settings.service_name,\n        version=settings.version,\n        default_response_class=container.default_response_class(),\n        lifespan=container.build_lifespan(),\n    )\n\n    register_routes(app)\n    app.state.container = container\n    return app\n</code></pre>"},{"location":"atomic/services/fastapi/application-factory/#container-responsibilities","title":"Container Responsibilities","text":"<ul> <li>Construct singletons (database engine, Redis client, RabbitMQ connections).</li> <li>Expose dependency providers (<code>get_user_service</code>, <code>get_unit_of_work</code>).</li> <li>Provide lifespan context manager for startup/shutdown (see <code>lifespan-management.md</code>).</li> </ul>"},{"location":"atomic/services/fastapi/application-factory/#testing-with-the-factory","title":"Testing with the Factory","text":"<pre><code>from fastapi.testclient import TestClient\nfrom src.main import create_app\nfrom src.tests.factories import TestContainer\n\n\ndef test_health_endpoint() -&gt; None:\n    app = create_app(settings=TestContainer.settings())\n    client = TestClient(app)\n\n    response = client.get(\"/api/v1/health\")\n\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\n</code></pre>"},{"location":"atomic/services/fastapi/application-factory/#advantages","title":"Advantages","text":"<ul> <li>Deterministic boot \u2013 settings resolved once, DI container centralised.</li> <li>Override-friendly \u2013 tests inject fake dependencies via <code>dependency_overrides</code> or container hooks.</li> <li>Reduced cold start \u2013 heavy resources initialised during lifespan, not at import time.</li> </ul>"},{"location":"atomic/services/fastapi/application-factory/#checklist","title":"Checklist","text":"<ul> <li> <code>create_app()</code> accepts optional settings for tests.</li> <li> Container/DI wiring happens inside the factory.</li> <li> Routes registered via dedicated helper (no inline definitions in <code>main.py</code>).</li> <li> <code>app.state</code> stores container for internal usage only (never imported directly).</li> </ul>"},{"location":"atomic/services/fastapi/application-factory/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> <li><code>docs/atomic/architecture/project-structure-patterns.md</code></li> </ul>"},{"location":"atomic/services/fastapi/basic-setup/","title":"FastAPI Basic Setup","text":"<p>This guide covers the minimum scaffolding required to spin up a FastAPI business service that conforms to the Improved Hybrid Approach.</p>"},{"location":"atomic/services/fastapi/basic-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+ with <code>uv</code> or <code>pip</code> for dependency management.</li> <li><code>src/</code> layout prepared according to <code>docs/atomic/architecture/project-structure-patterns.md</code>.</li> <li>Shared configuration defined in <code>src/core/config.py</code> (Pydantic <code>BaseSettings</code>).</li> </ul>"},{"location":"atomic/services/fastapi/basic-setup/#initial-project-structure","title":"Initial Project Structure","text":"<pre><code>src/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 v1/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 health_router.py\n\u251c\u2500\u2500 application/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 domain/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 schemas/\n\u2502   \u2514\u2500\u2500 health.py\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 logging.py\n\u2502   \u2514\u2500\u2500 di.py\n\u2514\u2500\u2500 main.py\n</code></pre>"},{"location":"atomic/services/fastapi/basic-setup/#dependencies","title":"Dependencies","text":"<pre><code># pyproject.toml\n[project]\nname = \"my_fastapi_service\"\nrequires-python = \"&gt;=3.12\"\n\n[project.dependencies]\nfastapi = \"^0.111\"\nuvicorn = \"^0.30\"\nhttpx = \"^0.27\"\nsqlalchemy = \"^2.0\"          # optional, keep only if needed\nasyncpg = \"^0.29\"             # optional, keep only if needed\norjson = \"^3.10\"\npydantic = \"^2.8\"\n</code></pre>"},{"location":"atomic/services/fastapi/basic-setup/#entry-point-mainpy","title":"Entry Point (<code>main.py</code>)","text":"<pre><code>from __future__ import annotations\n\nimport uvicorn\nfrom fastapi import FastAPI\nfrom src.core.logging import configure_logging\nfrom src.api.v1.health_router import router as health_router\n\n\ndef create_app() -&gt; FastAPI:\n    \"\"\"Instantiate the FastAPI application with minimal defaults.\"\"\"\n    configure_logging()\n\n    app = FastAPI(\n        title=\"My FastAPI Service\",\n        version=\"1.0.0\",\n        default_response_class=None,  # override in routers where needed\n    )\n\n    app.include_router(health_router, prefix=\"/api/v1\", tags=[\"health\"])\n    return app\n\n\napp = create_app()\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(\n        \"src.main:app\",\n        host=\"0.0.0.0\",\n        port=8000,\n        reload=False,\n        log_config=None,\n    )\n</code></pre>"},{"location":"atomic/services/fastapi/basic-setup/#health-router-health_routerpy","title":"Health Router (<code>health_router.py</code>)","text":"<pre><code>from __future__ import annotations\n\nfrom fastapi import APIRouter, status\nfrom src.schemas.health import HealthResponse\n\nrouter = APIRouter()\n\n\n@router.get(\n    \"/health\",\n    response_model=HealthResponse,\n    status_code=status.HTTP_200_OK,\n    summary=\"Liveness probe\",\n)\nasync def health() -&gt; HealthResponse:\n    return HealthResponse(status=\"ok\")\n</code></pre>"},{"location":"atomic/services/fastapi/basic-setup/#dto-example-schemashealthpy","title":"DTO Example (<code>schemas/health.py</code>)","text":"<pre><code>from __future__ import annotations\n\nfrom pydantic import BaseModel, Field\n\n\nclass HealthResponse(BaseModel):\n    status: str = Field(..., description=\"Service liveness indicator\")\n</code></pre>"},{"location":"atomic/services/fastapi/basic-setup/#startup-checklist","title":"Startup Checklist","text":"<ul> <li> Project structure matches the reference layout.</li> <li> Logging configured once in <code>create_app()</code>.</li> <li> <code>/api/v1/health</code> endpoint returns static status.</li> <li> Uvicorn entry point uses application factory instead of global side effects.</li> </ul>"},{"location":"atomic/services/fastapi/basic-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/application-factory.md</code></li> <li><code>docs/atomic/architecture/service-separation-principles.md</code></li> </ul>"},{"location":"atomic/services/fastapi/dependency-injection/","title":"Dependency Injection","text":"<p>Use FastAPI dependencies and a lightweight service container to provide integrations, application services, and security context.</p>"},{"location":"atomic/services/fastapi/dependency-injection/#provider-pattern","title":"Provider Pattern","text":"<pre><code>from __future__ import annotations\n\nfrom collections.abc import AsyncGenerator\nfrom fastapi import Depends\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.core.di import Container\nfrom src.infrastructure.db import get_session\nfrom src.application.users import UserService\n\n\ndef get_container() -&gt; Container:\n    return Container.current()\n\n\ndef get_db_session(\n    container: Container = Depends(get_container),\n) -&gt; AsyncGenerator[AsyncSession, None]:\n    session = container.db_session()\n    try:\n        yield session\n    finally:\n        session.rollback()\n        session.close()\n\n\ndef get_user_service(\n    session: AsyncSession = Depends(get_db_session),\n    container: Container = Depends(get_container),\n) -&gt; UserService:\n    return container.user_service(session=session)\n</code></pre>"},{"location":"atomic/services/fastapi/dependency-injection/#design-guidelines","title":"Design Guidelines","text":"<ul> <li>Dependencies must be idempotent and quick to resolve.</li> <li>Use <code>Depends</code> for business services and security; avoid global singletons.</li> <li>Keep dependency functions in <code>src/core/di.py</code> or feature-specific modules.</li> <li>For simple configuration, return <code>Settings</code> directly from <code>Depends(get_settings)</code>.</li> </ul>"},{"location":"atomic/services/fastapi/dependency-injection/#override-strategy","title":"Override Strategy","text":"<pre><code>from fastapi.testclient import TestClient\nfrom src.main import create_app\nfrom tests.fakes.users import FakeUserService\n\n\ndef test_override_user_service() -&gt; None:\n    app = create_app()\n\n    app.dependency_overrides[get_user_service] = lambda: FakeUserService()\n\n    client = TestClient(app)\n    response = client.post(\"/api/v1/users\", json={\"email\": \"test@example.com\"})\n\n    assert response.status_code == 201\n</code></pre>"},{"location":"atomic/services/fastapi/dependency-injection/#anti-patterns","title":"Anti-Patterns","text":"<ul> <li>Creating database engines or Redis clients inside dependencies; initialise them during lifespan.</li> <li>Using dependency overrides to swap infrastructure in production (keep overrides for tests and local experiments only).</li> <li>Passing around <code>FastAPI</code> app instances; rely on DI instead.</li> </ul>"},{"location":"atomic/services/fastapi/dependency-injection/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/lifespan-management.md</code></li> <li><code>docs/atomic/architecture/service-separation-principles.md</code></li> </ul>"},{"location":"atomic/services/fastapi/error-handling/","title":"Error Handling","text":"<p>Return consistent, debuggable error responses using RFC 7807 Problem Details.</p>"},{"location":"atomic/services/fastapi/error-handling/#problem-details-structure","title":"Problem Details Structure","text":"<pre><code>{\n  \"type\": \"https://docs.example.com/errors/resource-not-found\",\n  \"title\": \"Resource not found\",\n  \"status\": 404,\n  \"detail\": \"User 42 not found\",\n  \"instance\": \"urn:request:123e4567-e89b-12d3-a456-426614174000\",\n  \"code\": \"USER_NOT_FOUND\",\n  \"context\": {\n    \"resource\": \"user\",\n    \"id\": \"42\"\n  }\n}\n</code></pre>"},{"location":"atomic/services/fastapi/error-handling/#implementation-pattern","title":"Implementation Pattern","text":"<pre><code>from __future__ import annotations\n\nfrom fastapi import Request\nfrom fastapi.responses import JSONResponse\nfrom src.core.errors import DomainError, NotFoundError\n\n\nasync def domain_error_handler(request: Request, exc: DomainError) -&gt; JSONResponse:\n    problem = {\n        \"type\": exc.problem_type,\n        \"title\": exc.title,\n        \"status\": exc.status_code,\n        \"detail\": exc.message,\n        \"instance\": str(request.state.request_id),\n        \"code\": exc.code,\n        \"context\": exc.context,\n    }\n    return JSONResponse(problem, status_code=exc.status_code)\n</code></pre> <p>Register handlers inside <code>create_app()</code>.</p> <pre><code>app.add_exception_handler(DomainError, domain_error_handler)\napp.add_exception_handler(NotFoundError, not_found_handler)\n</code></pre>"},{"location":"atomic/services/fastapi/error-handling/#guidelines","title":"Guidelines","text":"<ul> <li>Convert Pydantic validation errors (<code>RequestValidationError</code>) into Problem Details with field paths (<code>data.attributes.name</code>).</li> <li>Avoid <code>raise HTTPException(...)</code> in routers; instead raise domain/application exceptions.</li> <li>Include request IDs and correlation IDs in responses for traceability.</li> <li>Hide sensitive details; log full error context but redact secrets before returning to clients.</li> </ul>"},{"location":"atomic/services/fastapi/error-handling/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/services/fastapi/error-handling/#silent-exception-swallowing","title":"\u274c Silent Exception Swallowing","text":"<p>Problem: Using bare <code>except:</code> or <code>except Exception:</code> with <code>pass</code> silently swallows all errors, making debugging impossible</p> <p>Symptom: Application appears to work but silently drops errors, no logs, no alerts, failed operations return success</p> <p>Impact: Silent data loss, impossible debugging, no observability, corrupted state, user confusion</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: Bare except with pass\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.post(\"/payments\")\nasync def process_payment(payment_data: PaymentDTO) -&gt; dict:\n    \"\"\"Process payment.\"\"\"\n    try:\n        result = await payment_service.process(payment_data)\n        await notification_service.send_confirmation(result.id)\n        return {\"status\": \"success\", \"payment_id\": result.id}\n    except:  # \u274c Catches EVERYTHING including KeyboardInterrupt, SystemExit!\n        pass  # \u274c Silent failure - no logging, no retry, no user feedback!\n\n    # \u26a0\ufe0f Execution continues, returns None \u2192 crashes later or returns 200 OK with null!\n    return {\"status\": \"success\"}  # \u274c LIE: Payment actually failed!\n</code></pre></p> <p>Why This Matters: - Bare <code>except:</code> catches ALL exceptions including system signals (<code>KeyboardInterrupt</code>, <code>SystemExit</code>) - <code>pass</code> discards exception \u2192 no logging \u2192 impossible to debug production failures - Failed payments appear successful \u2192 financial discrepancies - No observability: Monitoring shows 100% success rate while operations fail silently - Corrupted state: Partial operations complete without rollback - Violates fail-fast principle: Errors should bubble up, not disappear</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Specific exception handling with logging and proper error responses\nfrom fastapi import APIRouter, HTTPException, Request\nfrom src.core.errors import DomainError, PaymentProviderError\nimport structlog\n\nrouter = APIRouter()\nlogger = structlog.get_logger()\n\n@router.post(\"/payments\")\nasync def process_payment(\n    payment_data: PaymentDTO,\n    request: Request\n) -&gt; dict:\n    \"\"\"\n    Process payment with proper error handling.\n\n    Args:\n        payment_data: Payment information\n        request: FastAPI request (for request_id)\n\n    Returns:\n        Payment result with status\n\n    Raises:\n        DomainError: If payment validation fails\n        HTTPException: If payment provider is unavailable\n    \"\"\"\n    try:\n        result = await payment_service.process(payment_data)\n        await notification_service.send_confirmation(result.id)\n\n        logger.info(\n            \"payment_processed\",\n            payment_id=result.id,\n            amount=payment_data.amount,\n            request_id=str(request.state.request_id)\n        )\n\n        return {\"status\": \"success\", \"payment_id\": result.id}\n\n    except PaymentProviderError as e:\n        # \u2705 Specific exception: Payment provider is down\n        logger.error(\n            \"payment_provider_error\",\n            error=str(e),\n            payment_data=payment_data.dict(exclude={\"card_number\"}),\n            request_id=str(request.state.request_id)\n        )\n        raise DomainError(\n            code=\"PAYMENT_PROVIDER_UNAVAILABLE\",\n            message=\"Payment provider temporarily unavailable\",\n            context={\"retry_after\": 60}\n        ) from e\n\n    except ValidationError as e:\n        # \u2705 Specific exception: Invalid payment data\n        logger.warning(\n            \"payment_validation_failed\",\n            error=str(e),\n            request_id=str(request.state.request_id)\n        )\n        raise DomainError(\n            code=\"PAYMENT_VALIDATION_FAILED\",\n            message=\"Invalid payment data\",\n            context={\"errors\": e.errors()}\n        ) from e\n\n    except Exception as e:\n        # \u2705 Last resort: Log unexpected errors and raise\n        logger.exception(\n            \"payment_unexpected_error\",\n            error_type=type(e).__name__,\n            error=str(e),\n            request_id=str(request.state.request_id)\n        )\n        # \u2705 Re-raise to trigger 500 error handler\n        raise\n</code></pre></p> <p>Architecture Rule:</p> <p>Never use bare <code>except:</code> or <code>except Exception: pass</code>. Always catch specific exceptions, log errors with context, and re-raise or convert to domain errors. Silent failures are unacceptable in production systems.</p> <p>Best Practices: - Catch specific exceptions (<code>PaymentProviderError</code>, <code>ValidationError</code>) not <code>Exception</code> - Always log errors with request IDs and relevant context - Re-raise exceptions or convert to domain-specific errors with clear error codes - Use <code>logger.exception()</code> to capture full stack trace - Include <code>from e</code> to preserve exception chain for debugging - Fail fast: Let unexpected errors bubble up to global error handler</p> <p>Related Anti-Patterns: - No Graceful Shutdown \u2192 <code>docs/atomic/integrations/cross-service/graceful-shutdown.md#no-graceful-shutdown</code></p>"},{"location":"atomic/services/fastapi/error-handling/#testing","title":"Testing","text":"<ul> <li>Unit-test exception handlers to ensure correct payload shape.</li> <li>Integration tests should assert status codes and <code>code</code> values for each error scenario.</li> </ul>"},{"location":"atomic/services/fastapi/error-handling/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/observability/logging/structured-logging.md</code></li> <li><code>docs/atomic/services/fastapi/security-patterns.md</code></li> <li><code>docs/atomic/observability/error-tracking/sentry-integration.md</code></li> </ul>"},{"location":"atomic/services/fastapi/lifespan-management/","title":"FastAPI Lifespan Management","text":"<p>Lifespan hooks manage startup and shutdown for databases, caches, message brokers, and background tasks. Always use the <code>lifespan</code> parameter of <code>FastAPI</code> to encapsulate resource ownership.</p>"},{"location":"atomic/services/fastapi/lifespan-management/#template","title":"Template","text":"<pre><code>from __future__ import annotations\n\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom src.core.config import Settings\nfrom src.infrastructure.db import Database\nfrom src.infrastructure.redis import RedisClient\nfrom src.infrastructure.messaging import RabbitMQClient\n\n\ndef build_lifespan(settings: Settings):\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        db = Database(settings.database_url)\n        redis = RedisClient(settings.redis_url)\n        rabbit = RabbitMQClient(settings.rabbitmq_url)\n\n        await db.connect()\n        await redis.connect()\n        await rabbit.connect()\n\n        app.state.db = db\n        app.state.redis = redis\n        app.state.rabbit = rabbit\n\n        try:\n            yield\n        finally:\n            await rabbit.close()\n            await redis.close()\n            await db.disconnect()\n\n    return lifespan\n</code></pre>"},{"location":"atomic/services/fastapi/lifespan-management/#guidelines","title":"Guidelines","text":"<ul> <li>Initialise resources once during startup; reuse through dependency injection.</li> <li>Set timeouts when connecting to external systems to avoid hanging deployments.</li> <li>Register health checks after connections succeed to prevent false positives.</li> <li>Remove state from <code>app.state</code> during shutdown to avoid memory leaks in reload mode.</li> </ul>"},{"location":"atomic/services/fastapi/lifespan-management/#monitoring","title":"Monitoring","text":"<ul> <li>Log startup and shutdown with request/trace IDs from <code>logging_rules</code> patterns.</li> <li>Emit Prometheus gauges for connection pool size and availability.</li> <li>Alert when connection retries exceed defined thresholds.</li> </ul>"},{"location":"atomic/services/fastapi/lifespan-management/#failure-handling","title":"Failure Handling","text":"<ul> <li>Wrap connection attempts in retries (exponential backoff) but fail fast after a limited number of attempts.</li> <li>If a critical dependency fails to start, raise and let the orchestrator restart the container; do not swallow the exception.</li> </ul>"},{"location":"atomic/services/fastapi/lifespan-management/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"atomic/services/fastapi/lifespan-management/#deprecated-lifecycle-apis","title":"\u274c Deprecated Lifecycle APIs","text":"<p>Problem: Using deprecated <code>@app.on_event(\"startup\")</code> and <code>@app.on_event(\"shutdown\")</code> decorators instead of modern <code>lifespan</code> context manager</p> <p>Symptom: Deprecation warnings in logs, breaking changes on FastAPI upgrades, inconsistent startup/shutdown behavior</p> <p>Impact: Code breaks on FastAPI 0.109+, difficult to track resource lifecycle, no exception handling guarantees</p> <p>Example (WRONG): <pre><code># \u274c ANTI-PATTERN: Deprecated @app.on_event() decorators\nfrom fastapi import FastAPI\nfrom src.infrastructure.db import Database\nfrom src.infrastructure.redis import RedisClient\n\napp = FastAPI()\n\n# \u274c DEPRECATED since FastAPI 0.93, removed in 0.109+\n@app.on_event(\"startup\")\nasync def startup():\n    \"\"\"Initialize resources on startup.\"\"\"\n    app.state.db = Database(settings.database_url)\n    await app.state.db.connect()\n\n    app.state.redis = RedisClient(settings.redis_url)\n    await app.state.redis.connect()\n\n# \u274c DEPRECATED\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    \"\"\"Clean up resources on shutdown.\"\"\"\n    await app.state.redis.close()\n    await app.state.db.disconnect()\n\n# \u26a0\ufe0f Issues:\n# - No exception handling guarantee (startup may fail silently)\n# - Shutdown may not run if startup fails\n# - Multiple @on_event decorators have undefined order\n# - No context management (resources may leak)\n</code></pre></p> <p>Why This Matters: - <code>@app.on_event()</code> is DEPRECATED since FastAPI 0.93 (June 2023) - Removed entirely in FastAPI 0.109+ (breaking change) - No guaranteed exception handling: startup can fail without cleanup - Shutdown handlers may not run if startup fails midway - Difficult to test: decorators run at app creation, not in tests - No context manager guarantees: resources may not be released</p> <p>Solution (CORRECT): <pre><code># \u2705 CORRECT: Modern @asynccontextmanager lifespan\nfrom __future__ import annotations\n\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom src.core.config import Settings\nfrom src.infrastructure.db import Database\nfrom src.infrastructure.redis import RedisClient\nimport structlog\n\nlogger = structlog.get_logger()\n\ndef build_lifespan(settings: Settings):\n    \"\"\"\n    Build lifespan context manager for FastAPI application.\n\n    Args:\n        settings: Application settings\n\n    Returns:\n        Async context manager for application lifecycle\n    \"\"\"\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        \"\"\"\n        Manage application lifecycle: startup and shutdown.\n\n        Handles resource initialization on startup and guaranteed cleanup\n        on shutdown, even if startup fails.\n        \"\"\"\n        # Startup phase\n        logger.info(\"application_startup_initiated\")\n\n        db = Database(settings.database_url)\n        redis = RedisClient(settings.redis_url)\n\n        try:\n            # Initialize resources with retry logic\n            await db.connect()\n            logger.info(\"database_connected\")\n\n            await redis.connect()\n            logger.info(\"redis_connected\")\n\n            # Store in app state for dependency injection\n            app.state.db = db\n            app.state.redis = redis\n\n            logger.info(\"application_startup_complete\")\n\n            # \u2705 Yield: Application runs here\n            yield\n\n        finally:\n            # \u2705 Shutdown phase: GUARANTEED to run, even if startup fails\n            logger.info(\"application_shutdown_initiated\")\n\n            # Close in reverse order\n            if hasattr(app.state, \"redis\"):\n                await redis.close()\n                logger.info(\"redis_closed\")\n\n            if hasattr(app.state, \"db\"):\n                await db.disconnect()\n                logger.info(\"database_closed\")\n\n            logger.info(\"application_shutdown_complete\")\n\n    return lifespan\n\n# Create app with lifespan\nsettings = Settings()\napp = FastAPI(lifespan=build_lifespan(settings))\n</code></pre></p> <p>Architecture Rule:</p> <p>Use <code>@asynccontextmanager</code> lifespan for all resource management. Never use deprecated <code>@app.on_event()</code>. Lifespan guarantees cleanup runs even if startup fails.</p> <p>Migration Guide: <pre><code># Before (DEPRECATED):\n@app.on_event(\"startup\")\nasync def startup():\n    app.state.resource = init_resource()\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    await app.state.resource.close()\n\n# After (CORRECT):\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    resource = init_resource()\n    app.state.resource = resource\n    try:\n        yield\n    finally:\n        await resource.close()\n\napp = FastAPI(lifespan=lifespan)\n</code></pre></p> <p>Benefits of Lifespan: - \u2705 Guaranteed cleanup: <code>finally</code> block always runs - \u2705 Exception safety: Cleanup runs even if startup fails - \u2705 Clear context: All lifecycle code in one place - \u2705 Testable: Can test lifespan independently - \u2705 Future-proof: Won't break on FastAPI upgrades</p> <p>Related Anti-Patterns: - No Graceful Shutdown \u2192 <code>docs/atomic/integrations/cross-service/graceful-shutdown.md#no-graceful-shutdown</code></p>"},{"location":"atomic/services/fastapi/lifespan-management/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/dependency-injection.md</code></li> <li><code>docs/atomic/architecture/event-loop-management.md</code></li> <li><code>docs/atomic/services/fastapi/basic-setup.md</code></li> </ul>"},{"location":"atomic/services/fastapi/openapi-documentation/","title":"OpenAPI Documentation","text":"<p>FastAPI auto-generates OpenAPI schemas; refine them to stay contract-first.</p>"},{"location":"atomic/services/fastapi/openapi-documentation/#metadata","title":"Metadata","text":"<p>Set global metadata in <code>create_app()</code>:</p> <pre><code>app = FastAPI(\n    title=settings.service_name,\n    version=settings.version,\n    description=\"HTTP API for managing user accounts\",\n    contact={\"name\": \"Platform Team\", \"email\": \"platform@example.com\"},\n    license_info={\"name\": \"Proprietary\"},\n)\n</code></pre>"},{"location":"atomic/services/fastapi/openapi-documentation/#tags-and-summaries","title":"Tags and Summaries","text":"<ul> <li>Group endpoints by router tags (e.g., <code>users</code>, <code>orders</code>).</li> <li>Provide concise <code>summary</code> and detailed <code>description</code> for each endpoint.</li> <li>Use <code>deprecated=True</code> to mark endpoints scheduled for removal.</li> </ul>"},{"location":"atomic/services/fastapi/openapi-documentation/#schema-customisation","title":"Schema Customisation","text":"<ul> <li>Define reusable enums and models; avoid <code>Any</code>.</li> <li>Document error responses by adding <code>responses</code> parameter on routes.</li> </ul> <pre><code>error_responses = {\n    404: {\"description\": \"User not found\", \"model\": ProblemDetails},\n    409: {\"description\": \"Conflict\", \"model\": ProblemDetails},\n}\n\n@router.post(\"\", responses=error_responses)\nasync def create_user(...):\n    ...\n</code></pre>"},{"location":"atomic/services/fastapi/openapi-documentation/#documentation-workflow","title":"Documentation Workflow","text":"<ol> <li>Generate schema during CI (<code>poetry run uvicorn src.main:app --reload</code> or <code>python -m scripts.export_openapi</code>).</li> <li>Review diff in pull requests; breaking changes require API version bump.</li> <li>Publish schema to the developer portal or <code>docs/reference</code> as needed.</li> </ol>"},{"location":"atomic/services/fastapi/openapi-documentation/#testing","title":"Testing","text":"<ul> <li>Snap test the OpenAPI spec to prevent accidental contract drift.</li> <li>Validate schema with <code>openapi-spec-validator</code> in CI.</li> </ul>"},{"location":"atomic/services/fastapi/openapi-documentation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/schema-validation.md</code></li> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code></li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/","title":"Performance Optimization","text":"<p>Tune FastAPI services for predictable latency and throughput while avoiding premature micro-optimisation.</p>"},{"location":"atomic/services/fastapi/performance-optimization/#baseline-practices","title":"Baseline Practices","text":"<ul> <li>Use <code>uvicorn</code> with <code>uvloop</code> and <code>httptools</code> in production: <code>uvicorn src.main:app --http httptools --loop uvloop</code>.</li> <li>Prefer async drivers (<code>asyncpg</code>, <code>httpx.AsyncClient</code>, <code>redis.asyncio</code>) to eliminate blocking calls.</li> <li>Enable connection pooling for databases and caches; reuse clients via the DI container.</li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/#request-handling","title":"Request Handling","text":"<ul> <li>Avoid heavy computations inside request handlers; offload to workers or <code>asyncio.to_thread</code> when unavoidable.</li> <li>Limit response payload sizes; paginate lists and stream large files with <code>StreamingResponse</code>.</li> <li>Apply caching for idempotent read endpoints using Redis with explicit TTLs.</li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/#timeouts-retries","title":"Timeouts &amp; Retries","text":"<ul> <li>Set client timeouts (<code>httpx.AsyncClient(timeout=Timeout(5.0, connect=1.0))</code>).</li> <li>Implement circuit breakers when cascading failures are possible.</li> <li>Expose configuration for timeouts/throttling via settings to allow tuning per environment.</li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/#profiling-monitoring","title":"Profiling &amp; Monitoring","text":"<ul> <li>Track P95/P99 latency via Prometheus and alert on regressions.</li> <li>Use <code>pyinstrument</code> or <code>yappi</code> during performance investigations.</li> <li>Capture slow query logs (<code>statement_timeout</code> in PostgreSQL) and fix N+1 patterns.</li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/#load-testing","title":"Load Testing","text":"<ul> <li>Run k6/Locust scenarios before major releases.</li> <li>Automate smoke performance tests with representative traffic patterns (auth, data fetch, writes).</li> <li>Store baseline metrics; treat regressions as release blockers.</li> </ul>"},{"location":"atomic/services/fastapi/performance-optimization/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/architecture/quality-standards.md</code></li> <li><code>docs/atomic/services/fastapi/testing-strategies.md</code></li> </ul>"},{"location":"atomic/services/fastapi/routing-patterns/","title":"Routing Patterns","text":"<p>Routers translate HTTP requests into application service calls. Keep them transport-focused and free of business logic.</p>"},{"location":"atomic/services/fastapi/routing-patterns/#router-layout","title":"Router Layout","text":"<pre><code>src/api/v1/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 users_router.py\n\u2514\u2500\u2500 orders_router.py\n</code></pre> <p>Each router defines: - Endpoint metadata (<code>summary</code>, <code>description</code>, tags). - DTO usage via <code>response_model</code>. - Dependency injection for services, security, and context.</p>"},{"location":"atomic/services/fastapi/routing-patterns/#example","title":"Example","text":"<pre><code>from __future__ import annotations\n\nfrom fastapi import APIRouter, Depends, status\nfrom src.schemas.users import UserCreate, UserPublic\nfrom src.application.users import UserService, get_user_service\n\nrouter = APIRouter(prefix=\"/users\", tags=[\"users\"])\n\n\n@router.post(\n    \"\",\n    response_model=UserPublic,\n    status_code=status.HTTP_201_CREATED,\n    summary=\"Create user\",\n)\nasync def create_user(\n    payload: UserCreate,\n    service: UserService = Depends(get_user_service),\n) -&gt; UserPublic:\n    return await service.create_user(payload)\n</code></pre>"},{"location":"atomic/services/fastapi/routing-patterns/#best-practices","title":"Best Practices","text":"<ul> <li>Register routers in a central function (<code>register_routes(app)</code>), not inline in <code>main.py</code>.</li> <li>Use <code>APIRouter(prefix=\"/resource\", tags=[\"resource\"])</code> to keep URL namespaces consistent.</li> <li>Apply middlewares or dependencies at router level for shared concerns (authentication, rate limits).</li> <li>For feature toggles, guard entire routers rather than individual endpoints to simplify removal.</li> </ul>"},{"location":"atomic/services/fastapi/routing-patterns/#versioning","title":"Versioning","text":"<ul> <li>Include routers under <code>/api/v{major}</code>; deprecate old versions using the <code>deprecated=True</code> flag in endpoint metadata.</li> <li>Avoid mixing experimental endpoints with stable ones; publish under <code>/api/experimental</code> if needed.</li> </ul>"},{"location":"atomic/services/fastapi/routing-patterns/#validation-documentation","title":"Validation &amp; Documentation","text":"<ul> <li>Always set <code>response_model</code> and <code>status_code</code> explicitly.</li> <li>Use descriptive summaries and descriptions; these surface in the OpenAPI schema.</li> <li>Prefer <code>ORJSONResponse</code> for JSON payloads; specify per-endpoint when large responses demand streaming.</li> </ul>"},{"location":"atomic/services/fastapi/routing-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/schema-validation.md</code></li> <li><code>docs/atomic/services/fastapi/error-handling.md</code></li> </ul>"},{"location":"atomic/services/fastapi/schema-validation/","title":"Schema Validation","text":"<p>FastAPI services must expose strictly typed HTTP contracts using Pydantic models.</p>"},{"location":"atomic/services/fastapi/schema-validation/#dto-conventions","title":"DTO Conventions","text":"<ul> <li>Place models in <code>src/schemas/&lt;feature&gt;/</code>.</li> <li>Use descriptive suffixes: <code>...Base</code>, <code>...Create</code>, <code>...Update</code>, <code>...Public</code>, <code>...Filter</code>.</li> <li>Annotate every field with constraints and descriptions.</li> </ul> <pre><code>from __future__ import annotations\n\nfrom datetime import datetime\nfrom pydantic import BaseModel, EmailStr, Field\n\n\nclass UserBase(BaseModel):\n    email: EmailStr = Field(..., description=\"Unique email address\")\n    full_name: str = Field(..., min_length=1, max_length=200)\n\n\nclass UserCreate(UserBase):\n    password: str = Field(..., min_length=12, max_length=128)\n\n\nclass UserPublic(UserBase):\n    id: str = Field(..., description=\"UUID of the user\")\n    created_at: datetime = Field(..., description=\"UTC timestamp with timezone\")\n</code></pre>"},{"location":"atomic/services/fastapi/schema-validation/#response-models","title":"Response Models","text":"<ul> <li>Set <code>response_model</code> on every route.</li> <li>Use <code>response_model_exclude_none=True</code> when representing sparse objects.</li> <li>Return Problem Details (<code>dict</code>) for errors; see <code>error-handling.md</code>.</li> </ul> <pre><code>@router.get(\n    \"\",\n    response_model=list[UserPublic],\n    response_model_exclude_none=True,\n)\nasync def list_users(...):\n    ...\n</code></pre>"},{"location":"atomic/services/fastapi/schema-validation/#validation-rules","title":"Validation Rules","text":"<ul> <li>Enforce length/regex constraints at schema level; do not rely on database errors.</li> <li>Use enums for finite sets (<code>Literal</code> or <code>Enum</code>).</li> <li>Apply nested models for embedded structures instead of <code>dict[str, Any]</code>.</li> </ul>"},{"location":"atomic/services/fastapi/schema-validation/#serialization-performance","title":"Serialization Performance","text":"<ul> <li>Prefer <code>orjson</code> via <code>ORJSONResponse</code> for JSON endpoints.</li> <li>Convert decimal/UUID types explicitly if custom behaviour is required.</li> </ul>"},{"location":"atomic/services/fastapi/schema-validation/#testing","title":"Testing","text":"<ul> <li>Add unit tests verifying schema validation: send invalid payloads and assert 422 responses with field-specific error messages.</li> <li>Snapshot OpenAPI schema in contract tests to detect breaking changes.</li> </ul>"},{"location":"atomic/services/fastapi/schema-validation/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/error-handling.md</code></li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code></li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/","title":"Security Patterns","text":"<p>FastAPI services must enforce authentication, authorization, and data protection at the transport boundary.</p>"},{"location":"atomic/services/fastapi/security-patterns/#authentication","title":"Authentication","text":"<ul> <li>Implement auth dependencies (<code>Depends(get_current_user)</code>) per router or endpoint.</li> <li>Support token-based schemes (JWT, OAuth2) via <code>fastapi.security</code> utilities.</li> <li>Reject requests lacking required scopes with <code>403</code> Problem Details.</li> </ul> <pre><code>from fastapi import Depends, Security\nfrom fastapi.security import OAuth2PasswordBearer\nfrom src.core.security import get_current_user\n\nreusable_oauth2 = OAuth2PasswordBearer(tokenUrl=\"/auth/token\")\n\n\nasync def require_user(token: str = Security(reusable_oauth2)) -&gt; CurrentUser:\n    return await get_current_user(token)\n</code></pre>"},{"location":"atomic/services/fastapi/security-patterns/#authorization","title":"Authorization","text":"<ul> <li>Encode roles/scopes in the auth dependency result.</li> <li>Perform coarse-grained checks in routers, fine-grained checks in application services.</li> <li>Log security-relevant decisions (<code>user_id</code>, <code>scope</code>, <code>resource</code>) without exposing PII.</li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/#input-hardening","title":"Input Hardening","text":"<ul> <li>Enforce payload size limits using FastAPI settings (<code>app = FastAPI(max_request_size=...)</code>).</li> <li>Validate <code>Content-Type</code> headers and reject unexpected media types.</li> <li>Sanitise user-generated strings before logging.</li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/#secrets-handling","title":"Secrets Handling","text":"<ul> <li>Store secrets in environment variables or secret managers; load via <code>Settings</code>.</li> <li>Avoid passing secrets to clients or including them in responses.</li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/#cors","title":"CORS","text":"<ul> <li>Default to deny-all; allow origins per environment through configuration.</li> <li>Set explicit allowed methods/headers and enable credentials only when necessary.</li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/#security-testing","title":"Security Testing","text":"<ul> <li>Add tests for auth absence (<code>401</code>) and insufficient permissions (<code>403</code>).</li> <li>Use dependency overrides in tests to simulate authenticated users.</li> <li>Run security scanners (<code>bandit</code>, dependency audit) in CI.</li> </ul>"},{"location":"atomic/services/fastapi/security-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/services/fastapi/error-handling.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/services/fastapi/testing-strategies/","title":"Testing Strategies","text":"<p>FastAPI services must ship with comprehensive unit, integration, and contract tests that follow the global quality standards.</p>"},{"location":"atomic/services/fastapi/testing-strategies/#unit-tests","title":"Unit Tests","text":"<ul> <li>Use <code>pytest</code> with <code>pytest-asyncio</code> for async endpoints.</li> <li>Mock external dependencies by overriding FastAPI dependencies (<code>app.dependency_overrides</code>).</li> <li>Focus on application services and domain logic; routers should simply orchestrate.</li> </ul> <pre><code>@pytest.mark.asyncio\nasync def test_create_user_returns_201(fastapi_client, fake_user_service):\n    fastapi_client.app.dependency_overrides[get_user_service] = lambda: fake_user_service\n\n    response = await fastapi_client.post(\n        \"/api/v1/users\",\n        json={\"email\": \"test@example.com\", \"full_name\": \"Test\", \"password\": \"P@ssw0rd!!!!\"},\n    )\n\n    assert response.status_code == 201\n</code></pre>"},{"location":"atomic/services/fastapi/testing-strategies/#integration-tests","title":"Integration Tests","text":"<ul> <li>Use Testcontainers to spin up PostgreSQL/MongoDB/Redis as required.</li> <li>Run tests against the real HTTP API using <code>httpx.AsyncClient</code> or <code>FastAPI AsyncClient</code>.</li> <li>Seed data via migrations or fixtures; clean up between tests.</li> </ul>"},{"location":"atomic/services/fastapi/testing-strategies/#contract-tests","title":"Contract Tests","text":"<ul> <li>Snapshot the OpenAPI schema to detect breaking changes.</li> <li>Use consumer-driven contracts (e.g., Pact) when other teams depend on the API.</li> </ul>"},{"location":"atomic/services/fastapi/testing-strategies/#non-functional-tests","title":"Non-Functional Tests","text":"<ul> <li>Execute load tests for critical paths, referencing <code>performance-optimization.md</code>.</li> <li>Add security tests (auth bypass attempts, rate limits) as part of service-specific suites.</li> </ul>"},{"location":"atomic/services/fastapi/testing-strategies/#ci-expectations","title":"CI Expectations","text":"<ul> <li>CI must run unit + integration suites, linting, type checks, and security scans.</li> <li>Coverage reports must meet the platform threshold (100% for new/changed lines).</li> <li>Publish test artefacts (coverage.xml, junit.xml) for visibility.</li> </ul>"},{"location":"atomic/services/fastapi/testing-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/http-integration-testing.md</code></li> <li><code>docs/atomic/architecture/quality-standards.md</code></li> </ul>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/","title":"End-to-End Test Setup","text":"<p>Configure end-to-end testing infrastructure with Playwright or Selenium to verify complete user workflows across multiple services, databases, and frontend interfaces. E2E tests validate that the entire system works together correctly in realistic conditions.</p> <p>This document covers E2E test environment setup using Docker Compose for service orchestration, Playwright for browser automation, pytest integration, CI/CD configuration, and artifact management. E2E test infrastructure ensures your complete system can be tested reliably and repeatably.</p> <p>E2E testing infrastructure validates system integration from user perspective by running real services, databases, and browsers together. These tests catch issues that unit and integration tests miss by exercising complete workflows end-to-end.</p>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#overview","title":"Overview","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#when-to-use-e2e-tests","title":"When to Use E2E Tests","text":"<p>Use E2E tests for: - Critical user journeys (signup, login, core transactions) - Multi-service workflows (API \u2192 Worker \u2192 Bot notification) - Payment and transaction flows - Authentication and authorization flows - Data consistency across services - Frontend-to-backend integration</p> <p>Don't use E2E tests for: - Unit-level logic (use unit tests) - Database queries (use integration tests) - Internal API contracts (use service tests) - Detailed edge cases (use lower-level tests)</p>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#test-infrastructure-setup","title":"Test Infrastructure Setup","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#docker-compose-configuration","title":"Docker Compose Configuration","text":"<pre><code># docker-compose.e2e.yml\nversion: '3.8'\n\nservices:\n  # PostgreSQL database\n  postgres:\n    image: postgres:16-alpine\n    environment:\n      POSTGRES_DB: testdb\n      POSTGRES_USER: testuser\n      POSTGRES_PASSWORD: testpass\n    ports:\n      - \"5433:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U testuser\"]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n\n  # MongoDB database\n  mongo:\n    image: mongo:7-jammy\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: testuser\n      MONGO_INITDB_ROOT_PASSWORD: testpass\n    ports:\n      - \"27018:27017\"\n    healthcheck:\n      test: [\"CMD\", \"mongosh\", \"--eval\", \"db.adminCommand('ping')\"]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n\n  # Redis cache\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6380:6379\"\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n\n  # RabbitMQ message broker\n  rabbitmq:\n    image: rabbitmq:3-management-alpine\n    environment:\n      RABBITMQ_DEFAULT_USER: testuser\n      RABBITMQ_DEFAULT_PASS: testpass\n    ports:\n      - \"5673:5672\"\n      - \"15673:15672\"\n    healthcheck:\n      test: [\"CMD\", \"rabbitmq-diagnostics\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Data service (PostgreSQL API)\n  data_service:\n    build:\n      context: ./services/finance_data_postgres_api\n      dockerfile: Dockerfile\n    environment:\n      DATABASE_URL: postgresql+asyncpg://testuser:testpass@postgres:5432/testdb\n      REDIS_URL: redis://redis:6379/0\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    ports:\n      - \"8001:8000\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Business API service\n  business_api:\n    build:\n      context: ./services/finance_lending_api\n      dockerfile: Dockerfile\n    environment:\n      DATA_SERVICE_URL: http://data_service:8000\n      RABBITMQ_URL: amqp://testuser:testpass@rabbitmq:5672/\n      REDIS_URL: redis://redis:6379/0\n    depends_on:\n      data_service:\n        condition: service_healthy\n      rabbitmq:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Frontend (if applicable)\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    environment:\n      API_URL: http://business_api:8000\n    depends_on:\n      business_api:\n        condition: service_healthy\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#playwright-setup","title":"Playwright Setup","text":"<pre><code># Install Playwright\npip install playwright pytest-playwright\n\n# Install browser drivers\nplaywright install chromium firefox webkit\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#pytest-configuration","title":"Pytest Configuration","text":"<pre><code># pytest.ini\n[pytest]\nmarkers =\n    e2e: mark test as end-to-end test\n    slow: mark test as slow-running\n    chrome: run test in Chrome only\n    firefox: run test in Firefox only\n    webkit: run test in WebKit only\n\n# E2E test configuration\ntestpaths = tests/e2e\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\n\n# Playwright configuration\nasyncio_mode = auto\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#conftest-configuration","title":"Conftest Configuration","text":"<pre><code># tests/e2e/conftest.py\nimport pytest\nimport subprocess\nimport time\nfrom playwright.sync_api import sync_playwright\n\n\n@pytest.fixture(scope=\"session\")\ndef docker_compose():\n    \"\"\"Start Docker Compose services for E2E tests.\"\"\"\n    # Start services\n    subprocess.run(\n        [\"docker-compose\", \"-f\", \"docker-compose.e2e.yml\", \"up\", \"-d\"],\n        check=True\n    )\n\n    # Wait for services to be healthy\n    time.sleep(30)\n\n    yield\n\n    # Teardown: stop services\n    subprocess.run(\n        [\"docker-compose\", \"-f\", \"docker-compose.e2e.yml\", \"down\", \"-v\"],\n        check=True\n    )\n\n\n@pytest.fixture(scope=\"session\")\ndef browser_context(docker_compose):\n    \"\"\"Provide browser context for tests.\"\"\"\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        context = browser.new_context(\n            viewport={\"width\": 1920, \"height\": 1080},\n            record_video_dir=\"test-results/videos/\",\n            record_video_size={\"width\": 1920, \"height\": 1080}\n        )\n        yield context\n        context.close()\n        browser.close()\n\n\n@pytest.fixture\ndef page(browser_context):\n    \"\"\"Provide new page for each test.\"\"\"\n    page = browser_context.new_page()\n    yield page\n    # Screenshot on failure handled by pytest-playwright\n    page.close()\n\n\n@pytest.fixture\ndef api_client():\n    \"\"\"Provide HTTP client for API calls.\"\"\"\n    import httpx\n    return httpx.Client(base_url=\"http://localhost:8000\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#environment-variables","title":"Environment Variables","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#test-environment-configuration","title":"Test Environment Configuration","text":"<pre><code># .env.e2e\n# Database\nDATABASE_URL=postgresql+asyncpg://testuser:testpass@localhost:5433/testdb\nMONGO_URL=mongodb://testuser:testpass@localhost:27018/testdb\n\n# Redis\nREDIS_URL=redis://localhost:6380/0\n\n# RabbitMQ\nRABBITMQ_URL=amqp://testuser:testpass@localhost:5673/\n\n# Services\nDATA_SERVICE_URL=http://localhost:8001\nBUSINESS_API_URL=http://localhost:8000\nFRONTEND_URL=http://localhost:3000\n\n# Test configuration\nHEADLESS=true\nSLOW_MO=0\nSCREENSHOT_ON_FAILURE=true\nVIDEO_ON_FAILURE=true\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#running-e2e-tests","title":"Running E2E Tests","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#local-execution","title":"Local Execution","text":"<pre><code># Start infrastructure\ndocker-compose -f docker-compose.e2e.yml up -d\n\n# Wait for services to be healthy\ndocker-compose -f docker-compose.e2e.yml ps\n\n# Run all E2E tests\npytest tests/e2e -v -m e2e\n\n# Run specific test file\npytest tests/e2e/test_user_registration.py -v\n\n# Run with headed browser (visible)\nHEADLESS=false pytest tests/e2e -v\n\n# Run in specific browser\npytest tests/e2e -v --browser chromium\npytest tests/e2e -v --browser firefox\npytest tests/e2e -v --browser webkit\n\n# Stop infrastructure\ndocker-compose -f docker-compose.e2e.yml down -v\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#parallel-execution","title":"Parallel Execution","text":"<pre><code># Install pytest-xdist\npip install pytest-xdist\n\n# Run tests in parallel (4 workers)\npytest tests/e2e -v -n 4 -m e2e\n\n# Each worker gets isolated browser context\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<pre><code># .github/workflows/e2e-tests.yml\nname: E2E Tests\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  e2e-tests:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements-test.txt\n          playwright install --with-deps chromium\n\n      - name: Start services\n        run: |\n          docker-compose -f docker-compose.e2e.yml up -d\n          sleep 30\n\n      - name: Wait for services\n        run: |\n          chmod +x scripts/wait-for-services.sh\n          ./scripts/wait-for-services.sh\n\n      - name: Run E2E tests\n        run: |\n          pytest tests/e2e -v -m e2e \\\n            --video on \\\n            --screenshot on \\\n            --tracing on\n\n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: e2e-test-results\n          path: |\n            test-results/\n            screenshots/\n            videos/\n\n      - name: Stop services\n        if: always()\n        run: docker-compose -f docker-compose.e2e.yml down -v\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#wait-for-services-script","title":"Wait for Services Script","text":"<pre><code>#!/bin/bash\n# scripts/wait-for-services.sh\n\nset -e\n\nservices=(\n  \"http://localhost:8001/health\"\n  \"http://localhost:8000/health\"\n  \"http://localhost:3000\"\n)\n\nfor service in \"${services[@]}\"; do\n  echo \"Waiting for $service...\"\n  timeout 60 bash -c \"\n    until curl -f -s $service &gt; /dev/null; do\n      echo 'Waiting...'\n      sleep 2\n    done\n  \"\n  echo \"$service is ready!\"\ndone\n\necho \"All services are ready!\"\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#screenshots-and-videos","title":"Screenshots and Videos","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#automatic-capture-on-failure","title":"Automatic Capture on Failure","text":"<pre><code># Playwright automatically captures on failure\n@pytest.mark.e2e\ndef test_user_login_failure(page):\n    \"\"\"Test captures screenshot and video on failure.\"\"\"\n    page.goto(\"http://localhost:3000/login\")\n    page.fill(\"#email\", \"user@example.com\")\n    page.fill(\"#password\", \"wrongpassword\")\n    page.click(\"#login-button\")\n\n    # This assertion will fail and trigger screenshot\n    assert page.locator(\".error-message\").is_visible()\n    # Screenshot saved to test-results/screenshots/\n    # Video saved to test-results/videos/\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#manual-screenshot-capture","title":"Manual Screenshot Capture","text":"<pre><code># CORRECT: Capture screenshot at specific points\n@pytest.mark.e2e\ndef test_checkout_flow(page):\n    \"\"\"Test captures screenshots at key steps.\"\"\"\n    page.goto(\"http://localhost:3000/products\")\n    page.screenshot(path=\"test-results/step1-products.png\")\n\n    page.click(\"#product-1\")\n    page.screenshot(path=\"test-results/step2-product-detail.png\")\n\n    page.click(\"#add-to-cart\")\n    page.screenshot(path=\"test-results/step3-cart.png\")\n\n    page.click(\"#checkout\")\n    page.screenshot(path=\"test-results/step4-checkout.png\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#test-data-management","title":"Test Data Management","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#database-seeding","title":"Database Seeding","text":"<pre><code># tests/e2e/helpers/seed_data.py\nimport asyncio\nimport httpx\n\n\nasync def seed_test_users():\n    \"\"\"Seed test users via API.\"\"\"\n    async with httpx.AsyncClient(base_url=\"http://localhost:8001\") as client:\n        users = [\n            {\"email\": \"user1@test.com\", \"name\": \"Test User 1\"},\n            {\"email\": \"user2@test.com\", \"name\": \"Test User 2\"},\n            {\"email\": \"admin@test.com\", \"name\": \"Admin User\"},\n        ]\n        for user in users:\n            await client.post(\"/api/users\", json=user)\n\n\nasync def cleanup_test_data():\n    \"\"\"Clean up test data after tests.\"\"\"\n    async with httpx.AsyncClient(base_url=\"http://localhost:8001\") as client:\n        await client.delete(\"/api/users?test=true\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#using-seeds-in-tests","title":"Using Seeds in Tests","text":"<pre><code>@pytest.fixture(scope=\"session\")\nasync def test_data(docker_compose):\n    \"\"\"Seed test data before tests.\"\"\"\n    from tests.e2e.helpers.seed_data import seed_test_users, cleanup_test_data\n\n    await seed_test_users()\n    yield\n    await cleanup_test_data()\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#do-use-page-object-pattern","title":"DO: Use Page Object Pattern","text":"<pre><code># CORRECT: Use page objects for maintainability\n# tests/e2e/pages/login_page.py\nclass LoginPage:\n    \"\"\"Page object for login page.\"\"\"\n\n    def __init__(self, page):\n        self.page = page\n        self.email_input = \"#email\"\n        self.password_input = \"#password\"\n        self.login_button = \"#login-button\"\n        self.error_message = \".error-message\"\n\n    def goto(self):\n        \"\"\"Navigate to login page.\"\"\"\n        self.page.goto(\"http://localhost:3000/login\")\n\n    def login(self, email: str, password: str):\n        \"\"\"Perform login action.\"\"\"\n        self.page.fill(self.email_input, email)\n        self.page.fill(self.password_input, password)\n        self.page.click(self.login_button)\n\n    def get_error_message(self) -&gt; str:\n        \"\"\"Get error message text.\"\"\"\n        return self.page.locator(self.error_message).text_content()\n\n\n# Use in tests\n@pytest.mark.e2e\ndef test_login(page):\n    \"\"\"Test login with page object.\"\"\"\n    login_page = LoginPage(page)\n    login_page.goto()\n    login_page.login(\"user@example.com\", \"password123\")\n    assert page.url.endswith(\"/dashboard\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#do-wait-for-elements-properly","title":"DO: Wait for Elements Properly","text":"<pre><code># CORRECT: Wait for elements before interacting\n@pytest.mark.e2e\ndef test_wait_for_elements(page):\n    \"\"\"Wait for dynamic content.\"\"\"\n    page.goto(\"http://localhost:3000/dashboard\")\n\n    # Wait for element to be visible\n    page.wait_for_selector(\"#data-loaded\", state=\"visible\", timeout=5000)\n\n    # Wait for API response\n    with page.expect_response(\"**/api/users\") as response_info:\n        page.click(\"#load-users\")\n    response = response_info.value\n    assert response.status == 200\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#dont-hardcode-timeouts","title":"DON'T: Hardcode Timeouts","text":"<pre><code># INCORRECT: Hardcoded sleep\n@pytest.mark.e2e\ndef test_with_hardcoded_sleep(page):\n    \"\"\"WRONG: Using time.sleep.\"\"\"\n    page.goto(\"http://localhost:3000\")\n    time.sleep(5)  # Bad: arbitrary wait\n    page.click(\"#button\")\n\n\n# CORRECT: Wait for specific conditions\n@pytest.mark.e2e\ndef test_with_proper_wait(page):\n    \"\"\"Use Playwright's waiting mechanisms.\"\"\"\n    page.goto(\"http://localhost:3000\")\n    page.wait_for_load_state(\"networkidle\")\n    page.wait_for_selector(\"#button\", state=\"visible\")\n    page.click(\"#button\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#checklist","title":"Checklist","text":"<ul> <li> Docker Compose configuration for all services</li> <li> Health checks for all containers</li> <li> Playwright/Selenium installed with browser drivers</li> <li> pytest configuration with E2E markers</li> <li> Fixtures for browser context and pages</li> <li> Environment variables for test configuration</li> <li> CI/CD pipeline with E2E test step</li> <li> Screenshot capture on test failure</li> <li> Video recording for debugging</li> <li> Test data seeding and cleanup</li> <li> Page object pattern for UI tests</li> <li> Proper waits instead of hardcoded sleeps</li> <li> Parallel execution configuration</li> </ul>"},{"location":"atomic/testing/end-to-end-testing/e2e-test-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/end-to-end-testing/user-journey-testing.md</code> \u2014 Testing complete user workflows</li> <li><code>docs/atomic/testing/end-to-end-testing/performance-testing.md</code> \u2014 Load and performance testing</li> <li><code>docs/atomic/infrastructure/docker/docker-compose-patterns.md</code> \u2014 Docker Compose best practices</li> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Container-based integration tests</li> </ul>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/","title":"End-to-End Performance Testing","text":"<p>Test system performance under realistic load conditions to verify scalability, identify bottlenecks, and establish performance baselines. Performance tests validate that the system meets response time, throughput, and resource usage requirements under expected and peak loads.</p> <p>This document covers performance testing patterns using Locust and k6, load testing strategies, stress testing, metrics collection, and CI/CD integration. Performance tests ensure your microservices handle production traffic without degradation.</p> <p>Performance testing validates that services respond quickly under load, scale horizontally as needed, maintain data consistency under concurrent access, and gracefully handle peak traffic spikes. These tests prevent production outages caused by performance issues.</p>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#performance-testing-types","title":"Performance Testing Types","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#load-testing","title":"Load Testing","text":"<p>Test system behavior under expected production load. Verify the system handles target concurrent users and request rates without performance degradation.</p>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#stress-testing","title":"Stress Testing","text":"<p>Push system beyond normal capacity to find breaking points. Identify maximum load the system can handle before failure.</p>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#spike-testing","title":"Spike Testing","text":"<p>Sudden dramatic increase in load to test elasticity. Verify auto-scaling and graceful degradation under traffic spikes.</p>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#soak-testing","title":"Soak Testing","text":"<p>Sustained load over extended period (hours/days) to detect memory leaks, resource exhaustion, and performance degradation over time.</p>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#load-testing-with-locust","title":"Load Testing with Locust","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#basic-locust-setup","title":"Basic Locust Setup","text":"<pre><code># tests/performance/locustfile.py\nfrom locust import HttpUser, task, between\nimport random\n\n\nclass LoanApplicationUser(HttpUser):\n    \"\"\"Simulate users applying for loans.\"\"\"\n\n    wait_time = between(1, 3)  # Wait 1-3 seconds between tasks\n    host = \"http://localhost:8000\"\n\n    def on_start(self):\n        \"\"\"Execute once when user starts.\"\"\"\n        # Login or get auth token\n        response = self.client.post(\"/api/auth/login\", json={\n            \"email\": f\"user{random.randint(1, 1000)}@test.com\",\n            \"password\": \"testpass\"\n        })\n        self.auth_token = response.json().get(\"token\")\n\n    @task(3)\n    def view_dashboard(self):\n        \"\"\"View dashboard (most common action).\"\"\"\n        self.client.get(\"/api/dashboard\", headers={\n            \"Authorization\": f\"Bearer {self.auth_token}\"\n        })\n\n    @task(2)\n    def list_loans(self):\n        \"\"\"List user's loans.\"\"\"\n        self.client.get(\"/api/loans\", headers={\n            \"Authorization\": f\"Bearer {self.auth_token}\"\n        })\n\n    @task(1)\n    def apply_for_loan(self):\n        \"\"\"Apply for a loan (less frequent).\"\"\"\n        self.client.post(\"/api/loans\", json={\n            \"amount\": random.randint(5000, 50000),\n            \"purpose\": random.choice([\"business\", \"personal\", \"education\"]),\n            \"term_months\": random.choice([12, 24, 36])\n        }, headers={\n            \"Authorization\": f\"Bearer {self.auth_token}\"\n        })\n\n\n# Run: locust -f locustfile.py --users 100 --spawn-rate 10\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#advanced-locust-patterns","title":"Advanced Locust Patterns","text":"<pre><code># CORRECT: Test multiple user types\nclass AdminUser(HttpUser):\n    \"\"\"Simulate admin users.\"\"\"\n    wait_time = between(2, 5)\n    weight = 1  # 10% of users\n\n    @task\n    def approve_loans(self):\n        \"\"\"Approve pending loans.\"\"\"\n        response = self.client.get(\"/api/loans?status=pending\")\n        loans = response.json()[\"loans\"]\n        if loans:\n            loan_id = random.choice(loans)[\"id\"]\n            self.client.post(f\"/api/loans/{loan_id}/approve\")\n\n\nclass RegularUser(HttpUser):\n    \"\"\"Simulate regular users.\"\"\"\n    wait_time = between(1, 3)\n    weight = 9  # 90% of users\n\n    @task(5)\n    def browse(self):\n        self.client.get(\"/api/products\")\n\n    @task(1)\n    def purchase(self):\n        self.client.post(\"/api/orders\", json={\"product_id\": \"prod-1\"})\n\n\n# CORRECT: Sequential task execution\nfrom locust import SequentialTaskSet\n\nclass CheckoutFlow(SequentialTaskSet):\n    \"\"\"Execute tasks in order.\"\"\"\n\n    @task\n    def view_product(self):\n        self.client.get(\"/api/products/1\")\n\n    @task\n    def add_to_cart(self):\n        self.client.post(\"/api/cart\", json={\"product_id\": 1, \"quantity\": 1})\n\n    @task\n    def checkout(self):\n        self.client.post(\"/api/checkout\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#running-locust-tests","title":"Running Locust Tests","text":"<pre><code># Local execution\nlocust -f tests/performance/locustfile.py \\\n    --users 100 \\\n    --spawn-rate 10 \\\n    --run-time 5m \\\n    --headless\n\n# With custom host\nlocust -f locustfile.py --host https://staging.example.com\n\n# Generate HTML report\nlocust -f locustfile.py --users 100 --run-time 5m --html report.html\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#load-testing-with-k6","title":"Load Testing with k6","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#basic-k6-script","title":"Basic k6 Script","text":"<pre><code>// tests/performance/load_test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate } from 'k6/metrics';\n\n// Custom metric\nconst errorRate = new Rate('errors');\n\nexport const options = {\n  stages: [\n    { duration: '2m', target: 50 },   // Ramp up to 50 users\n    { duration: '5m', target: 50 },   // Stay at 50 users\n    { duration: '2m', target: 100 },  // Ramp to 100 users\n    { duration: '5m', target: 100 },  // Stay at 100 users\n    { duration: '2m', target: 0 },    // Ramp down\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)&lt;500', 'p(99)&lt;1000'], // 95% &lt; 500ms, 99% &lt; 1s\n    http_req_failed: ['rate&lt;0.01'],  // Error rate &lt; 1%\n    errors: ['rate&lt;0.1'],\n  },\n};\n\nexport default function () {\n  // Test loan application endpoint\n  const payload = JSON.stringify({\n    amount: 10000,\n    purpose: 'business',\n    term_months: 24,\n  });\n\n  const params = {\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': 'Bearer test-token',\n    },\n  };\n\n  const response = http.post('http://localhost:8000/api/loans', payload, params);\n\n  // Validate response\n  const success = check(response, {\n    'status is 201': (r) =&gt; r.status === 201,\n    'response time &lt; 500ms': (r) =&gt; r.timings.duration &lt; 500,\n    'has loan_id': (r) =&gt; JSON.parse(r.body).id !== undefined,\n  });\n\n  errorRate.add(!success);\n\n  sleep(1);\n}\n\n// Run: k6 run load_test.js\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#stress-testing-with-k6","title":"Stress Testing with k6","text":"<pre><code>// tests/performance/stress_test.js\nexport const options = {\n  stages: [\n    { duration: '5m', target: 100 },   // Normal load\n    { duration: '5m', target: 200 },   // Above normal\n    { duration: '5m', target: 300 },   // Stress\n    { duration: '5m', target: 400 },   // Heavy stress\n    { duration: '5m', target: 0 },     // Recovery\n  ],\n};\n\nexport default function () {\n  // Test critical endpoints under stress\n  const responses = http.batch([\n    ['GET', 'http://localhost:8000/api/users'],\n    ['GET', 'http://localhost:8000/api/loans'],\n    ['POST', 'http://localhost:8000/api/transactions', JSON.stringify({amount: 100})],\n  ]);\n\n  // Check if any request failed\n  responses.forEach((response, index) =&gt; {\n    check(response, {\n      [`request ${index} succeeded`]: (r) =&gt; r.status &lt; 400,\n    });\n  });\n}\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#spike-testing_1","title":"Spike Testing","text":"<pre><code>// tests/performance/spike_test.js\nexport const options = {\n  stages: [\n    { duration: '1m', target: 50 },    // Normal load\n    { duration: '30s', target: 500 },  // Sudden spike\n    { duration: '1m', target: 500 },   // Sustain spike\n    { duration: '1m', target: 50 },    // Return to normal\n  ],\n};\n\nexport default function () {\n  http.get('http://localhost:8000/api/products');\n  sleep(1);\n}\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#metrics-collection","title":"Metrics Collection","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#key-performance-metrics","title":"Key Performance Metrics","text":"<pre><code># Performance thresholds\nperformance_requirements:\n  response_time:\n    p50: &lt;200ms  # Median response time\n    p95: &lt;500ms  # 95th percentile\n    p99: &lt;1000ms # 99th percentile\n\n  throughput:\n    target_rps: 1000  # Requests per second\n\n  error_rate:\n    max_rate: 1%      # Maximum 1% errors\n\n  resource_usage:\n    cpu_max: 80%      # Maximum CPU utilization\n    memory_max: 80%   # Maximum memory utilization\n    database_connections_max: 80%\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#monitoring-during-tests","title":"Monitoring During Tests","text":"<pre><code># CORRECT: Collect metrics during load test\nimport prometheus_client\nfrom locust import events\n\n@events.test_start.add_listener\ndef on_test_start(environment, **kwargs):\n    \"\"\"Start metrics collection.\"\"\"\n    print(\"Starting metrics collection...\")\n    # Start Prometheus scraping\n\n@events.request.add_listener\ndef on_request(request_type, name, response_time, response_length, **kwargs):\n    \"\"\"Track individual requests.\"\"\"\n    if response_time &gt; 1000:\n        print(f\"Slow request: {name} took {response_time}ms\")\n\n@events.test_stop.add_listener\ndef on_test_stop(environment, **kwargs):\n    \"\"\"Generate performance report.\"\"\"\n    stats = environment.stats\n    print(f\"Total requests: {stats.total.num_requests}\")\n    print(f\"Failed requests: {stats.total.num_failures}\")\n    print(f\"Median response time: {stats.total.median_response_time}ms\")\n    print(f\"95th percentile: {stats.total.get_response_time_percentile(0.95)}ms\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#database-performance-testing","title":"Database Performance Testing","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#testing-database-under-load","title":"Testing Database Under Load","text":"<pre><code>@task\ndef complex_query(self):\n    \"\"\"Test expensive database query under load.\"\"\"\n    self.client.get(\"/api/reports/user-analytics\", params={\n        \"start_date\": \"2025-01-01\",\n        \"end_date\": \"2025-01-31\",\n        \"group_by\": \"day\"\n    })\n\n\n@task\ndef concurrent_writes(self):\n    \"\"\"Test concurrent writes to database.\"\"\"\n    self.client.post(\"/api/transactions\", json={\n        \"user_id\": f\"user-{random.randint(1, 1000)}\",\n        \"amount\": random.randint(10, 1000)\n    })\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#github-actions-performance-tests","title":"GitHub Actions Performance Tests","text":"<pre><code># .github/workflows/performance-tests.yml\nname: Performance Tests\n\non:\n  schedule:\n    - cron: '0 2 * * *'  # Nightly\n  workflow_dispatch:\n\njobs:\n  performance:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Start services\n        run: docker-compose -f docker-compose.perf.yml up -d\n\n      - name: Run k6 tests\n        uses: grafana/k6-action@v0.3.0\n        with:\n          filename: tests/performance/load_test.js\n          cloud: false\n\n      - name: Check performance thresholds\n        run: |\n          if [ ${{ steps.k6.outputs.exit_code }} -ne 0 ]; then\n            echo \"Performance thresholds not met!\"\n            exit 1\n          fi\n\n      - name: Upload results\n        uses: actions/upload-artifact@v4\n        with:\n          name: k6-results\n          path: summary.json\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/end-to-end-testing/performance-testing/#do-test-realistic-scenarios","title":"DO: Test Realistic Scenarios","text":"<pre><code># CORRECT: Realistic user behavior\nclass RealisticUser(HttpUser):\n    \"\"\"Simulate realistic user behavior.\"\"\"\n\n    @task\n    def user_journey(self):\n        # Login\n        self.client.post(\"/api/auth/login\", json={...})\n        self.wait()\n\n        # Browse products\n        self.client.get(\"/api/products\")\n        self.wait()\n\n        # View product details\n        self.client.get(\"/api/products/123\")\n        self.wait()\n\n        # Add to cart\n        self.client.post(\"/api/cart\", json={...})\n        self.wait()\n\n        # Checkout\n        self.client.post(\"/api/orders\", json={...})\n\n    def wait(self):\n        \"\"\"Realistic think time.\"\"\"\n        sleep(random.uniform(2, 5))\n\n\n# INCORRECT: Unrealistic constant hammering\nclass UnrealisticUser(HttpUser):\n    \"\"\"WRONG: Unrealistic load pattern.\"\"\"\n\n    @task\n    def hammer_endpoint(self):\n        for _ in range(100):\n            self.client.get(\"/api/products\")  # No wait time\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#do-establish-baselines","title":"DO: Establish Baselines","text":"<pre><code># CORRECT: Run baseline before changes\nk6 run tests/performance/baseline.js --out json=baseline.json\n\n# Make code changes\n\n# Run comparison test\nk6 run tests/performance/baseline.js --out json=after_changes.json\n\n# Compare results\npython scripts/compare_performance.py baseline.json after_changes.json\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#dont-test-production","title":"DON'T: Test Production","text":"<pre><code># INCORRECT: Testing production\nlocust -f locustfile.py --host https://api.production.com\n\n\n# CORRECT: Test staging or dedicated perf environment\nlocust -f locustfile.py --host https://api.staging.com\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#checklist","title":"Checklist","text":"<ul> <li> Define performance requirements (response time, throughput, error rate)</li> <li> Set up load testing tool (Locust, k6, JMeter)</li> <li> Create realistic user scenarios</li> <li> Test under expected load</li> <li> Test under peak load (stress testing)</li> <li> Test sudden traffic spikes (spike testing)</li> <li> Test sustained load (soak testing)</li> <li> Monitor resource usage (CPU, memory, database connections)</li> <li> Collect and analyze metrics</li> <li> Establish performance baselines</li> <li> Integrate tests into CI/CD</li> <li> Test with production-like data volumes</li> <li> Identify and document bottlenecks</li> </ul>"},{"location":"atomic/testing/end-to-end-testing/performance-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/end-to-end-testing/e2e-test-setup.md</code> \u2014 E2E test infrastructure</li> <li><code>docs/atomic/testing/end-to-end-testing/user-journey-testing.md</code> \u2014 User workflow testing</li> <li><code>docs/atomic/observability/metrics/prometheus-integration.md</code> \u2014 Metrics collection</li> <li><code>docs/atomic/infrastructure/docker/docker-compose-patterns.md</code> \u2014 Service orchestration</li> </ul>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/","title":"User Journey Testing","text":"<p>Test complete user workflows end-to-end across multiple services, databases, and interfaces to verify business-critical flows work correctly in realistic conditions. User journey tests validate that users can successfully complete key tasks without errors or data inconsistencies.</p> <p>This document covers testing patterns for complete user journeys in microservices, including multi-step workflows, cross-service communication, state persistence, and data consistency verification. User journey tests ensure your system delivers value to real users.</p> <p>Testing user journeys validates that business-critical workflows execute correctly from user perspective, data flows properly between services, and system state remains consistent throughout complex operations. These tests catch integration issues that unit and service tests cannot detect.</p>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#common-user-journeys","title":"Common User Journeys","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#critical-journeys-to-test","title":"Critical Journeys to Test","text":"<p>Authentication &amp; Onboarding: - User registration \u2192 Email verification \u2192 Profile setup - User login \u2192 Session management \u2192 Password reset</p> <p>Core Business Flows: - Loan application \u2192 Credit check \u2192 Approval/Rejection \u2192 Notification - Payment processing \u2192 Transaction confirmation \u2192 Receipt generation</p> <p>Multi-Service Workflows: - API request \u2192 Worker processing \u2192 Bot notification - Frontend action \u2192 API call \u2192 Database update \u2192 Event publishing</p>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-registration-flow","title":"Testing Registration Flow","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#complete-registration-journey","title":"Complete Registration Journey","text":"<pre><code># tests/e2e/test_user_registration.py\nimport pytest\nfrom tests.e2e.pages.registration_page import RegistrationPage\nfrom tests.e2e.pages.email_verification_page import EmailVerificationPage\nfrom tests.e2e.pages.profile_page import ProfilePage\n\n\n@pytest.mark.e2e\n@pytest.mark.slow\ndef test_complete_user_registration_journey(page, api_client):\n    \"\"\"Test user completes full registration journey.\"\"\"\n\n    # Step 1: Navigate to registration page\n    reg_page = RegistrationPage(page)\n    reg_page.goto()\n\n    # Step 2: Fill registration form\n    user_email = \"newuser@test.com\"\n    reg_page.fill_registration_form(\n        email=user_email,\n        password=\"SecurePass123!\",\n        full_name=\"Test User\"\n    )\n    reg_page.submit()\n\n    # Step 3: Verify success message\n    assert reg_page.get_success_message() == \"Registration successful! Check your email.\"\n\n    # Step 4: Verify user created in database via API\n    response = api_client.get(f\"/api/users?email={user_email}\")\n    assert response.status_code == 200\n    users = response.json()[\"users\"]\n    assert len(users) == 1\n    assert users[0][\"email\"] == user_email\n    assert users[0][\"verified\"] is False\n\n    # Step 5: Simulate email verification (get token from DB/email)\n    verification_token = get_verification_token_from_db(user_email)\n    verify_page = EmailVerificationPage(page)\n    verify_page.goto_with_token(verification_token)\n\n    # Step 6: Verify account activated\n    assert verify_page.get_confirmation_message() == \"Email verified successfully!\"\n\n    # Step 7: Verify database updated\n    response = api_client.get(f\"/api/users?email={user_email}\")\n    users = response.json()[\"users\"]\n    assert users[0][\"verified\"] is True\n\n    # Step 8: Login with new account\n    reg_page.goto_login()\n    reg_page.login(user_email, \"SecurePass123!\")\n\n    # Step 9: Verify redirected to dashboard\n    assert page.url.endswith(\"/dashboard\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-loan-application-flow","title":"Testing Loan Application Flow","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#multi-service-loan-journey","title":"Multi-Service Loan Journey","text":"<pre><code>@pytest.mark.e2e\n@pytest.mark.slow\nasync def test_loan_application_journey(page, api_client, rabbitmq_client):\n    \"\"\"Test complete loan application from request to notification.\"\"\"\n\n    # Step 1: User logs in\n    page.goto(\"http://localhost:3000/login\")\n    page.fill(\"#email\", \"borrower@test.com\")\n    page.fill(\"#password\", \"password123\")\n    page.click(\"#login-button\")\n    page.wait_for_url(\"**/dashboard\")\n\n    # Step 2: Navigate to loan application\n    page.click(\"#apply-for-loan\")\n    page.wait_for_url(\"**/loans/apply\")\n\n    # Step 3: Fill loan application form\n    page.fill(\"#loan-amount\", \"10000\")\n    page.select_option(\"#loan-purpose\", \"business\")\n    page.fill(\"#loan-term\", \"24\")\n    page.click(\"#submit-application\")\n\n    # Step 4: Verify application submitted\n    page.wait_for_selector(\".success-message\")\n    assert \"Application submitted\" in page.locator(\".success-message\").text_content()\n\n    # Step 5: Get loan application ID\n    loan_id = page.locator(\"#loan-id\").text_content()\n\n    # Step 6: Verify loan created in database via API\n    response = api_client.get(f\"/api/loans/{loan_id}\")\n    assert response.status_code == 200\n    loan = response.json()\n    assert loan[\"amount\"] == 10000\n    assert loan[\"status\"] == \"pending\"\n\n    # Step 7: Verify event published to RabbitMQ\n    await asyncio.sleep(1)  # Allow event to be published\n    message = await rabbitmq_client.consume_one(\"loan.application.submitted\")\n    assert message[\"loan_id\"] == loan_id\n    assert message[\"amount\"] == 10000\n\n    # Step 8: Wait for worker to process (credit check)\n    await asyncio.sleep(5)  # Worker processing time\n\n    # Step 9: Verify loan status updated\n    response = api_client.get(f\"/api/loans/{loan_id}\")\n    loan = response.json()\n    assert loan[\"status\"] in [\"approved\", \"rejected\"]\n\n    # Step 10: Verify notification sent (check bot or email log)\n    notifications = api_client.get(f\"/api/notifications?user_id={loan['user_id']}\")\n    assert len(notifications.json()[\"notifications\"]) &gt; 0\n    assert loan_id in notifications.json()[\"notifications\"][0][\"content\"]\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-bot-interaction-flow","title":"Testing Bot Interaction Flow","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#telegram-bot-user-journey","title":"Telegram Bot User Journey","text":"<pre><code>@pytest.mark.e2e\nasync def test_telegram_bot_loan_application_journey(bot_client, api_client):\n    \"\"\"Test loan application via Telegram bot.\"\"\"\n\n    # Step 1: User sends /start command\n    update = create_bot_update(text=\"/start\", user_id=123456)\n    response = await bot_client.send_update(update)\n    assert \"Welcome\" in response.text\n\n    # Step 2: User sends /apply_loan command\n    update = create_bot_update(text=\"/apply_loan\", user_id=123456)\n    response = await bot_client.send_update(update)\n    assert \"How much would you like to borrow?\" in response.text\n\n    # Step 3: User provides loan amount\n    update = create_bot_update(text=\"10000\", user_id=123456)\n    response = await bot_client.send_update(update)\n    assert \"What is the purpose\" in response.text\n\n    # Step 4: User provides purpose\n    update = create_bot_update(text=\"Business expansion\", user_id=123456)\n    response = await bot_client.send_update(update)\n    assert \"How many months\" in response.text\n\n    # Step 5: User provides term\n    update = create_bot_update(text=\"24\", user_id=123456)\n    response = await bot_client.send_update(update)\n    assert \"application submitted\" in response.text.lower()\n\n    # Step 6: Verify loan created via API\n    loans = api_client.get(\"/api/loans?telegram_user_id=123456\")\n    assert len(loans.json()[\"loans\"]) == 1\n    loan = loans.json()[\"loans\"][0]\n    assert loan[\"amount\"] == 10000\n    assert loan[\"purpose\"] == \"Business expansion\"\n    assert loan[\"term_months\"] == 24\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-cross-service-communication","title":"Testing Cross-Service Communication","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#api-worker-bot-notification-flow","title":"API \u2192 Worker \u2192 Bot Notification Flow","text":"<pre><code>@pytest.mark.e2e\nasync def test_cross_service_notification_flow(api_client, rabbitmq_client, bot_client):\n    \"\"\"Test notification flows from API through worker to bot.\"\"\"\n\n    # Step 1: Trigger action via API (loan approved)\n    response = api_client.post(\"/api/loans/loan-123/approve\")\n    assert response.status_code == 200\n\n    # Step 2: Verify event published to RabbitMQ\n    await asyncio.sleep(0.5)\n    message = await rabbitmq_client.consume_one(\"loan.approved\")\n    assert message[\"loan_id\"] == \"loan-123\"\n\n    # Step 3: Wait for worker to process event\n    await asyncio.sleep(2)\n\n    # Step 4: Verify notification record created\n    notifications = api_client.get(\"/api/notifications?loan_id=loan-123\")\n    assert len(notifications.json()[\"notifications\"]) &gt; 0\n    notification = notifications.json()[\"notifications\"][0]\n    assert notification[\"type\"] == \"loan_approved\"\n\n    # Step 5: Verify bot sent message to user\n    await asyncio.sleep(1)\n    sent_messages = await bot_client.get_sent_messages(user_id=notification[\"user_id\"])\n    assert len(sent_messages) &gt; 0\n    assert \"approved\" in sent_messages[-1][\"text\"].lower()\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-data-consistency","title":"Testing Data Consistency","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#verify-data-across-services","title":"Verify Data Across Services","text":"<pre><code>@pytest.mark.e2e\ndef test_data_consistency_across_services(api_client):\n    \"\"\"Test data remains consistent across multiple services.\"\"\"\n\n    # Step 1: Create user via API\n    response = api_client.post(\"/api/users\", json={\n        \"email\": \"consistency@test.com\",\n        \"name\": \"Consistency Test\"\n    })\n    user_id = response.json()[\"id\"]\n\n    # Step 2: Create loan for user\n    response = api_client.post(\"/api/loans\", json={\n        \"user_id\": user_id,\n        \"amount\": 5000,\n        \"purpose\": \"test\"\n    })\n    loan_id = response.json()[\"id\"]\n\n    # Step 3: Verify user shows loan in their profile\n    response = api_client.get(f\"/api/users/{user_id}\")\n    user = response.json()\n    assert loan_id in [loan[\"id\"] for loan in user[\"loans\"]]\n\n    # Step 4: Verify loan shows correct user\n    response = api_client.get(f\"/api/loans/{loan_id}\")\n    loan = response.json()\n    assert loan[\"user_id\"] == user_id\n    assert loan[\"user_email\"] == \"consistency@test.com\"\n\n    # Step 5: Update loan status\n    api_client.patch(f\"/api/loans/{loan_id}\", json={\"status\": \"approved\"})\n\n    # Step 6: Verify user's loan list reflects update\n    response = api_client.get(f\"/api/users/{user_id}/loans\")\n    loans = response.json()[\"loans\"]\n    loan_from_user = next(l for l in loans if l[\"id\"] == loan_id)\n    assert loan_from_user[\"status\"] == \"approved\"\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-error-recovery","title":"Testing Error Recovery","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#handle-failures-gracefully","title":"Handle Failures Gracefully","text":"<pre><code>@pytest.mark.e2e\nasync def test_loan_application_with_service_failure(page, api_client, mock_service):\n    \"\"\"Test user journey when dependent service fails.\"\"\"\n\n    # Step 1: Start loan application\n    page.goto(\"http://localhost:3000/loans/apply\")\n    page.fill(\"#loan-amount\", \"10000\")\n    page.click(\"#submit-application\")\n\n    # Step 2: Simulate credit check service failure\n    mock_service.simulate_failure(\"credit_check_service\")\n\n    # Step 3: Verify graceful error handling\n    page.wait_for_selector(\".error-message\")\n    error_text = page.locator(\".error-message\").text_content()\n    assert \"temporarily unavailable\" in error_text.lower()\n\n    # Step 4: Verify application saved with pending status\n    response = api_client.get(\"/api/loans?status=pending_retry\")\n    loans = response.json()[\"loans\"]\n    assert len(loans) &gt; 0\n\n    # Step 5: Restore service\n    mock_service.restore(\"credit_check_service\")\n\n    # Step 6: Trigger retry\n    page.click(\"#retry-button\")\n\n    # Step 7: Verify successful completion\n    page.wait_for_selector(\".success-message\")\n    assert \"processed successfully\" in page.locator(\".success-message\").text_content().lower()\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#testing-multi-user-scenarios","title":"Testing Multi-User Scenarios","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#concurrent-user-journeys","title":"Concurrent User Journeys","text":"<pre><code>@pytest.mark.e2e\nasync def test_multiple_users_concurrent_journeys():\n    \"\"\"Test multiple users performing actions concurrently.\"\"\"\n    import asyncio\n\n    async def user_journey(user_id: str, email: str):\n        \"\"\"Simulate one user's journey.\"\"\"\n        async with httpx.AsyncClient(base_url=\"http://localhost:8000\") as client:\n            # Register\n            response = await client.post(\"/api/users\", json={\n                \"email\": email,\n                \"name\": f\"User {user_id}\"\n            })\n            assert response.status_code == 201\n\n            # Apply for loan\n            user_data = response.json()\n            response = await client.post(\"/api/loans\", json={\n                \"user_id\": user_data[\"id\"],\n                \"amount\": 5000 + int(user_id) * 1000\n            })\n            assert response.status_code == 201\n\n            return response.json()\n\n    # Run 10 users concurrently\n    tasks = [\n        user_journey(str(i), f\"user{i}@test.com\")\n        for i in range(10)\n    ]\n    results = await asyncio.gather(*tasks)\n\n    # Verify all succeeded\n    assert len(results) == 10\n    assert all(r[\"status\"] == \"pending\" for r in results)\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#do-test-complete-workflows","title":"DO: Test Complete Workflows","text":"<pre><code># CORRECT: Test entire user journey\n@pytest.mark.e2e\ndef test_complete_purchase_journey(page):\n    \"\"\"Test full purchase from browsing to confirmation.\"\"\"\n    # Browse \u2192 Select \u2192 Add to cart \u2192 Checkout \u2192 Payment \u2192 Confirmation\n    page.goto(\"http://localhost:3000/products\")\n    page.click(\"#product-1\")\n    page.click(\"#add-to-cart\")\n    page.goto(\"http://localhost:3000/checkout\")\n    page.fill(\"#card-number\", \"4111111111111111\")\n    page.click(\"#complete-purchase\")\n    page.wait_for_selector(\".confirmation\")\n    assert \"Order confirmed\" in page.text_content(\".confirmation\")\n\n\n# INCORRECT: Test partial workflow\n@pytest.mark.e2e\ndef test_partial_journey(page):\n    \"\"\"WRONG: Only tests part of journey.\"\"\"\n    page.goto(\"http://localhost:3000/checkout\")\n    page.click(\"#complete-purchase\")\n    # Missing: product selection, cart, payment details\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#do-verify-data-consistency","title":"DO: Verify Data Consistency","text":"<pre><code># CORRECT: Check data across all touchpoints\n@pytest.mark.e2e\ndef test_order_data_consistency(page, api_client):\n    \"\"\"Verify order data consistent across UI, API, and database.\"\"\"\n    # Create order via UI\n    page.goto(\"http://localhost:3000/products\")\n    page.click(\"#buy-now\")\n    order_id = page.locator(\"#order-id\").text_content()\n\n    # Verify via API\n    response = api_client.get(f\"/api/orders/{order_id}\")\n    api_order = response.json()\n    assert api_order[\"status\"] == \"pending\"\n\n    # Verify in user's order history\n    page.goto(\"http://localhost:3000/orders\")\n    assert order_id in page.text_content(\"body\")\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#dont-test-implementation-details","title":"DON'T: Test Implementation Details","text":"<pre><code># INCORRECT: Testing internal implementation\n@pytest.mark.e2e\ndef test_internal_cache_behavior(api_client):\n    \"\"\"WRONG: Tests internal caching logic.\"\"\"\n    # E2E tests should focus on user outcomes, not cache hits\n\n\n# CORRECT: Test user-visible behavior\n@pytest.mark.e2e\ndef test_fast_page_load(page):\n    \"\"\"Test page loads quickly (user cares about speed, not cache).\"\"\"\n    start = time.time()\n    page.goto(\"http://localhost:3000/dashboard\")\n    load_time = time.time() - start\n    assert load_time &lt; 2.0  # User cares: page loads in &lt;2s\n</code></pre>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#checklist","title":"Checklist","text":"<ul> <li> Test complete user workflows end-to-end</li> <li> Verify multi-step journeys across services</li> <li> Test cross-service communication (API \u2192 Worker \u2192 Bot)</li> <li> Verify data consistency across all touchpoints</li> <li> Test error handling and recovery</li> <li> Test concurrent user scenarios</li> <li> Verify state persistence across steps</li> <li> Test notification delivery</li> <li> Verify authentication flows</li> <li> Test critical business transactions</li> <li> Use page objects for maintainability</li> <li> Mark tests with <code>@pytest.mark.e2e</code> and <code>@pytest.mark.slow</code></li> </ul>"},{"location":"atomic/testing/end-to-end-testing/user-journey-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/end-to-end-testing/e2e-test-setup.md</code> \u2014 E2E test infrastructure setup</li> <li><code>docs/atomic/testing/end-to-end-testing/performance-testing.md</code> \u2014 Performance and load testing</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 API service testing</li> <li><code>docs/atomic/testing/service-testing/aiogram-testing-patterns.md</code> \u2014 Bot testing patterns</li> </ul>"},{"location":"atomic/testing/integration-testing/database-testing/","title":"Database Integration Testing","text":"<p>Test database integration with real PostgreSQL and MongoDB containers to verify queries, transactions, constraints, and schema changes work correctly. Integration tests with real databases catch SQL errors, constraint violations, and transaction issues that mocks cannot detect.</p> <p>This document covers testing patterns for PostgreSQL (with SQLAlchemy) and MongoDB (with Motor), transaction management, migration testing, and parallel test execution with isolated databases. Database integration tests bridge the gap between unit tests and production behavior.</p> <p>Real database testing ensures your ORM queries translate correctly to SQL, constraints enforce data integrity, and transactions maintain consistency under concurrent access. These tests are slower than unit tests but provide confidence in data layer correctness.</p>"},{"location":"atomic/testing/integration-testing/database-testing/#postgresql-testing-with-sqlalchemy","title":"PostgreSQL Testing with SQLAlchemy","text":""},{"location":"atomic/testing/integration-testing/database-testing/#repository-testing","title":"Repository Testing","text":"<pre><code># tests/integration/test_user_repository.py\nimport pytest\nfrom finance_lending_api.infrastructure.repositories import UserRepository\nfrom finance_lending_api.domain.models import User\nfrom sqlalchemy import select\n\n\n@pytest.mark.integration\nasync def test_user_repository_create(db_session):\n    \"\"\"Test creating user in PostgreSQL.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    user = await repo.create(\n        email=\"test@example.com\",\n        name=\"Test User\",\n        credit_score=750\n    )\n\n    assert user.id is not None\n    assert user.email == \"test@example.com\"\n    assert user.created_at is not None\n\n\n@pytest.mark.integration\nasync def test_user_repository_find_by_email(db_session):\n    \"\"\"Test finding user by email.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    # Create user\n    created_user = await repo.create(email=\"find@example.com\", name=\"Find Me\")\n\n    # Find by email\n    found_user = await repo.find_by_email(\"find@example.com\")\n\n    assert found_user is not None\n    assert found_user.id == created_user.id\n    assert found_user.email == \"find@example.com\"\n\n\n@pytest.mark.integration\nasync def test_user_repository_update(db_session):\n    \"\"\"Test updating user fields.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    user = await repo.create(email=\"update@example.com\", name=\"Original Name\")\n    original_id = user.id\n\n    # Update\n    user.name = \"Updated Name\"\n    user.credit_score = 800\n    await db_session.commit()\n\n    # Verify\n    updated_user = await repo.get_by_id(original_id)\n    assert updated_user.name == \"Updated Name\"\n    assert updated_user.credit_score == 800\n\n\n@pytest.mark.integration\nasync def test_user_repository_delete(db_session):\n    \"\"\"Test deleting user.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    user = await repo.create(email=\"delete@example.com\", name=\"Delete Me\")\n    user_id = user.id\n\n    # Delete\n    await repo.delete(user_id)\n    await db_session.commit()\n\n    # Verify deleted\n    deleted_user = await repo.get_by_id(user_id)\n    assert deleted_user is None\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#constraint-testing","title":"Constraint Testing","text":"<pre><code># CORRECT: Test unique constraints\n@pytest.mark.integration\nasync def test_unique_email_constraint(db_session):\n    \"\"\"Test database enforces unique email constraint.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    # First user succeeds\n    user1 = await repo.create(email=\"unique@example.com\", name=\"User 1\")\n    await db_session.commit()\n    assert user1.id is not None\n\n    # Duplicate email fails\n    from sqlalchemy.exc import IntegrityError\n    with pytest.raises(IntegrityError, match=\"unique\"):\n        user2 = await repo.create(email=\"unique@example.com\", name=\"User 2\")\n        await db_session.commit()\n\n\n# CORRECT: Test foreign key constraints\n@pytest.mark.integration\nasync def test_foreign_key_constraint(db_session):\n    \"\"\"Test foreign key integrity.\"\"\"\n    from finance_lending_api.infrastructure.repositories import LoanRepository\n\n    user_repo = UserRepository(session=db_session)\n    loan_repo = LoanRepository(session=db_session)\n\n    # Create user\n    user = await user_repo.create(email=\"borrower@example.com\", name=\"Borrower\")\n    await db_session.commit()\n\n    # Create loan with valid user_id\n    loan = await loan_repo.create(user_id=user.id, amount=10000)\n    await db_session.commit()\n    assert loan.id is not None\n\n    # Creating loan with non-existent user_id fails\n    from sqlalchemy.exc import IntegrityError\n    with pytest.raises(IntegrityError, match=\"foreign key\"):\n        invalid_loan = await loan_repo.create(user_id=99999, amount=5000)\n        await db_session.commit()\n\n\n# CORRECT: Test check constraints\n@pytest.mark.integration\nasync def test_check_constraint_positive_amount(db_session):\n    \"\"\"Test check constraint for positive loan amount.\"\"\"\n    from finance_lending_api.infrastructure.repositories import LoanRepository\n\n    loan_repo = LoanRepository(session=db_session)\n\n    # Negative amount violates check constraint\n    from sqlalchemy.exc import IntegrityError\n    with pytest.raises(IntegrityError, match=\"check constraint\"):\n        loan = await loan_repo.create(user_id=1, amount=-1000)\n        await db_session.commit()\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#transaction-testing","title":"Transaction Testing","text":"<pre><code># CORRECT: Test transaction rollback on error\n@pytest.mark.integration\nasync def test_transaction_rollback_on_error(db_session):\n    \"\"\"Test that errors rollback entire transaction.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    try:\n        # Create first user\n        user1 = await repo.create(email=\"user1@example.com\", name=\"User 1\")\n\n        # Create second user with duplicate email (will fail)\n        user2 = await repo.create(email=\"user1@example.com\", name=\"User 2\")\n\n        await db_session.commit()\n    except Exception:\n        await db_session.rollback()\n\n    # Verify neither user was committed\n    found_user = await repo.find_by_email(\"user1@example.com\")\n    assert found_user is None  # Rolled back\n\n\n# CORRECT: Test concurrent transactions\n@pytest.mark.integration\nasync def test_concurrent_transactions(db_engine):\n    \"\"\"Test isolation between concurrent transactions.\"\"\"\n    import asyncio\n    from sqlalchemy.ext.asyncio import AsyncSession\n    from sqlalchemy.orm import sessionmaker\n\n    async_session = sessionmaker(\n        db_engine,\n        class_=AsyncSession,\n        expire_on_commit=False\n    )\n\n    user_email = \"concurrent@example.com\"\n\n    async def create_user_transaction():\n        async with async_session() as session:\n            repo = UserRepository(session=session)\n            user = await repo.create(email=user_email, name=\"Concurrent User\")\n            await asyncio.sleep(0.1)  # Simulate processing\n            await session.commit()\n            return user\n\n    # Run two concurrent transactions\n    results = await asyncio.gather(\n        create_user_transaction(),\n        create_user_transaction(),\n        return_exceptions=True\n    )\n\n    # One should succeed, one should fail with unique constraint\n    successful = [r for r in results if not isinstance(r, Exception)]\n    failed = [r for r in results if isinstance(r, Exception)]\n\n    assert len(successful) == 1\n    assert len(failed) == 1\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#query-performance-testing","title":"Query Performance Testing","text":"<pre><code># CORRECT: Test N+1 query problem\n@pytest.mark.integration\nasync def test_eager_loading_prevents_n_plus_1(db_session):\n    \"\"\"Test that eager loading prevents N+1 queries.\"\"\"\n    from sqlalchemy import select\n    from sqlalchemy.orm import selectinload\n\n    user_repo = UserRepository(session=db_session)\n    loan_repo = LoanRepository(session=db_session)\n\n    # Create user with 10 loans\n    user = await user_repo.create(email=\"borrower@example.com\", name=\"Borrower\")\n    await db_session.commit()\n\n    for i in range(10):\n        await loan_repo.create(user_id=user.id, amount=1000 * i)\n    await db_session.commit()\n\n    # Query with eager loading\n    stmt = (\n        select(User)\n        .where(User.email == \"borrower@example.com\")\n        .options(selectinload(User.loans))\n    )\n    result = await db_session.execute(stmt)\n    user_with_loans = result.scalar_one()\n\n    # Accessing loans doesn't trigger additional queries\n    assert len(user_with_loans.loans) == 10\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#mongodb-testing-with-motor","title":"MongoDB Testing with Motor","text":""},{"location":"atomic/testing/integration-testing/database-testing/#document-repository-testing","title":"Document Repository Testing","text":"<pre><code># tests/integration/test_mongo_repository.py\nimport pytest\nfrom finance_lending_api.infrastructure.mongo_repositories import DocumentRepository\n\n\n@pytest.mark.integration\nasync def test_document_insert(mongo_db):\n    \"\"\"Test inserting document into MongoDB.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    doc_id = await repo.insert({\n        \"user_id\": \"user-123\",\n        \"type\": \"profile\",\n        \"data\": {\n            \"bio\": \"Test bio\",\n            \"interests\": [\"coding\", \"testing\"]\n        }\n    })\n\n    assert doc_id is not None\n\n    # Verify inserted\n    doc = await repo.find_by_id(doc_id)\n    assert doc[\"user_id\"] == \"user-123\"\n    assert doc[\"data\"][\"bio\"] == \"Test bio\"\n\n\n@pytest.mark.integration\nasync def test_document_find_with_filter(mongo_db):\n    \"\"\"Test querying documents with filters.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    # Insert test documents\n    await repo.insert({\"user_id\": \"user-1\", \"status\": \"active\", \"score\": 90})\n    await repo.insert({\"user_id\": \"user-2\", \"status\": \"inactive\", \"score\": 75})\n    await repo.insert({\"user_id\": \"user-3\", \"status\": \"active\", \"score\": 85})\n\n    # Query active users with score &gt;= 85\n    results = await repo.find_many({\n        \"status\": \"active\",\n        \"score\": {\"$gte\": 85}\n    })\n\n    assert len(results) == 2\n    user_ids = [doc[\"user_id\"] for doc in results]\n    assert \"user-1\" in user_ids\n    assert \"user-3\" in user_ids\n\n\n@pytest.mark.integration\nasync def test_document_update(mongo_db):\n    \"\"\"Test updating document fields.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    # Insert\n    doc_id = await repo.insert({\"name\": \"Original\", \"count\": 10})\n\n    # Update\n    result = await repo.update_one(\n        {\"_id\": doc_id},\n        {\"$set\": {\"name\": \"Updated\"}, \"$inc\": {\"count\": 5}}\n    )\n\n    assert result.modified_count == 1\n\n    # Verify\n    updated = await repo.find_by_id(doc_id)\n    assert updated[\"name\"] == \"Updated\"\n    assert updated[\"count\"] == 15\n\n\n@pytest.mark.integration\nasync def test_document_aggregation(mongo_db):\n    \"\"\"Test MongoDB aggregation pipeline.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    # Insert sample data\n    await repo.insert_many([\n        {\"category\": \"electronics\", \"price\": 1000},\n        {\"category\": \"electronics\", \"price\": 1500},\n        {\"category\": \"books\", \"price\": 50},\n        {\"category\": \"books\", \"price\": 30},\n    ])\n\n    # Aggregate: average price by category\n    pipeline = [\n        {\"$group\": {\n            \"_id\": \"$category\",\n            \"avg_price\": {\"$avg\": \"$price\"},\n            \"count\": {\"$sum\": 1}\n        }},\n        {\"$sort\": {\"avg_price\": -1}}\n    ]\n\n    results = await repo.aggregate(pipeline)\n\n    assert len(results) == 2\n    electronics = next(r for r in results if r[\"_id\"] == \"electronics\")\n    assert electronics[\"avg_price\"] == 1250\n    assert electronics[\"count\"] == 2\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#index-testing","title":"Index Testing","text":"<pre><code># CORRECT: Test query performance with indexes\n@pytest.mark.integration\nasync def test_index_improves_query_performance(mongo_db):\n    \"\"\"Test that indexes improve query performance.\"\"\"\n    collection = mongo_db[\"users\"]\n\n    # Insert 1000 documents\n    docs = [{\"email\": f\"user{i}@example.com\", \"age\": i % 100} for i in range(1000)]\n    await collection.insert_many(docs)\n\n    # Query without index (slow for large datasets)\n    import time\n    start = time.time()\n    result = await collection.find_one({\"email\": \"user999@example.com\"})\n    no_index_time = time.time() - start\n\n    # Create index\n    await collection.create_index(\"email\")\n\n    # Query with index (faster)\n    start = time.time()\n    result = await collection.find_one({\"email\": \"user999@example.com\"})\n    with_index_time = time.time() - start\n\n    assert result is not None\n    # Index should make query faster (though difference may be small for 1000 docs)\n    # In production with millions of docs, difference is dramatic\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#migration-testing","title":"Migration Testing","text":""},{"location":"atomic/testing/integration-testing/database-testing/#testing-alembic-migrations","title":"Testing Alembic Migrations","text":"<pre><code># tests/integration/test_migrations.py\nimport pytest\nfrom alembic import command\nfrom alembic.config import Config\n\n\n@pytest.mark.integration\ndef test_migrations_run_successfully(postgres_container):\n    \"\"\"Test that all migrations can be applied.\"\"\"\n    db_url = postgres_container.get_connection_url()\n\n    # Configure Alembic\n    alembic_cfg = Config(\"alembic.ini\")\n    alembic_cfg.set_main_option(\"sqlalchemy.url\", db_url)\n\n    # Run migrations\n    command.upgrade(alembic_cfg, \"head\")\n\n    # Verify migrations applied\n    from sqlalchemy import create_engine, inspect\n    engine = create_engine(db_url)\n    inspector = inspect(engine)\n\n    tables = inspector.get_table_names()\n    assert \"users\" in tables\n    assert \"loans\" in tables\n    assert \"alembic_version\" in tables\n\n\n@pytest.mark.integration\ndef test_migration_downgrade_and_upgrade(postgres_container):\n    \"\"\"Test migrations can be downgraded and re-applied.\"\"\"\n    db_url = postgres_container.get_connection_url()\n    alembic_cfg = Config(\"alembic.ini\")\n    alembic_cfg.set_main_option(\"sqlalchemy.url\", db_url)\n\n    # Upgrade to head\n    command.upgrade(alembic_cfg, \"head\")\n\n    # Downgrade one revision\n    command.downgrade(alembic_cfg, \"-1\")\n\n    # Upgrade back to head\n    command.upgrade(alembic_cfg, \"head\")\n\n    # Verify schema is correct\n    from sqlalchemy import create_engine, inspect\n    engine = create_engine(db_url)\n    inspector = inspect(engine)\n\n    assert len(inspector.get_table_names()) &gt; 0\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/integration-testing/database-testing/#do-use-transaction-rollback-for-isolation","title":"DO: Use Transaction Rollback for Isolation","text":"<pre><code># CORRECT: Rollback transactions to keep database clean\n@pytest.fixture\nasync def db_session(db_engine):\n    \"\"\"Provide session with automatic rollback.\"\"\"\n    async with db_engine.connect() as connection:\n        async with connection.begin() as transaction:\n            async_session = sessionmaker(\n                bind=connection,\n                class_=AsyncSession,\n                expire_on_commit=False\n            )\n\n            async with async_session() as session:\n                yield session\n                await transaction.rollback()  # Rollback after test\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#do-test-edge-cases","title":"DO: Test Edge Cases","text":"<pre><code># CORRECT: Test pagination edge cases\n@pytest.mark.integration\nasync def test_pagination_last_page(db_session):\n    \"\"\"Test pagination on last page with fewer items.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    # Create 15 users\n    for i in range(15):\n        await repo.create(email=f\"user{i}@example.com\", name=f\"User {i}\")\n    await db_session.commit()\n\n    # Get page 2 (10 items per page, only 5 remaining)\n    page2 = await repo.get_paginated(page=2, per_page=10)\n\n    assert len(page2.items) == 5\n    assert page2.total == 15\n    assert page2.page == 2\n    assert page2.pages == 2\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#dont-share-state-between-tests","title":"DON'T: Share State Between Tests","text":"<pre><code># INCORRECT: Tests depend on each other\n@pytest.mark.integration\nasync def test_create_user_with_id_1(db_session):\n    \"\"\"WRONG: Assumes empty database.\"\"\"\n    user = await create_user(id=1)\n    assert user.id == 1  # Fails if user ID=1 already exists\n\n\n# CORRECT: Each test is self-contained\n@pytest.mark.integration\nasync def test_create_and_find_user(db_session):\n    \"\"\"Test is self-contained.\"\"\"\n    # Create user in this test\n    created = await repo.create(email=\"test@example.com\", name=\"Test\")\n\n    # Find user by ID from this test\n    found = await repo.get_by_id(created.id)\n    assert found.email == \"test@example.com\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/database-testing/#checklist","title":"Checklist","text":"<ul> <li> Use testcontainers for real PostgreSQL/MongoDB instances</li> <li> Test constraints (unique, foreign key, check)</li> <li> Test transactions (commit, rollback, isolation)</li> <li> Test complex queries and joins</li> <li> Test pagination, sorting, filtering</li> <li> Test migrations can be applied and reverted</li> <li> Use transaction rollback to isolate tests</li> <li> Tests are independent and self-contained</li> <li> Test both success and error scenarios</li> <li> Test query performance with indexes</li> <li> Mark integration tests with <code>@pytest.mark.integration</code></li> <li> Clean up test data after each test</li> </ul>"},{"location":"atomic/testing/integration-testing/database-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Setting up Docker containers for tests</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Pytest fixtures for database sessions</li> <li><code>docs/atomic/databases/postgresql/basic-setup.md</code> \u2014 PostgreSQL configuration</li> <li><code>docs/atomic/infrastructure/databases/postgres-docker.md</code> \u2014 PostgreSQL Docker setup</li> <li><code>docs/atomic/infrastructure/databases/migrations.md</code> \u2014 Database migrations with Alembic</li> </ul>"},{"location":"atomic/testing/integration-testing/http-integration-testing/","title":"HTTP Integration Testing","text":"<p>Test HTTP client integration with real service endpoints to verify request/response handling, error recovery, retries, and timeouts. Integration tests catch serialization errors, network failures, and protocol issues that mocks cannot detect.</p> <p>This document covers testing patterns for httpx async client, testing HTTP calls to data services and external APIs, retry logic verification, and timeout handling. HTTP integration tests ensure services communicate correctly over the network.</p> <p>Real HTTP testing validates that requests serialize correctly, responses deserialize properly, and error handling gracefully recovers from network failures. These tests catch real-world integration issues between services.</p>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#basic-http-testing","title":"Basic HTTP Testing","text":"<pre><code># tests/integration/test_http_client.py\nimport pytest\nimport httpx\nfrom finance_lending_api.integrations.data_service_client import DataServiceClient\n\n\n@pytest.mark.integration\nasync def test_get_request(httpx_mock):\n    \"\"\"Test GET request to data service.\"\"\"\n    # Mock external service\n    httpx_mock.add_response(\n        method=\"GET\",\n        url=\"http://localhost:8001/api/users/123\",\n        json={\"id\": \"123\", \"name\": \"John\", \"email\": \"john@example.com\"},\n        status_code=200\n    )\n\n    client = DataServiceClient(base_url=\"http://localhost:8001\")\n    user = await client.get_user(\"123\")\n\n    assert user[\"id\"] == \"123\"\n    assert user[\"name\"] == \"John\"\n\n\n@pytest.mark.integration\nasync def test_post_request(httpx_mock):\n    \"\"\"Test POST request creates resource.\"\"\"\n    httpx_mock.add_response(\n        method=\"POST\",\n        url=\"http://localhost:8001/api/users\",\n        json={\"id\": \"new-123\", \"name\": \"Jane\", \"email\": \"jane@example.com\"},\n        status_code=201\n    )\n\n    client = DataServiceClient(base_url=\"http://localhost:8001\")\n    user = await client.create_user({\"name\": \"Jane\", \"email\": \"jane@example.com\"})\n\n    assert user[\"id\"] == \"new-123\"\n    assert user[\"name\"] == \"Jane\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#error-handling","title":"Error Handling","text":"<pre><code>@pytest.mark.integration\nasync def test_404_not_found():\n    \"\"\"Test 404 error handling.\"\"\"\n    client = DataServiceClient(base_url=\"http://localhost:8001\")\n\n    with pytest.raises(httpx.HTTPStatusError) as exc_info:\n        await client.get_user(\"nonexistent\")\n\n    assert exc_info.value.response.status_code == 404\n\n\n@pytest.mark.integration\nasync def test_500_internal_error():\n    \"\"\"Test 500 error handling.\"\"\"\n    client = DataServiceClient(base_url=\"http://localhost:8001\")\n\n    with pytest.raises(httpx.HTTPStatusError) as exc_info:\n        await client.create_user({\"invalid\": \"data\"})\n\n    assert exc_info.value.response.status_code == 500\n\n\n@pytest.mark.integration\nasync def test_network_timeout():\n    \"\"\"Test request timeout handling.\"\"\"\n    client = DataServiceClient(base_url=\"http://localhost:8001\", timeout=1)\n\n    with pytest.raises(httpx.TimeoutException):\n        await client.get_user(\"slow-endpoint\")\n</code></pre>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#retry-logic","title":"Retry Logic","text":"<pre><code>@pytest.mark.integration\nasync def test_retry_on_transient_failure(httpx_mock):\n    \"\"\"Test retry mechanism on transient failures.\"\"\"\n    # First two requests fail, third succeeds\n    httpx_mock.add_response(status_code=503)  # Service unavailable\n    httpx_mock.add_response(status_code=503)\n    httpx_mock.add_response(\n        json={\"id\": \"123\", \"name\": \"John\"},\n        status_code=200\n    )\n\n    client = DataServiceClient(base_url=\"http://localhost:8001\", max_retries=3)\n    user = await client.get_user(\"123\")\n\n    assert user[\"id\"] == \"123\"\n    assert httpx_mock.get_requests().__len__() == 3\n\n\n@pytest.mark.integration\nasync def test_no_retry_on_client_error(httpx_mock):\n    \"\"\"Test no retry on 4xx client errors.\"\"\"\n    httpx_mock.add_response(status_code=400)  # Bad request\n\n    client = DataServiceClient(base_url=\"http://localhost:8001\", max_retries=3)\n\n    with pytest.raises(httpx.HTTPStatusError):\n        await client.create_user({\"invalid\": \"data\"})\n\n    # Only one request made (no retries for 4xx)\n    assert httpx_mock.get_requests().__len__() == 1\n</code></pre>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#request-headers-and-authentication","title":"Request Headers and Authentication","text":"<pre><code>@pytest.mark.integration\nasync def test_authentication_header(httpx_mock):\n    \"\"\"Test authentication header is included.\"\"\"\n    httpx_mock.add_response(json={\"status\": \"ok\"})\n\n    client = DataServiceClient(\n        base_url=\"http://localhost:8001\",\n        auth_token=\"secret-token\"\n    )\n    await client.get_user(\"123\")\n\n    request = httpx_mock.get_request()\n    assert request.headers[\"Authorization\"] == \"Bearer secret-token\"\n\n\n@pytest.mark.integration\nasync def test_request_id_propagation(httpx_mock):\n    \"\"\"Test request ID is propagated.\"\"\"\n    httpx_mock.add_response(json={\"status\": \"ok\"})\n\n    client = DataServiceClient(base_url=\"http://localhost:8001\")\n    await client.get_user(\"123\", request_id=\"req-abc-123\")\n\n    request = httpx_mock.get_request()\n    assert request.headers[\"X-Request-ID\"] == \"req-abc-123\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#checklist","title":"Checklist","text":"<ul> <li> Test GET, POST, PUT, DELETE requests</li> <li> Test error handling (4xx, 5xx)</li> <li> Test timeout handling</li> <li> Test retry logic on transient failures</li> <li> Test authentication headers</li> <li> Test request/response serialization</li> <li> Use pytest-httpx or respx for mocking</li> <li> Mark integration tests with <code>@pytest.mark.integration</code></li> </ul>"},{"location":"atomic/testing/integration-testing/http-integration-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/integrations/http-communication/http-client-patterns.md</code> \u2014 HTTP client implementation</li> <li><code>docs/atomic/integrations/http-communication/retry-strategies.md</code> \u2014 Retry logic patterns</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking HTTP clients in unit tests</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 Testing FastAPI endpoints</li> </ul>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/","title":"RabbitMQ Integration Testing","text":"<p>Test RabbitMQ message publishing, consumption, routing, and acknowledgment with real RabbitMQ containers to verify message delivery, queue behavior, and exchange routing logic. Integration tests catch serialization errors, routing misconfigurations, and acknowledgment issues that mocks cannot detect.</p> <p>This document covers testing patterns for aio-pika async client, message publishing/consuming, exchange and queue declarations, routing patterns, and error handling. RabbitMQ integration tests ensure events are routed correctly and consumed reliably.</p> <p>Real RabbitMQ testing validates that messages serialize correctly, exchanges route to proper queues, and consumers process messages without loss. These tests catch protocol-specific issues and confirm resilience under failure scenarios.</p>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#publishing-and-consuming","title":"Publishing and Consuming","text":"<pre><code># tests/integration/test_rabbitmq.py\nimport pytest\nimport json\nimport aio_pika\nfrom finance_lending_api.events.publisher import EventPublisher\n\n\n@pytest.mark.integration\nasync def test_publish_and_consume_message(rabbitmq_channel):\n    \"\"\"Test basic message publishing and consumption.\"\"\"\n    # Declare queue\n    queue = await rabbitmq_channel.declare_queue(\"test.events\", auto_delete=True)\n\n    # Publish message\n    publisher = EventPublisher(rabbitmq_channel)\n    await publisher.publish_user_created(user_id=\"user-123\", email=\"test@example.com\")\n\n    # Consume message\n    message = await queue.get(timeout=5)\n    assert message is not None\n\n    event_data = json.loads(message.body.decode())\n    assert event_data[\"user_id\"] == \"user-123\"\n    assert event_data[\"email\"] == \"test@example.com\"\n\n    await message.ack()\n\n\n@pytest.mark.integration\nasync def test_message_acknowledgment(rabbitmq_channel):\n    \"\"\"Test that unacknowledged messages are redelivered.\"\"\"\n    queue = await rabbitmq_channel.declare_queue(\"ack.test\", auto_delete=True)\n\n    # Publish message\n    await rabbitmq_channel.default_exchange.publish(\n        aio_pika.Message(body=b\"test message\"),\n        routing_key=\"ack.test\"\n    )\n\n    # Consume but don't acknowledge\n    message1 = await queue.get(timeout=1)\n    assert message1 is not None\n    # Don't call message1.ack()\n\n    # Close channel (simulates consumer crash)\n    await rabbitmq_channel.close()\n\n    # Reconnect\n    from tests.conftest import rabbitmq_connection\n    new_channel = await rabbitmq_connection.channel()\n    new_queue = await new_channel.get_queue(\"ack.test\")\n\n    # Message redelivered\n    message2 = await new_queue.get(timeout=1)\n    assert message2 is not None\n    assert message2.body == b\"test message\"\n    assert message2.redelivered is True\n\n    await message2.ack()\n</code></pre>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#exchange-and-routing","title":"Exchange and Routing","text":"<pre><code>@pytest.mark.integration\nasync def test_topic_exchange_routing(rabbitmq_channel):\n    \"\"\"Test topic-based message routing.\"\"\"\n    # Declare topic exchange\n    exchange = await rabbitmq_channel.declare_exchange(\n        \"events\",\n        type=aio_pika.ExchangeType.TOPIC,\n        auto_delete=True\n    )\n\n    # Bind queues with routing patterns\n    user_queue = await rabbitmq_channel.declare_queue(\"user.events\", auto_delete=True)\n    await user_queue.bind(exchange, routing_key=\"user.*\")\n\n    loan_queue = await rabbitmq_channel.declare_queue(\"loan.events\", auto_delete=True)\n    await loan_queue.bind(exchange, routing_key=\"loan.*\")\n\n    # Publish user event\n    await exchange.publish(\n        aio_pika.Message(body=b'{\"event\": \"user_created\"}'),\n        routing_key=\"user.created\"\n    )\n\n    # User queue receives it\n    user_message = await user_queue.get(timeout=1)\n    assert user_message is not None\n    await user_message.ack()\n\n    # Loan queue is empty\n    with pytest.raises(aio_pika.exceptions.QueueEmpty):\n        await loan_queue.get(timeout=0.1, fail=True)\n\n\n@pytest.mark.integration\nasync def test_fanout_exchange_broadcasts(rabbitmq_channel):\n    \"\"\"Test fanout exchange broadcasts to all queues.\"\"\"\n    # Declare fanout exchange\n    exchange = await rabbitmq_channel.declare_exchange(\n        \"broadcast\",\n        type=aio_pika.ExchangeType.FANOUT,\n        auto_delete=True\n    )\n\n    # Bind multiple queues\n    queue1 = await rabbitmq_channel.declare_queue(\"listener1\", auto_delete=True)\n    await queue1.bind(exchange)\n\n    queue2 = await rabbitmq_channel.declare_queue(\"listener2\", auto_delete=True)\n    await queue2.bind(exchange)\n\n    # Publish message\n    await exchange.publish(\n        aio_pika.Message(body=b\"broadcast message\"),\n        routing_key=\"\"  # Ignored by fanout\n    )\n\n    # Both queues receive message\n    msg1 = await queue1.get(timeout=1)\n    msg2 = await queue2.get(timeout=1)\n\n    assert msg1.body == b\"broadcast message\"\n    assert msg2.body == b\"broadcast message\"\n\n    await msg1.ack()\n    await msg2.ack()\n</code></pre>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#dead-letter-exchange","title":"Dead Letter Exchange","text":"<pre><code>@pytest.mark.integration\nasync def test_dead_letter_queue(rabbitmq_channel):\n    \"\"\"Test that rejected messages go to dead letter exchange.\"\"\"\n    # Declare dead letter exchange\n    dlx = await rabbitmq_channel.declare_exchange(\n        \"dead_letters\",\n        type=aio_pika.ExchangeType.DIRECT,\n        auto_delete=True\n    )\n\n    dlq = await rabbitmq_channel.declare_queue(\"dead_letter_queue\", auto_delete=True)\n    await dlq.bind(dlx, routing_key=\"failed\")\n\n    # Declare main queue with DLX\n    main_queue = await rabbitmq_channel.declare_queue(\n        \"main_queue\",\n        auto_delete=True,\n        arguments={\n            \"x-dead-letter-exchange\": \"dead_letters\",\n            \"x-dead-letter-routing-key\": \"failed\"\n        }\n    )\n\n    # Publish message\n    await rabbitmq_channel.default_exchange.publish(\n        aio_pika.Message(body=b\"will be rejected\"),\n        routing_key=\"main_queue\"\n    )\n\n    # Consume and reject\n    message = await main_queue.get(timeout=1)\n    await message.reject(requeue=False)  # Send to DLX\n\n    # Message appears in dead letter queue\n    dl_message = await dlq.get(timeout=1)\n    assert dl_message.body == b\"will be rejected\"\n    await dl_message.ack()\n</code></pre>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#consumer-testing","title":"Consumer Testing","text":"<pre><code>@pytest.mark.integration\nasync def test_consumer_processes_messages(rabbitmq_channel):\n    \"\"\"Test consumer processes messages correctly.\"\"\"\n    from finance_lending_api.events.consumer import UserEventConsumer\n\n    queue = await rabbitmq_channel.declare_queue(\"user.events\", auto_delete=True)\n    consumer = UserEventConsumer(rabbitmq_channel)\n\n    processed = []\n\n    async def on_message(message: aio_pika.IncomingMessage):\n        async with message.process():\n            event = json.loads(message.body.decode())\n            processed.append(event)\n\n    await queue.consume(on_message)\n\n    # Publish test event\n    await rabbitmq_channel.default_exchange.publish(\n        aio_pika.Message(body=json.dumps({\"user_id\": \"123\"}).encode()),\n        routing_key=\"user.events\"\n    )\n\n    # Wait for processing\n    import asyncio\n    await asyncio.sleep(0.5)\n\n    assert len(processed) == 1\n    assert processed[0][\"user_id\"] == \"123\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#checklist","title":"Checklist","text":"<ul> <li> Test publishing and consuming messages</li> <li> Test message acknowledgment and redelivery</li> <li> Test exchange routing (direct, topic, fanout)</li> <li> Test dead letter exchanges</li> <li> Test queue bindings and routing keys</li> <li> Test consumer error handling</li> <li> Use testcontainers for real RabbitMQ</li> <li> Clean up queues and exchanges after tests</li> <li> Mark integration tests with <code>@pytest.mark.integration</code></li> </ul>"},{"location":"atomic/testing/integration-testing/rabbitmq-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Docker containers for tests</li> <li><code>docs/atomic/integrations/rabbitmq/message-publishing.md</code> \u2014 RabbitMQ publishing patterns</li> <li><code>docs/atomic/integrations/rabbitmq/message-consumption.md</code> \u2014 Consumer implementation</li> <li><code>docs/atomic/integrations/rabbitmq/exchange-patterns.md</code> \u2014 Exchange types and routing</li> </ul>"},{"location":"atomic/testing/integration-testing/redis-testing/","title":"Redis Integration Testing","text":"<p>Test Redis caching, idempotency keys, distributed locks, and pub/sub messaging with real Redis containers to verify cache behavior, TTL expiration, and concurrent access patterns. Integration tests catch timing issues, serialization errors, and race conditions that mocks cannot detect.</p> <p>This document covers caching patterns, idempotency enforcement, distributed locking, TTL verification, and pub/sub testing with testcontainers-python. Redis integration tests ensure cache invalidation works correctly and concurrent operations maintain data consistency.</p> <p>Redis testing validates that cache keys expire correctly, idempotency prevents duplicate operations, and distributed locks coordinate access across multiple processes. These tests run against real Redis to catch protocol-specific issues.</p>"},{"location":"atomic/testing/integration-testing/redis-testing/#cache-testing","title":"Cache Testing","text":""},{"location":"atomic/testing/integration-testing/redis-testing/#basic-cache-operations","title":"Basic Cache Operations","text":"<pre><code># tests/integration/test_redis_cache.py\nimport pytest\nfrom finance_lending_api.services.cache import CacheService\n\n\n@pytest.mark.integration\nasync def test_cache_set_and_get(redis_client):\n    \"\"\"Test setting and retrieving cached values.\"\"\"\n    cache = CacheService(redis_client)\n\n    # Set value\n    await cache.set(\"user:123\", {\"id\": \"123\", \"name\": \"John\"}, ttl=60)\n\n    # Get value\n    result = await cache.get(\"user:123\")\n\n    assert result is not None\n    assert result[\"id\"] == \"123\"\n    assert result[\"name\"] == \"John\"\n\n\n@pytest.mark.integration\nasync def test_cache_miss_returns_none(redis_client):\n    \"\"\"Test that cache miss returns None.\"\"\"\n    cache = CacheService(redis_client)\n\n    result = await cache.get(\"nonexistent:key\")\n    assert result is None\n\n\n@pytest.mark.integration\nasync def test_cache_delete(redis_client):\n    \"\"\"Test deleting cached value.\"\"\"\n    cache = CacheService(redis_client)\n\n    # Set value\n    await cache.set(\"temp:key\", \"value\")\n\n    # Verify exists\n    assert await cache.get(\"temp:key\") == \"value\"\n\n    # Delete\n    await cache.delete(\"temp:key\")\n\n    # Verify deleted\n    assert await cache.get(\"temp:key\") is None\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#ttl-and-expiration","title":"TTL and Expiration","text":"<pre><code># CORRECT: Test cache expiration\n@pytest.mark.integration\nasync def test_cache_expiration(redis_client):\n    \"\"\"Test that cached values expire after TTL.\"\"\"\n    cache = CacheService(redis_client)\n\n    # Set with 1 second TTL\n    await cache.set(\"expire:key\", \"value\", ttl=1)\n\n    # Value exists immediately\n    assert await cache.get(\"expire:key\") == \"value\"\n\n    # Wait for expiration\n    import asyncio\n    await asyncio.sleep(1.5)\n\n    # Value expired\n    assert await cache.get(\"expire:key\") is None\n\n\n# CORRECT: Test TTL extension\n@pytest.mark.integration\nasync def test_extend_ttl(redis_client):\n    \"\"\"Test extending TTL of cached value.\"\"\"\n    # Set with 2 second TTL\n    await redis_client.setex(\"extend:key\", 2, \"value\")\n\n    # Wait 1 second\n    import asyncio\n    await asyncio.sleep(1)\n\n    # Extend TTL by another 2 seconds\n    await redis_client.expire(\"extend:key\", 2)\n\n    # Wait 1.5 more seconds (would have expired without extension)\n    await asyncio.sleep(1.5)\n\n    # Value still exists\n    result = await redis_client.get(\"extend:key\")\n    assert result == \"value\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#cache-invalidation-patterns","title":"Cache Invalidation Patterns","text":"<pre><code># CORRECT: Test cache invalidation on update\n@pytest.mark.integration\nasync def test_cache_invalidation_on_user_update(redis_client, db_session):\n    \"\"\"Test that cache is invalidated when user is updated.\"\"\"\n    from finance_lending_api.services.user_service import UserService\n\n    service = UserService(db_session=db_session, cache=redis_client)\n\n    # Create user (cached)\n    user = await service.create_user(email=\"test@example.com\", name=\"John\")\n    user_id = user.id\n\n    # Cache populated\n    cached = await redis_client.get(f\"user:{user_id}\")\n    assert cached is not None\n\n    # Update user (should invalidate cache)\n    await service.update_user(user_id, name=\"Jane\")\n\n    # Cache invalidated\n    cached_after = await redis_client.get(f\"user:{user_id}\")\n    assert cached_after is None\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#idempotency-key-testing","title":"Idempotency Key Testing","text":""},{"location":"atomic/testing/integration-testing/redis-testing/#request-deduplication","title":"Request Deduplication","text":"<pre><code># CORRECT: Test idempotency key prevents duplicate requests\n@pytest.mark.integration\nasync def test_idempotency_key_prevents_duplicates(redis_client):\n    \"\"\"Test that idempotency keys prevent duplicate operations.\"\"\"\n    from finance_lending_api.middleware.idempotency import IdempotencyService\n\n    service = IdempotencyService(redis_client)\n    request_id = \"req-12345\"\n\n    # First request: not seen before\n    is_duplicate = await service.is_duplicate(request_id)\n    assert is_duplicate is False\n\n    # Store request result\n    await service.store_request(request_id, {\"result\": \"processed\", \"amount\": 100})\n\n    # Second request: duplicate detected\n    is_duplicate = await service.is_duplicate(request_id)\n    assert is_duplicate is True\n\n    # Get cached result\n    cached_result = await service.get_result(request_id)\n    assert cached_result[\"result\"] == \"processed\"\n    assert cached_result[\"amount\"] == 100\n\n\n# CORRECT: Test idempotency key expiration\n@pytest.mark.integration\nasync def test_idempotency_key_expires(redis_client):\n    \"\"\"Test that idempotency keys expire after TTL.\"\"\"\n    from finance_lending_api.middleware.idempotency import IdempotencyService\n\n    service = IdempotencyService(redis_client, ttl=1)  # 1 second TTL\n    request_id = \"req-expire\"\n\n    # Store request\n    await service.store_request(request_id, {\"result\": \"ok\"})\n\n    # Immediately recognized as duplicate\n    assert await service.is_duplicate(request_id) is True\n\n    # Wait for expiration\n    import asyncio\n    await asyncio.sleep(1.5)\n\n    # No longer recognized as duplicate\n    assert await service.is_duplicate(request_id) is False\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#distributed-lock-testing","title":"Distributed Lock Testing","text":""},{"location":"atomic/testing/integration-testing/redis-testing/#lock-acquisition-and-release","title":"Lock Acquisition and Release","text":"<pre><code># CORRECT: Test distributed lock prevents concurrent access\n@pytest.mark.integration\nasync def test_distributed_lock(redis_client):\n    \"\"\"Test that distributed lock prevents concurrent access.\"\"\"\n    from finance_lending_api.infrastructure.redis_lock import RedisLock\n\n    lock = RedisLock(redis_client, \"resource:123\", timeout=5)\n\n    # Acquire lock\n    acquired = await lock.acquire()\n    assert acquired is True\n\n    # Second attempt fails (already locked)\n    lock2 = RedisLock(redis_client, \"resource:123\", timeout=5)\n    acquired2 = await lock2.acquire()\n    assert acquired2 is False\n\n    # Release lock\n    await lock.release()\n\n    # Now can acquire\n    acquired3 = await lock2.acquire()\n    assert acquired3 is True\n    await lock2.release()\n\n\n# CORRECT: Test lock auto-expires\n@pytest.mark.integration\nasync def test_lock_auto_expiration(redis_client):\n    \"\"\"Test that locks auto-expire after timeout.\"\"\"\n    from finance_lending_api.infrastructure.redis_lock import RedisLock\n\n    lock = RedisLock(redis_client, \"expire:lock\", timeout=1)\n\n    # Acquire lock\n    await lock.acquire()\n\n    # Wait for expiration\n    import asyncio\n    await asyncio.sleep(1.5)\n\n    # Another process can acquire (lock expired)\n    lock2 = RedisLock(redis_client, \"expire:lock\", timeout=1)\n    acquired = await lock2.acquire()\n    assert acquired is True\n    await lock2.release()\n\n\n# CORRECT: Test concurrent lock attempts\n@pytest.mark.integration\nasync def test_concurrent_lock_acquisition(redis_client):\n    \"\"\"Test that only one of concurrent attempts acquires lock.\"\"\"\n    import asyncio\n    from finance_lending_api.infrastructure.redis_lock import RedisLock\n\n    lock_key = \"concurrent:lock\"\n    results = []\n\n    async def try_lock(id: int):\n        lock = RedisLock(redis_client, lock_key, timeout=1)\n        acquired = await lock.acquire()\n        if acquired:\n            results.append(f\"worker-{id}\")\n            await asyncio.sleep(0.1)\n            await lock.release()\n        return acquired\n\n    # 5 workers try to acquire lock simultaneously\n    tasks = [try_lock(i) for i in range(5)]\n    outcomes = await asyncio.gather(*tasks)\n\n    # Only one worker acquired lock\n    assert sum(outcomes) == 1\n    assert len(results) == 1\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#rate-limiting-testing","title":"Rate Limiting Testing","text":"<pre><code># CORRECT: Test rate limiting with Redis\n@pytest.mark.integration\nasync def test_rate_limiting(redis_client):\n    \"\"\"Test rate limiting with sliding window.\"\"\"\n    from finance_lending_api.middleware.rate_limit import RateLimiter\n\n    limiter = RateLimiter(redis_client, max_requests=3, window_seconds=1)\n    user_id = \"user-123\"\n\n    # First 3 requests allowed\n    for i in range(3):\n        allowed = await limiter.is_allowed(user_id)\n        assert allowed is True\n\n    # 4th request blocked\n    allowed = await limiter.is_allowed(user_id)\n    assert allowed is False\n\n    # Wait for window to slide\n    import asyncio\n    await asyncio.sleep(1.1)\n\n    # Requests allowed again\n    allowed = await limiter.is_allowed(user_id)\n    assert allowed is True\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#pubsub-testing","title":"Pub/Sub Testing","text":"<pre><code># CORRECT: Test Redis pub/sub messaging\n@pytest.mark.integration\nasync def test_pubsub_messaging(redis_client):\n    \"\"\"Test publishing and subscribing to Redis channels.\"\"\"\n    import asyncio\n    import json\n\n    channel = \"events:user\"\n    message_received = []\n\n    # Subscribe\n    pubsub = redis_client.pubsub()\n    await pubsub.subscribe(channel)\n\n    # Subscriber task\n    async def listen():\n        async for message in pubsub.listen():\n            if message[\"type\"] == \"message\":\n                data = json.loads(message[\"data\"])\n                message_received.append(data)\n                break\n\n    listener_task = asyncio.create_task(listen())\n\n    # Small delay to ensure subscription registered\n    await asyncio.sleep(0.1)\n\n    # Publish message\n    await redis_client.publish(channel, json.dumps({\"event\": \"user_created\", \"user_id\": \"123\"}))\n\n    # Wait for message\n    await asyncio.wait_for(listener_task, timeout=2)\n\n    # Verify received\n    assert len(message_received) == 1\n    assert message_received[0][\"event\"] == \"user_created\"\n    assert message_received[0][\"user_id\"] == \"123\"\n\n    await pubsub.unsubscribe(channel)\n    await pubsub.close()\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#serialization-testing","title":"Serialization Testing","text":"<pre><code># CORRECT: Test JSON serialization/deserialization\n@pytest.mark.integration\nasync def test_cache_json_serialization(redis_client):\n    \"\"\"Test that complex objects are serialized correctly.\"\"\"\n    cache = CacheService(redis_client)\n\n    complex_data = {\n        \"user\": {\"id\": \"123\", \"name\": \"John\"},\n        \"loans\": [\n            {\"id\": \"loan-1\", \"amount\": 10000},\n            {\"id\": \"loan-2\", \"amount\": 5000},\n        ],\n        \"metadata\": {\"created_at\": \"2025-01-15T10:00:00Z\"}\n    }\n\n    # Store\n    await cache.set(\"complex:data\", complex_data)\n\n    # Retrieve\n    retrieved = await cache.get(\"complex:data\")\n\n    assert retrieved[\"user\"][\"id\"] == \"123\"\n    assert len(retrieved[\"loans\"]) == 2\n    assert retrieved[\"loans\"][0][\"amount\"] == 10000\n    assert retrieved[\"metadata\"][\"created_at\"] == \"2025-01-15T10:00:00Z\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#pipeline-testing","title":"Pipeline Testing","text":"<pre><code># CORRECT: Test Redis pipeline for batch operations\n@pytest.mark.integration\nasync def test_redis_pipeline(redis_client):\n    \"\"\"Test Redis pipeline for efficient batch operations.\"\"\"\n    # Create pipeline\n    pipe = redis_client.pipeline()\n\n    # Queue multiple operations\n    await pipe.set(\"key1\", \"value1\")\n    await pipe.set(\"key2\", \"value2\")\n    await pipe.set(\"key3\", \"value3\")\n    await pipe.get(\"key1\")\n    await pipe.get(\"key2\")\n\n    # Execute all at once\n    results = await pipe.execute()\n\n    # All operations executed\n    assert results[0] is True  # set key1\n    assert results[1] is True  # set key2\n    assert results[2] is True  # set key3\n    assert results[3] == \"value1\"  # get key1\n    assert results[4] == \"value2\"  # get key2\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/integration-testing/redis-testing/#do-use-real-redis-for-integration-tests","title":"DO: Use Real Redis for Integration Tests","text":"<pre><code># CORRECT: Use testcontainers Redis\n@pytest.fixture(scope=\"module\")\ndef redis_container():\n    \"\"\"Provide Redis container for integration tests.\"\"\"\n    from testcontainers.redis import RedisContainer\n\n    with RedisContainer(\"redis:7-alpine\") as container:\n        yield container\n\n\n# INCORRECT: Using fake Redis for integration tests\nimport fakeredis\n\n@pytest.fixture\ndef fake_redis():  # WRONG: Not testing real Redis behavior\n    return fakeredis.FakeRedis()\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#do-clean-redis-between-tests","title":"DO: Clean Redis Between Tests","text":"<pre><code># CORRECT: Flush database after each test\n@pytest.fixture\nasync def redis_client(redis_container):\n    \"\"\"Provide clean Redis client for each test.\"\"\"\n    from redis.asyncio import Redis\n\n    client = Redis.from_url(\n        redis_container.get_connection_url(),\n        encoding=\"utf-8\",\n        decode_responses=True\n    )\n\n    yield client\n\n    # Cleanup\n    await client.flushdb()\n    await client.close()\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#dont-share-keys-between-tests","title":"DON'T: Share Keys Between Tests","text":"<pre><code># INCORRECT: Tests share keys\n@pytest.mark.integration\nasync def test_set_user_cache(redis_client):\n    \"\"\"WRONG: Uses hardcoded key.\"\"\"\n    await redis_client.set(\"user:1\", \"John\")\n    assert await redis_client.get(\"user:1\") == \"John\"\n\n\n@pytest.mark.integration\nasync def test_get_user_cache(redis_client):\n    \"\"\"WRONG: Depends on previous test.\"\"\"\n    # Assumes \"user:1\" exists from previous test\n    assert await redis_client.get(\"user:1\") == \"John\"\n\n\n# CORRECT: Each test is independent\n@pytest.mark.integration\nasync def test_user_cache_lifecycle(redis_client):\n    \"\"\"Test is self-contained.\"\"\"\n    # Set in this test\n    await redis_client.set(\"user:test123\", \"John\")\n\n    # Get in this test\n    assert await redis_client.get(\"user:test123\") == \"John\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/redis-testing/#checklist","title":"Checklist","text":"<ul> <li> Use testcontainers for real Redis instances</li> <li> Test cache set, get, delete operations</li> <li> Test TTL expiration with asyncio.sleep</li> <li> Test idempotency key storage and checking</li> <li> Test distributed locks prevent concurrent access</li> <li> Test rate limiting with sliding windows</li> <li> Test pub/sub message delivery</li> <li> Test JSON serialization/deserialization</li> <li> Test Redis pipelines for batch operations</li> <li> Flush Redis database after each test</li> <li> Tests are independent and self-contained</li> <li> Mark integration tests with <code>@pytest.mark.integration</code></li> </ul>"},{"location":"atomic/testing/integration-testing/redis-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Setting up Docker containers for tests</li> <li><code>docs/atomic/integrations/redis/connection-management.md</code> \u2014 Redis client configuration</li> <li><code>docs/atomic/integrations/redis/caching-strategies.md</code> \u2014 Caching patterns</li> <li><code>docs/atomic/integrations/redis/idempotency-keys.md</code> \u2014 Idempotency implementation</li> <li><code>docs/atomic/integrations/redis/distributed-locks.md</code> \u2014 Distributed locking patterns</li> </ul>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/","title":"Testcontainers Setup","text":"<p>Use Testcontainers to provision real Docker containers for integration tests, eliminating the gap between test and production environments. Testcontainers manages container lifecycle automatically, ensuring consistent, isolated test environments with production-like dependencies (PostgreSQL, Redis, MongoDB, RabbitMQ).</p> <p>This document covers testcontainers-python setup, container configuration patterns, wait strategies for service readiness, and pytest fixtures for container management. Integration tests with Testcontainers provide confidence that code works with real databases and message brokers, not mocks.</p> <p>Testcontainers bridges the gap between unit tests (mocked dependencies) and manual testing (shared dev environments). Each test run gets fresh containers, preventing test pollution and race conditions while maintaining test speed with container reuse strategies.</p>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#why-testcontainers","title":"Why Testcontainers","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#benefits-over-mocking","title":"Benefits Over Mocking","text":"<pre><code># MOCKING (unit test): Fast but unrealistic\n@pytest.mark.unit\nasync def test_user_creation_mocked(mocker):\n    \"\"\"Test with mocked PostgreSQL.\"\"\"\n    mock_session = mocker.patch(\"sqlalchemy.orm.Session\")\n    mock_session.execute.return_value = Mock(scalar_one_or_none=Mock(id=\"user-123\"))\n    # Fast, but doesn't test real SQL, transactions, constraints\n\n\n# TESTCONTAINERS (integration test): Realistic and reliable\n@pytest.mark.integration\nasync def test_user_creation_real_database(postgres_container):\n    \"\"\"Test with real PostgreSQL container.\"\"\"\n    async with get_session(postgres_container.get_connection_url()) as session:\n        user = User(email=\"test@example.com\", name=\"Test\")\n        session.add(user)\n        await session.commit()\n        # Tests real SQL, transactions, unique constraints, triggers\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#benefits-over-shared-test-databases","title":"Benefits Over Shared Test Databases","text":"Approach Isolation Consistency Setup Complexity Shared test DB \u274c Tests pollute each other \u274c State accumulates \u2705 Simple Testcontainers \u2705 Fresh per test run \u2705 Clean state \u2705 Automated Manual Docker \u26a0\ufe0f Manual cleanup \u26a0\ufe0f Requires discipline \u274c Complex scripts"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#setup","title":"Setup","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#installation","title":"Installation","text":"<pre><code># pyproject.toml\n[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=8.0\",\n    \"pytest-asyncio&gt;=0.23\",\n    \"testcontainers&gt;=4.0\",\n    # Database drivers\n    \"asyncpg&gt;=0.29\",         # PostgreSQL async driver\n    \"redis&gt;=5.0\",            # Redis client\n    \"motor&gt;=3.3\",            # MongoDB async driver\n    \"aio-pika&gt;=9.3\",         # RabbitMQ async client\n]\n</code></pre> <p>Install with:</p> <pre><code>pip install -e \".[test]\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed and running (testcontainers controls Docker daemon)</li> <li>Docker daemon accessible (usually <code>unix:///var/run/docker.sock</code>)</li> <li>Sufficient Docker resources (disk space, memory for multiple containers)</li> </ul> <p>Verify Docker is running:</p> <pre><code>docker info\n# Should show Docker version and running containers\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#postgresql-container","title":"PostgreSQL Container","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#basic-setup","title":"Basic Setup","text":"<pre><code># tests/integration/conftest.py\nimport pytest\nfrom testcontainers.postgres import PostgresContainer\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker\n\n\n# CORRECT: Module-scoped container (shared across module tests)\n@pytest.fixture(scope=\"module\")\ndef postgres_container():\n    \"\"\"Provide PostgreSQL container for integration tests.\"\"\"\n    with PostgresContainer(\"postgres:16-alpine\") as container:\n        yield container\n\n\n# CORRECT: Async database engine from container\n@pytest.fixture(scope=\"module\")\nasync def db_engine(postgres_container):\n    \"\"\"Create async SQLAlchemy engine from container.\"\"\"\n    # Get connection URL from container\n    db_url = postgres_container.get_connection_url().replace(\n        \"psycopg2\", \"asyncpg\"  # Use async driver\n    )\n\n    engine = create_async_engine(db_url, echo=True)\n\n    # Create tables\n    from finance_lending_api.infrastructure.database import Base\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield engine\n\n    await engine.dispose()\n\n\n# CORRECT: Fresh session per test\n@pytest.fixture\nasync def db_session(db_engine):\n    \"\"\"Provide fresh database session for each test.\"\"\"\n    async_session = sessionmaker(\n        db_engine,\n        class_=AsyncSession,\n        expire_on_commit=False\n    )\n\n    async with async_session() as session:\n        yield session\n        await session.rollback()  # Rollback to keep container clean\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#using-postgresql-in-tests","title":"Using PostgreSQL in Tests","text":"<pre><code># tests/integration/test_user_repository.py\nimport pytest\nfrom finance_lending_api.infrastructure.repositories import UserRepository\nfrom finance_lending_api.domain.models import User\n\n\n@pytest.mark.integration\nasync def test_user_crud_operations(db_session):\n    \"\"\"Test user CRUD with real PostgreSQL.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    # Create\n    user = await repo.create(email=\"test@example.com\", name=\"Test User\")\n    assert user.id is not None\n\n    # Read\n    found_user = await repo.get_by_id(user.id)\n    assert found_user.email == \"test@example.com\"\n\n    # Update\n    found_user.name = \"Updated Name\"\n    await db_session.commit()\n    updated_user = await repo.get_by_id(user.id)\n    assert updated_user.name == \"Updated Name\"\n\n    # Delete\n    await repo.delete(user.id)\n    deleted_user = await repo.get_by_id(user.id)\n    assert deleted_user is None\n\n\n@pytest.mark.integration\nasync def test_unique_email_constraint(db_session):\n    \"\"\"Test database enforces unique email constraint.\"\"\"\n    repo = UserRepository(session=db_session)\n\n    # Create first user\n    user1 = await repo.create(email=\"unique@example.com\", name=\"User 1\")\n    assert user1.id is not None\n\n    # Attempt to create duplicate email\n    from sqlalchemy.exc import IntegrityError\n    with pytest.raises(IntegrityError, match=\"unique constraint\"):\n        await repo.create(email=\"unique@example.com\", name=\"User 2\")\n        await db_session.commit()\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#redis-container","title":"Redis Container","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#setup_1","title":"Setup","text":"<pre><code># tests/integration/conftest.py\nimport pytest\nfrom testcontainers.redis import RedisContainer\nfrom redis.asyncio import Redis\n\n\n@pytest.fixture(scope=\"module\")\ndef redis_container():\n    \"\"\"Provide Redis container for integration tests.\"\"\"\n    with RedisContainer(\"redis:7-alpine\") as container:\n        yield container\n\n\n@pytest.fixture\nasync def redis_client(redis_container):\n    \"\"\"Provide Redis client connected to container.\"\"\"\n    client = Redis.from_url(\n        redis_container.get_connection_url(),\n        encoding=\"utf-8\",\n        decode_responses=True\n    )\n\n    yield client\n\n    # Cleanup: flush database after each test\n    await client.flushdb()\n    await client.close()\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#using-redis-in-tests","title":"Using Redis in Tests","text":"<pre><code># tests/integration/test_cache_service.py\nimport pytest\nfrom finance_lending_api.services.cache import CacheService\n\n\n@pytest.mark.integration\nasync def test_cache_set_and_get(redis_client):\n    \"\"\"Test Redis cache operations.\"\"\"\n    cache = CacheService(redis_client)\n\n    # Set value\n    await cache.set(\"user:123\", {\"name\": \"Test\", \"email\": \"test@example.com\"}, ttl=60)\n\n    # Get value\n    result = await cache.get(\"user:123\")\n    assert result[\"name\"] == \"Test\"\n    assert result[\"email\"] == \"test@example.com\"\n\n\n@pytest.mark.integration\nasync def test_cache_expiration(redis_client):\n    \"\"\"Test cache TTL and expiration.\"\"\"\n    cache = CacheService(redis_client)\n\n    # Set with short TTL\n    await cache.set(\"temp:key\", \"value\", ttl=1)\n\n    # Value exists immediately\n    result = await cache.get(\"temp:key\")\n    assert result == \"value\"\n\n    # Wait for expiration\n    import asyncio\n    await asyncio.sleep(2)\n\n    # Value expired\n    result = await cache.get(\"temp:key\")\n    assert result is None\n\n\n@pytest.mark.integration\nasync def test_idempotency_key_check(redis_client):\n    \"\"\"Test idempotency key storage and checking.\"\"\"\n    from finance_lending_api.middleware.idempotency import IdempotencyService\n\n    service = IdempotencyService(redis_client)\n    request_id = \"req-12345\"\n\n    # First request: not seen before\n    is_duplicate = await service.is_duplicate(request_id)\n    assert is_duplicate is False\n\n    # Store request\n    await service.store_request(request_id, {\"result\": \"processed\"})\n\n    # Second request: duplicate\n    is_duplicate = await service.is_duplicate(request_id)\n    assert is_duplicate is True\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#mongodb-container","title":"MongoDB Container","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#setup_2","title":"Setup","text":"<pre><code># tests/integration/conftest.py\nimport pytest\nfrom testcontainers.mongodb import MongoDbContainer\nfrom motor.motor_asyncio import AsyncIOMotorClient\n\n\n@pytest.fixture(scope=\"module\")\ndef mongo_container():\n    \"\"\"Provide MongoDB container for integration tests.\"\"\"\n    with MongoDbContainer(\"mongo:7\") as container:\n        yield container\n\n\n@pytest.fixture\nasync def mongo_client(mongo_container):\n    \"\"\"Provide MongoDB client connected to container.\"\"\"\n    client = AsyncIOMotorClient(mongo_container.get_connection_url())\n\n    yield client\n\n    # Cleanup: drop database after tests\n    await client.drop_database(\"test_db\")\n    client.close()\n\n\n@pytest.fixture\nasync def mongo_db(mongo_client):\n    \"\"\"Provide MongoDB database for tests.\"\"\"\n    return mongo_client[\"test_db\"]\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#using-mongodb-in-tests","title":"Using MongoDB in Tests","text":"<pre><code># tests/integration/test_document_repository.py\nimport pytest\nfrom finance_lending_api.infrastructure.mongo_repositories import DocumentRepository\n\n\n@pytest.mark.integration\nasync def test_document_insert_and_find(mongo_db):\n    \"\"\"Test MongoDB document operations.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    # Insert document\n    doc_id = await repo.insert({\n        \"user_id\": \"user-123\",\n        \"type\": \"profile\",\n        \"data\": {\"bio\": \"Test bio\"}\n    })\n    assert doc_id is not None\n\n    # Find document\n    doc = await repo.find_by_id(doc_id)\n    assert doc[\"user_id\"] == \"user-123\"\n    assert doc[\"data\"][\"bio\"] == \"Test bio\"\n\n\n@pytest.mark.integration\nasync def test_document_query_with_filter(mongo_db):\n    \"\"\"Test MongoDB queries with filters.\"\"\"\n    repo = DocumentRepository(mongo_db)\n\n    # Insert multiple documents\n    await repo.insert({\"user_id\": \"user-1\", \"status\": \"active\", \"score\": 90})\n    await repo.insert({\"user_id\": \"user-2\", \"status\": \"inactive\", \"score\": 75})\n    await repo.insert({\"user_id\": \"user-3\", \"status\": \"active\", \"score\": 85})\n\n    # Query active users with score &gt; 80\n    results = await repo.find_many({\n        \"status\": \"active\",\n        \"score\": {\"$gt\": 80}\n    })\n\n    assert len(results) == 2\n    assert all(doc[\"status\"] == \"active\" for doc in results)\n    assert all(doc[\"score\"] &gt; 80 for doc in results)\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#rabbitmq-container","title":"RabbitMQ Container","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#setup_3","title":"Setup","text":"<pre><code># tests/integration/conftest.py\nimport pytest\nfrom testcontainers.rabbitmq import RabbitMqContainer\nimport aio_pika\n\n\n@pytest.fixture(scope=\"module\")\ndef rabbitmq_container():\n    \"\"\"Provide RabbitMQ container for integration tests.\"\"\"\n    with RabbitMqContainer(\"rabbitmq:3-management-alpine\") as container:\n        yield container\n\n\n@pytest.fixture\nasync def rabbitmq_connection(rabbitmq_container):\n    \"\"\"Provide RabbitMQ connection.\"\"\"\n    connection = await aio_pika.connect_robust(\n        rabbitmq_container.get_connection_url()\n    )\n\n    yield connection\n\n    await connection.close()\n\n\n@pytest.fixture\nasync def rabbitmq_channel(rabbitmq_connection):\n    \"\"\"Provide RabbitMQ channel.\"\"\"\n    channel = await rabbitmq_connection.channel()\n    yield channel\n    await channel.close()\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#using-rabbitmq-in-tests","title":"Using RabbitMQ in Tests","text":"<pre><code># tests/integration/test_event_publisher.py\nimport pytest\nimport json\nfrom finance_lending_api.events.publisher import EventPublisher\n\n\n@pytest.mark.integration\nasync def test_publish_and_consume_event(rabbitmq_channel):\n    \"\"\"Test RabbitMQ message publishing and consumption.\"\"\"\n    # Declare queue\n    queue = await rabbitmq_channel.declare_queue(\"test.events\", auto_delete=True)\n\n    # Publish event\n    publisher = EventPublisher(rabbitmq_channel)\n    await publisher.publish_user_created(user_id=\"user-123\", email=\"test@example.com\")\n\n    # Consume event\n    message = await queue.get(timeout=5)\n    assert message is not None\n\n    event_data = json.loads(message.body.decode())\n    assert event_data[\"user_id\"] == \"user-123\"\n    assert event_data[\"email\"] == \"test@example.com\"\n\n    await message.ack()\n\n\n@pytest.mark.integration\nasync def test_event_routing_by_topic(rabbitmq_channel):\n    \"\"\"Test topic-based routing in RabbitMQ.\"\"\"\n    # Declare topic exchange\n    exchange = await rabbitmq_channel.declare_exchange(\n        \"events\",\n        type=aio_pika.ExchangeType.TOPIC,\n        auto_delete=True\n    )\n\n    # Bind queues with routing patterns\n    user_queue = await rabbitmq_channel.declare_queue(\"user.events\", auto_delete=True)\n    await user_queue.bind(exchange, routing_key=\"user.*\")\n\n    loan_queue = await rabbitmq_channel.declare_queue(\"loan.events\", auto_delete=True)\n    await loan_queue.bind(exchange, routing_key=\"loan.*\")\n\n    # Publish user event\n    await exchange.publish(\n        aio_pika.Message(body=b'{\"event\": \"user_created\"}'),\n        routing_key=\"user.created\"\n    )\n\n    # Only user queue receives it\n    user_message = await user_queue.get(timeout=1)\n    assert user_message is not None\n\n    # Loan queue is empty\n    with pytest.raises(aio_pika.exceptions.QueueEmpty):\n        await loan_queue.get(timeout=1, fail=True)\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#multiple-containers-composition","title":"Multiple Containers Composition","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#docker-compose-with-testcontainers","title":"Docker Compose with Testcontainers","text":"<pre><code># tests/integration/conftest.py\nimport pytest\nfrom testcontainers.compose import DockerCompose\n\n\n@pytest.fixture(scope=\"session\")\ndef docker_compose():\n    \"\"\"Start all services with docker-compose for integration tests.\"\"\"\n    compose_path = Path(__file__).parent / \"docker-compose.test.yml\"\n\n    with DockerCompose(\n        filepath=compose_path.parent,\n        compose_file_name=compose_path.name,\n        pull=True\n    ) as compose:\n        # Wait for services to be ready\n        compose.wait_for(\"http://localhost:5432\")  # PostgreSQL\n        compose.wait_for(\"http://localhost:6379\")  # Redis\n        compose.wait_for(\"http://localhost:27017\")  # MongoDB\n        compose.wait_for(\"http://localhost:5672\")  # RabbitMQ\n\n        yield compose\n</code></pre> <pre><code># tests/integration/docker-compose.test.yml\nversion: '3.8'\n\nservices:\n  postgres:\n    image: postgres:16-alpine\n    environment:\n      POSTGRES_DB: test_db\n      POSTGRES_USER: test_user\n      POSTGRES_PASSWORD: test_pass\n    ports:\n      - \"5432:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U test_user\"]\n      interval: 1s\n      timeout: 5s\n      retries: 10\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 1s\n      timeout: 3s\n      retries: 10\n\n  mongo:\n    image: mongo:7\n    ports:\n      - \"27017:27017\"\n    healthcheck:\n      test: [\"CMD\", \"mongosh\", \"--eval\", \"db.adminCommand('ping')\"]\n      interval: 1s\n      timeout: 3s\n      retries: 10\n\n  rabbitmq:\n    image: rabbitmq:3-management-alpine\n    ports:\n      - \"5672:5672\"\n      - \"15672:15672\"\n    healthcheck:\n      test: [\"CMD\", \"rabbitmq-diagnostics\", \"-q\", \"ping\"]\n      interval: 1s\n      timeout: 3s\n      retries: 10\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#wait-strategies","title":"Wait Strategies","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#custom-wait-strategies","title":"Custom Wait Strategies","text":"<pre><code># CORRECT: Wait for service to be ready\nfrom testcontainers.core.waiting_utils import wait_for_logs\n\n\n@pytest.fixture(scope=\"module\")\ndef postgres_container():\n    \"\"\"PostgreSQL container with wait strategy.\"\"\"\n    container = PostgresContainer(\"postgres:16-alpine\")\n    container.start()\n\n    # Wait for PostgreSQL to be ready\n    wait_for_logs(container, \"database system is ready to accept connections\", timeout=30)\n\n    yield container\n    container.stop()\n\n\n# CORRECT: Custom health check\nfrom testcontainers.core.generic import DbContainer\n\n\n@pytest.fixture(scope=\"module\")\ndef custom_container():\n    \"\"\"Container with custom readiness check.\"\"\"\n    container = DbContainer(\"my-custom-service:latest\")\n    container.with_exposed_ports(8080)\n    container.start()\n\n    # Custom wait: poll health endpoint\n    import time\n    import requests\n    from requests.exceptions import RequestException\n\n    port = container.get_exposed_port(8080)\n    health_url = f\"http://localhost:{port}/health\"\n\n    for attempt in range(30):\n        try:\n            response = requests.get(health_url, timeout=1)\n            if response.status_code == 200:\n                break\n        except RequestException:\n            pass\n        time.sleep(1)\n    else:\n        raise TimeoutError(\"Service did not become healthy\")\n\n    yield container\n    container.stop()\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#performance-optimization","title":"Performance Optimization","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#container-reuse-strategies","title":"Container Reuse Strategies","text":"<pre><code># CORRECT: Module scope for container reuse across tests\n@pytest.fixture(scope=\"module\")\ndef postgres_container():\n    \"\"\"Reuse PostgreSQL container for all tests in module.\"\"\"\n    with PostgresContainer(\"postgres:16-alpine\") as container:\n        yield container\n    # Container stopped after all module tests complete\n\n\n# CORRECT: Session scope for maximum reuse\n@pytest.fixture(scope=\"session\")\ndef redis_container():\n    \"\"\"Reuse Redis container for entire test session.\"\"\"\n    with RedisContainer(\"redis:7-alpine\") as container:\n        yield container\n    # Container stopped after all tests complete\n\n\n# INCORRECT: Function scope (slow - new container per test)\n@pytest.fixture(scope=\"function\")\ndef slow_postgres_container():\n    \"\"\"WRONG: Creates new container for every single test.\"\"\"\n    with PostgresContainer(\"postgres:16-alpine\") as container:\n        yield container\n    # Very slow for test suites with many tests\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#transaction-rollback-for-speed","title":"Transaction Rollback for Speed","text":"<pre><code># CORRECT: Use transaction rollback instead of recreating data\n@pytest.fixture\nasync def db_session(db_engine):\n    \"\"\"Provide session with automatic rollback.\"\"\"\n    async with db_engine.begin() as connection:\n        async_session = sessionmaker(\n            bind=connection,\n            class_=AsyncSession,\n            expire_on_commit=False\n        )\n\n        async with async_session() as session:\n            yield session\n            # Implicit rollback - changes don't persist to container\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/integration-testing/testcontainers-setup/#do-use-appropriate-scopes","title":"DO: Use Appropriate Scopes","text":"<pre><code># CORRECT: Session scope for expensive containers\n@pytest.fixture(scope=\"session\")\ndef postgres_container():\n    \"\"\"Start PostgreSQL once for all tests.\"\"\"\n    with PostgresContainer(\"postgres:16-alpine\") as container:\n        yield container\n\n\n# CORRECT: Function scope for test isolation needs\n@pytest.fixture(scope=\"function\")\nasync def clean_redis(redis_client):\n    \"\"\"Flush Redis before each test for isolation.\"\"\"\n    await redis_client.flushdb()\n    yield redis_client\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#do-clean-up-between-tests","title":"DO: Clean Up Between Tests","text":"<pre><code># CORRECT: Explicit cleanup in fixture\n@pytest.fixture\nasync def mongo_collection(mongo_db):\n    \"\"\"Provide clean collection for each test.\"\"\"\n    collection = mongo_db[\"users\"]\n\n    yield collection\n\n    # Cleanup: drop collection after test\n    await collection.drop()\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#dont-rely-on-container-state","title":"DON'T: Rely on Container State","text":"<pre><code># INCORRECT: Tests depend on execution order\n@pytest.mark.integration\nasync def test_create_user(db_session):\n    \"\"\"Create user with ID=1.\"\"\"\n    user = await create_user(id=1, email=\"test@example.com\")\n    assert user.id == 1\n\n\n@pytest.mark.integration\nasync def test_find_user(db_session):\n    \"\"\"WRONG: Assumes test_create_user ran first.\"\"\"\n    user = await find_user(id=1)  # Might not exist!\n    assert user.email == \"test@example.com\"\n\n\n# CORRECT: Each test is self-contained\n@pytest.mark.integration\nasync def test_find_user_independent(db_session):\n    \"\"\"Test is self-contained with its own setup.\"\"\"\n    # Setup: create user in this test\n    await create_user(id=1, email=\"test@example.com\")\n\n    # Test: find user\n    user = await find_user(id=1)\n    assert user.email == \"test@example.com\"\n</code></pre>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#checklist","title":"Checklist","text":"<ul> <li> Docker installed and running on test machine</li> <li> <code>testcontainers</code> package installed in test dependencies</li> <li> Containers use module or session scope for reuse</li> <li> Wait strategies ensure services are ready before tests run</li> <li> Cleanup performed after each test (rollback, flush, drop)</li> <li> Tests are independent and don't rely on execution order</li> <li> Container images pinned to specific versions (e.g., <code>postgres:16</code>, not <code>postgres:latest</code>)</li> <li> Health checks configured for containers</li> <li> Connection URLs obtained from containers dynamically</li> <li> Async drivers used for async tests (asyncpg, motor, etc.)</li> <li> CI/CD environment has Docker available</li> <li> Integration tests marked with <code>@pytest.mark.integration</code></li> </ul>"},{"location":"atomic/testing/integration-testing/testcontainers-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/database-testing.md</code> \u2014 Testing with PostgreSQL and MongoDB</li> <li><code>docs/atomic/testing/integration-testing/redis-testing.md</code> \u2014 Testing Redis caching and idempotency</li> <li><code>docs/atomic/testing/integration-testing/rabbitmq-testing.md</code> \u2014 Testing RabbitMQ messaging</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Pytest fixture patterns</li> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code> \u2014 Pytest configuration</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/","title":"Code Review Checklist","text":"<p>Conduct systematic code reviews to ensure code quality, catch bugs early, share knowledge across team, and maintain consistent architecture and style standards. Code reviews improve code quality through peer feedback before merging changes into the main branch.</p> <p>This document covers code review processes, comprehensive checklists for architecture, code quality, testing, security, performance, documentation review, automated CI/CD checks, and best practices for giving and receiving feedback. Code reviews are mandatory quality gates before merging any code.</p> <p>Code review validates that changes align with architecture principles, follow coding standards, include comprehensive tests, handle errors gracefully, maintain security best practices, and include clear documentation. Reviews catch issues that automated tools miss and facilitate knowledge transfer across the team.</p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#code-review-process","title":"Code Review Process","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#when-to-require-review","title":"When to Require Review","text":"<p>Mandatory review for: - All pull requests to main/master branch - Changes to core business logic or data models - New service implementations or major refactors - Security-sensitive code (authentication, authorization, payments) - Infrastructure and deployment configuration changes - Database schema migrations - API contract changes (breaking or non-breaking)</p> <p>Optional review (team discretion): - Documentation-only changes - Minor typo fixes in comments - Test data or fixture updates</p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#review-workflow","title":"Review Workflow","text":"<pre><code>graph LR\n    A[Create PR] --&gt; B[Self-Review]\n    B --&gt; C[Request Review]\n    C --&gt; D[Reviewer Analysis]\n    D --&gt; E{Approve?}\n    E --&gt;|Yes| F[Merge]\n    E --&gt;|Changes Requested| G[Address Feedback]\n    G --&gt; C</code></pre> <p>Step 1: Author Self-Review - Review own changes before requesting review - Run all tests locally - Verify linting and type checking pass - Add descriptive PR description - Link related issues/tickets</p> <p>Step 2: Reviewer Analysis - Read PR description and context - Review code changes line-by-line - Run code locally if needed - Check test coverage and quality - Verify CI/CD checks pass</p> <p>Step 3: Feedback Loop - Provide constructive, actionable feedback - Author addresses comments - Re-review after changes - Approve when all concerns resolved</p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#architecture-design-review","title":"Architecture &amp; Design Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist","title":"Checklist","text":"<ul> <li> Service Boundaries: Changes respect microservice boundaries and separation of concerns</li> <li> Data Access: Uses HTTP-only data access (no direct database connections from business services)</li> <li> Communication Patterns: Follows synchronous (HTTP) or asynchronous (RabbitMQ) patterns correctly</li> <li> Error Handling: Implements proper error handling with meaningful messages</li> <li> Design Patterns: Uses appropriate design patterns (repository, factory, strategy, etc.)</li> <li> SOLID Principles: Follows Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion</li> <li> Dependency Injection: Uses dependency injection for testability</li> <li> Configuration: Externalizes configuration via environment variables</li> <li> Naming Conventions: Follows <code>{context}_{domain}_{type}</code> naming pattern</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review","title":"Example Review","text":"<pre><code># CORRECT: Proper service separation and HTTP-only data access\nclass UserService:\n    \"\"\"User business logic service.\"\"\"\n\n    def __init__(self, data_client: DataServiceClient):\n        \"\"\"Inject data service client.\"\"\"\n        self.data_client = data_client\n\n    async def create_user(self, email: str, name: str) -&gt; User:\n        \"\"\"Create user via data service HTTP API.\"\"\"\n        try:\n            response = await self.data_client.post(\"/api/users\", json={\n                \"email\": email,\n                \"name\": name\n            })\n            return User.parse_obj(response.json())\n        except HTTPException as e:\n            raise UserCreationError(f\"Failed to create user: {e}\")\n\n\n# INCORRECT: Direct database access from business service\nclass UserService:\n    \"\"\"WRONG: Business service accessing database directly.\"\"\"\n\n    def __init__(self, db_session: AsyncSession):  # \u274c Direct DB dependency\n        self.db = db_session\n\n    async def create_user(self, email: str, name: str) -&gt; User:\n        \"\"\"WRONG: Direct database query.\"\"\"\n        user = User(email=email, name=name)\n        self.db.add(user)  # \u274c Violates HTTP-only constraint\n        await self.db.commit()\n        return user\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#code-quality-review","title":"Code Quality Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_1","title":"Checklist","text":"<ul> <li> Readability: Code is clear, well-structured, and easy to understand</li> <li> Complexity: Functions are focused and not overly complex (McCabe &lt; 10)</li> <li> DRY Principle: No unnecessary code duplication</li> <li> Variable Names: Descriptive, meaningful variable and function names</li> <li> Magic Numbers: No hardcoded values; use named constants</li> <li> Comments: Code explains \"why\", not \"what\"; complex logic is documented</li> <li> Type Hints: All functions have complete type annotations</li> <li> Error Messages: Clear, actionable error messages for debugging</li> <li> Resource Cleanup: Proper use of context managers for file/connection handling</li> <li> Async/Await: Correct async/await usage (no blocking calls in async functions)</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review_1","title":"Example Review","text":"<pre><code># CORRECT: Clear, well-structured code\nfrom typing import Optional\nfrom dataclasses import dataclass\n\n# Named constant instead of magic number\nMIN_CREDIT_SCORE = 650\n\n\n@dataclass\nclass LoanDecision:\n    \"\"\"Loan approval decision.\"\"\"\n    approved: bool\n    reason: str\n    credit_score: int\n\n\nasync def evaluate_loan_application(\n    user_id: str,\n    loan_amount: int,\n    credit_service: CreditCheckService\n) -&gt; LoanDecision:\n    \"\"\"\n    Evaluate loan application based on credit score.\n\n    Args:\n        user_id: User identifier\n        loan_amount: Requested loan amount in cents\n        credit_service: Credit check service client\n\n    Returns:\n        LoanDecision with approval status and reason\n    \"\"\"\n    credit_score = await credit_service.get_credit_score(user_id)\n\n    if credit_score &lt; MIN_CREDIT_SCORE:\n        return LoanDecision(\n            approved=False,\n            reason=f\"Credit score {credit_score} below minimum {MIN_CREDIT_SCORE}\",\n            credit_score=credit_score\n        )\n\n    return LoanDecision(\n        approved=True,\n        reason=\"Credit score meets requirements\",\n        credit_score=credit_score\n    )\n\n\n# INCORRECT: Poor code quality\nasync def check(uid, amt, svc):  # \u274c Unclear parameter names, no type hints\n    \"\"\"Check stuff.\"\"\"  # \u274c Vague docstring\n    s = await svc.get(uid)  # \u274c Single-letter variable\n    if s &lt; 650:  # \u274c Magic number\n        return False, \"bad\"  # \u274c Unclear return value\n    return True, \"good\"\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#testing-review","title":"Testing Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_2","title":"Checklist","text":"<ul> <li> Test Coverage: New code has 80%+ test coverage</li> <li> Test Types: Appropriate mix of unit, integration, and E2E tests</li> <li> Test Quality: Tests are clear, focused, and test one thing</li> <li> Test Names: Descriptive test names explain what is being tested</li> <li> Assertions: Clear assertions with meaningful error messages</li> <li> Edge Cases: Tests cover edge cases and error conditions</li> <li> Mocking: Appropriate use of mocks for external dependencies</li> <li> Test Data: Realistic test data that represents production scenarios</li> <li> Test Independence: Tests don't depend on execution order</li> <li> Async Testing: Proper use of pytest-asyncio for async code</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review_2","title":"Example Review","text":"<pre><code># CORRECT: Comprehensive test with clear structure\nimport pytest\nfrom unittest.mock import AsyncMock\n\n@pytest.mark.asyncio\nasync def test_loan_approval_rejects_low_credit_score():\n    \"\"\"Test loan application rejected when credit score below minimum.\"\"\"\n    # Arrange\n    mock_credit_service = AsyncMock(spec=CreditCheckService)\n    mock_credit_service.get_credit_score.return_value = 600\n\n    # Act\n    decision = await evaluate_loan_application(\n        user_id=\"user-123\",\n        loan_amount=10000,\n        credit_service=mock_credit_service\n    )\n\n    # Assert\n    assert decision.approved is False\n    assert \"below minimum\" in decision.reason\n    assert decision.credit_score == 600\n    mock_credit_service.get_credit_score.assert_called_once_with(\"user-123\")\n\n\n# INCORRECT: Poor test quality\ndef test_loan():  # \u274c No async, unclear name\n    \"\"\"Test loan.\"\"\"  # \u274c Vague docstring\n    result = check(\"123\", 10000, None)  # \u274c No mocking, hardcoded values\n    assert result  # \u274c Unclear assertion\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#security-review","title":"Security Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_3","title":"Checklist","text":"<ul> <li> Authentication: Proper authentication for all protected endpoints</li> <li> Authorization: Correct authorization checks (user permissions)</li> <li> Input Validation: All user input validated and sanitized</li> <li> SQL Injection: No raw SQL queries; use parameterized queries or ORM</li> <li> XSS Prevention: Output encoding for user-generated content</li> <li> Secrets Management: No hardcoded secrets; use environment variables</li> <li> Encryption: Sensitive data encrypted in transit (HTTPS) and at rest</li> <li> Rate Limiting: API endpoints protected against abuse</li> <li> CORS Configuration: Proper CORS settings for frontend-backend communication</li> <li> Dependency Vulnerabilities: No known vulnerabilities in dependencies</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review_3","title":"Example Review","text":"<pre><code># CORRECT: Secure implementation\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer\n\nsecurity = HTTPBearer()\n\n\nasync def get_current_user(token: str = Depends(security)) -&gt; User:\n    \"\"\"Validate JWT token and return current user.\"\"\"\n    try:\n        payload = jwt.decode(token.credentials, settings.SECRET_KEY, algorithms=[\"HS256\"])\n        user_id = payload.get(\"sub\")\n        if user_id is None:\n            raise HTTPException(status_code=401, detail=\"Invalid token\")\n        return await user_service.get_user(user_id)\n    except jwt.JWTError:\n        raise HTTPException(status_code=401, detail=\"Invalid token\")\n\n\n@router.get(\"/api/users/{user_id}\")\nasync def get_user(\n    user_id: str,\n    current_user: User = Depends(get_current_user)\n) -&gt; UserResponse:\n    \"\"\"Get user by ID (requires authentication).\"\"\"\n    # Authorization check\n    if current_user.id != user_id and not current_user.is_admin:\n        raise HTTPException(status_code=403, detail=\"Access denied\")\n\n    return await user_service.get_user(user_id)\n\n\n# INCORRECT: Security vulnerabilities\n@router.get(\"/api/users/{user_id}\")\nasync def get_user(user_id: str) -&gt; UserResponse:  # \u274c No authentication\n    \"\"\"WRONG: Public endpoint exposing user data.\"\"\"\n    # \u274c No authorization check\n    query = f\"SELECT * FROM users WHERE id = '{user_id}'\"  # \u274c SQL injection\n    result = await db.execute(query)\n    return result\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#performance-review","title":"Performance Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_4","title":"Checklist","text":"<ul> <li> Database Queries: Efficient queries with proper indexes</li> <li> N+1 Queries: No N+1 query problems; use eager loading</li> <li> Caching: Appropriate caching for frequently accessed data</li> <li> Pagination: Large result sets paginated</li> <li> Async Operations: Blocking operations don't block event loop</li> <li> Connection Pooling: Proper connection pool configuration</li> <li> Memory Usage: No memory leaks or excessive memory consumption</li> <li> Algorithm Complexity: Efficient algorithms (avoid O(n\u00b2) when possible)</li> <li> Background Tasks: Long-running tasks delegated to background workers</li> <li> Resource Limits: Proper timeouts and rate limiting</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review_4","title":"Example Review","text":"<pre><code># CORRECT: Efficient implementation with caching and pagination\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\nasync def get_user_permissions(user_id: str) -&gt; list[str]:\n    \"\"\"Get user permissions with caching.\"\"\"\n    response = await data_client.get(f\"/api/users/{user_id}/permissions\")\n    return response.json()[\"permissions\"]\n\n\nasync def get_users_paginated(\n    page: int = 1,\n    page_size: int = 50\n) -&gt; list[User]:\n    \"\"\"Get users with pagination.\"\"\"\n    offset = (page - 1) * page_size\n    response = await data_client.get(\n        \"/api/users\",\n        params={\"offset\": offset, \"limit\": page_size}\n    )\n    return [User.parse_obj(u) for u in response.json()[\"users\"]]\n\n\n# INCORRECT: Performance issues\nasync def get_loan_applications() -&gt; list[LoanWithUser]:\n    \"\"\"WRONG: N+1 query problem.\"\"\"\n    loans = await get_all_loans()  # 1 query\n    result = []\n    for loan in loans:\n        user = await get_user(loan.user_id)  # N queries \u274c\n        result.append(LoanWithUser(loan=loan, user=user))\n    return result  # Total: 1 + N queries\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#documentation-review","title":"Documentation Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_5","title":"Checklist","text":"<ul> <li> PR Description: Clear description of changes and motivation</li> <li> Docstrings: All public functions have docstrings with Args, Returns, Raises</li> <li> README Updates: README updated if functionality or setup changes</li> <li> API Documentation: API endpoints documented (OpenAPI/Swagger)</li> <li> Architecture Decisions: ADRs created for significant architectural changes</li> <li> Migration Guides: Breaking changes include migration instructions</li> <li> Changelog: CHANGELOG.md updated with notable changes</li> <li> Comments: Complex logic explained with comments</li> <li> Type Hints: Type hints serve as inline documentation</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-review_5","title":"Example Review","text":"<pre><code># CORRECT: Well-documented function\nasync def process_loan_application(\n    loan_id: str,\n    approval_status: Literal[\"approved\", \"rejected\"],\n    reviewer_id: str,\n    notes: Optional[str] = None\n) -&gt; LoanDecision:\n    \"\"\"\n    Process loan application and update status.\n\n    Validates loan exists, checks reviewer permissions, updates loan status,\n    publishes event to RabbitMQ for notification service, and returns decision.\n\n    Args:\n        loan_id: Unique loan application identifier\n        approval_status: Either \"approved\" or \"rejected\"\n        reviewer_id: ID of reviewer making decision\n        notes: Optional reviewer notes explaining decision\n\n    Returns:\n        LoanDecision object with updated status and timestamp\n\n    Raises:\n        LoanNotFoundError: If loan_id does not exist\n        UnauthorizedError: If reviewer lacks approval permissions\n        InvalidStatusError: If approval_status is invalid\n    \"\"\"\n    # Validate loan exists\n    loan = await loan_service.get_loan(loan_id)\n    if not loan:\n        raise LoanNotFoundError(f\"Loan {loan_id} not found\")\n\n    # Check reviewer permissions\n    reviewer = await user_service.get_user(reviewer_id)\n    if not reviewer.can_approve_loans:\n        raise UnauthorizedError(f\"User {reviewer_id} cannot approve loans\")\n\n    # Update loan status\n    loan.status = approval_status\n    loan.reviewer_id = reviewer_id\n    loan.notes = notes\n    loan.reviewed_at = datetime.utcnow()\n\n    await loan_service.update_loan(loan)\n\n    # Publish event for notification\n    await event_publisher.publish(\"loan.processed\", {\n        \"loan_id\": loan_id,\n        \"status\": approval_status,\n        \"user_id\": loan.user_id\n    })\n\n    return LoanDecision.from_loan(loan)\n\n\n# INCORRECT: Poorly documented\nasync def process(lid, status, rid, n=None):  # \u274c No docstring, unclear params\n    \"\"\"Process loan.\"\"\"  # \u274c Too vague\n    l = await get_loan(lid)  # \u274c No comments explaining logic\n    if not l:\n        raise Exception(\"Not found\")  # \u274c Generic exception\n    # ... rest of code without documentation\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#style-readability-review","title":"Style &amp; Readability Review","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_6","title":"Checklist","text":"<ul> <li> Linting: Code passes Ruff/Black formatting</li> <li> Line Length: Lines under 100 characters</li> <li> Import Organization: Imports organized (stdlib, third-party, local)</li> <li> Naming Conventions: PEP 8 naming (snake_case functions, PascalCase classes)</li> <li> Consistency: Code style consistent with existing codebase</li> <li> Dead Code: No commented-out code or unused imports</li> <li> Print Statements: No debug print() statements</li> <li> TODO Comments: No untracked TODO comments (create issues instead)</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#automated-checks","title":"Automated Checks","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code># .github/workflows/pr-checks.yml\nname: PR Checks\n\non: [pull_request]\n\njobs:\n  code-quality:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install ruff black mypy pytest pytest-cov\n\n      - name: Run Ruff linting\n        run: ruff check src/ tests/\n\n      - name: Run Black formatting check\n        run: black --check src/ tests/\n\n      - name: Run mypy type checking\n        run: mypy src/ --strict\n\n      - name: Run tests with coverage\n        run: pytest tests/ --cov=src --cov-report=xml --cov-fail-under=80\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          file: ./coverage.xml\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#giving-feedback","title":"Giving Feedback","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#best-practices","title":"Best Practices","text":"<p>DO: - Be respectful, constructive, and empathetic - Explain \"why\" behind suggestions - Provide specific examples or code snippets - Ask questions instead of making demands - Acknowledge good practices and improvements - Focus on code, not the person - Prioritize feedback (critical vs. nice-to-have)</p> <p>DON'T: - Use aggressive or condescending language - Make vague comments without context - Nitpick minor style issues (let linters handle this) - Block PRs for subjective preferences - Demand changes without explanation</p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#example-feedback","title":"Example Feedback","text":"<pre><code># CORRECT: Constructive feedback\n\n**High Priority:**\n\ud83d\udea8 **Security concern**: This endpoint lacks authentication. Consider adding `Depends(get_current_user)` to protect user data.\n\n```python\n@router.get(\"/api/users/{user_id}\", dependencies=[Depends(get_current_user)])\nasync def get_user(user_id: str):\n    ...\n</code></pre> <p>Medium Priority: \ud83d\udca1 Suggestion: Consider extracting this validation logic into a separate function for reusability:</p> <pre><code>def validate_email(email: str) -&gt; bool:\n    \"\"\"Validate email format.\"\"\"\n    return re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', email) is not None\n</code></pre> <p>Nice to have: \u2728 Nit: Could we add a docstring here explaining the business logic?</p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#incorrect-poor-feedback","title":"INCORRECT: Poor feedback","text":"<p>\u274c \"This is wrong.\"  # No context or explanation</p> <p>\u274c \"Why didn't you use X pattern?\"  # Sounds accusatory</p> <p>\u274c \"I would never write code like this.\"  # Personal attack</p> <p>\u274c \"This whole file needs to be rewritten.\"  # Too vague, not actionable <pre><code>## Receiving Feedback\n\n### Best Practices\n\n**DO:**\n- Assume positive intent from reviewers\n- Ask clarifying questions if feedback is unclear\n- Thank reviewers for their time and insights\n- Address all feedback (implement, explain, or discuss)\n- Mark conversations as resolved after addressing\n- Learn from feedback patterns to improve future code\n\n**DON'T:**\n- Take feedback personally\n- Argue defensively or dismiss concerns\n- Ignore feedback without discussion\n- Leave feedback unresolved without explanation\n- Rush to implement changes without understanding\n\n### Responding to Feedback\n\n```markdown\n# CORRECT: Professional responses\n\n\"Great catch! I missed that authentication check. Fixed in [commit abc123].\"\n\n\"Good point about performance. I've added pagination in [commit def456].\"\n\n\"I'm not sure I understand this suggestion. Could you elaborate on why approach X is preferable to Y?\"\n\n\"I disagree with this approach because [technical reason]. Would [alternative] work better?\"\n\n---\n\n# INCORRECT: Unprofessional responses\n\n\u274c \"This works fine, no need to change it.\"  # Dismissive\n\n\u274c \"You're wrong.\"  # Confrontational\n\n\u274c \"Whatever, I'll change it.\"  # Passive-aggressive\n\n\u274c [No response, ignores feedback]  # Disrespectful\n</code></pre></p>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\n[Brief description of changes]\n\n## Motivation and Context\n[Why are these changes necessary? What problem do they solve?]\n\n## Type of Change\n- [ ] Bug fix (non-breaking change fixing an issue)\n- [ ] New feature (non-breaking change adding functionality)\n- [ ] Breaking change (fix or feature causing existing functionality to change)\n- [ ] Documentation update\n\n## How Has This Been Tested?\n[Describe tests that verify changes work correctly]\n\n## Screenshots (if applicable)\n[Add screenshots for UI changes]\n\n## Checklist\n- [ ] My code follows the style guidelines\n- [ ] I have performed a self-review\n- [ ] I have commented complex code\n- [ ] I have updated documentation\n- [ ] My changes generate no new warnings\n- [ ] I have added tests that prove my fix is effective or feature works\n- [ ] New and existing tests pass locally\n- [ ] Any dependent changes have been merged and published\n\n## Related Issues\nCloses #[issue number]\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#best-practices_1","title":"Best Practices","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#do-review-promptly","title":"DO: Review Promptly","text":"<pre><code># CORRECT: Timely review process\n- Review PRs within 24 hours of request\n- Set aside dedicated time for reviews daily\n- Prioritize urgent/blocking PRs\n- Notify author if review will be delayed\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#do-focus-on-high-impact-issues","title":"DO: Focus on High-Impact Issues","text":"<pre><code># CORRECT: Prioritize important feedback\n\n# High Priority: Security vulnerability\n# \ud83d\udea8 This allows unauthorized access\nif user_id == request.user_id:  # Missing admin check\n    return user_data\n\n# Medium Priority: Performance issue\n# \ud83d\udca1 This creates N+1 queries\nfor loan in loans:\n    user = await get_user(loan.user_id)\n\n# Low Priority: Style preference\n# \u2728 Consider using f-string instead of format()\nmessage = \"Hello, {}\".format(name)  # Personal preference\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#dont-block-on-nitpicks","title":"DON'T: Block on Nitpicks","text":"<pre><code># INCORRECT: Blocking PR for minor style issues\n\u274c \"Requested changes: Add space after comma in line 42\"\n\n# CORRECT: Approve with non-blocking suggestions\n\u2705 \"Approved! Minor suggestion: could add space after comma (line 42) for consistency. Feel free to merge as-is or update.\"\n</code></pre>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#checklist_7","title":"Checklist","text":""},{"location":"atomic/testing/quality-assurance/code-review-checklist/#architecture-design","title":"Architecture &amp; Design","text":"<ul> <li> Service boundaries respected</li> <li> HTTP-only data access followed</li> <li> Proper error handling implemented</li> <li> Design patterns used appropriately</li> <li> SOLID principles followed</li> <li> Configuration externalized</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#code-quality","title":"Code Quality","text":"<ul> <li> Code is readable and well-structured</li> <li> Functions focused (low complexity)</li> <li> No code duplication</li> <li> Descriptive naming</li> <li> Type hints complete</li> <li> Clear error messages</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#testing","title":"Testing","text":"<ul> <li> 80%+ test coverage</li> <li> Unit, integration, E2E tests appropriate</li> <li> Edge cases covered</li> <li> Mocks used properly</li> <li> Tests are independent</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#security","title":"Security","text":"<ul> <li> Authentication required</li> <li> Authorization checks present</li> <li> Input validation complete</li> <li> No SQL injection vulnerabilities</li> <li> Secrets not hardcoded</li> <li> Dependencies up-to-date</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#performance","title":"Performance","text":"<ul> <li> Efficient database queries</li> <li> No N+1 query problems</li> <li> Caching used appropriately</li> <li> Pagination for large datasets</li> <li> Async operations non-blocking</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#documentation","title":"Documentation","text":"<ul> <li> PR description clear</li> <li> Docstrings complete</li> <li> README updated if needed</li> <li> API documentation updated</li> <li> ADRs created for major changes</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#style-cicd","title":"Style &amp; CI/CD","text":"<ul> <li> Linting passes</li> <li> Type checking passes</li> <li> All tests pass</li> <li> No commented-out code</li> <li> CI/CD pipeline green</li> </ul>"},{"location":"atomic/testing/quality-assurance/code-review-checklist/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/quality-assurance/linting-standards.md</code> \u2014 Code linting standards with Ruff</li> <li><code>docs/atomic/testing/quality-assurance/type-checking.md</code> \u2014 Static type checking with mypy</li> <li><code>docs/atomic/architecture/architecture-principles.md</code> \u2014 Core architecture guidelines</li> <li><code>docs/atomic/architecture/naming/README.md</code> \u2014 Service and variable naming standards</li> </ul>"},{"location":"atomic/testing/quality-assurance/linting-standards/","title":"Linting Standards","text":"<p>Enforce consistent code style, detect common errors, and maintain code quality through automated linting tools. Linting standards ensure codebase consistency, prevent bugs, and improve maintainability across all services.</p> <p>This document covers linting tool configuration for Python projects using Ruff, flake8, black, isort, and pre-commit hooks. Linting standards automate code quality checks and enforce team-wide consistency without manual review overhead.</p> <p>Linting tools validate code style (formatting, naming, imports), detect potential bugs (unused variables, undefined names), and enforce best practices (complexity limits, docstring requirements). These automated checks catch issues before code review.</p>"},{"location":"atomic/testing/quality-assurance/linting-standards/#recommended-tools","title":"Recommended Tools","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#primary-tools","title":"Primary Tools","text":"<ul> <li>Ruff: Fast all-in-one linter (replaces flake8, isort, pyupgrade, autoflake)</li> <li>Black: Opinionated code formatter</li> <li>mypy: Static type checker (see type-checking.md)</li> </ul>"},{"location":"atomic/testing/quality-assurance/linting-standards/#legacy-tools-being-replaced-by-ruff","title":"Legacy Tools (Being Replaced by Ruff)","text":"<ul> <li>flake8: Style guide enforcement (being replaced by Ruff)</li> <li>isort: Import sorting (being replaced by Ruff)</li> <li>pylint: Comprehensive linter (optional, slower than Ruff)</li> </ul>"},{"location":"atomic/testing/quality-assurance/linting-standards/#ruff-configuration","title":"Ruff Configuration","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#installation","title":"Installation","text":"<pre><code>pip install ruff==0.1.9\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#configuration-file","title":"Configuration File","text":"<pre><code># pyproject.toml\n[tool.ruff]\ntarget-version = \"py312\"\nline-length = 100\nfix = true\n\n# Enable rule categories\nselect = [\n    \"E\",     # pycodestyle errors\n    \"W\",     # pycodestyle warnings\n    \"F\",     # pyflakes\n    \"I\",     # isort (import sorting)\n    \"N\",     # pep8-naming\n    \"UP\",    # pyupgrade\n    \"YTT\",   # flake8-2020\n    \"S\",     # flake8-bandit (security)\n    \"B\",     # flake8-bugbear\n    \"C4\",    # flake8-comprehensions\n    \"DTZ\",   # flake8-datetimez\n    \"T10\",   # flake8-debugger\n    \"EM\",    # flake8-errmsg\n    \"ISC\",   # flake8-implicit-str-concat\n    \"ICN\",   # flake8-import-conventions\n    \"G\",     # flake8-logging-format\n    \"PIE\",   # flake8-pie\n    \"T20\",   # flake8-print\n    \"PT\",    # flake8-pytest-style\n    \"Q\",     # flake8-quotes\n    \"RET\",   # flake8-return\n    \"SIM\",   # flake8-simplify\n    \"TCH\",   # flake8-type-checking\n    \"ARG\",   # flake8-unused-arguments\n    \"PTH\",   # flake8-use-pathlib\n    \"ERA\",   # eradicate (commented code)\n    \"PL\",    # pylint\n    \"TRY\",   # tryceratops\n    \"RUF\",   # Ruff-specific rules\n]\n\n# Ignore specific rules\nignore = [\n    \"E501\",   # Line too long (handled by formatter)\n    \"S101\",   # Use of assert (OK in tests)\n    \"PLR0913\", # Too many arguments (sometimes necessary)\n]\n\n[tool.ruff.per-file-ignores]\n# Ignore specific rules in tests\n\"tests/**/*.py\" = [\n    \"S101\",    # assert usage\n    \"PLR2004\", # magic values\n    \"ARG\",     # unused arguments\n]\n\n# Ignore import rules in __init__.py\n\"**/__init__.py\" = [\"F401\"]\n\n[tool.ruff.isort]\nknown-first-party = [\"finance_lending_api\", \"finance_data_postgres_api\"]\nforce-single-line = false\nsplit-on-trailing-comma = true\n\n[tool.ruff.mccabe]\nmax-complexity = 10\n\n[tool.ruff.pylint]\nmax-args = 7\nmax-branches = 12\nmax-returns = 6\nmax-statements = 50\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#running-ruff","title":"Running Ruff","text":"<pre><code># Check code\nruff check src/ tests/\n\n# Auto-fix issues\nruff check --fix src/ tests/\n\n# Format code\nruff format src/ tests/\n\n# Check specific file\nruff check src/services/user_service.py\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#black-configuration","title":"Black Configuration","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#installation_1","title":"Installation","text":"<pre><code>pip install black==24.1.0\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#configuration","title":"Configuration","text":"<pre><code># pyproject.toml\n[tool.black]\nline-length = 100\ntarget-version = [\"py312\"]\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n    \\.git\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#running-black","title":"Running Black","text":"<pre><code># Format all code\nblack src/ tests/\n\n# Check without modifying\nblack --check src/ tests/\n\n# Format specific file\nblack src/services/user_service.py\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#pre-commit-hooks","title":"Pre-commit Hooks","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#setup","title":"Setup","text":"<pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#configuration_1","title":"Configuration","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      # Run linter\n      - id: ruff\n        args: [--fix, --exit-non-zero-on-fix]\n      # Run formatter\n      - id: ruff-format\n\n  - repo: https://github.com/psf/black\n    rev: 24.1.0\n    hooks:\n      - id: black\n        language_version: python3.12\n\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-toml\n      - id: check-added-large-files\n        args: [--maxkb=1000]\n      - id: check-merge-conflict\n      - id: debug-statements\n\n  - repo: https://github.com/pycqa/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        args: [\"-c\", \"pyproject.toml\", \"-r\", \"src\"]\n        additional_dependencies: [\"bandit[toml]\"]\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#running-pre-commit","title":"Running Pre-commit","text":"<pre><code># Run on all files\npre-commit run --all-files\n\n# Run specific hook\npre-commit run ruff --all-files\n\n# Skip hooks for emergency commit\ngit commit --no-verify -m \"Emergency fix\"\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/lint.yml\nname: Lint\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install ruff==0.1.9 black==24.1.0\n\n      - name: Run Ruff\n        run: ruff check src/ tests/\n\n      - name: Run Black\n        run: black --check src/ tests/\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#makefile-commands","title":"Makefile Commands","text":"<pre><code># Makefile\n.PHONY: lint format check\n\nlint:\n    @echo \"Running linters...\"\n    ruff check src/ tests/\n    black --check src/ tests/\n\nformat:\n    @echo \"Formatting code...\"\n    ruff check --fix src/ tests/\n    black src/ tests/\n\ncheck: lint\n    @echo \"All checks passed!\"\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#common-linting-rules","title":"Common Linting Rules","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#code-style-rules","title":"Code Style Rules","text":"<pre><code># CORRECT: Follow PEP 8 naming conventions\nclass UserService:\n    \"\"\"Service for user management.\"\"\"\n\n    def get_user_by_id(self, user_id: str) -&gt; User:\n        \"\"\"Get user by ID.\"\"\"\n        return self.repository.find_by_id(user_id)\n\n\n# INCORRECT: Inconsistent naming\nclass userService:  # Class names should be PascalCase\n    def GetUserByID(self, UserID):  # Methods should be snake_case\n        return self.Repository.findByID(UserID)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#import-organization","title":"Import Organization","text":"<pre><code># CORRECT: Imports organized by Ruff/isort\nimport asyncio\nimport json\nfrom typing import Optional\n\nimport httpx\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\nfrom finance_lending_api.config import settings\nfrom finance_lending_api.services.user_service import UserService\n\n\n# INCORRECT: Disorganized imports\nfrom finance_lending_api.services.user_service import UserService\nimport json\nfrom fastapi import FastAPI, HTTPException\nimport asyncio\nfrom pydantic import BaseModel\nimport httpx\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#line-length","title":"Line Length","text":"<pre><code># CORRECT: Lines under 100 characters\nuser = UserService().get_user_by_email(\n    email=user_email,\n    include_loans=True,\n    include_transactions=True\n)\n\n\n# INCORRECT: Line too long\nuser = UserService().get_user_by_email(email=user_email, include_loans=True, include_transactions=True, include_profile=True)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#complexity-limits","title":"Complexity Limits","text":"<pre><code># CORRECT: Low complexity function\ndef process_loan_application(loan: Loan) -&gt; LoanDecision:\n    \"\"\"Process loan application.\"\"\"\n    if not loan.is_valid():\n        return LoanDecision.rejected(\"Invalid loan data\")\n\n    credit_score = get_credit_score(loan.user_id)\n    if credit_score &lt; settings.MIN_CREDIT_SCORE:\n        return LoanDecision.rejected(\"Insufficient credit score\")\n\n    return LoanDecision.approved()\n\n\n# INCORRECT: High complexity (McCabe &gt; 10)\ndef process_loan_application_complex(loan):\n    if loan.amount &gt; 50000:\n        if loan.credit_score &gt; 750:\n            if loan.income &gt; 100000:\n                if loan.debt_ratio &lt; 0.3:\n                    return \"approved\"\n    # ... many more nested conditions\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#exception-to-rules","title":"Exception to Rules","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#allowed-in-tests","title":"Allowed in Tests","text":"<pre><code># OK: Magic numbers in tests\nassert response.status_code == 201  # OK\nassert len(users) == 5  # OK\n\n# OK: Long lines in parametrize\n@pytest.mark.parametrize(\n    \"email,password,expected_status\",\n    [\n        (\"user1@test.com\", \"pass123\", 200),  # OK: test data\n        (\"user2@test.com\", \"pass456\", 200),\n        (\"invalid-email\", \"pass789\", 422),\n    ]\n)\ndef test_login(email, password, expected_status):\n    ...\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#allowed-in-configuration","title":"Allowed in Configuration","text":"<pre><code># OK: Long URLs in settings\nDATABASE_URL = \"postgresql+asyncpg://user:password@localhost:5432/dbname?pool_size=20&amp;max_overflow=10\"  # noqa: E501\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/quality-assurance/linting-standards/#do-fix-issues-incrementally","title":"DO: Fix Issues Incrementally","text":"<pre><code># CORRECT: Fix one rule at a time\nruff check --select F --fix src/\nruff check --select E --fix src/\nruff check --select I --fix src/\n\n\n# INCORRECT: Don't ignore all issues\n# pyproject.toml\n[tool.ruff]\nignore = [\"E\", \"F\", \"I\", \"N\", \"UP\", \"S\", \"B\"]  # Too permissive\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#do-use-noqa-sparingly","title":"DO: Use noqa Sparingly","text":"<pre><code># CORRECT: Justified noqa comment\nlong_url = \"https://api.example.com/v1/users?include=profile,loans,transactions\"  # noqa: E501\n\n# INCORRECT: Overusing noqa\ndef bad_function():  # noqa\n    x = 1  # noqa\n    return x  # noqa\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#dont-commit-unformatted-code","title":"DON'T: Commit Unformatted Code","text":"<pre><code># CORRECT: Format before commit\ngit add src/\nmake format\ngit commit -m \"Add feature\"\n\n\n# INCORRECT: Skip formatting\ngit commit --no-verify -m \"Quick fix\"  # Skips pre-commit hooks\n</code></pre>"},{"location":"atomic/testing/quality-assurance/linting-standards/#checklist","title":"Checklist","text":"<ul> <li> Install Ruff and Black</li> <li> Configure pyproject.toml with project-specific rules</li> <li> Set up pre-commit hooks</li> <li> Configure CI/CD linting checks</li> <li> Run linters before committing code</li> <li> Fix linting issues incrementally</li> <li> Document exceptions with noqa comments</li> <li> Keep line length under 100 characters</li> <li> Organize imports consistently</li> <li> Limit function complexity (McCabe &lt; 10)</li> <li> Use meaningful variable names</li> <li> Remove commented-out code</li> </ul>"},{"location":"atomic/testing/quality-assurance/linting-standards/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/quality-assurance/type-checking.md</code> \u2014 Static type checking with mypy</li> <li><code>docs/atomic/testing/quality-assurance/code-review-checklist.md</code> \u2014 Code review guidelines</li> <li><code>docs/atomic/architecture/code-organization.md</code> \u2014 Project structure standards</li> </ul>"},{"location":"atomic/testing/quality-assurance/type-checking/","title":"Type Checking","text":"<p>Catch type errors before runtime using static type analysis with mypy. Type checking validates function signatures, variable types, and return values to prevent TypeError exceptions and improve code reliability.</p> <p>This document covers mypy configuration, type hint best practices, gradual typing strategies, and CI/CD integration. Type checking provides early error detection, better IDE support, and improved code documentation.</p> <p>Type checking validates that function arguments match expected types, return types match declarations, and type conversions are safe. These static checks catch bugs during development that would otherwise cause runtime errors in production.</p>"},{"location":"atomic/testing/quality-assurance/type-checking/#installation-and-setup","title":"Installation and Setup","text":"<pre><code># Install mypy\npip install mypy==1.8.0\n\n# Install type stubs for third-party libraries\npip install types-redis types-aiofiles types-PyYAML\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#mypy-configuration","title":"Mypy Configuration","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#pyprojecttoml-configuration","title":"pyproject.toml Configuration","text":"<pre><code># pyproject.toml\n[tool.mypy]\npython_version = \"3.12\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_any_unimported = false\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\nwarn_unreachable = true\nstrict_equality = true\nstrict_concatenate = true\n\n# Per-module options\n[[tool.mypy.overrides]]\nmodule = \"tests.*\"\ndisallow_untyped_defs = false\n\n[[tool.mypy.overrides]]\nmodule = \"third_party_lib.*\"\nignore_missing_imports = true\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#running-mypy","title":"Running Mypy","text":"<pre><code># Check entire project\nmypy src/\n\n# Check specific file\nmypy src/services/user_service.py\n\n# Check with strict mode\nmypy --strict src/\n\n# Generate HTML report\nmypy src/ --html-report mypy-report/\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#type-hints-basics","title":"Type Hints Basics","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#function-annotations","title":"Function Annotations","text":"<pre><code># CORRECT: All function signatures typed\ndef get_user_by_id(user_id: str) -&gt; User:\n    \"\"\"Get user by ID.\"\"\"\n    return repository.find_by_id(user_id)\n\n\nasync def create_user(email: str, name: str) -&gt; User:\n    \"\"\"Create new user.\"\"\"\n    user = User(email=email, name=name)\n    await repository.save(user)\n    return user\n\n\ndef process_loan(loan: Loan, approved: bool) -&gt; LoanDecision:\n    \"\"\"Process loan application.\"\"\"\n    if approved:\n        return LoanDecision(status=\"approved\", loan=loan)\n    return LoanDecision(status=\"rejected\", loan=loan)\n\n\n# INCORRECT: Missing type hints\ndef get_user_by_id(user_id):  # Missing parameter and return types\n    return repository.find_by_id(user_id)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#variable-annotations","title":"Variable Annotations","text":"<pre><code>from typing import Optional, List, Dict\n\n# CORRECT: Explicit type annotations\nuser_id: str = \"user-123\"\nusers: List[User] = []\ncache: Dict[str, User] = {}\ncurrent_user: Optional[User] = None\n\n\n# Type annotation without assignment\nloan_decision: LoanDecision\nif approved:\n    loan_decision = LoanDecision(status=\"approved\")\nelse:\n    loan_decision = LoanDecision(status=\"rejected\")\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#advanced-type-hints","title":"Advanced Type Hints","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#optional-and-union-types","title":"Optional and Union Types","text":"<pre><code>from typing import Optional, Union\n\n# CORRECT: Use Optional for nullable values\ndef get_user(user_id: str) -&gt; Optional[User]:\n    \"\"\"Return user or None if not found.\"\"\"\n    return repository.find_by_id(user_id)\n\n\n# CORRECT: Use Union for multiple possible types\ndef parse_user_id(value: Union[str, int]) -&gt; str:\n    \"\"\"Accept string or int, return string.\"\"\"\n    return str(value)\n\n\n# Python 3.12+ syntax (preferred)\ndef get_user_new(user_id: str) -&gt; User | None:\n    \"\"\"Return user or None if not found.\"\"\"\n    return repository.find_by_id(user_id)\n\n\ndef parse_user_id_new(value: str | int) -&gt; str:\n    \"\"\"Accept string or int, return string.\"\"\"\n    return str(value)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#generic-types","title":"Generic Types","text":"<pre><code>from typing import TypeVar, Generic, List\n\nT = TypeVar('T')\n\n\nclass Repository(Generic[T]):\n    \"\"\"Generic repository.\"\"\"\n\n    def find_by_id(self, id: str) -&gt; Optional[T]:\n        \"\"\"Find entity by ID.\"\"\"\n        ...\n\n    def find_all(self) -&gt; List[T]:\n        \"\"\"Find all entities.\"\"\"\n        ...\n\n\n# Usage\nuser_repo: Repository[User] = Repository()\nloan_repo: Repository[Loan] = Repository()\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#protocol-and-structural-typing","title":"Protocol and Structural Typing","text":"<pre><code>from typing import Protocol\n\nclass Cacheable(Protocol):\n    \"\"\"Protocol for cacheable objects.\"\"\"\n\n    def cache_key(self) -&gt; str:\n        \"\"\"Return cache key for this object.\"\"\"\n        ...\n\n\ndef cache_object(obj: Cacheable) -&gt; None:\n    \"\"\"Cache any object implementing Cacheable protocol.\"\"\"\n    key = obj.cache_key()\n    redis.set(key, serialize(obj))\n\n\n# Any class with cache_key() method satisfies the protocol\nclass User:\n    def cache_key(self) -&gt; str:\n        return f\"user:{self.id}\"\n\n\ncache_object(User())  # Type checks!\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#literal-and-typeddict","title":"Literal and TypedDict","text":"<pre><code>from typing import Literal, TypedDict\n\n# Literal types for constrained strings\nLoanStatus = Literal[\"pending\", \"approved\", \"rejected\"]\n\ndef update_loan_status(loan_id: str, status: LoanStatus) -&gt; None:\n    \"\"\"Update loan status.\"\"\"\n    # mypy enforces only these three values\n    repository.update(loan_id, status=status)\n\n\n# TypedDict for structured dictionaries\nclass UserDict(TypedDict):\n    id: str\n    email: str\n    name: str\n    verified: bool\n\n\ndef create_user_from_dict(data: UserDict) -&gt; User:\n    \"\"\"Create user from dictionary.\"\"\"\n    return User(\n        id=data[\"id\"],\n        email=data[\"email\"],\n        name=data[\"name\"],\n        verified=data[\"verified\"]\n    )\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#async-type-hints","title":"Async Type Hints","text":"<pre><code>from typing import Awaitable\n\n# CORRECT: Async function return types\nasync def fetch_user(user_id: str) -&gt; User:\n    \"\"\"Fetch user asynchronously.\"\"\"\n    response = await http_client.get(f\"/users/{user_id}\")\n    return User.parse(response.json())\n\n\n# Async generator\nasync def stream_users() -&gt; AsyncIterator[User]:\n    \"\"\"Stream users from database.\"\"\"\n    async for row in database.stream(\"SELECT * FROM users\"):\n        yield User.from_row(row)\n\n\n# Function that returns awaitable\ndef get_user_async(user_id: str) -&gt; Awaitable[User]:\n    \"\"\"Return awaitable user.\"\"\"\n    return fetch_user(user_id)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#common-patterns","title":"Common Patterns","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#class-attributes-and-methods","title":"Class Attributes and Methods","text":"<pre><code>from typing import ClassVar\n\nclass UserService:\n    \"\"\"User service with typed attributes.\"\"\"\n\n    max_retries: ClassVar[int] = 3  # Class variable\n    _instance: ClassVar[Optional['UserService']] = None  # Singleton\n\n    def __init__(self, repository: UserRepository) -&gt; None:\n        self.repository: UserRepository = repository\n        self.cache: Dict[str, User] = {}\n\n    @classmethod\n    def get_instance(cls) -&gt; 'UserService':\n        \"\"\"Get singleton instance.\"\"\"\n        if cls._instance is None:\n            cls._instance = cls(UserRepository())\n        return cls._instance\n\n    def get_user(self, user_id: str) -&gt; Optional[User]:\n        \"\"\"Get user from cache or repository.\"\"\"\n        if user_id in self.cache:\n            return self.cache[user_id]\n        return self.repository.find_by_id(user_id)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#callbacks-and-callables","title":"Callbacks and Callables","text":"<pre><code>from typing import Callable\n\n# Function taking a callback\ndef process_users(\n    users: List[User],\n    callback: Callable[[User], None]\n) -&gt; None:\n    \"\"\"Process each user with callback.\"\"\"\n    for user in users:\n        callback(user)\n\n\n# Function returning a function\ndef create_validator(\n    min_length: int\n) -&gt; Callable[[str], bool]:\n    \"\"\"Create validator function.\"\"\"\n    def validator(value: str) -&gt; bool:\n        return len(value) &gt;= min_length\n    return validator\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#gradual-typing","title":"Gradual Typing","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#adding-types-incrementally","title":"Adding Types Incrementally","text":"<pre><code># Step 1: Start with `# type: ignore`\ndef legacy_function(data):  # type: ignore\n    \"\"\"Legacy function without types.\"\"\"\n    return process(data)\n\n\n# Step 2: Add basic type hints\ndef legacy_function(data: dict) -&gt; dict:\n    \"\"\"Function with basic types.\"\"\"\n    return process(data)\n\n\n# Step 3: Add specific types\ndef legacy_function(data: UserDict) -&gt; ProcessedData:\n    \"\"\"Function with specific types.\"\"\"\n    return process(data)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#handling-untyped-libraries","title":"Handling Untyped Libraries","text":"<pre><code>from typing import Any\n\n# CORRECT: Type third-party libraries without stubs\nimport untyped_library  # type: ignore\n\ndef use_untyped_lib(data: str) -&gt; Any:\n    \"\"\"Use library without type stubs.\"\"\"\n    return untyped_library.process(data)\n\n\n# CORRECT: Create stub files for common libraries\n# stubs/untyped_library.pyi\ndef process(data: str) -&gt; dict: ...\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/type-check.yml\nname: Type Check\n\non: [push, pull_request]\n\njobs:\n  mypy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install mypy==1.8.0\n          pip install types-redis types-aiofiles\n\n      - name: Run mypy\n        run: mypy src/ --strict\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#makefile-integration","title":"Makefile Integration","text":"<pre><code># Makefile\n.PHONY: typecheck\n\ntypecheck:\n    @echo \"Running type checks...\"\n    mypy src/ tests/\n\ntypecheck-strict:\n    @echo \"Running strict type checks...\"\n    mypy src/ --strict\n\ntypecheck-report:\n    @echo \"Generating type check report...\"\n    mypy src/ --html-report mypy-report/\n    @echo \"Report generated in mypy-report/index.html\"\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#do-type-all-public-apis","title":"DO: Type All Public APIs","text":"<pre><code># CORRECT: All public functions typed\ndef create_loan(\n    user_id: str,\n    amount: int,\n    purpose: str,\n    term_months: int\n) -&gt; Loan:\n    \"\"\"Create loan application.\"\"\"\n    return Loan(\n        user_id=user_id,\n        amount=amount,\n        purpose=purpose,\n        term_months=term_months\n    )\n\n\n# INCORRECT: Missing types on public function\ndef create_loan(user_id, amount, purpose, term_months):\n    \"\"\"WRONG: Public API without types.\"\"\"\n    return Loan(...)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#do-use-specific-types","title":"DO: Use Specific Types","text":"<pre><code># CORRECT: Specific types\nfrom typing import List, Dict\n\ndef get_user_loans(user_id: str) -&gt; List[Loan]:\n    \"\"\"Return list of user's loans.\"\"\"\n    return repository.find_loans_by_user(user_id)\n\ndef get_loan_stats() -&gt; Dict[str, int]:\n    \"\"\"Return loan statistics.\"\"\"\n    return {\"total\": 100, \"pending\": 20, \"approved\": 80}\n\n\n# INCORRECT: Using `Any` unnecessarily\nfrom typing import Any\n\ndef get_user_loans(user_id: str) -&gt; Any:  # Too vague\n    return repository.find_loans_by_user(user_id)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#dont-overuse-any","title":"DON'T: Overuse <code>Any</code>","text":"<pre><code>from typing import Any\n\n# INCORRECT: Any defeats the purpose of type checking\ndef process_data(data: Any) -&gt; Any:\n    \"\"\"WRONG: No type safety.\"\"\"\n    return transform(data)\n\n\n# CORRECT: Specific types or generics\nfrom typing import TypeVar\n\nT = TypeVar('T')\n\ndef process_data(data: T) -&gt; T:\n    \"\"\"Preserve input type.\"\"\"\n    return transform(data)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#common-mypy-errors","title":"Common mypy Errors","text":""},{"location":"atomic/testing/quality-assurance/type-checking/#fixing-incompatible-return-value-type","title":"Fixing \"Incompatible return value type\"","text":"<pre><code># ERROR: Incompatible return value type (got \"None\", expected \"User\")\ndef get_user(user_id: str) -&gt; User:\n    user = repository.find_by_id(user_id)\n    if user is None:\n        return None  # ERROR: Can't return None\n\n\n# FIX: Use Optional\ndef get_user(user_id: str) -&gt; Optional[User]:\n    return repository.find_by_id(user_id)\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#fixing-cannot-determine-type","title":"Fixing \"Cannot determine type\"","text":"<pre><code># ERROR: Cannot determine type of 'users'\nusers = []  # mypy doesn't know the type\n\n\n# FIX: Annotate variable\nusers: List[User] = []\n</code></pre>"},{"location":"atomic/testing/quality-assurance/type-checking/#checklist","title":"Checklist","text":"<ul> <li> Install mypy and type stubs</li> <li> Configure mypy in pyproject.toml</li> <li> Add type hints to all function signatures</li> <li> Use Optional for nullable return values</li> <li> Use specific types instead of <code>Any</code></li> <li> Type all public API functions</li> <li> Use Protocol for duck typing</li> <li> Add mypy to pre-commit hooks</li> <li> Integrate type checking in CI/CD</li> <li> Fix mypy errors incrementally</li> <li> Document type ignore comments</li> <li> Use strict mode for new code</li> </ul>"},{"location":"atomic/testing/quality-assurance/type-checking/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/quality-assurance/linting-standards.md</code> \u2014 Code linting with Ruff</li> <li><code>docs/atomic/testing/quality-assurance/code-review-checklist.md</code> \u2014 Code review guidelines</li> <li><code>docs/atomic/architecture/code-organization.md</code> \u2014 Project structure standards</li> </ul>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/","title":"Aiogram Service Testing Patterns","text":"<p>Test Aiogram bot handlers, FSM states, middleware, and filters to verify message processing, state transitions, and callback handling without connecting to real Telegram servers. Service-level bot tests validate business logic and user interaction flows in isolation.</p> <p>This document covers testing patterns for Aiogram 3.x bots using pytest-aiogram, mocking Telegram API calls, testing FSM state machines, handler validation, and middleware verification. Aiogram service tests ensure your bot responds correctly to user interactions.</p> <p>Testing Aiogram bots validates that handlers process messages correctly, FSM transitions work as expected, filters match appropriate updates, and keyboard interactions trigger correct responses. These tests run quickly while providing confidence in bot behavior.</p>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#basic-test-setup","title":"Basic Test Setup","text":"<pre><code># tests/service/test_bot_handlers.py\nimport pytest\nfrom aiogram import Bot, Dispatcher\nfrom aiogram.fsm.storage.memory import MemoryStorage\nfrom aiogram.types import Message, User, Chat\nfrom aiogram.enums import ChatType\nfrom unittest.mock import AsyncMock\n\n\n@pytest.fixture\ndef bot():\n    \"\"\"Provide mocked bot instance.\"\"\"\n    bot = Bot(token=\"TEST_TOKEN:test\")\n    bot.session = AsyncMock()\n    return bot\n\n\n@pytest.fixture\ndef dispatcher():\n    \"\"\"Provide dispatcher with memory storage.\"\"\"\n    storage = MemoryStorage()\n    dp = Dispatcher(storage=storage)\n    # Register handlers here\n    return dp\n\n\n@pytest.fixture\ndef user():\n    \"\"\"Provide test user.\"\"\"\n    return User(\n        id=123456789,\n        is_bot=False,\n        first_name=\"Test\",\n        last_name=\"User\",\n        username=\"testuser\",\n        language_code=\"en\"\n    )\n\n\n@pytest.fixture\ndef chat():\n    \"\"\"Provide test chat.\"\"\"\n    return Chat(\n        id=123456789,\n        type=ChatType.PRIVATE\n    )\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#mocking-message-objects","title":"Mocking Message Objects","text":"<pre><code># CORRECT: Create mock Message for testing\ndef create_message(text: str, user: User, chat: Chat, bot: Bot) -&gt; Message:\n    \"\"\"Create Message object for testing.\"\"\"\n    return Message(\n        message_id=1,\n        date=1234567890,\n        chat=chat,\n        from_user=user,\n        text=text,\n        bot=bot\n    )\n\n\n# CORRECT: Helper for quick message creation\n@pytest.fixture\ndef message_factory(bot, user, chat):\n    \"\"\"Provide factory for creating test messages.\"\"\"\n    def _create(text: str) -&gt; Message:\n        return create_message(text=text, user=user, chat=chat, bot=bot)\n    return _create\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-message-handlers","title":"Testing Message Handlers","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#basic-command-handlers","title":"Basic Command Handlers","text":"<pre><code># src/handlers/start.py\nfrom aiogram import Router\nfrom aiogram.filters import Command\nfrom aiogram.types import Message\n\nrouter = Router()\n\n\n@router.message(Command(\"start\"))\nasync def cmd_start(message: Message) -&gt; None:\n    \"\"\"Handle /start command.\"\"\"\n    await message.answer(f\"Welcome, {message.from_user.first_name}!\")\n\n\n# CORRECT: Test command handler\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_start_command(bot, user, chat, message_factory):\n    \"\"\"Test /start command sends welcome message.\"\"\"\n    from src.handlers.start import cmd_start\n\n    # Create message\n    message = message_factory(\"/start\")\n    message.answer = AsyncMock()\n\n    # Call handler\n    await cmd_start(message)\n\n    # Verify response\n    message.answer.assert_called_once()\n    call_args = message.answer.call_args[1] if message.answer.call_args[1] else {}\n    response_text = message.answer.call_args[0][0] if message.answer.call_args[0] else call_args.get(\"text\", \"\")\n    assert \"Welcome\" in response_text\n    assert user.first_name in response_text\n\n\n# CORRECT: Test command with parameters\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_help_command(message_factory):\n    \"\"\"Test /help command returns help text.\"\"\"\n    from src.handlers.help import cmd_help\n\n    message = message_factory(\"/help\")\n    message.answer = AsyncMock()\n\n    await cmd_help(message)\n\n    message.answer.assert_called_once()\n    response_text = message.answer.call_args[0][0]\n    assert \"Available commands\" in response_text\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#text-message-handlers","title":"Text Message Handlers","text":"<pre><code># CORRECT: Test text message handler\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_echo_handler(message_factory):\n    \"\"\"Test echo handler repeats message.\"\"\"\n    from src.handlers.echo import echo_handler\n\n    message = message_factory(\"Hello, bot!\")\n    message.answer = AsyncMock()\n\n    await echo_handler(message)\n\n    message.answer.assert_called_once_with(\"You said: Hello, bot!\")\n\n\n# CORRECT: Test message with specific content\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_loan_request_handler(message_factory):\n    \"\"\"Test loan request extracts amount.\"\"\"\n    from src.handlers.loans import handle_loan_request\n\n    message = message_factory(\"I need a loan of $5000\")\n    message.answer = AsyncMock()\n\n    await handle_loan_request(message)\n\n    message.answer.assert_called_once()\n    response = message.answer.call_args[0][0]\n    assert \"5000\" in response\n    assert \"loan application\" in response.lower()\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-fsm-finite-state-machine","title":"Testing FSM (Finite State Machine)","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#fsm-state-testing","title":"FSM State Testing","text":"<pre><code># src/states/loan_application.py\nfrom aiogram.fsm.state import State, StatesGroup\n\n\nclass LoanApplicationStates(StatesGroup):\n    \"\"\"States for loan application flow.\"\"\"\n    waiting_for_amount = State()\n    waiting_for_purpose = State()\n    waiting_for_confirmation = State()\n\n\n# CORRECT: Test FSM state transitions\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_loan_application_flow(bot, user, chat, message_factory):\n    \"\"\"Test complete loan application FSM flow.\"\"\"\n    from aiogram.fsm.context import FSMContext\n    from aiogram.fsm.storage.memory import MemoryStorage\n    from src.handlers.loan import start_loan_application, process_loan_amount, process_loan_purpose\n\n    storage = MemoryStorage()\n    state = FSMContext(storage=storage, key=f\"user:{user.id}:chat:{chat.id}\")\n\n    # Step 1: Start application\n    message = message_factory(\"/apply_loan\")\n    message.answer = AsyncMock()\n    await start_loan_application(message, state)\n\n    # Verify state transition\n    current_state = await state.get_state()\n    assert current_state == LoanApplicationStates.waiting_for_amount.state\n\n    # Step 2: Provide amount\n    message = message_factory(\"10000\")\n    message.answer = AsyncMock()\n    await process_loan_amount(message, state)\n\n    # Verify data stored and state updated\n    data = await state.get_data()\n    assert data[\"amount\"] == 10000\n    current_state = await state.get_state()\n    assert current_state == LoanApplicationStates.waiting_for_purpose.state\n\n    # Step 3: Provide purpose\n    message = message_factory(\"Business expansion\")\n    message.answer = AsyncMock()\n    await process_loan_purpose(message, state)\n\n    # Verify completion\n    data = await state.get_data()\n    assert data[\"purpose\"] == \"Business expansion\"\n\n\n# CORRECT: Test FSM cancellation\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_cancel_fsm(message_factory):\n    \"\"\"Test cancelling FSM flow.\"\"\"\n    from aiogram.fsm.context import FSMContext\n    from aiogram.fsm.storage.memory import MemoryStorage\n    from src.handlers.common import cmd_cancel\n\n    storage = MemoryStorage()\n    state = FSMContext(storage=storage, key=\"test:123\")\n\n    # Set initial state\n    await state.set_state(LoanApplicationStates.waiting_for_amount)\n\n    # Cancel\n    message = message_factory(\"/cancel\")\n    message.answer = AsyncMock()\n    await cmd_cancel(message, state)\n\n    # Verify state cleared\n    current_state = await state.get_state()\n    assert current_state is None\n\n    # Verify confirmation message\n    message.answer.assert_called_once()\n    response = message.answer.call_args[0][0]\n    assert \"cancelled\" in response.lower()\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-callback-query-handlers","title":"Testing Callback Query Handlers","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#inline-keyboard-callbacks","title":"Inline Keyboard Callbacks","text":"<pre><code># CORRECT: Test callback query handler\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_callback_approve_loan(bot, user):\n    \"\"\"Test loan approval callback.\"\"\"\n    from aiogram.types import CallbackQuery, Message as Msg\n    from src.handlers.loan import callback_approve_loan\n\n    # Create callback query\n    callback = CallbackQuery(\n        id=\"callback-123\",\n        from_user=user,\n        message=Msg(\n            message_id=1,\n            date=1234567890,\n            chat=Chat(id=user.id, type=ChatType.PRIVATE),\n            text=\"Approve this loan?\",\n            bot=bot\n        ),\n        data=\"approve_loan:12345\",\n        chat_instance=\"test\"\n    )\n    callback.answer = AsyncMock()\n    callback.message.edit_text = AsyncMock()\n\n    # Call handler\n    await callback_approve_loan(callback)\n\n    # Verify callback answered\n    callback.answer.assert_called_once()\n\n    # Verify message edited\n    callback.message.edit_text.assert_called_once()\n    edit_text = callback.message.edit_text.call_args[0][0]\n    assert \"approved\" in edit_text.lower()\n\n\n# CORRECT: Test callback with data extraction\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_callback_select_option(bot, user):\n    \"\"\"Test callback extracts option from data.\"\"\"\n    from aiogram.types import CallbackQuery, Message as Msg\n    from src.handlers.menu import callback_select_option\n\n    callback = CallbackQuery(\n        id=\"cb-456\",\n        from_user=user,\n        message=Msg(\n            message_id=2,\n            date=1234567890,\n            chat=Chat(id=user.id, type=ChatType.PRIVATE),\n            text=\"Select an option:\",\n            bot=bot\n        ),\n        data=\"option:premium\",\n        chat_instance=\"test\"\n    )\n    callback.answer = AsyncMock()\n    callback.message.answer = AsyncMock()\n\n    await callback_select_option(callback)\n\n    # Verify correct option processed\n    callback.message.answer.assert_called_once()\n    response = callback.message.answer.call_args[0][0]\n    assert \"premium\" in response.lower()\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-filters","title":"Testing Filters","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#custom-filter-testing","title":"Custom Filter Testing","text":"<pre><code># src/filters/user_role.py\nfrom aiogram.filters import Filter\nfrom aiogram.types import Message\n\n\nclass IsAdminFilter(Filter):\n    \"\"\"Filter messages from admin users.\"\"\"\n\n    async def __call__(self, message: Message) -&gt; bool:\n        \"\"\"Check if user is admin.\"\"\"\n        admin_ids = [111111, 222222, 333333]\n        return message.from_user.id in admin_ids\n\n\n# CORRECT: Test custom filter\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_admin_filter_accepts_admin(bot, chat):\n    \"\"\"Test admin filter accepts admin users.\"\"\"\n    from src.filters.user_role import IsAdminFilter\n\n    # Admin user\n    admin_user = User(id=111111, is_bot=False, first_name=\"Admin\")\n    message = create_message(\"test\", admin_user, chat, bot)\n\n    filter_instance = IsAdminFilter()\n    result = await filter_instance(message)\n\n    assert result is True\n\n\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_admin_filter_rejects_regular_user(bot, user, chat):\n    \"\"\"Test admin filter rejects regular users.\"\"\"\n    from src.filters.user_role import IsAdminFilter\n\n    # Regular user (ID not in admin list)\n    message = create_message(\"test\", user, chat, bot)\n\n    filter_instance = IsAdminFilter()\n    result = await filter_instance(message)\n\n    assert result is False\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-middleware","title":"Testing Middleware","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#custom-middleware-testing","title":"Custom Middleware Testing","text":"<pre><code># src/middleware/logging.py\nfrom typing import Callable, Dict, Any, Awaitable\nfrom aiogram import BaseMiddleware\nfrom aiogram.types import Message\n\n\nclass LoggingMiddleware(BaseMiddleware):\n    \"\"\"Middleware to log all messages.\"\"\"\n\n    async def __call__(\n        self,\n        handler: Callable[[Message, Dict[str, Any]], Awaitable[Any]],\n        event: Message,\n        data: Dict[str, Any]\n    ) -&gt; Any:\n        \"\"\"Log message before and after processing.\"\"\"\n        print(f\"Received: {event.text}\")\n        result = await handler(event, data)\n        print(f\"Processed: {event.text}\")\n        return result\n\n\n# CORRECT: Test middleware\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_logging_middleware(bot, user, chat, capsys):\n    \"\"\"Test logging middleware logs messages.\"\"\"\n    from src.middleware.logging import LoggingMiddleware\n\n    middleware = LoggingMiddleware()\n    message = create_message(\"test message\", user, chat, bot)\n\n    # Mock handler\n    async def mock_handler(event: Message, data: dict) -&gt; None:\n        await event.answer(\"Response\")\n\n    # Call middleware\n    await middleware(mock_handler, message, {})\n\n    # Verify logs\n    captured = capsys.readouterr()\n    assert \"Received: test message\" in captured.out\n    assert \"Processed: test message\" in captured.out\n\n\n# CORRECT: Test middleware modifies data\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_user_enrichment_middleware(bot, user, chat):\n    \"\"\"Test middleware enriches handler data.\"\"\"\n    from src.middleware.user_enrichment import UserEnrichmentMiddleware\n\n    middleware = UserEnrichmentMiddleware()\n    message = create_message(\"test\", user, chat, bot)\n\n    handler_data = {}\n\n    async def mock_handler(event: Message, data: dict) -&gt; None:\n        # Capture data passed to handler\n        handler_data.update(data)\n\n    await middleware(mock_handler, message, {})\n\n    # Verify data enriched\n    assert \"user_profile\" in handler_data\n    assert handler_data[\"user_profile\"][\"user_id\"] == user.id\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-keyboards","title":"Testing Keyboards","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#inline-keyboard-testing","title":"Inline Keyboard Testing","text":"<pre><code># CORRECT: Test inline keyboard generation\n@pytest.mark.service\ndef test_create_approval_keyboard():\n    \"\"\"Test approval keyboard has correct buttons.\"\"\"\n    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton\n    from src.keyboards.loan import create_approval_keyboard\n\n    keyboard = create_approval_keyboard(loan_id=\"loan-123\")\n\n    assert isinstance(keyboard, InlineKeyboardMarkup)\n    assert len(keyboard.inline_keyboard) == 1  # One row\n    assert len(keyboard.inline_keyboard[0]) == 2  # Two buttons\n\n    # Check button data\n    approve_button = keyboard.inline_keyboard[0][0]\n    reject_button = keyboard.inline_keyboard[0][1]\n\n    assert approve_button.text == \"\u2705 Approve\"\n    assert approve_button.callback_data == \"approve_loan:loan-123\"\n\n    assert reject_button.text == \"\u274c Reject\"\n    assert reject_button.callback_data == \"reject_loan:loan-123\"\n\n\n# CORRECT: Test reply keyboard\n@pytest.mark.service\ndef test_create_main_menu_keyboard():\n    \"\"\"Test main menu keyboard.\"\"\"\n    from aiogram.types import ReplyKeyboardMarkup\n    from src.keyboards.main_menu import create_main_menu\n\n    keyboard = create_main_menu()\n\n    assert isinstance(keyboard, ReplyKeyboardMarkup)\n    assert len(keyboard.keyboard) &gt;= 2  # At least 2 rows\n\n    # Verify buttons exist\n    all_buttons = [btn.text for row in keyboard.keyboard for btn in row]\n    assert \"\ud83d\udcdd Apply for Loan\" in all_buttons\n    assert \"\ud83d\udcca My Loans\" in all_buttons\n    assert \"\u2139\ufe0f Help\" in all_buttons\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#testing-bot-integration","title":"Testing Bot Integration","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#full-handler-registration","title":"Full Handler Registration","text":"<pre><code># CORRECT: Test dispatcher with registered handlers\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_dispatcher_routes_command(bot, user, chat, message_factory):\n    \"\"\"Test dispatcher routes command to correct handler.\"\"\"\n    from aiogram import Dispatcher\n    from aiogram.fsm.storage.memory import MemoryStorage\n    from src.handlers import register_handlers\n\n    # Create dispatcher\n    storage = MemoryStorage()\n    dp = Dispatcher(storage=storage)\n    register_handlers(dp)\n\n    # Create message\n    message = message_factory(\"/start\")\n    message.answer = AsyncMock()\n\n    # Process update\n    await dp.feed_update(bot, {\"message\": message.model_dump(mode=\"json\")})\n\n    # Verify handler called\n    message.answer.assert_called()\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#do-mock-telegram-api-calls","title":"DO: Mock Telegram API Calls","text":"<pre><code># CORRECT: Mock bot API methods\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_with_mocked_bot_methods(bot, user, chat):\n    \"\"\"Mock bot.send_message to test handler.\"\"\"\n    from src.handlers.notification import send_notification\n\n    bot.send_message = AsyncMock()\n\n    await send_notification(bot, user_id=user.id, text=\"Test notification\")\n\n    bot.send_message.assert_called_once_with(\n        chat_id=user.id,\n        text=\"Test notification\"\n    )\n\n\n# INCORRECT: Don't call real Telegram API\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_without_mocking():\n    \"\"\"WRONG: Calls real Telegram API.\"\"\"\n    real_bot = Bot(token=\"REAL_TOKEN\")\n    # This will make real API call\n    await real_bot.send_message(chat_id=123, text=\"test\")\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#do-test-state-transitions","title":"DO: Test State Transitions","text":"<pre><code># CORRECT: Verify FSM state changes\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_state_transitions():\n    \"\"\"Test FSM transitions through states.\"\"\"\n    from aiogram.fsm.context import FSMContext\n    from aiogram.fsm.storage.memory import MemoryStorage\n    from src.states.registration import RegistrationStates\n\n    storage = MemoryStorage()\n    state = FSMContext(storage=storage, key=\"test:123\")\n\n    # Initial state\n    await state.set_state(RegistrationStates.waiting_for_name)\n    assert await state.get_state() == RegistrationStates.waiting_for_name.state\n\n    # Transition\n    await state.set_state(RegistrationStates.waiting_for_email)\n    assert await state.get_state() == RegistrationStates.waiting_for_email.state\n\n    # Clear state\n    await state.clear()\n    assert await state.get_state() is None\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#dont-test-multiple-handlers-together","title":"DON'T: Test Multiple Handlers Together","text":"<pre><code># INCORRECT: Testing multiple handlers in one test\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_multiple_handlers_together(message_factory):\n    \"\"\"WRONG: Tests multiple handlers at once.\"\"\"\n    msg1 = message_factory(\"/start\")\n    await cmd_start(msg1)\n\n    msg2 = message_factory(\"/help\")\n    await cmd_help(msg2)\n\n    # Hard to debug which handler failed\n\n\n# CORRECT: Test each handler separately\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_start_handler_alone(message_factory):\n    \"\"\"Test only start handler.\"\"\"\n    message = message_factory(\"/start\")\n    message.answer = AsyncMock()\n    await cmd_start(message)\n    # Clear assertions\n\n\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_help_handler_alone(message_factory):\n    \"\"\"Test only help handler.\"\"\"\n    message = message_factory(\"/help\")\n    message.answer = AsyncMock()\n    await cmd_help(message)\n    # Clear assertions\n</code></pre>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#checklist","title":"Checklist","text":"<ul> <li> Test all bot commands (/start, /help, custom commands)</li> <li> Test message handlers (text, photos, documents)</li> <li> Test callback query handlers</li> <li> Test FSM state transitions and data storage</li> <li> Test custom filters accept/reject correctly</li> <li> Test middleware modifies data as expected</li> <li> Test keyboard generation (inline and reply)</li> <li> Mock all Telegram API calls (don't call real API)</li> <li> Test error handling in handlers</li> <li> Use <code>@pytest.mark.service</code> to mark service tests</li> <li> Clean up FSM state after tests</li> </ul>"},{"location":"atomic/testing/service-testing/aiogram-testing-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies with AsyncMock</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Pytest fixture patterns for bot testing</li> <li><code>docs/atomic/services/aiogram-service/handler-patterns.md</code> \u2014 Aiogram handler implementation</li> <li><code>docs/atomic/services/aiogram-service/fsm-patterns.md</code> \u2014 FSM state machine patterns</li> <li><code>docs/atomic/services/aiogram-service/middleware-patterns.md</code> \u2014 Custom middleware implementation</li> </ul>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/","title":"AsyncIO Service Testing Patterns","text":"<p>Test AsyncIO workers, background tasks, concurrent operations, and event-driven patterns to verify task execution, cancellation handling, queue processing, and timeout behavior. Service-level AsyncIO tests validate worker logic and concurrent processing without running production event loops.</p> <p>This document covers testing patterns for AsyncIO-based worker services using pytest-asyncio, testing background task execution, concurrent operations, queue processing, and resource cleanup. AsyncIO service tests ensure your workers handle tasks correctly under async conditions.</p> <p>Testing AsyncIO workers validates that tasks execute correctly, cancellation is handled gracefully, queues process messages reliably, and timeouts prevent hanging operations. These tests run quickly while providing confidence in async worker behavior.</p>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#basic-asyncio-test-setup","title":"Basic AsyncIO Test Setup","text":"<pre><code># tests/service/test_worker.py\nimport pytest\nimport asyncio\nfrom unittest.mock import AsyncMock, Mock\n\n\n# CORRECT: Mark async tests\n@pytest.mark.asyncio\nasync def test_async_function():\n    \"\"\"Test async function executes correctly.\"\"\"\n    result = await some_async_function()\n    assert result == expected_value\n\n\n# CORRECT: Use pytest-asyncio fixtures\n@pytest.fixture\nasync def async_client():\n    \"\"\"Provide async client with cleanup.\"\"\"\n    client = AsyncClient()\n    await client.connect()\n    yield client\n    await client.disconnect()\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#configuring-pytest-asyncio","title":"Configuring pytest-asyncio","text":"<pre><code># pytest.ini\n[pytest]\nasyncio_mode = auto\nmarkers =\n    asyncio: mark test as requiring asyncio\n    service: mark test as service-level test\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-async-functions","title":"Testing Async Functions","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#basic-async-function-testing","title":"Basic Async Function Testing","text":"<pre><code># CORRECT: Test async function\n@pytest.mark.asyncio\nasync def test_fetch_user_data():\n    \"\"\"Test async function fetches user data.\"\"\"\n    from finance_lending_worker.services.user_service import fetch_user_data\n\n    user_data = await fetch_user_data(user_id=\"user-123\")\n\n    assert user_data[\"id\"] == \"user-123\"\n    assert \"email\" in user_data\n    assert \"credit_score\" in user_data\n\n\n# CORRECT: Test async function with mocked dependencies\n@pytest.mark.asyncio\nasync def test_fetch_user_data_mocked():\n    \"\"\"Test async function with mocked HTTP client.\"\"\"\n    from finance_lending_worker.services.user_service import UserService\n    from unittest.mock import AsyncMock\n\n    mock_http_client = AsyncMock()\n    mock_http_client.get.return_value = {\"id\": \"user-123\", \"email\": \"test@example.com\"}\n\n    service = UserService(http_client=mock_http_client)\n    user_data = await service.fetch_user_data(\"user-123\")\n\n    assert user_data[\"id\"] == \"user-123\"\n    mock_http_client.get.assert_called_once_with(\"/users/user-123\")\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-async-exceptions","title":"Testing Async Exceptions","text":"<pre><code># CORRECT: Test async function raises exception\n@pytest.mark.asyncio\nasync def test_fetch_user_not_found():\n    \"\"\"Test async function raises exception for missing user.\"\"\"\n    from finance_lending_worker.services.user_service import fetch_user_data, UserNotFoundError\n\n    with pytest.raises(UserNotFoundError, match=\"user-999\"):\n        await fetch_user_data(user_id=\"user-999\")\n\n\n# CORRECT: Test async function error handling\n@pytest.mark.asyncio\nasync def test_fetch_user_handles_http_error():\n    \"\"\"Test async function handles HTTP errors gracefully.\"\"\"\n    from finance_lending_worker.services.user_service import UserService\n    from unittest.mock import AsyncMock\n    import httpx\n\n    mock_client = AsyncMock()\n    mock_client.get.side_effect = httpx.HTTPStatusError(\n        message=\"Not Found\",\n        request=Mock(),\n        response=Mock(status_code=404)\n    )\n\n    service = UserService(http_client=mock_client)\n\n    with pytest.raises(httpx.HTTPStatusError):\n        await service.fetch_user_data(\"user-123\")\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-background-tasks","title":"Testing Background Tasks","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#task-execution-testing","title":"Task Execution Testing","text":"<pre><code># CORRECT: Test background task execution\n@pytest.mark.asyncio\nasync def test_background_task_processes_job():\n    \"\"\"Test background task processes job correctly.\"\"\"\n    from finance_lending_worker.tasks.loan_processor import process_loan_application\n\n    job_data = {\n        \"loan_id\": \"loan-123\",\n        \"user_id\": \"user-456\",\n        \"amount\": 10000\n    }\n\n    result = await process_loan_application(job_data)\n\n    assert result[\"status\"] == \"completed\"\n    assert result[\"loan_id\"] == \"loan-123\"\n\n\n# CORRECT: Test task with multiple operations\n@pytest.mark.asyncio\nasync def test_background_task_workflow():\n    \"\"\"Test background task executes full workflow.\"\"\"\n    from finance_lending_worker.tasks.onboarding import onboard_new_user\n    from unittest.mock import AsyncMock\n\n    mock_db = AsyncMock()\n    mock_email = AsyncMock()\n\n    await onboard_new_user(\n        user_id=\"user-123\",\n        email=\"newuser@example.com\",\n        db=mock_db,\n        email_service=mock_email\n    )\n\n    # Verify all steps executed\n    mock_db.create_user_profile.assert_called_once()\n    mock_email.send_welcome_email.assert_called_once()\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-task-cancellation","title":"Testing Task Cancellation","text":"<pre><code># CORRECT: Test task cancellation handling\n@pytest.mark.asyncio\nasync def test_task_handles_cancellation():\n    \"\"\"Test task cleans up on cancellation.\"\"\"\n    import asyncio\n    from finance_lending_worker.tasks.long_running import process_large_dataset\n\n    cleanup_called = []\n\n    async def monitored_task():\n        try:\n            await process_large_dataset()\n        except asyncio.CancelledError:\n            cleanup_called.append(True)\n            raise\n\n    task = asyncio.create_task(monitored_task())\n\n    # Let task start\n    await asyncio.sleep(0.1)\n\n    # Cancel task\n    task.cancel()\n\n    with pytest.raises(asyncio.CancelledError):\n        await task\n\n    # Verify cleanup executed\n    assert len(cleanup_called) == 1\n\n\n# CORRECT: Test graceful shutdown\n@pytest.mark.asyncio\nasync def test_worker_graceful_shutdown():\n    \"\"\"Test worker shuts down gracefully.\"\"\"\n    from finance_lending_worker.worker import Worker\n\n    worker = Worker()\n    worker_task = asyncio.create_task(worker.run())\n\n    # Let worker start\n    await asyncio.sleep(0.1)\n\n    # Request shutdown\n    await worker.shutdown()\n\n    # Verify worker stopped\n    await asyncio.wait_for(worker_task, timeout=5)\n    assert worker.is_stopped()\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-concurrent-operations","title":"Testing Concurrent Operations","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#parallel-task-execution","title":"Parallel Task Execution","text":"<pre><code># CORRECT: Test concurrent task execution\n@pytest.mark.asyncio\nasync def test_process_multiple_jobs_concurrently():\n    \"\"\"Test worker processes multiple jobs in parallel.\"\"\"\n    from finance_lending_worker.tasks.processor import process_jobs\n\n    jobs = [\n        {\"id\": \"job-1\", \"data\": \"task1\"},\n        {\"id\": \"job-2\", \"data\": \"task2\"},\n        {\"id\": \"job-3\", \"data\": \"task3\"},\n    ]\n\n    results = await process_jobs(jobs, max_concurrent=3)\n\n    assert len(results) == 3\n    assert all(r[\"status\"] == \"completed\" for r in results)\n\n\n# CORRECT: Test asyncio.gather for concurrent operations\n@pytest.mark.asyncio\nasync def test_gather_multiple_operations():\n    \"\"\"Test gathering results from concurrent operations.\"\"\"\n    from finance_lending_worker.services.data_fetcher import fetch_user, fetch_loans, fetch_credit_score\n\n    user_id = \"user-123\"\n\n    # Execute concurrently\n    user, loans, credit_score = await asyncio.gather(\n        fetch_user(user_id),\n        fetch_loans(user_id),\n        fetch_credit_score(user_id)\n    )\n\n    assert user[\"id\"] == user_id\n    assert isinstance(loans, list)\n    assert isinstance(credit_score, int)\n\n\n# CORRECT: Test error handling in concurrent tasks\n@pytest.mark.asyncio\nasync def test_gather_handles_partial_failure():\n    \"\"\"Test gather with return_exceptions handles failures.\"\"\"\n    from finance_lending_worker.services.api_client import call_api\n\n    results = await asyncio.gather(\n        call_api(\"endpoint1\"),  # Succeeds\n        call_api(\"failing_endpoint\"),  # Fails\n        call_api(\"endpoint3\"),  # Succeeds\n        return_exceptions=True\n    )\n\n    # First and third succeed, second is exception\n    assert results[0][\"status\"] == \"ok\"\n    assert isinstance(results[1], Exception)\n    assert results[2][\"status\"] == \"ok\"\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-timeouts","title":"Testing Timeouts","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#operation-timeout-testing","title":"Operation Timeout Testing","text":"<pre><code># CORRECT: Test operation respects timeout\n@pytest.mark.asyncio\nasync def test_fetch_with_timeout():\n    \"\"\"Test operation times out after limit.\"\"\"\n    from finance_lending_worker.services.api_client import fetch_data_with_timeout\n    import asyncio\n\n    with pytest.raises(asyncio.TimeoutError):\n        await fetch_data_with_timeout(url=\"http://slow-api.com\", timeout=1)\n\n\n# CORRECT: Test timeout with asyncio.wait_for\n@pytest.mark.asyncio\nasync def test_wait_for_timeout():\n    \"\"\"Test asyncio.wait_for enforces timeout.\"\"\"\n    async def slow_operation():\n        await asyncio.sleep(10)\n        return \"result\"\n\n    with pytest.raises(asyncio.TimeoutError):\n        await asyncio.wait_for(slow_operation(), timeout=1)\n\n\n# CORRECT: Test timeout with fallback\n@pytest.mark.asyncio\nasync def test_operation_with_timeout_fallback():\n    \"\"\"Test operation falls back on timeout.\"\"\"\n    from finance_lending_worker.services.cache import get_cached_or_fetch\n\n    async def slow_fetch():\n        await asyncio.sleep(10)\n        return \"fresh data\"\n\n    result = await get_cached_or_fetch(\n        key=\"user:123\",\n        fetch_func=slow_fetch,\n        timeout=1,\n        fallback=\"cached data\"\n    )\n\n    assert result == \"cached data\"\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-asyncio-queues","title":"Testing AsyncIO Queues","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#queue-processing-testing","title":"Queue Processing Testing","text":"<pre><code># CORRECT: Test queue consumer\n@pytest.mark.asyncio\nasync def test_queue_consumer_processes_messages():\n    \"\"\"Test queue consumer processes all messages.\"\"\"\n    from finance_lending_worker.queue.consumer import consume_queue\n    import asyncio\n\n    queue = asyncio.Queue()\n    processed = []\n\n    async def processor(item):\n        processed.append(item)\n\n    # Add items to queue\n    for i in range(5):\n        await queue.put(f\"message-{i}\")\n\n    # Add sentinel to stop consumer\n    await queue.put(None)\n\n    # Consume queue\n    await consume_queue(queue, processor)\n\n    assert len(processed) == 5\n    assert processed[0] == \"message-0\"\n    assert processed[4] == \"message-4\"\n\n\n# CORRECT: Test queue producer-consumer pattern\n@pytest.mark.asyncio\nasync def test_producer_consumer_pattern():\n    \"\"\"Test producer-consumer queue pattern.\"\"\"\n    import asyncio\n\n    queue = asyncio.Queue(maxsize=10)\n    consumed = []\n\n    async def producer():\n        for i in range(5):\n            await queue.put(f\"item-{i}\")\n            await asyncio.sleep(0.01)\n        await queue.put(None)  # Sentinel\n\n    async def consumer():\n        while True:\n            item = await queue.get()\n            if item is None:\n                break\n            consumed.append(item)\n            queue.task_done()\n\n    await asyncio.gather(producer(), consumer())\n\n    assert len(consumed) == 5\n    assert queue.empty()\n\n\n# CORRECT: Test queue with timeout\n@pytest.mark.asyncio\nasync def test_queue_get_with_timeout():\n    \"\"\"Test queue.get with timeout.\"\"\"\n    import asyncio\n\n    queue = asyncio.Queue()\n\n    with pytest.raises(asyncio.TimeoutError):\n        await asyncio.wait_for(queue.get(), timeout=1)\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-locks-and-synchronization","title":"Testing Locks and Synchronization","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#lock-testing","title":"Lock Testing","text":"<pre><code># CORRECT: Test asyncio.Lock prevents concurrent access\n@pytest.mark.asyncio\nasync def test_lock_prevents_concurrent_access():\n    \"\"\"Test lock prevents concurrent resource access.\"\"\"\n    import asyncio\n\n    lock = asyncio.Lock()\n    access_log = []\n\n    async def access_resource(worker_id: int):\n        async with lock:\n            access_log.append(f\"start-{worker_id}\")\n            await asyncio.sleep(0.1)\n            access_log.append(f\"end-{worker_id}\")\n\n    # Run 3 workers concurrently\n    await asyncio.gather(\n        access_resource(1),\n        access_resource(2),\n        access_resource(3)\n    )\n\n    # Verify no overlap (start/end pairs are sequential)\n    assert access_log[0] == \"start-1\"\n    assert access_log[1] == \"end-1\"\n    assert access_log[2] == \"start-2\"\n    assert access_log[3] == \"end-2\"\n\n\n# CORRECT: Test semaphore limits concurrent access\n@pytest.mark.asyncio\nasync def test_semaphore_limits_concurrency():\n    \"\"\"Test semaphore limits concurrent operations.\"\"\"\n    import asyncio\n\n    semaphore = asyncio.Semaphore(2)  # Max 2 concurrent\n    active_count = []\n    max_active = 0\n\n    async def worker(worker_id: int):\n        nonlocal max_active\n        async with semaphore:\n            active_count.append(worker_id)\n            max_active = max(max_active, len(active_count))\n            await asyncio.sleep(0.1)\n            active_count.remove(worker_id)\n\n    # Run 5 workers\n    await asyncio.gather(*[worker(i) for i in range(5)])\n\n    # Verify max 2 concurrent\n    assert max_active == 2\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-event-driven-patterns","title":"Testing Event-Driven Patterns","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#asyncio-event-testing","title":"AsyncIO Event Testing","text":"<pre><code># CORRECT: Test asyncio.Event coordination\n@pytest.mark.asyncio\nasync def test_event_coordinates_tasks():\n    \"\"\"Test asyncio.Event coordinates task execution.\"\"\"\n    import asyncio\n\n    ready_event = asyncio.Event()\n    results = []\n\n    async def waiter(worker_id: int):\n        await ready_event.wait()\n        results.append(f\"worker-{worker_id}\")\n\n    # Start waiters\n    tasks = [asyncio.create_task(waiter(i)) for i in range(3)]\n\n    # Let waiters start\n    await asyncio.sleep(0.1)\n\n    # No results yet\n    assert len(results) == 0\n\n    # Signal ready\n    ready_event.set()\n\n    # Wait for all tasks\n    await asyncio.gather(*tasks)\n\n    # All workers executed\n    assert len(results) == 3\n\n\n# CORRECT: Test condition variable\n@pytest.mark.asyncio\nasync def test_condition_variable():\n    \"\"\"Test asyncio.Condition for producer-consumer.\"\"\"\n    import asyncio\n\n    condition = asyncio.Condition()\n    items = []\n\n    async def producer():\n        async with condition:\n            items.append(\"item\")\n            condition.notify()\n\n    async def consumer():\n        async with condition:\n            await condition.wait()\n            return items.pop()\n\n    producer_task = asyncio.create_task(producer())\n    consumer_task = asyncio.create_task(consumer())\n\n    await asyncio.gather(producer_task, consumer_task)\n\n    item = consumer_task.result()\n    assert item == \"item\"\n    assert len(items) == 0\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#testing-worker-services","title":"Testing Worker Services","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#worker-lifecycle-testing","title":"Worker Lifecycle Testing","text":"<pre><code># CORRECT: Test worker startup and shutdown\n@pytest.mark.asyncio\nasync def test_worker_lifecycle():\n    \"\"\"Test worker starts and stops correctly.\"\"\"\n    from finance_lending_worker.worker import Worker\n\n    worker = Worker()\n\n    # Start worker\n    worker_task = asyncio.create_task(worker.run())\n    await asyncio.sleep(0.1)\n\n    assert worker.is_running()\n\n    # Stop worker\n    await worker.stop()\n    await worker_task\n\n    assert not worker.is_running()\n\n\n# CORRECT: Test worker processes jobs\n@pytest.mark.asyncio\nasync def test_worker_processes_jobs():\n    \"\"\"Test worker consumes and processes jobs.\"\"\"\n    from finance_lending_worker.worker import Worker\n    import asyncio\n\n    worker = Worker()\n    job_queue = asyncio.Queue()\n\n    # Add jobs\n    await job_queue.put({\"id\": \"job-1\", \"action\": \"process\"})\n    await job_queue.put({\"id\": \"job-2\", \"action\": \"process\"})\n    await job_queue.put(None)  # Stop signal\n\n    results = await worker.process_queue(job_queue)\n\n    assert len(results) == 2\n    assert results[0][\"id\"] == \"job-1\"\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#do-use-pytest-asyncio","title":"DO: Use pytest-asyncio","text":"<pre><code># CORRECT: Mark async tests properly\n@pytest.mark.asyncio\nasync def test_async_operation():\n    \"\"\"Use @pytest.mark.asyncio for async tests.\"\"\"\n    result = await async_function()\n    assert result is not None\n\n\n# INCORRECT: Don't use asyncio.run in pytest\ndef test_async_wrong():\n    \"\"\"WRONG: Don't use asyncio.run in pytest.\"\"\"\n    # This creates a new event loop, causing issues\n    result = asyncio.run(async_function())\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#do-test-cancellation-handling","title":"DO: Test Cancellation Handling","text":"<pre><code># CORRECT: Test graceful cancellation\n@pytest.mark.asyncio\nasync def test_cancellation_cleanup():\n    \"\"\"Test task cleans up on cancellation.\"\"\"\n    cleanup_done = []\n\n    async def task_with_cleanup():\n        try:\n            await asyncio.sleep(10)\n        except asyncio.CancelledError:\n            cleanup_done.append(True)\n            raise\n\n    task = asyncio.create_task(task_with_cleanup())\n    await asyncio.sleep(0.1)\n    task.cancel()\n\n    with pytest.raises(asyncio.CancelledError):\n        await task\n\n    assert len(cleanup_done) == 1\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#dont-block-the-event-loop","title":"DON'T: Block the Event Loop","text":"<pre><code># INCORRECT: Don't use blocking sleep\n@pytest.mark.asyncio\nasync def test_with_blocking_sleep():\n    \"\"\"WRONG: Blocks event loop.\"\"\"\n    import time\n    time.sleep(1)  # Blocks event loop!\n    result = await async_operation()\n\n\n# CORRECT: Use asyncio.sleep\n@pytest.mark.asyncio\nasync def test_with_async_sleep():\n    \"\"\"Use asyncio.sleep instead.\"\"\"\n    await asyncio.sleep(1)\n    result = await async_operation()\n</code></pre>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#checklist","title":"Checklist","text":"<ul> <li> Test async functions with await</li> <li> Test background task execution</li> <li> Test task cancellation handling</li> <li> Test concurrent operations with gather</li> <li> Test timeouts with asyncio.wait_for</li> <li> Test queue producer-consumer patterns</li> <li> Test locks and semaphores prevent races</li> <li> Test event coordination patterns</li> <li> Test worker lifecycle (start/stop)</li> <li> Use <code>@pytest.mark.asyncio</code> for async tests</li> <li> Mock async dependencies with AsyncMock</li> <li> Test exception handling in async code</li> </ul>"},{"location":"atomic/testing/service-testing/asyncio-testing-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking async functions with AsyncMock</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Async fixture patterns</li> <li><code>docs/atomic/services/asyncio-service/worker-patterns.md</code> \u2014 AsyncIO worker implementation</li> <li><code>docs/atomic/services/asyncio-service/task-management.md</code> \u2014 Background task patterns</li> <li><code>docs/atomic/services/asyncio-service/concurrency-patterns.md</code> \u2014 Concurrent execution patterns</li> </ul>"},{"location":"atomic/testing/service-testing/data-service-testing/","title":"Data Service Testing Patterns","text":"<p>Test data service HTTP endpoints to verify CRUD operations, query parameters, pagination, filtering, and error handling without connecting to external business services. Data service tests validate the HTTP API layer over PostgreSQL and MongoDB repositories in isolation.</p> <p>This document covers testing patterns for FastAPI data services (template_data_postgres_api, template_data_mongo_api) using TestClient, testing CRUD endpoints, query parameter validation, pagination, and database error handling. Data service tests ensure your HTTP layer correctly exposes database operations.</p> <p>Testing data services validates that endpoints handle requests correctly, repositories interact properly with databases, query parameters filter and paginate results, and errors return appropriate HTTP status codes. These tests bridge unit tests and integration tests by exercising the full HTTP request cycle with mocked or real databases.</p>"},{"location":"atomic/testing/service-testing/data-service-testing/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#basic-data-service-test-setup","title":"Basic Data Service Test Setup","text":"<pre><code># tests/service/test_data_service.py\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom httpx import AsyncClient\nfrom unittest.mock import AsyncMock\n\n\n@pytest.fixture\ndef test_client():\n    \"\"\"Provide TestClient for data service.\"\"\"\n    from finance_data_postgres_api.main import app\n    return TestClient(app)\n\n\n@pytest.fixture\nasync def async_client():\n    \"\"\"Provide AsyncClient for async tests.\"\"\"\n    from finance_data_postgres_api.main import app\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n\n\n@pytest.fixture\ndef mock_repository():\n    \"\"\"Provide mocked repository.\"\"\"\n    return AsyncMock()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#overriding-database-dependencies","title":"Overriding Database Dependencies","text":"<pre><code># CORRECT: Override database dependency\n@pytest.fixture\ndef client_with_mock_db(test_client):\n    \"\"\"Provide client with mocked database.\"\"\"\n    from finance_data_postgres_api.main import app\n    from finance_data_postgres_api.dependencies import get_db_session\n    from unittest.mock import AsyncMock\n\n    mock_db = AsyncMock()\n    app.dependency_overrides[get_db_session] = lambda: mock_db\n\n    yield test_client\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-crud-operations","title":"Testing CRUD Operations","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#create-post-endpoint-testing","title":"Create (POST) Endpoint Testing","text":"<pre><code># CORRECT: Test POST creates resource\n@pytest.mark.service\ndef test_create_user(test_client):\n    \"\"\"Test POST /users creates new user.\"\"\"\n    payload = {\n        \"email\": \"newuser@example.com\",\n        \"name\": \"New User\",\n        \"age\": 30\n    }\n\n    response = test_client.post(\"/api/users\", json=payload)\n\n    assert response.status_code == 201\n    created_user = response.json()\n    assert created_user[\"email\"] == payload[\"email\"]\n    assert created_user[\"name\"] == payload[\"name\"]\n    assert \"id\" in created_user\n    assert \"created_at\" in created_user\n\n\n# CORRECT: Test POST validation\n@pytest.mark.service\ndef test_create_user_validation_error(test_client):\n    \"\"\"Test POST with invalid data returns 422.\"\"\"\n    payload = {\n        \"email\": \"invalid-email\",\n        \"name\": \"\",\n        \"age\": -5\n    }\n\n    response = test_client.post(\"/api/users\", json=payload)\n\n    assert response.status_code == 422\n    errors = response.json()[\"detail\"]\n    error_fields = [e[\"loc\"][-1] for e in errors]\n    assert \"email\" in error_fields\n    assert \"name\" in error_fields\n    assert \"age\" in error_fields\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#read-get-endpoint-testing","title":"Read (GET) Endpoint Testing","text":"<pre><code># CORRECT: Test GET by ID\n@pytest.mark.service\ndef test_get_user_by_id(test_client):\n    \"\"\"Test GET /users/{id} returns user.\"\"\"\n    response = test_client.get(\"/api/users/user-123\")\n\n    assert response.status_code == 200\n    user = response.json()\n    assert user[\"id\"] == \"user-123\"\n    assert \"email\" in user\n    assert \"name\" in user\n\n\n# CORRECT: Test GET not found\n@pytest.mark.service\ndef test_get_user_not_found(test_client):\n    \"\"\"Test GET non-existent user returns 404.\"\"\"\n    response = test_client.get(\"/api/users/nonexistent\")\n\n    assert response.status_code == 404\n    error = response.json()\n    assert \"detail\" in error\n\n\n# CORRECT: Test GET list\n@pytest.mark.service\ndef test_list_users(test_client):\n    \"\"\"Test GET /users returns list.\"\"\"\n    response = test_client.get(\"/api/users\")\n\n    assert response.status_code == 200\n    data = response.json()\n    assert \"users\" in data\n    assert \"total\" in data\n    assert isinstance(data[\"users\"], list)\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#update-putpatch-endpoint-testing","title":"Update (PUT/PATCH) Endpoint Testing","text":"<pre><code># CORRECT: Test PUT updates entire resource\n@pytest.mark.service\ndef test_update_user_put(test_client):\n    \"\"\"Test PUT /users/{id} updates user.\"\"\"\n    payload = {\n        \"email\": \"updated@example.com\",\n        \"name\": \"Updated Name\",\n        \"age\": 35\n    }\n\n    response = test_client.put(\"/api/users/user-123\", json=payload)\n\n    assert response.status_code == 200\n    updated_user = response.json()\n    assert updated_user[\"email\"] == payload[\"email\"]\n    assert updated_user[\"name\"] == payload[\"name\"]\n    assert updated_user[\"age\"] == payload[\"age\"]\n\n\n# CORRECT: Test PATCH partial update\n@pytest.mark.service\ndef test_update_user_patch(test_client):\n    \"\"\"Test PATCH /users/{id} partial update.\"\"\"\n    payload = {\"name\": \"Only Name Changed\"}\n\n    response = test_client.patch(\"/api/users/user-123\", json=payload)\n\n    assert response.status_code == 200\n    user = response.json()\n    assert user[\"name\"] == \"Only Name Changed\"\n\n\n# CORRECT: Test update non-existent resource\n@pytest.mark.service\ndef test_update_nonexistent_user(test_client):\n    \"\"\"Test updating non-existent user returns 404.\"\"\"\n    payload = {\"name\": \"New Name\"}\n\n    response = test_client.patch(\"/api/users/nonexistent\", json=payload)\n\n    assert response.status_code == 404\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#delete-delete-endpoint-testing","title":"Delete (DELETE) Endpoint Testing","text":"<pre><code># CORRECT: Test DELETE removes resource\n@pytest.mark.service\ndef test_delete_user(test_client):\n    \"\"\"Test DELETE /users/{id} removes user.\"\"\"\n    response = test_client.delete(\"/api/users/user-123\")\n\n    assert response.status_code == 204\n\n    # Verify deletion\n    get_response = test_client.get(\"/api/users/user-123\")\n    assert get_response.status_code == 404\n\n\n# CORRECT: Test delete non-existent resource\n@pytest.mark.service\ndef test_delete_nonexistent_user(test_client):\n    \"\"\"Test deleting non-existent user returns 404.\"\"\"\n    response = test_client.delete(\"/api/users/nonexistent\")\n\n    assert response.status_code == 404\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-query-parameters","title":"Testing Query Parameters","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#filtering","title":"Filtering","text":"<pre><code># CORRECT: Test filtering by field\n@pytest.mark.service\ndef test_filter_users_by_status(test_client):\n    \"\"\"Test filtering users by status.\"\"\"\n    response = test_client.get(\"/api/users\", params={\"status\": \"active\"})\n\n    assert response.status_code == 200\n    data = response.json()\n    assert all(user[\"status\"] == \"active\" for user in data[\"users\"])\n\n\n# CORRECT: Test multiple filters\n@pytest.mark.service\ndef test_filter_users_multiple_criteria(test_client):\n    \"\"\"Test filtering with multiple criteria.\"\"\"\n    response = test_client.get(\"/api/users\", params={\n        \"status\": \"active\",\n        \"min_age\": 18,\n        \"max_age\": 65\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    for user in data[\"users\"]:\n        assert user[\"status\"] == \"active\"\n        assert 18 &lt;= user[\"age\"] &lt;= 65\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#sorting","title":"Sorting","text":"<pre><code># CORRECT: Test sorting by field\n@pytest.mark.service\ndef test_sort_users_by_name(test_client):\n    \"\"\"Test sorting users by name.\"\"\"\n    response = test_client.get(\"/api/users\", params={\"sort\": \"name\"})\n\n    assert response.status_code == 200\n    users = response.json()[\"users\"]\n\n    # Verify sorted order\n    names = [u[\"name\"] for u in users]\n    assert names == sorted(names)\n\n\n# CORRECT: Test descending sort\n@pytest.mark.service\ndef test_sort_users_descending(test_client):\n    \"\"\"Test sorting users in descending order.\"\"\"\n    response = test_client.get(\"/api/users\", params={\"sort\": \"-created_at\"})\n\n    assert response.status_code == 200\n    users = response.json()[\"users\"]\n\n    # Verify descending order\n    timestamps = [u[\"created_at\"] for u in users]\n    assert timestamps == sorted(timestamps, reverse=True)\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#pagination","title":"Pagination","text":"<pre><code># CORRECT: Test pagination\n@pytest.mark.service\ndef test_paginate_users(test_client):\n    \"\"\"Test pagination returns correct page.\"\"\"\n    response = test_client.get(\"/api/users\", params={\n        \"page\": 2,\n        \"per_page\": 10\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data[\"users\"]) &lt;= 10\n    assert data[\"page\"] == 2\n    assert data[\"per_page\"] == 10\n    assert \"total\" in data\n    assert \"pages\" in data\n\n\n# CORRECT: Test pagination boundaries\n@pytest.mark.service\ndef test_pagination_last_page(test_client):\n    \"\"\"Test pagination on last page with fewer items.\"\"\"\n    # Assuming 25 total users\n    response = test_client.get(\"/api/users\", params={\n        \"page\": 3,\n        \"per_page\": 10\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data[\"users\"]) == 5  # Last 5 items\n    assert data[\"total\"] == 25\n    assert data[\"pages\"] == 3\n\n\n# CORRECT: Test invalid page number\n@pytest.mark.service\ndef test_pagination_invalid_page(test_client):\n    \"\"\"Test requesting page beyond total returns empty.\"\"\"\n    response = test_client.get(\"/api/users\", params={\n        \"page\": 999,\n        \"per_page\": 10\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data[\"users\"]) == 0\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-postgresql-data-service","title":"Testing PostgreSQL Data Service","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#repository-integration-testing","title":"Repository Integration Testing","text":"<pre><code># CORRECT: Test endpoint with mocked repository\n@pytest.mark.service\ndef test_create_user_with_mock_repo():\n    \"\"\"Test create endpoint with mocked repository.\"\"\"\n    from fastapi.testclient import TestClient\n    from finance_data_postgres_api.main import app\n    from finance_data_postgres_api.dependencies import get_user_repository\n    from unittest.mock import AsyncMock\n\n    mock_repo = AsyncMock()\n    mock_repo.create.return_value = {\n        \"id\": \"user-123\",\n        \"email\": \"test@example.com\",\n        \"name\": \"Test User\"\n    }\n\n    app.dependency_overrides[get_user_repository] = lambda: mock_repo\n\n    client = TestClient(app)\n    response = client.post(\"/api/users\", json={\n        \"email\": \"test@example.com\",\n        \"name\": \"Test User\"\n    })\n\n    assert response.status_code == 201\n    mock_repo.create.assert_called_once()\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-unique-constraints","title":"Testing Unique Constraints","text":"<pre><code># CORRECT: Test unique constraint violation\n@pytest.mark.service\ndef test_create_duplicate_email(test_client):\n    \"\"\"Test creating user with duplicate email fails.\"\"\"\n    payload = {\"email\": \"duplicate@example.com\", \"name\": \"User 1\"}\n\n    # First create succeeds\n    response1 = test_client.post(\"/api/users\", json=payload)\n    assert response1.status_code == 201\n\n    # Second create fails (duplicate email)\n    response2 = test_client.post(\"/api/users\", json=payload)\n    assert response2.status_code == 409\n    error = response2.json()\n    assert \"already exists\" in error[\"detail\"].lower()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-mongodb-data-service","title":"Testing MongoDB Data Service","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#document-query-testing","title":"Document Query Testing","text":"<pre><code># CORRECT: Test MongoDB document filtering\n@pytest.mark.service\ndef test_filter_documents_by_field(test_client):\n    \"\"\"Test filtering MongoDB documents.\"\"\"\n    response = test_client.get(\"/api/documents\", params={\n        \"category\": \"finance\",\n        \"status\": \"published\"\n    })\n\n    assert response.status_code == 200\n    documents = response.json()[\"documents\"]\n    assert all(d[\"category\"] == \"finance\" for d in documents)\n    assert all(d[\"status\"] == \"published\" for d in documents)\n\n\n# CORRECT: Test MongoDB aggregation endpoint\n@pytest.mark.service\ndef test_aggregate_documents(test_client):\n    \"\"\"Test aggregation endpoint.\"\"\"\n    response = test_client.get(\"/api/documents/stats\", params={\n        \"group_by\": \"category\"\n    })\n\n    assert response.status_code == 200\n    stats = response.json()\n    assert \"categories\" in stats\n    for category_stat in stats[\"categories\"]:\n        assert \"category\" in category_stat\n        assert \"count\" in category_stat\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-nested-document-updates","title":"Testing Nested Document Updates","text":"<pre><code># CORRECT: Test updating nested document fields\n@pytest.mark.service\ndef test_update_nested_field(test_client):\n    \"\"\"Test updating nested document field.\"\"\"\n    payload = {\n        \"metadata.tags\": [\"updated\", \"finance\"],\n        \"metadata.priority\": \"high\"\n    }\n\n    response = test_client.patch(\"/api/documents/doc-123\", json=payload)\n\n    assert response.status_code == 200\n    document = response.json()\n    assert \"updated\" in document[\"metadata\"][\"tags\"]\n    assert document[\"metadata\"][\"priority\"] == \"high\"\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-error-handling","title":"Testing Error Handling","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#database-connection-errors","title":"Database Connection Errors","text":"<pre><code># CORRECT: Test database connection error handling\n@pytest.mark.service\ndef test_database_connection_error():\n    \"\"\"Test graceful handling of database connection errors.\"\"\"\n    from fastapi.testclient import TestClient\n    from finance_data_postgres_api.main import app\n    from finance_data_postgres_api.dependencies import get_db_session\n    from sqlalchemy.exc import OperationalError\n\n    async def failing_db_session():\n        raise OperationalError(\"Connection failed\", None, None)\n\n    app.dependency_overrides[get_db_session] = failing_db_session\n\n    client = TestClient(app)\n    response = client.get(\"/api/users\")\n\n    assert response.status_code == 503\n    error = response.json()\n    assert \"database\" in error[\"detail\"].lower()\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#validation-errors","title":"Validation Errors","text":"<pre><code># CORRECT: Test validation error responses\n@pytest.mark.service\ndef test_validation_error_format(test_client):\n    \"\"\"Test validation errors return detailed messages.\"\"\"\n    payload = {\n        \"email\": \"not-an-email\",\n        \"age\": \"not-a-number\"\n    }\n\n    response = test_client.post(\"/api/users\", json=payload)\n\n    assert response.status_code == 422\n    errors = response.json()[\"detail\"]\n\n    # Verify error structure\n    assert isinstance(errors, list)\n    for error in errors:\n        assert \"loc\" in error\n        assert \"msg\" in error\n        assert \"type\" in error\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#testing-transaction-handling","title":"Testing Transaction Handling","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#atomic-operations","title":"Atomic Operations","text":"<pre><code># CORRECT: Test transaction rollback on error\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_transaction_rollback():\n    \"\"\"Test transaction rolls back on error.\"\"\"\n    from finance_data_postgres_api.services.user_service import UserService\n    from unittest.mock import AsyncMock\n\n    mock_db = AsyncMock()\n    mock_db.commit.side_effect = Exception(\"Database error\")\n\n    service = UserService(db=mock_db)\n\n    with pytest.raises(Exception):\n        await service.create_user_with_profile(\n            email=\"test@example.com\",\n            name=\"Test User\"\n        )\n\n    # Verify rollback called\n    mock_db.rollback.assert_called_once()\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/service-testing/data-service-testing/#do-test-http-layer-only","title":"DO: Test HTTP Layer Only","text":"<pre><code># CORRECT: Test data service HTTP endpoints\n@pytest.mark.service\ndef test_endpoint_with_mocked_repo():\n    \"\"\"Test HTTP layer with mocked repository.\"\"\"\n    from finance_data_postgres_api.dependencies import get_user_repository\n    from unittest.mock import AsyncMock\n\n    mock_repo = AsyncMock()\n    mock_repo.get_by_id.return_value = {\"id\": \"123\", \"name\": \"Test\"}\n\n    app.dependency_overrides[get_user_repository] = lambda: mock_repo\n\n    response = test_client.get(\"/api/users/123\")\n    assert response.status_code == 200\n\n\n# INCORRECT: Don't test repository logic in service tests\n@pytest.mark.service\ndef test_repository_directly():\n    \"\"\"WRONG: Tests repository, not HTTP layer.\"\"\"\n    repo = UserRepository(session=db_session)\n    user = await repo.create(email=\"test@example.com\")\n    # This is integration testing, not service testing\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#do-test-all-http-status-codes","title":"DO: Test All HTTP Status Codes","text":"<pre><code># CORRECT: Test success and error responses\n@pytest.mark.service\ndef test_all_status_codes():\n    \"\"\"Test endpoint returns correct status codes.\"\"\"\n    # 200 OK\n    response = test_client.get(\"/api/users/existing\")\n    assert response.status_code == 200\n\n    # 404 Not Found\n    response = test_client.get(\"/api/users/nonexistent\")\n    assert response.status_code == 404\n\n    # 422 Validation Error\n    response = test_client.post(\"/api/users\", json={\"invalid\": \"data\"})\n    assert response.status_code == 422\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#dont-make-real-database-calls","title":"DON'T: Make Real Database Calls","text":"<pre><code># INCORRECT: Service test making real database calls\n@pytest.mark.service\nasync def test_with_real_database():\n    \"\"\"WRONG: Makes real database queries.\"\"\"\n    # This should be integration test, not service test\n    real_db = await create_real_db_connection()\n    await real_db.execute(\"INSERT INTO users...\")\n\n\n# CORRECT: Mock database dependencies\n@pytest.mark.service\ndef test_with_mocked_database():\n    \"\"\"Mock database for service tests.\"\"\"\n    mock_db = AsyncMock()\n    app.dependency_overrides[get_db_session] = lambda: mock_db\n    # Test HTTP layer only\n</code></pre>"},{"location":"atomic/testing/service-testing/data-service-testing/#checklist","title":"Checklist","text":"<ul> <li> Test all CRUD operations (POST, GET, PUT/PATCH, DELETE)</li> <li> Test query parameters (filtering, sorting, pagination)</li> <li> Test request validation with invalid data</li> <li> Test response serialization follows models</li> <li> Test error responses (404, 422, 500, 503)</li> <li> Test unique constraint violations</li> <li> Test database connection error handling</li> <li> Mock repositories and database sessions</li> <li> Test transaction rollback on errors</li> <li> Use <code>@pytest.mark.service</code> for service tests</li> <li> Clean up dependency overrides after tests</li> </ul>"},{"location":"atomic/testing/service-testing/data-service-testing/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 FastAPI testing patterns</li> <li><code>docs/atomic/testing/integration-testing/database-testing.md</code> \u2014 Integration tests with real databases</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking repositories and database sessions</li> <li><code>docs/atomic/services/fastapi-service/endpoint-patterns.md</code> \u2014 Data service endpoint implementation</li> <li><code>docs/atomic/databases/postgresql/repository-patterns.md</code> \u2014 PostgreSQL repository patterns</li> </ul>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/","title":"FastAPI Service Testing Patterns","text":"<p>Test FastAPI endpoints with TestClient to verify request handling, response serialization, dependency injection, middleware behavior, and error handling without running a live server. Service-level tests bridge unit tests and end-to-end tests by exercising the full request/response cycle.</p> <p>This document covers testing patterns for FastAPI applications using TestClient and pytest-asyncio, including endpoint testing, dependency overrides, lifespan event testing, middleware verification, and authentication. FastAPI service tests ensure your API behaves correctly under realistic conditions.</p> <p>Testing FastAPI services validates that routes handle requests correctly, dependencies inject properly, validation catches bad input, and error handlers return appropriate responses. These tests run quickly while providing confidence in your API's contract with clients.</p>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#basic-test-setup","title":"Basic Test Setup","text":"<pre><code># tests/service/test_api.py\nimport pytest\nfrom httpx import AsyncClient\nfrom fastapi.testclient import TestClient\nfrom finance_lending_api.main import app\n\n\n# CORRECT: Use TestClient for synchronous tests\n@pytest.mark.service\ndef test_health_endpoint_sync():\n    \"\"\"Test health check endpoint with TestClient.\"\"\"\n    client = TestClient(app)\n    response = client.get(\"/health\")\n\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"healthy\"}\n\n\n# CORRECT: Use AsyncClient for async tests\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_health_endpoint_async():\n    \"\"\"Test health check endpoint with AsyncClient.\"\"\"\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        response = await client.get(\"/health\")\n\n        assert response.status_code == 200\n        assert response.json() == {\"status\": \"healthy\"}\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#fixtures-for-fastapi-testing","title":"Fixtures for FastAPI Testing","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom httpx import AsyncClient\nfrom finance_lending_api.main import app\n\n\n@pytest.fixture\ndef test_client():\n    \"\"\"Provide TestClient for synchronous tests.\"\"\"\n    return TestClient(app)\n\n\n@pytest.fixture\nasync def async_client():\n    \"\"\"Provide AsyncClient for async tests.\"\"\"\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n\n\n@pytest.fixture\ndef override_dependencies():\n    \"\"\"Helper to override FastAPI dependencies.\"\"\"\n    overrides = {}\n\n    def _override(dependency, override_value):\n        app.dependency_overrides[dependency] = lambda: override_value\n        overrides[dependency] = override_value\n\n    yield _override\n\n    # Cleanup\n    for dependency in overrides:\n        app.dependency_overrides.pop(dependency, None)\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-endpoints","title":"Testing Endpoints","text":""},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#get-requests","title":"GET Requests","text":"<pre><code># CORRECT: Test GET endpoint with query parameters\n@pytest.mark.service\ndef test_list_users_with_filters(test_client):\n    \"\"\"Test listing users with query filters.\"\"\"\n    response = test_client.get(\"/api/users\", params={\n        \"status\": \"active\",\n        \"limit\": 10,\n        \"offset\": 0\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert \"users\" in data\n    assert \"total\" in data\n    assert len(data[\"users\"]) &lt;= 10\n\n\n# CORRECT: Test path parameters\n@pytest.mark.service\ndef test_get_user_by_id(test_client):\n    \"\"\"Test retrieving user by ID.\"\"\"\n    response = test_client.get(\"/api/users/user-123\")\n\n    assert response.status_code == 200\n    user = response.json()\n    assert user[\"id\"] == \"user-123\"\n    assert \"email\" in user\n    assert \"name\" in user\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#post-requests","title":"POST Requests","text":"<pre><code># CORRECT: Test POST with request body\n@pytest.mark.service\ndef test_create_user(test_client):\n    \"\"\"Test creating new user.\"\"\"\n    payload = {\n        \"email\": \"newuser@example.com\",\n        \"name\": \"New User\",\n        \"credit_score\": 750\n    }\n\n    response = test_client.post(\"/api/users\", json=payload)\n\n    assert response.status_code == 201\n    created_user = response.json()\n    assert created_user[\"email\"] == payload[\"email\"]\n    assert created_user[\"name\"] == payload[\"name\"]\n    assert \"id\" in created_user\n    assert \"created_at\" in created_user\n\n\n# CORRECT: Test validation errors\n@pytest.mark.service\ndef test_create_user_validation_error(test_client):\n    \"\"\"Test validation catches invalid data.\"\"\"\n    payload = {\n        \"email\": \"invalid-email\",  # Invalid format\n        \"name\": \"\",  # Empty string\n        \"credit_score\": -100  # Negative value\n    }\n\n    response = test_client.post(\"/api/users\", json=payload)\n\n    assert response.status_code == 422\n    errors = response.json()[\"detail\"]\n\n    # Check all validation errors present\n    error_fields = [e[\"loc\"][-1] for e in errors]\n    assert \"email\" in error_fields\n    assert \"name\" in error_fields\n    assert \"credit_score\" in error_fields\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#putpatch-requests","title":"PUT/PATCH Requests","text":"<pre><code># CORRECT: Test updating resource\n@pytest.mark.service\ndef test_update_user(test_client):\n    \"\"\"Test updating user fields.\"\"\"\n    update_payload = {\n        \"name\": \"Updated Name\",\n        \"credit_score\": 800\n    }\n\n    response = test_client.patch(\"/api/users/user-123\", json=update_payload)\n\n    assert response.status_code == 200\n    updated_user = response.json()\n    assert updated_user[\"name\"] == \"Updated Name\"\n    assert updated_user[\"credit_score\"] == 800\n\n\n# CORRECT: Test partial updates\n@pytest.mark.service\ndef test_partial_update_user(test_client):\n    \"\"\"Test partial update only changes specified fields.\"\"\"\n    response = test_client.patch(\n        \"/api/users/user-123\",\n        json={\"name\": \"Only Name Changed\"}\n    )\n\n    assert response.status_code == 200\n    user = response.json()\n    assert user[\"name\"] == \"Only Name Changed\"\n    # Other fields unchanged\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#delete-requests","title":"DELETE Requests","text":"<pre><code># CORRECT: Test resource deletion\n@pytest.mark.service\ndef test_delete_user(test_client):\n    \"\"\"Test deleting user.\"\"\"\n    response = test_client.delete(\"/api/users/user-123\")\n\n    assert response.status_code == 204\n\n    # Verify deletion\n    get_response = test_client.get(\"/api/users/user-123\")\n    assert get_response.status_code == 404\n\n\n# CORRECT: Test deleting non-existent resource\n@pytest.mark.service\ndef test_delete_nonexistent_user(test_client):\n    \"\"\"Test deleting non-existent user returns 404.\"\"\"\n    response = test_client.delete(\"/api/users/nonexistent\")\n    assert response.status_code == 404\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-dependencies","title":"Testing Dependencies","text":""},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#overriding-dependencies","title":"Overriding Dependencies","text":"<pre><code># src/dependencies.py\nfrom fastapi import Depends, HTTPException\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\n\nasync def get_db_session() -&gt; AsyncSession:\n    \"\"\"Provide database session.\"\"\"\n    # Production implementation\n    pass\n\n\nasync def get_current_user(token: str = Depends(get_token)) -&gt; dict:\n    \"\"\"Get authenticated user from token.\"\"\"\n    # Production implementation\n    pass\n\n\n# CORRECT: Override dependencies in tests\n@pytest.mark.service\ndef test_endpoint_with_mocked_db():\n    \"\"\"Test endpoint with mocked database dependency.\"\"\"\n    from finance_lending_api.main import app\n    from finance_lending_api.dependencies import get_db_session\n    from unittest.mock import AsyncMock\n\n    # Mock database session\n    mock_db = AsyncMock()\n    app.dependency_overrides[get_db_session] = lambda: mock_db\n\n    client = TestClient(app)\n    response = client.get(\"/api/users\")\n\n    assert response.status_code == 200\n\n    # Cleanup\n    app.dependency_overrides.clear()\n\n\n# CORRECT: Override authentication dependency\n@pytest.mark.service\ndef test_protected_endpoint_with_auth():\n    \"\"\"Test protected endpoint with mocked authentication.\"\"\"\n    from finance_lending_api.dependencies import get_current_user\n\n    mock_user = {\"id\": \"user-123\", \"email\": \"test@example.com\", \"role\": \"admin\"}\n    app.dependency_overrides[get_current_user] = lambda: mock_user\n\n    client = TestClient(app)\n    response = client.get(\"/api/protected/resource\")\n\n    assert response.status_code == 200\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#dependency-fixtures","title":"Dependency Fixtures","text":"<pre><code># CORRECT: Use fixtures to manage dependency overrides\n@pytest.fixture\ndef authenticated_client(test_client):\n    \"\"\"Provide client with authenticated user.\"\"\"\n    from finance_lending_api.dependencies import get_current_user\n\n    mock_user = {\"id\": \"user-123\", \"email\": \"test@example.com\"}\n    app.dependency_overrides[get_current_user] = lambda: mock_user\n\n    yield test_client\n\n    app.dependency_overrides.clear()\n\n\n@pytest.mark.service\ndef test_with_authenticated_client(authenticated_client):\n    \"\"\"Test using authenticated client fixture.\"\"\"\n    response = authenticated_client.get(\"/api/protected/data\")\n    assert response.status_code == 200\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-lifespan-events","title":"Testing Lifespan Events","text":"<pre><code># CORRECT: Test startup/shutdown events\n@pytest.mark.service\n@pytest.mark.asyncio\nasync def test_lifespan_events():\n    \"\"\"Test application lifespan events.\"\"\"\n    from contextlib import asynccontextmanager\n    from fastapi import FastAPI\n\n    startup_called = []\n    shutdown_called = []\n\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        # Startup\n        startup_called.append(True)\n        yield\n        # Shutdown\n        shutdown_called.append(True)\n\n    test_app = FastAPI(lifespan=lifespan)\n\n    @test_app.get(\"/test\")\n    async def test_endpoint():\n        return {\"status\": \"ok\"}\n\n    # Use AsyncClient to trigger lifespan\n    async with AsyncClient(app=test_app, base_url=\"http://test\") as client:\n        response = await client.get(\"/test\")\n        assert response.status_code == 200\n        assert len(startup_called) == 1\n\n    # After client closes, shutdown should be called\n    assert len(shutdown_called) == 1\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-middleware","title":"Testing Middleware","text":"<pre><code># CORRECT: Test custom middleware\n@pytest.mark.service\ndef test_request_id_middleware():\n    \"\"\"Test that middleware adds request ID to response headers.\"\"\"\n    client = TestClient(app)\n\n    response = client.get(\"/api/users\")\n\n    assert \"X-Request-ID\" in response.headers\n    assert len(response.headers[\"X-Request-ID\"]) &gt; 0\n\n\n# CORRECT: Test CORS middleware\n@pytest.mark.service\ndef test_cors_middleware():\n    \"\"\"Test CORS headers are added.\"\"\"\n    client = TestClient(app)\n\n    response = client.options(\n        \"/api/users\",\n        headers={\"Origin\": \"http://localhost:3000\"}\n    )\n\n    assert response.status_code == 200\n    assert \"Access-Control-Allow-Origin\" in response.headers\n\n\n# CORRECT: Test authentication middleware\n@pytest.mark.service\ndef test_auth_middleware_blocks_unauthenticated():\n    \"\"\"Test middleware blocks requests without token.\"\"\"\n    client = TestClient(app)\n\n    response = client.get(\"/api/protected/resource\")\n\n    assert response.status_code == 401\n    assert \"detail\" in response.json()\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-error-handlers","title":"Testing Error Handlers","text":"<pre><code># CORRECT: Test custom exception handlers\n@pytest.mark.service\ndef test_not_found_exception_handler():\n    \"\"\"Test 404 handler returns correct format.\"\"\"\n    client = TestClient(app)\n\n    response = client.get(\"/api/nonexistent/endpoint\")\n\n    assert response.status_code == 404\n    error = response.json()\n    assert \"detail\" in error\n    assert \"timestamp\" in error\n\n\n# CORRECT: Test validation exception handler\n@pytest.mark.service\ndef test_validation_exception_handler():\n    \"\"\"Test validation errors return detailed messages.\"\"\"\n    client = TestClient(app)\n\n    response = client.post(\"/api/users\", json={\"invalid\": \"data\"})\n\n    assert response.status_code == 422\n    error = response.json()\n    assert \"detail\" in error\n    assert isinstance(error[\"detail\"], list)\n\n\n# CORRECT: Test custom business logic exception\n@pytest.mark.service\ndef test_business_logic_exception_handler():\n    \"\"\"Test custom exceptions return proper HTTP status.\"\"\"\n    from finance_lending_api.exceptions import InsufficientCreditError\n\n    client = TestClient(app)\n\n    # Endpoint that raises InsufficientCreditError\n    response = client.post(\"/api/loans\", json={\n        \"user_id\": \"user-poor-credit\",\n        \"amount\": 50000\n    })\n\n    assert response.status_code == 400\n    error = response.json()\n    assert error[\"error_code\"] == \"INSUFFICIENT_CREDIT\"\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-response-models","title":"Testing Response Models","text":"<pre><code># CORRECT: Test response serialization\n@pytest.mark.service\ndef test_response_model_serialization():\n    \"\"\"Test response follows Pydantic model schema.\"\"\"\n    client = TestClient(app)\n\n    response = client.get(\"/api/users/user-123\")\n\n    assert response.status_code == 200\n    user = response.json()\n\n    # Verify all required fields present\n    required_fields = [\"id\", \"email\", \"name\", \"created_at\", \"updated_at\"]\n    for field in required_fields:\n        assert field in user\n\n    # Verify no extra fields (response_model_exclude_unset)\n    assert \"password_hash\" not in user\n    assert \"internal_notes\" not in user\n\n\n# CORRECT: Test response model validation\n@pytest.mark.service\ndef test_response_model_validates_types():\n    \"\"\"Test response model enforces type constraints.\"\"\"\n    client = TestClient(app)\n\n    response = client.get(\"/api/loans/loan-123\")\n    loan = response.json()\n\n    # Verify types\n    assert isinstance(loan[\"id\"], str)\n    assert isinstance(loan[\"amount\"], (int, float))\n    assert isinstance(loan[\"interest_rate\"], (int, float))\n    assert isinstance(loan[\"approved\"], bool)\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-authentication-and-authorization","title":"Testing Authentication and Authorization","text":"<pre><code># CORRECT: Test JWT authentication\n@pytest.mark.service\ndef test_jwt_authentication():\n    \"\"\"Test endpoint requires valid JWT token.\"\"\"\n    client = TestClient(app)\n\n    # Without token\n    response = client.get(\"/api/protected/data\")\n    assert response.status_code == 401\n\n    # With invalid token\n    response = client.get(\n        \"/api/protected/data\",\n        headers={\"Authorization\": \"Bearer invalid-token\"}\n    )\n    assert response.status_code == 401\n\n    # With valid token\n    valid_token = \"valid-jwt-token-here\"\n    response = client.get(\n        \"/api/protected/data\",\n        headers={\"Authorization\": f\"Bearer {valid_token}\"}\n    )\n    assert response.status_code == 200\n\n\n# CORRECT: Test role-based authorization\n@pytest.mark.service\ndef test_admin_only_endpoint():\n    \"\"\"Test endpoint restricted to admin role.\"\"\"\n    from finance_lending_api.dependencies import get_current_user\n\n    client = TestClient(app)\n\n    # Regular user\n    app.dependency_overrides[get_current_user] = lambda: {\n        \"id\": \"user-123\",\n        \"role\": \"user\"\n    }\n    response = client.delete(\"/api/admin/users/other-user\")\n    assert response.status_code == 403\n\n    # Admin user\n    app.dependency_overrides[get_current_user] = lambda: {\n        \"id\": \"admin-123\",\n        \"role\": \"admin\"\n    }\n    response = client.delete(\"/api/admin/users/other-user\")\n    assert response.status_code == 204\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#testing-websocket-endpoints","title":"Testing WebSocket Endpoints","text":"<pre><code># CORRECT: Test WebSocket connection\n@pytest.mark.service\ndef test_websocket_connection():\n    \"\"\"Test WebSocket endpoint accepts connections.\"\"\"\n    client = TestClient(app)\n\n    with client.websocket_connect(\"/ws/notifications\") as websocket:\n        # Send message\n        websocket.send_json({\"type\": \"subscribe\", \"channel\": \"updates\"})\n\n        # Receive response\n        data = websocket.receive_json()\n        assert data[\"type\"] == \"subscribed\"\n        assert data[\"channel\"] == \"updates\"\n\n\n# CORRECT: Test WebSocket message handling\n@pytest.mark.service\ndef test_websocket_message_handling():\n    \"\"\"Test WebSocket handles messages correctly.\"\"\"\n    client = TestClient(app)\n\n    with client.websocket_connect(\"/ws/chat\") as websocket:\n        # Send chat message\n        websocket.send_json({\n            \"type\": \"message\",\n            \"text\": \"Hello, world!\"\n        })\n\n        # Receive echo\n        response = websocket.receive_json()\n        assert response[\"type\"] == \"message\"\n        assert response[\"text\"] == \"Hello, world!\"\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#do-use-dependency-overrides","title":"DO: Use Dependency Overrides","text":"<pre><code># CORRECT: Override dependencies to isolate tests\n@pytest.mark.service\ndef test_with_dependency_override():\n    \"\"\"Isolate test by mocking dependencies.\"\"\"\n    from finance_lending_api.dependencies import get_db_session\n    from unittest.mock import AsyncMock\n\n    mock_db = AsyncMock()\n    app.dependency_overrides[get_db_session] = lambda: mock_db\n\n    client = TestClient(app)\n    response = client.get(\"/api/data\")\n\n    assert response.status_code == 200\n    app.dependency_overrides.clear()\n\n\n# INCORRECT: Don't call real dependencies in service tests\n@pytest.mark.service\ndef test_without_override():\n    \"\"\"WRONG: Calls real database.\"\"\"\n    client = TestClient(app)\n    # This will hit real database if not overridden\n    response = client.get(\"/api/users\")\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#do-test-requestresponse-contracts","title":"DO: Test Request/Response Contracts","text":"<pre><code># CORRECT: Verify complete API contract\n@pytest.mark.service\ndef test_api_contract():\n    \"\"\"Test request and response match OpenAPI spec.\"\"\"\n    client = TestClient(app)\n\n    # Valid request\n    payload = {\n        \"email\": \"user@example.com\",\n        \"name\": \"Test User\",\n        \"age\": 30\n    }\n    response = client.post(\"/api/users\", json=payload)\n\n    # Verify status code\n    assert response.status_code == 201\n\n    # Verify response schema\n    user = response.json()\n    assert all(key in user for key in [\"id\", \"email\", \"name\", \"age\", \"created_at\"])\n\n    # Verify types\n    assert isinstance(user[\"id\"], str)\n    assert isinstance(user[\"email\"], str)\n    assert isinstance(user[\"age\"], int)\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#dont-mix-service-and-integration-tests","title":"DON'T: Mix Service and Integration Tests","text":"<pre><code># INCORRECT: Service test calling real database\n@pytest.mark.service\nasync def test_mixed_layers():\n    \"\"\"WRONG: Mixes service and integration testing.\"\"\"\n    # Creates real database record\n    db_session = await get_real_db_session()\n    user = await create_user_in_db(db_session, email=\"test@example.com\")\n\n    # Then tests API\n    client = TestClient(app)\n    response = client.get(f\"/api/users/{user.id}\")\n\n\n# CORRECT: Service test with mocked dependencies\n@pytest.mark.service\ndef test_isolated_service():\n    \"\"\"Service test with all dependencies mocked.\"\"\"\n    from finance_lending_api.dependencies import get_user_service\n    from unittest.mock import AsyncMock\n\n    mock_service = AsyncMock()\n    mock_service.get_user.return_value = {\"id\": \"123\", \"email\": \"test@example.com\"}\n\n    app.dependency_overrides[get_user_service] = lambda: mock_service\n\n    client = TestClient(app)\n    response = client.get(\"/api/users/123\")\n\n    assert response.status_code == 200\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#checklist","title":"Checklist","text":"<ul> <li> Test all HTTP methods (GET, POST, PUT, PATCH, DELETE)</li> <li> Test query parameters, path parameters, request bodies</li> <li> Test request validation with invalid data</li> <li> Test response serialization follows models</li> <li> Test authentication and authorization</li> <li> Override dependencies to isolate from external systems</li> <li> Test middleware behavior (CORS, auth, request ID)</li> <li> Test custom exception handlers</li> <li> Test lifespan events (startup/shutdown)</li> <li> Test WebSocket endpoints if applicable</li> <li> Use <code>@pytest.mark.service</code> to mark service tests</li> <li> Clean up dependency overrides after tests</li> </ul>"},{"location":"atomic/testing/service-testing/fastapi-testing-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Real database containers for integration tests</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies</li> <li><code>docs/atomic/services/fastapi-service/endpoint-patterns.md</code> \u2014 FastAPI endpoint implementation patterns</li> <li><code>docs/atomic/services/fastapi-service/dependency-injection.md</code> \u2014 FastAPI dependency injection patterns</li> <li><code>docs/atomic/integrations/http-communication/http-client-patterns.md</code> \u2014 HTTP client patterns for inter-service calls</li> </ul>"},{"location":"atomic/testing/unit-testing/coverage-requirements/","title":"Coverage Requirements","text":"<p>Define and enforce test coverage standards to ensure code quality and reduce production defects. Coverage metrics measure which lines, branches, and paths in your code are executed during test runs, providing quantitative insight into test completeness.</p> <p>This document establishes coverage targets, configuration patterns, and enforcement strategies for Python services in this platform. Proper coverage tracking helps identify untested code paths, supports refactoring confidence, and serves as a quality gate in CI/CD pipelines.</p> <p>Coverage requirements differ by maturity level, but all levels require complete, production-quality code. The difference is in coverage thresholds and infrastructure features, not code completeness: PoC requires \u226560%, Development \u226575%, Pre-Production \u226580%, and Production \u226585%. See <code>docs/reference/maturity-levels.md</code> for definitive thresholds per level.</p>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#configuration","title":"Configuration","text":""},{"location":"atomic/testing/unit-testing/coverage-requirements/#pytest-cov-setup","title":"Pytest-Cov Setup","text":"<p>Install pytest-cov and configure it in <code>pyproject.toml</code>:</p> <pre><code>[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=8.0\",\n    \"pytest-cov&gt;=4.1\",\n    \"pytest-asyncio&gt;=0.23\",\n]\n</code></pre> <p>Add coverage options to <code>pytest.ini</code>:</p> <pre><code># pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\n\naddopts =\n    --verbose\n    --strict-markers\n    --cov=src\n    --cov-report=html\n    --cov-report=term\n    --cov-report=xml\n    --cov-fail-under=80\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#coverage-configuration-file","title":"Coverage Configuration File","text":"<p>Create <code>.coveragerc</code> to control coverage behavior:</p> <pre><code># .coveragerc\n[run]\nsource = src\nbranch = true\nomit =\n    */tests/*\n    */migrations/*\n    */__pycache__/*\n    */.venv/*\n    */venv/*\n    */site-packages/*\n\n[report]\nprecision = 2\nshow_missing = true\nskip_covered = false\n\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    def __str__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\n    if TYPE_CHECKING:\n    @abstractmethod\n    @overload\n\n[html]\ndirectory = htmlcov\n\n[xml]\noutput = coverage.xml\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#coverage-targets-by-maturity-level","title":"Coverage Targets by Maturity Level","text":"Maturity Level Minimum Coverage Enforcement Typical Use Case Level 1: PoC \u2265 60% None Proof of concept, rapid prototyping Level 2: Development \u2265 75% Warning only Active development, MVP Level 3: Pre-Production \u2265 80% CI warning Staging, beta testing Level 4: Production \u2265 85% CI failure Production services <p>SSOT: See <code>docs/reference/maturity-levels.md</code> for authoritative thresholds.</p>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#correct-production-coverage-enforcement","title":"CORRECT: Production Coverage Enforcement","text":"<pre><code># pytest.ini for Production services\n[pytest]\naddopts =\n    --cov=src\n    --cov-fail-under=80  # Fail CI if below 80%\n    --cov-branch          # Include branch coverage\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#incorrect-no-coverage-enforcement-for-production","title":"INCORRECT: No Coverage Enforcement for Production","text":"<pre><code># pytest.ini \u2014 WRONG for Production\n[pytest]\naddopts =\n    --cov=src\n    # Missing --cov-fail-under means coverage can drop without CI failure\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#excluding-code-from-coverage","title":"Excluding Code from Coverage","text":""},{"location":"atomic/testing/unit-testing/coverage-requirements/#files-to-exclude","title":"Files to Exclude","text":"<p>Always exclude from coverage calculations:</p> <pre><code>[run]\nomit =\n    */tests/*              # Test files themselves\n    */migrations/*         # Database migrations (data, not logic)\n    */__pycache__/*        # Compiled bytecode\n    */conftest.py          # Pytest fixtures (tested implicitly)\n    */manage.py            # Django/Flask management scripts\n    */.venv/*              # Virtual environment\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#code-patterns-to-exclude","title":"Code Patterns to Exclude","text":"<p>Use <code># pragma: no cover</code> for specific lines:</p> <pre><code># CORRECT: Exclude defensive code that's hard to test\ndef process_item(item: dict) -&gt; None:\n    try:\n        validate_and_save(item)\n    except Exception as e:  # pragma: no cover\n        # Defensive: log unexpected errors but don't fail\n        logger.exception(\"Unexpected error processing item\")\n        raise\n\n\n# CORRECT: Exclude __repr__ and __str__ (low value to test)\nclass User:\n    def __repr__(self) -&gt; str:  # pragma: no cover\n        return f\"&lt;User {self.email}&gt;\"\n\n\n# CORRECT: Exclude TYPE_CHECKING imports\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:  # pragma: no cover\n    from mypy_extensions import TypedDict\n\n\n# INCORRECT: Overusing pragma to inflate coverage\ndef critical_business_logic(data: dict) -&gt; bool:\n    if not data:  # pragma: no cover \u2014 WRONG! This should be tested\n        return False\n    return validate(data)\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#report-formats","title":"Report Formats","text":""},{"location":"atomic/testing/unit-testing/coverage-requirements/#html-report-for-local-development","title":"HTML Report (for local development)","text":"<p>Generate interactive HTML coverage report:</p> <pre><code>pytest --cov=src --cov-report=html\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre> <p>The HTML report highlights: - Green lines: Covered by tests - Red lines: Not covered - Yellow lines: Partially covered branches</p>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#terminal-report-for-quick-feedback","title":"Terminal Report (for quick feedback)","text":"<pre><code>pytest --cov=src --cov-report=term-missing\n\n# Output:\n# Name                      Stmts   Miss Branch BrPart  Cover   Missing\n# ---------------------------------------------------------------------\n# src/domain/user.py           45      5     12      2    89%   23-25, 67\n# src/api/v1/users.py          32      0      8      0   100%\n# ---------------------------------------------------------------------\n# TOTAL                        77      5     20      2    93%\n</code></pre> <p>The <code>Missing</code> column shows uncovered line numbers.</p>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#xml-report-for-cicd-integration","title":"XML Report (for CI/CD integration)","text":"<pre><code>pytest --cov=src --cov-report=xml\n\n# Generates coverage.xml for tools like:\n# - Codecov\n# - Coveralls\n# - SonarQube\n# - GitLab CI coverage visualization\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#cicd-enforcement","title":"CI/CD Enforcement","text":""},{"location":"atomic/testing/unit-testing/coverage-requirements/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install -e \".[test]\"\n\n      - name: Run tests with coverage\n        run: |\n          pytest --cov=src --cov-report=xml --cov-fail-under=80\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n          fail_ci_if_error: true\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#gitlab-ci-example","title":"GitLab CI Example","text":"<pre><code># .gitlab-ci.yml\ntest:\n  stage: test\n  image: python:3.12\n  script:\n    - pip install -e \".[test]\"\n    - pytest --cov=src --cov-report=xml --cov-report=term --cov-fail-under=80\n  coverage: '/TOTAL.*\\s+(\\d+%)$/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/unit-testing/coverage-requirements/#coverage-interpretation","title":"Coverage Interpretation","text":"<pre><code># CORRECT: High coverage with meaningful assertions\n@pytest.mark.unit\nasync def test_user_creation_validates_email():\n    \"\"\"Test email validation during user creation.\"\"\"\n    service = UserService()\n\n    with pytest.raises(ValidationError, match=\"Invalid email format\"):\n        await service.create_user(email=\"invalid\", name=\"John\")\n\n    # Also test success case\n    user = await service.create_user(email=\"john@example.com\", name=\"John\")\n    assert user.email == \"john@example.com\"\n    assert user.name == \"John\"\n\n\n# INCORRECT: High coverage with weak assertions (false confidence)\n@pytest.mark.unit\nasync def test_user_creation():\n    \"\"\"Test user creation.\"\"\"\n    service = UserService()\n    user = await service.create_user(email=\"john@example.com\", name=\"John\")\n    assert user  # Weak: doesn't validate correctness, just that it doesn't crash\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#coverage-metrics-guidelines","title":"Coverage Metrics Guidelines","text":"<ol> <li>Line Coverage \u2260 Test Quality: 100% coverage doesn't mean bug-free code</li> <li>Branch Coverage Matters: Use <code>--cov-branch</code> to ensure all conditional paths tested</li> <li>Focus on Critical Paths: Prioritize business logic over boilerplate</li> <li>Avoid Coverage Theater: Don't write tests just to increase percentage</li> <li>Review Uncovered Code: Low coverage areas may indicate dead code or missing tests</li> </ol>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#correct-balanced-coverage-strategy","title":"CORRECT: Balanced Coverage Strategy","text":"<pre><code># High-value test for critical business logic\n@pytest.mark.unit\nasync def test_loan_approval_logic():\n    \"\"\"Test loan approval criteria (critical business rule).\"\"\"\n    service = LoanService()\n\n    # Test approval\n    result = await service.evaluate_loan(\n        credit_score=750,\n        income=80000,\n        debt_ratio=0.2\n    )\n    assert result.approved is True\n    assert result.interest_rate == 4.5\n\n    # Test rejection\n    result = await service.evaluate_loan(\n        credit_score=550,\n        income=30000,\n        debt_ratio=0.6\n    )\n    assert result.approved is False\n    assert result.rejection_reason == \"Credit score below minimum\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#incorrect-low-value-coverage-padding","title":"INCORRECT: Low-Value Coverage Padding","text":"<pre><code># Low-value test that inflates coverage without real benefit\n@pytest.mark.unit\ndef test_user_class_exists():\n    \"\"\"Test that User class can be imported.\"\"\"\n    from finance_lending_api.domain.models import User\n    assert User  # Pointless test\n\n\n# Low-value test for simple property\n@pytest.mark.unit\ndef test_user_email_property():\n    \"\"\"Test user email property.\"\"\"\n    user = User(email=\"test@example.com\", name=\"Test\")\n    assert user.email == \"test@example.com\"  # No logic, just data storage\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#monitoring-coverage-trends","title":"Monitoring Coverage Trends","text":"<p>Track coverage over time to detect regressions:</p> <pre><code># Store coverage percentage in CI artifacts\npytest --cov=src --cov-report=term | tee coverage.txt\ngrep \"TOTAL\" coverage.txt | awk '{print $NF}' &gt; coverage_percentage.txt\n</code></pre> <p>Set up alerts if coverage drops below threshold:</p> <pre><code># In CI script\nCURRENT_COVERAGE=$(grep \"TOTAL\" coverage.txt | awk '{print $NF}' | tr -d '%')\nif (( $(echo \"$CURRENT_COVERAGE &lt; 80\" | bc -l) )); then\n    echo \"\u274c Coverage dropped below 80%: ${CURRENT_COVERAGE}%\"\n    exit 1\nfi\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#running-coverage-checks","title":"Running Coverage Checks","text":"<pre><code># Local development: generate HTML report\npytest --cov=src --cov-report=html\nopen htmlcov/index.html\n\n# CI/CD: enforce minimum coverage\npytest --cov=src --cov-report=xml --cov-fail-under=80\n\n# Check specific module coverage\npytest tests/unit/domain/ --cov=src/domain --cov-report=term-missing\n\n# Branch coverage (recommended for Production)\npytest --cov=src --cov-branch --cov-report=term-missing\n</code></pre>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#checklist","title":"Checklist","text":"<ul> <li> <code>pytest-cov</code> installed and configured in <code>pyproject.toml</code></li> <li> <code>.coveragerc</code> excludes tests, migrations, virtual environments</li> <li> Coverage target set appropriately for maturity level (80%+ for Production)</li> <li> <code>--cov-fail-under</code> configured in <code>pytest.ini</code> or CI script</li> <li> Branch coverage enabled with <code>--cov-branch</code></li> <li> HTML report generated for local development</li> <li> XML report generated for CI/CD integration</li> <li> Coverage trends monitored over time</li> <li> CI pipeline fails on coverage regression</li> <li> <code># pragma: no cover</code> used sparingly and justified</li> </ul>"},{"location":"atomic/testing/unit-testing/coverage-requirements/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code> \u2014 Pytest configuration and basic setup</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Pytest fixture patterns for reusable test components</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies to isolate units</li> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Integration testing with real dependencies</li> <li><code>docs/atomic/testing/quality-assurance/linting-standards.md</code> \u2014 Code quality standards and enforcement</li> </ul>"},{"location":"atomic/testing/unit-testing/fixture-patterns/","title":"Test Fixture Patterns","text":"<p>Master pytest fixture patterns to create reusable, composable test components that reduce duplication and improve test maintainability. Fixtures provide a clean way to set up test preconditions, manage resources, and share common test data across your test suite.</p> <p>This document covers fixture scopes, composition patterns, conftest.py organization, and best practices for Python microservices. Proper fixture design isolates test setup from test logic, enables dependency injection for tests, and ensures consistent test environments across your codebase.</p> <p>Fixtures are pytest's most powerful feature for test organization. Understanding scope management, yield patterns, and autouse behavior is essential for building maintainable test suites that scale from unit tests to complex integration scenarios.</p>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#fixture-basics","title":"Fixture Basics","text":""},{"location":"atomic/testing/unit-testing/fixture-patterns/#simple-fixtures","title":"Simple Fixtures","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom finance_lending_api.domain.services import LoanService\n\n\n# CORRECT: Simple fixture with clear purpose\n@pytest.fixture\ndef loan_service() -&gt; LoanService:\n    \"\"\"Provide a LoanService instance for testing.\"\"\"\n    return LoanService()\n\n\n# CORRECT: Fixture with setup logic\n@pytest.fixture\ndef sample_user_data() -&gt; dict:\n    \"\"\"Provide valid user registration data.\"\"\"\n    return {\n        \"email\": \"test@example.com\",\n        \"name\": \"Test User\",\n        \"phone\": \"+1234567890\"\n    }\n\n\n# Using fixtures in tests\n@pytest.mark.unit\ndef test_loan_approval(loan_service: LoanService, sample_user_data: dict):\n    \"\"\"Test loan approval with valid user data.\"\"\"\n    result = loan_service.evaluate_loan(\n        user=sample_user_data,\n        amount=10000,\n        credit_score=750\n    )\n    assert result.approved is True\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#fixture-scopes","title":"Fixture Scopes","text":"<p>Control fixture lifecycle with scope parameter:</p> <pre><code># CORRECT: Function scope (default) \u2014 new instance per test\n@pytest.fixture(scope=\"function\")\ndef user_service():\n    \"\"\"Create new UserService for each test (isolated).\"\"\"\n    return UserService()\n\n\n# CORRECT: Class scope \u2014 shared across test class\n@pytest.fixture(scope=\"class\")\ndef database_connection():\n    \"\"\"Share database connection across test class.\"\"\"\n    conn = create_connection()\n    yield conn\n    conn.close()\n\n\n# CORRECT: Module scope \u2014 shared across module\n@pytest.fixture(scope=\"module\")\ndef redis_client():\n    \"\"\"Share Redis client across entire test module.\"\"\"\n    client = Redis.from_url(\"redis://localhost:6379\")\n    yield client\n    client.close()\n\n\n# CORRECT: Session scope \u2014 shared across entire test run\n@pytest.fixture(scope=\"session\")\ndef docker_services():\n    \"\"\"Start Docker services once for entire test session.\"\"\"\n    compose_file = Path(__file__).parent / \"docker-compose.test.yml\"\n    subprocess.run([\"docker-compose\", \"-f\", compose_file, \"up\", \"-d\"])\n    yield\n    subprocess.run([\"docker-compose\", \"-f\", compose_file, \"down\"])\n\n\n# INCORRECT: Session scope for mutable state (test pollution)\n@pytest.fixture(scope=\"session\")\ndef shared_list():\n    \"\"\"WRONG: Mutable fixture shared across all tests.\"\"\"\n    return []  # Tests will pollute each other's state\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#conftestpy-organization","title":"Conftest.py Organization","text":""},{"location":"atomic/testing/unit-testing/fixture-patterns/#directory-structure","title":"Directory Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py                    # Session/module-level fixtures\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 conftest.py               # Unit test fixtures\n\u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u251c\u2500\u2500 conftest.py          # Domain-specific fixtures\n\u2502   \u2502   \u2514\u2500\u2500 test_user_service.py\n\u2502   \u2514\u2500\u2500 infrastructure/\n\u2502       \u251c\u2500\u2500 conftest.py          # Infrastructure fixtures\n\u2502       \u2514\u2500\u2500 test_repositories.py\n\u2514\u2500\u2500 integration/\n    \u251c\u2500\u2500 conftest.py               # Integration test fixtures\n    \u2514\u2500\u2500 test_postgres.py\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#root-conftestpy","title":"Root conftest.py","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom typing import AsyncGenerator\nfrom redis.asyncio import Redis\nfrom httpx import AsyncClient\n\n\n# CORRECT: Session-scoped configuration\n@pytest.fixture(scope=\"session\")\ndef test_config():\n    \"\"\"Provide test configuration.\"\"\"\n    return {\n        \"REDIS_URL\": \"redis://localhost:6379/1\",\n        \"DATABASE_URL\": \"postgresql://test:test@localhost:5432/test_db\",\n        \"API_BASE_URL\": \"http://localhost:8000\"\n    }\n\n\n# CORRECT: Async fixture for Redis client\n@pytest.fixture(scope=\"module\")\nasync def redis_client(test_config) -&gt; AsyncGenerator[Redis, None]:\n    \"\"\"Provide Redis client for testing.\"\"\"\n    client = Redis.from_url(\n        test_config[\"REDIS_URL\"],\n        encoding=\"utf-8\",\n        decode_responses=True\n    )\n\n    yield client\n\n    # Cleanup: flush test database\n    await client.flushdb()\n    await client.close()\n\n\n# CORRECT: HTTP client fixture\n@pytest.fixture\nasync def http_client() -&gt; AsyncGenerator[AsyncClient, None]:\n    \"\"\"Provide async HTTP client for testing.\"\"\"\n    async with AsyncClient() as client:\n        yield client\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#domain-conftestpy","title":"Domain conftest.py","text":"<pre><code># tests/unit/domain/conftest.py\nimport pytest\nfrom finance_lending_api.domain.services import UserService, LoanService\nfrom finance_lending_api.domain.models import User\n\n\n@pytest.fixture\ndef user_service() -&gt; UserService:\n    \"\"\"Provide UserService instance.\"\"\"\n    return UserService()\n\n\n@pytest.fixture\ndef loan_service() -&gt; LoanService:\n    \"\"\"Provide LoanService instance.\"\"\"\n    return LoanService()\n\n\n@pytest.fixture\ndef sample_user() -&gt; User:\n    \"\"\"Provide sample User instance for testing.\"\"\"\n    return User(\n        id=\"user-123\",\n        email=\"test@example.com\",\n        name=\"Test User\",\n        credit_score=750\n    )\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#fixture-composition","title":"Fixture Composition","text":""},{"location":"atomic/testing/unit-testing/fixture-patterns/#fixtures-using-other-fixtures","title":"Fixtures Using Other Fixtures","text":"<pre><code># CORRECT: Compose fixtures to build complex objects\n@pytest.fixture\ndef database_url(test_config) -&gt; str:\n    \"\"\"Extract database URL from config.\"\"\"\n    return test_config[\"DATABASE_URL\"]\n\n\n@pytest.fixture\nasync def database_engine(database_url):\n    \"\"\"Create SQLAlchemy engine from URL.\"\"\"\n    from sqlalchemy.ext.asyncio import create_async_engine\n\n    engine = create_async_engine(database_url, echo=True)\n    yield engine\n    await engine.dispose()\n\n\n@pytest.fixture\nasync def database_session(database_engine):\n    \"\"\"Create database session from engine.\"\"\"\n    from sqlalchemy.ext.asyncio import AsyncSession\n    from sqlalchemy.orm import sessionmaker\n\n    async_session = sessionmaker(\n        database_engine,\n        class_=AsyncSession,\n        expire_on_commit=False\n    )\n\n    async with async_session() as session:\n        yield session\n\n\n@pytest.fixture\nasync def user_repository(database_session):\n    \"\"\"Create UserRepository with database session.\"\"\"\n    from finance_lending_api.infrastructure.repositories import UserRepository\n    return UserRepository(session=database_session)\n\n\n# Using composed fixtures\n@pytest.mark.asyncio\nasync def test_user_creation(user_repository):\n    \"\"\"Test user creation through repository.\"\"\"\n    user = await user_repository.create(\n        email=\"test@example.com\",\n        name=\"Test User\"\n    )\n    assert user.id is not None\n    assert user.email == \"test@example.com\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#factory-fixtures","title":"Factory Fixtures","text":"<pre><code># CORRECT: Factory pattern for creating multiple instances\n@pytest.fixture\ndef user_factory():\n    \"\"\"Factory for creating test users.\"\"\"\n    def _create_user(\n        email: str = \"test@example.com\",\n        name: str = \"Test User\",\n        credit_score: int = 700\n    ) -&gt; User:\n        return User(\n            id=f\"user-{uuid.uuid4()}\",\n            email=email,\n            name=name,\n            credit_score=credit_score\n        )\n    return _create_user\n\n\n# Using factory fixture\n@pytest.mark.unit\ndef test_multiple_users(user_factory):\n    \"\"\"Test with multiple user instances.\"\"\"\n    user1 = user_factory(email=\"user1@example.com\", credit_score=750)\n    user2 = user_factory(email=\"user2@example.com\", credit_score=650)\n    user3 = user_factory(email=\"user3@example.com\", credit_score=800)\n\n    assert user1.credit_score &gt; user2.credit_score\n    assert user3.credit_score &gt; user1.credit_score\n\n\n# CORRECT: Async factory fixture\n@pytest.fixture\ndef loan_factory(user_factory):\n    \"\"\"Factory for creating test loans.\"\"\"\n    async def _create_loan(\n        user: User | None = None,\n        amount: int = 10000,\n        term_months: int = 12\n    ) -&gt; Loan:\n        if user is None:\n            user = user_factory()\n\n        return Loan(\n            id=f\"loan-{uuid.uuid4()}\",\n            user_id=user.id,\n            amount=amount,\n            term_months=term_months\n        )\n    return _create_loan\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#yield-fixtures-setupteardown","title":"Yield Fixtures (Setup/Teardown)","text":"<pre><code># CORRECT: Resource management with yield\n@pytest.fixture\nasync def redis_client():\n    \"\"\"Provide Redis client with cleanup.\"\"\"\n    client = Redis.from_url(\"redis://localhost:6379/1\")\n\n    # Setup complete, provide fixture\n    yield client\n\n    # Teardown: cleanup after test\n    await client.flushdb()\n    await client.close()\n\n\n# CORRECT: File handling with yield\n@pytest.fixture\ndef temp_file(tmp_path):\n    \"\"\"Create temporary file with cleanup.\"\"\"\n    file_path = tmp_path / \"test_data.json\"\n    file_path.write_text('{\"key\": \"value\"}')\n\n    yield file_path\n\n    # Teardown: file automatically cleaned by tmp_path fixture\n\n\n# CORRECT: Mock patching with yield\n@pytest.fixture\ndef mock_external_api():\n    \"\"\"Mock external API calls.\"\"\"\n    with patch(\"finance_lending_api.integrations.credit_bureau.CreditBureauClient\") as mock:\n        mock.return_value.get_credit_score.return_value = 750\n        yield mock\n\n\n# INCORRECT: Using return instead of yield for cleanup\n@pytest.fixture\nasync def bad_redis_client():\n    \"\"\"WRONG: No cleanup performed.\"\"\"\n    client = Redis.from_url(\"redis://localhost:6379/1\")\n    return client  # Cleanup never happens!\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#autouse-fixtures","title":"Autouse Fixtures","text":"<pre><code># CORRECT: Autouse for logging setup (runs automatically)\n@pytest.fixture(autouse=True, scope=\"session\")\ndef configure_logging():\n    \"\"\"Configure logging for all tests.\"\"\"\n    import logging\n    logging.basicConfig(level=logging.DEBUG)\n\n\n# CORRECT: Autouse for transaction rollback in integration tests\n@pytest.fixture(autouse=True, scope=\"function\")\nasync def transaction_rollback(database_session):\n    \"\"\"Automatically rollback each test's database changes.\"\"\"\n    await database_session.begin()\n    yield\n    await database_session.rollback()\n\n\n# CORRECT: Autouse for clearing Redis between tests\n@pytest.fixture(autouse=True, scope=\"function\")\nasync def clear_redis(redis_client):\n    \"\"\"Clear Redis before each test.\"\"\"\n    await redis_client.flushdb()\n\n\n# INCORRECT: Autouse for expensive operation\n@pytest.fixture(autouse=True)\nasync def expensive_setup():\n    \"\"\"WRONG: Runs for ALL tests, even those that don't need it.\"\"\"\n    await initialize_machine_learning_model()  # Slow!\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#parametrized-fixtures","title":"Parametrized Fixtures","text":"<pre><code># CORRECT: Parametrize fixture for multiple scenarios\n@pytest.fixture(params=[\n    (\"user@example.com\", True),\n    (\"invalid-email\", False),\n    (\"user@\", False),\n    (\"@example.com\", False),\n])\ndef email_validation_case(request):\n    \"\"\"Provide email validation test cases.\"\"\"\n    return request.param\n\n\n@pytest.mark.unit\ndef test_email_validation(email_validation_case):\n    \"\"\"Test email validation with multiple cases.\"\"\"\n    email, expected_valid = email_validation_case\n    result = is_valid_email(email)\n    assert result == expected_valid\n\n\n# CORRECT: Parametrize fixture for different service types\n@pytest.fixture(params=[\"postgres\", \"mongo\"])\ndef data_service_client(request):\n    \"\"\"Provide different data service clients.\"\"\"\n    if request.param == \"postgres\":\n        return PostgresDataServiceClient(\"http://localhost:8001\")\n    elif request.param == \"mongo\":\n        return MongoDataServiceClient(\"http://localhost:8002\")\n\n\n# Using parametrized fixture\n@pytest.mark.integration\nasync def test_user_creation_across_services(data_service_client):\n    \"\"\"Test user creation works with both PostgreSQL and MongoDB.\"\"\"\n    user = await data_service_client.create_user({\n        \"email\": \"test@example.com\",\n        \"name\": \"Test User\"\n    })\n    assert user[\"email\"] == \"test@example.com\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#async-fixtures","title":"Async Fixtures","text":"<pre><code># CORRECT: Async fixture for async resources\n@pytest.fixture\nasync def async_redis_client() -&gt; AsyncGenerator[Redis, None]:\n    \"\"\"Provide async Redis client.\"\"\"\n    client = Redis.from_url(\"redis://localhost:6379/1\")\n\n    # Verify connection\n    await client.ping()\n\n    yield client\n\n    await client.flushdb()\n    await client.close()\n\n\n# CORRECT: Async fixture composition\n@pytest.fixture\nasync def user_with_loans(user_factory, loan_factory):\n    \"\"\"Create user with multiple loans.\"\"\"\n    user = user_factory(email=\"borrower@example.com\", credit_score=750)\n    loans = [\n        await loan_factory(user=user, amount=10000),\n        await loan_factory(user=user, amount=5000),\n        await loan_factory(user=user, amount=15000),\n    ]\n    return user, loans\n\n\n# Using async fixtures\n@pytest.mark.asyncio\nasync def test_user_total_debt(user_with_loans):\n    \"\"\"Test total debt calculation.\"\"\"\n    user, loans = user_with_loans\n    total_debt = sum(loan.amount for loan in loans)\n    assert total_debt == 30000\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/unit-testing/fixture-patterns/#do-keep-fixtures-focused","title":"DO: Keep Fixtures Focused","text":"<pre><code># CORRECT: Single-purpose fixtures\n@pytest.fixture\ndef valid_email() -&gt; str:\n    return \"test@example.com\"\n\n\n@pytest.fixture\ndef valid_user_data(valid_email) -&gt; dict:\n    return {\n        \"email\": valid_email,\n        \"name\": \"Test User\",\n        \"phone\": \"+1234567890\"\n    }\n\n\n# INCORRECT: Fixture doing too much\n@pytest.fixture\ndef everything():\n    \"\"\"WRONG: Fixture provides unrelated things.\"\"\"\n    return {\n        \"user\": User(email=\"test@example.com\"),\n        \"redis\": Redis.from_url(\"redis://localhost\"),\n        \"config\": {\"DEBUG\": True},\n        \"random_data\": [1, 2, 3]\n    }\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#do-use-meaningful-names","title":"DO: Use Meaningful Names","text":"<pre><code># CORRECT: Clear, descriptive names\n@pytest.fixture\ndef authenticated_user() -&gt; User:\n    return User(id=\"user-123\", email=\"auth@example.com\")\n\n\n@pytest.fixture\ndef expired_token() -&gt; str:\n    return \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n\n\n# INCORRECT: Vague names\n@pytest.fixture\ndef data():  # What kind of data?\n    return {\"key\": \"value\"}\n\n\n@pytest.fixture\ndef obj():  # What object?\n    return SomeClass()\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#do-document-fixture-purpose","title":"DO: Document Fixture Purpose","text":"<pre><code># CORRECT: Clear docstrings\n@pytest.fixture\nasync def postgres_data_service_client(test_config) -&gt; AsyncGenerator[DataServiceClient, None]:\n    \"\"\"Provide HTTP client for PostgreSQL data service.\n\n    Connects to the test instance of template_data_postgres_api service.\n    Automatically cleans up test data after each test.\n\n    Yields:\n        DataServiceClient configured for PostgreSQL data service\n    \"\"\"\n    client = DataServiceClient(base_url=test_config[\"POSTGRES_SERVICE_URL\"])\n    yield client\n    await client.cleanup_test_data()\n    await client.close()\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#dont-share-mutable-state","title":"DON'T: Share Mutable State","text":"<pre><code># INCORRECT: Mutable fixture shared across tests\n@pytest.fixture(scope=\"module\")\ndef shared_cache():\n    \"\"\"WRONG: Tests will pollute each other.\"\"\"\n    return {}  # Mutable dict shared across all tests\n\n\n# CORRECT: Fresh instance per test\n@pytest.fixture(scope=\"function\")\ndef isolated_cache():\n    \"\"\"Each test gets fresh cache.\"\"\"\n    return {}\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#common-patterns-for-microservices","title":"Common Patterns for Microservices","text":""},{"location":"atomic/testing/unit-testing/fixture-patterns/#fastapi-application-fixture","title":"FastAPI Application Fixture","text":"<pre><code>@pytest.fixture\nasync def app() -&gt; FastAPI:\n    \"\"\"Provide FastAPI application instance.\"\"\"\n    from finance_lending_api.main import create_app\n    return create_app()\n\n\n@pytest.fixture\nasync def client(app: FastAPI) -&gt; AsyncGenerator[AsyncClient, None]:\n    \"\"\"Provide HTTP client for FastAPI testing.\"\"\"\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#rabbitmq-connection-fixture","title":"RabbitMQ Connection Fixture","text":"<pre><code>@pytest.fixture\nasync def rabbitmq_connection(test_config):\n    \"\"\"Provide RabbitMQ connection for testing.\"\"\"\n    connection = await aio_pika.connect_robust(test_config[\"RABBITMQ_URL\"])\n    yield connection\n    await connection.close()\n\n\n@pytest.fixture\nasync def rabbitmq_channel(rabbitmq_connection):\n    \"\"\"Provide RabbitMQ channel from connection.\"\"\"\n    channel = await rabbitmq_connection.channel()\n    yield channel\n    await channel.close()\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#data-service-client-fixture","title":"Data Service Client Fixture","text":"<pre><code>@pytest.fixture\nasync def postgres_client(test_config) -&gt; AsyncGenerator[DataServiceClient, None]:\n    \"\"\"Provide PostgreSQL data service client.\"\"\"\n    client = DataServiceClient(test_config[\"POSTGRES_SERVICE_URL\"])\n    yield client\n    await client.close()\n</code></pre>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#checklist","title":"Checklist","text":"<ul> <li> Fixtures have appropriate scope (function/class/module/session)</li> <li> Async fixtures use <code>async def</code> and <code>AsyncGenerator</code> type hints</li> <li> Resource cleanup uses <code>yield</code> pattern, not <code>return</code></li> <li> Fixtures have clear, descriptive names</li> <li> Each fixture has a docstring explaining its purpose</li> <li> Conftest.py files organized by test directory hierarchy</li> <li> Autouse fixtures used sparingly (only for cross-cutting concerns)</li> <li> Factory fixtures used for creating multiple instances</li> <li> Fixture composition leverages dependency injection</li> <li> Mutable state not shared across tests via fixtures</li> <li> Parametrized fixtures used for data-driven testing</li> <li> Integration test fixtures clean up resources properly</li> </ul>"},{"location":"atomic/testing/unit-testing/fixture-patterns/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code> \u2014 Pytest configuration and basic setup</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies in tests</li> <li><code>docs/atomic/testing/unit-testing/parametrized-tests.md</code> \u2014 Advanced parametrization techniques</li> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Docker-based fixtures for integration tests</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 FastAPI-specific testing patterns</li> </ul>"},{"location":"atomic/testing/unit-testing/mocking-strategies/","title":"Mocking Strategies","text":"<p>Master mocking strategies to isolate units under test from external dependencies, enabling fast, deterministic unit tests that don't rely on databases, external APIs, or other services. Mocks replace real objects with controlled test doubles that verify interactions and return predictable values.</p> <p>This document covers pytest-mock patterns, AsyncMock for async code, patching strategies, and best practices for mocking Redis, HTTP clients, databases, and RabbitMQ connections in Python microservices. Proper mocking enables true unit testing by eliminating external dependencies while maintaining test realism.</p> <p>Understanding when to mock (unit tests) versus when to use real dependencies (integration tests) is critical for building a balanced test suite. Mocking reduces test runtime from seconds to milliseconds and eliminates flaky tests caused by external service failures.</p>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#setup","title":"Setup","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#dependencies","title":"Dependencies","text":"<pre><code># pyproject.toml\n[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=8.0\",\n    \"pytest-mock&gt;=3.12\",     # pytest wrapper for unittest.mock\n    \"pytest-asyncio&gt;=0.23\",  # for async tests\n    \"httpx&gt;=0.27\",           # for testing HTTP clients\n]\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#import-patterns","title":"Import Patterns","text":"<pre><code># CORRECT: Import mocking tools\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch, AsyncMock, call\nfrom pytest_mock import MockerFixture\n\n\n# Using pytest-mock fixture (recommended)\n@pytest.mark.unit\ndef test_with_mocker(mocker: MockerFixture):\n    \"\"\"Mocker fixture provides convenient mocking.\"\"\"\n    mock_redis = mocker.patch(\"my_module.redis_client\")\n    mock_redis.get.return_value = \"cached_value\"\n\n\n# Using unittest.mock directly (also valid)\n@pytest.mark.unit\n@patch(\"my_module.redis_client\")\ndef test_with_patch(mock_redis):\n    \"\"\"Traditional patch decorator.\"\"\"\n    mock_redis.get.return_value = \"cached_value\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#basic-mocking-patterns","title":"Basic Mocking Patterns","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#mock-vs-magicmock","title":"Mock vs MagicMock","text":"<pre><code>from unittest.mock import Mock, MagicMock\n\n\n# CORRECT: Use Mock for simple objects\n@pytest.mark.unit\ndef test_with_mock():\n    \"\"\"Mock provides basic mocking functionality.\"\"\"\n    mock_service = Mock()\n    mock_service.get_user.return_value = {\"id\": \"user-123\", \"name\": \"Test\"}\n\n    result = mock_service.get_user(\"user-123\")\n    assert result[\"name\"] == \"Test\"\n    mock_service.get_user.assert_called_once_with(\"user-123\")\n\n\n# CORRECT: Use MagicMock for objects needing magic methods\n@pytest.mark.unit\ndef test_with_magic_mock():\n    \"\"\"MagicMock supports magic methods like __len__, __iter__.\"\"\"\n    mock_list = MagicMock()\n    mock_list.__len__.return_value = 3\n    mock_list.__iter__.return_value = iter([1, 2, 3])\n\n    assert len(mock_list) == 3\n    assert list(mock_list) == [1, 2, 3]\n\n\n# INCORRECT: Using Mock when magic methods needed\n@pytest.mark.unit\ndef test_bad_mock():\n    \"\"\"WRONG: Mock doesn't support magic methods by default.\"\"\"\n    mock_list = Mock()\n    # len(mock_list)  # TypeError: object of type 'Mock' has no len()\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#return-values-and-side-effects","title":"Return Values and Side Effects","text":"<pre><code># CORRECT: Simple return value\n@pytest.mark.unit\ndef test_return_value():\n    \"\"\"Mock returns fixed value.\"\"\"\n    mock_service = Mock()\n    mock_service.calculate_interest.return_value = 150.50\n\n    result = mock_service.calculate_interest(amount=10000, rate=0.05)\n    assert result == 150.50\n\n\n# CORRECT: Different return values for sequential calls\n@pytest.mark.unit\ndef test_side_effect_sequence():\n    \"\"\"Mock returns different values for each call.\"\"\"\n    mock_service = Mock()\n    mock_service.get_random_number.side_effect = [1, 2, 3]\n\n    assert mock_service.get_random_number() == 1\n    assert mock_service.get_random_number() == 2\n    assert mock_service.get_random_number() == 3\n\n\n# CORRECT: Side effect raises exception\n@pytest.mark.unit\ndef test_side_effect_exception():\n    \"\"\"Mock raises exception.\"\"\"\n    mock_service = Mock()\n    mock_service.connect.side_effect = ConnectionError(\"Connection failed\")\n\n    with pytest.raises(ConnectionError, match=\"Connection failed\"):\n        mock_service.connect()\n\n\n# CORRECT: Side effect with custom function\n@pytest.mark.unit\ndef test_side_effect_function():\n    \"\"\"Mock uses function to compute return value.\"\"\"\n    def calculate_total(items: list) -&gt; float:\n        return sum(item[\"price\"] for item in items)\n\n    mock_service = Mock()\n    mock_service.calculate_total.side_effect = calculate_total\n\n    result = mock_service.calculate_total([\n        {\"price\": 10.0},\n        {\"price\": 20.0},\n    ])\n    assert result == 30.0\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#patching-strategies","title":"Patching Strategies","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#patch-decorator","title":"patch() Decorator","text":"<pre><code># CORRECT: Patch at import location (where it's used, not where it's defined)\n@pytest.mark.unit\n@patch(\"finance_lending_api.domain.services.redis_client\")\nasync def test_cache_lookup(mock_redis):\n    \"\"\"Patch Redis client where it's imported.\"\"\"\n    mock_redis.get.return_value = '{\"user_id\": \"user-123\"}'\n\n    from finance_lending_api.domain.services import UserService\n    service = UserService()\n    result = await service.get_cached_user(\"user-123\")\n\n    assert result[\"user_id\"] == \"user-123\"\n    mock_redis.get.assert_called_once_with(\"user:user-123\")\n\n\n# INCORRECT: Patching where defined instead of where used\n@pytest.mark.unit\n@patch(\"redis.asyncio.Redis\")  # WRONG: Patches redis library, not our import\nasync def test_bad_patch(mock_redis):\n    \"\"\"This won't work because UserService imports from different location.\"\"\"\n    from finance_lending_api.domain.services import UserService\n    service = UserService()\n    # Our redis_client is already imported, patch has no effect\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#patchobject","title":"patch.object()","text":"<pre><code># CORRECT: Patch specific method on object\n@pytest.mark.unit\nasync def test_patch_method():\n    \"\"\"Patch single method without replacing entire object.\"\"\"\n    from finance_lending_api.domain.services import UserService\n\n    service = UserService()\n\n    with patch.object(service, \"validate_email\", return_value=True):\n        result = await service.create_user(email=\"invalid-email\", name=\"Test\")\n        # validate_email is mocked to always return True\n        assert result is not None\n\n\n# CORRECT: Patch multiple methods on same object\n@pytest.mark.unit\nasync def test_patch_multiple_methods():\n    \"\"\"Patch multiple methods with patch.object.\"\"\"\n    from finance_lending_api.integrations.http_client import HTTPClient\n\n    client = HTTPClient()\n\n    with patch.object(client, \"get\", return_value={\"status\": \"ok\"}):\n        with patch.object(client, \"post\", return_value={\"id\": \"123\"}):\n            get_result = await client.get(\"/api/status\")\n            post_result = await client.post(\"/api/users\", data={})\n\n            assert get_result[\"status\"] == \"ok\"\n            assert post_result[\"id\"] == \"123\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#mocker-fixture-pytest-mock","title":"Mocker Fixture (pytest-mock)","text":"<pre><code># CORRECT: Use mocker fixture (cleaner syntax)\n@pytest.mark.unit\nasync def test_with_mocker(mocker: MockerFixture):\n    \"\"\"Mocker fixture provides convenient patching.\"\"\"\n    # Patch function\n    mock_validate = mocker.patch(\n        \"finance_lending_api.domain.validators.validate_email\",\n        return_value=True\n    )\n\n    # Patch class\n    mock_redis = mocker.patch(\"finance_lending_api.integrations.redis_client.Redis\")\n    mock_redis.return_value.get.return_value = \"cached\"\n\n    from finance_lending_api.domain.services import UserService\n    service = UserService()\n    result = await service.get_user(\"user-123\")\n\n    mock_validate.assert_called()\n    mock_redis.return_value.get.assert_called_once()\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#async-mocking","title":"Async Mocking","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#asyncmock-for-async-functions","title":"AsyncMock for Async Functions","text":"<pre><code># CORRECT: Use AsyncMock for async functions\n@pytest.mark.asyncio\nasync def test_async_mock():\n    \"\"\"AsyncMock works with await.\"\"\"\n    mock_service = AsyncMock()\n    mock_service.fetch_data.return_value = {\"data\": \"value\"}\n\n    result = await mock_service.fetch_data()\n    assert result[\"data\"] == \"value\"\n    mock_service.fetch_data.assert_called_once()\n\n\n# CORRECT: Mock async context manager\n@pytest.mark.asyncio\nasync def test_async_context_manager():\n    \"\"\"Mock async with statement.\"\"\"\n    mock_client = AsyncMock()\n    mock_client.__aenter__.return_value = mock_client\n    mock_client.get.return_value = {\"status\": \"ok\"}\n\n    async with mock_client as client:\n        result = await client.get(\"/status\")\n        assert result[\"status\"] == \"ok\"\n\n\n# INCORRECT: Using regular Mock for async function\n@pytest.mark.asyncio\nasync def test_bad_async_mock():\n    \"\"\"WRONG: Regular Mock doesn't work with await.\"\"\"\n    mock_service = Mock()\n    mock_service.fetch_data.return_value = {\"data\": \"value\"}\n\n    # result = await mock_service.fetch_data()  # TypeError: object Mock can't be used in 'await'\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#mocking-external-dependencies","title":"Mocking External Dependencies","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#redis-mocking","title":"Redis Mocking","text":"<pre><code># CORRECT: Mock Redis client\n@pytest.mark.unit\n@patch(\"finance_lending_api.integrations.redis_client.Redis\")\nasync def test_redis_cache(mock_redis_class):\n    \"\"\"Mock Redis client for caching logic.\"\"\"\n    mock_redis_instance = AsyncMock()\n    mock_redis_class.from_url.return_value = mock_redis_instance\n\n    # Mock cache miss then cache hit\n    mock_redis_instance.get.side_effect = [None, '{\"user_id\": \"user-123\"}']\n    mock_redis_instance.setex.return_value = True\n\n    from finance_lending_api.services.cache import CacheService\n    cache = CacheService()\n\n    # First call: cache miss\n    result1 = await cache.get_user(\"user-123\")\n    assert result1 is None\n\n    # Set cache\n    await cache.set_user(\"user-123\", {\"user_id\": \"user-123\"})\n\n    # Second call: cache hit\n    result2 = await cache.get_user(\"user-123\")\n    assert result2[\"user_id\"] == \"user-123\"\n\n    mock_redis_instance.setex.assert_called_once()\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#http-client-mocking","title":"HTTP Client Mocking","text":"<pre><code># CORRECT: Mock httpx.AsyncClient\n@pytest.mark.asyncio\nasync def test_http_client(mocker: MockerFixture):\n    \"\"\"Mock HTTP calls to external services.\"\"\"\n    mock_response = Mock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\"credit_score\": 750}\n\n    mock_client = AsyncMock()\n    mock_client.get.return_value = mock_response\n\n    mocker.patch(\"httpx.AsyncClient\", return_value=mock_client)\n\n    from finance_lending_api.integrations.credit_bureau import CreditBureauClient\n    bureau = CreditBureauClient()\n    score = await bureau.get_credit_score(\"user-123\")\n\n    assert score == 750\n    mock_client.get.assert_called_once_with(\n        \"https://credit-bureau.example.com/api/score/user-123\"\n    )\n\n\n# CORRECT: Mock respx for httpx (alternative approach)\nimport respx\n\n@pytest.mark.asyncio\n@respx.mock\nasync def test_with_respx():\n    \"\"\"Use respx library to mock httpx requests.\"\"\"\n    respx.get(\"https://api.example.com/users/123\").mock(\n        return_value=httpx.Response(200, json={\"id\": \"123\", \"name\": \"Test\"})\n    )\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/users/123\")\n        data = response.json()\n\n    assert data[\"name\"] == \"Test\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#database-mocking","title":"Database Mocking","text":"<pre><code># CORRECT: Mock database session\n@pytest.mark.unit\nasync def test_repository(mocker: MockerFixture):\n    \"\"\"Mock SQLAlchemy session for repository tests.\"\"\"\n    mock_session = AsyncMock()\n    mock_user = Mock()\n    mock_user.id = \"user-123\"\n    mock_user.email = \"test@example.com\"\n\n    # Mock query result\n    mock_result = Mock()\n    mock_result.scalar_one_or_none.return_value = mock_user\n    mock_session.execute.return_value = mock_result\n\n    from finance_lending_api.infrastructure.repositories import UserRepository\n    repo = UserRepository(session=mock_session)\n    user = await repo.get_by_id(\"user-123\")\n\n    assert user.email == \"test@example.com\"\n    mock_session.execute.assert_called_once()\n\n\n# INCORRECT: Don't mock database in integration tests\n@pytest.mark.integration  # WRONG: Integration tests should use real database\nasync def test_bad_integration(mocker: MockerFixture):\n    \"\"\"This defeats the purpose of integration testing.\"\"\"\n    mock_session = mocker.patch(\"sqlalchemy.orm.Session\")\n    # Integration tests should use testcontainers or real database\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#rabbitmq-mocking","title":"RabbitMQ Mocking","text":"<pre><code># CORRECT: Mock RabbitMQ channel and queue\n@pytest.mark.unit\nasync def test_rabbitmq_publish(mocker: MockerFixture):\n    \"\"\"Mock RabbitMQ message publishing.\"\"\"\n    mock_channel = AsyncMock()\n    mock_exchange = AsyncMock()\n    mock_channel.default_exchange = mock_exchange\n\n    mocker.patch(\n        \"finance_lending_api.integrations.rabbitmq.get_channel\",\n        return_value=mock_channel\n    )\n\n    from finance_lending_api.events.publisher import EventPublisher\n    publisher = EventPublisher()\n    await publisher.publish_user_created(user_id=\"user-123\")\n\n    mock_exchange.publish.assert_called_once()\n    call_args = mock_exchange.publish.call_args\n    assert \"user-123\" in str(call_args)\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#assertion-patterns","title":"Assertion Patterns","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#call-assertions","title":"Call Assertions","text":"<pre><code># CORRECT: Assert mock was called correctly\n@pytest.mark.unit\ndef test_call_assertions():\n    \"\"\"Verify mock call patterns.\"\"\"\n    mock_service = Mock()\n    mock_service.create_user(\"user@example.com\", \"John\")\n\n    # Assert called once\n    mock_service.create_user.assert_called_once()\n\n    # Assert called with specific arguments\n    mock_service.create_user.assert_called_once_with(\"user@example.com\", \"John\")\n\n    # Assert called with (allows multiple calls)\n    mock_service.create_user.assert_called_with(\"user@example.com\", \"John\")\n\n    # Assert any call (for multiple calls)\n    mock_service.create_user(\"jane@example.com\", \"Jane\")\n    mock_service.create_user.assert_any_call(\"user@example.com\", \"John\")\n    mock_service.create_user.assert_any_call(\"jane@example.com\", \"Jane\")\n\n\n# CORRECT: Assert call count\n@pytest.mark.unit\ndef test_call_count():\n    \"\"\"Verify number of calls.\"\"\"\n    mock_service = Mock()\n    mock_service.notify(\"user-1\")\n    mock_service.notify(\"user-2\")\n    mock_service.notify(\"user-3\")\n\n    assert mock_service.notify.call_count == 3\n\n\n# CORRECT: Assert not called\n@pytest.mark.unit\ndef test_not_called():\n    \"\"\"Verify mock was never called.\"\"\"\n    mock_service = Mock()\n    # Don't call mock_service.some_method()\n\n    mock_service.some_method.assert_not_called()\n\n\n# CORRECT: Inspect call arguments\n@pytest.mark.unit\ndef test_call_args():\n    \"\"\"Inspect what arguments were passed.\"\"\"\n    mock_service = Mock()\n    mock_service.log_event(\"user_created\", user_id=\"user-123\", timestamp=1234567890)\n\n    # Access call arguments\n    call_args = mock_service.log_event.call_args\n    assert call_args.args[0] == \"user_created\"\n    assert call_args.kwargs[\"user_id\"] == \"user-123\"\n\n    # Or use call() helper\n    mock_service.log_event.assert_called_with(\n        \"user_created\",\n        user_id=\"user-123\",\n        timestamp=1234567890\n    )\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/unit-testing/mocking-strategies/#do-mock-at-the-boundary","title":"DO: Mock at the Boundary","text":"<pre><code># CORRECT: Mock external dependencies (Redis, HTTP, database)\n@pytest.mark.unit\nasync def test_business_logic_mocked_dependencies(mocker: MockerFixture):\n    \"\"\"Unit test: mock external dependencies, test business logic.\"\"\"\n    # Mock Redis\n    mocker.patch(\"finance_lending_api.integrations.redis_client.get\", return_value=None)\n\n    # Mock HTTP client\n    mock_http = mocker.patch(\"finance_lending_api.integrations.http_client.post\")\n    mock_http.return_value = {\"approved\": True}\n\n    from finance_lending_api.domain.services import LoanService\n    service = LoanService()\n    result = await service.apply_for_loan(user_id=\"user-123\", amount=10000)\n\n    assert result[\"approved\"] is True\n\n\n# INCORRECT: Mocking internal business logic\n@pytest.mark.unit\nasync def test_bad_mocking(mocker: MockerFixture):\n    \"\"\"WRONG: Mocking the very logic you're trying to test.\"\"\"\n    mocker.patch(\n        \"finance_lending_api.domain.services.LoanService.calculate_interest\",\n        return_value=150.0\n    )\n    # Now we're not testing calculate_interest at all!\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#do-use-real-objects-when-possible","title":"DO: Use Real Objects When Possible","text":"<pre><code># CORRECT: Use real domain objects, mock only external dependencies\n@pytest.mark.unit\nasync def test_with_real_domain_objects(mocker: MockerFixture):\n    \"\"\"Use real domain objects, mock only integrations.\"\"\"\n    from finance_lending_api.domain.models import User, LoanApplication\n\n    # Real domain objects\n    user = User(id=\"user-123\", credit_score=750)\n    application = LoanApplication(user_id=user.id, amount=10000)\n\n    # Mock only external service\n    mock_credit_bureau = mocker.patch(\n        \"finance_lending_api.integrations.credit_bureau.get_score\",\n        return_value=750\n    )\n\n    from finance_lending_api.domain.services import LoanService\n    service = LoanService()\n    result = await service.evaluate_application(application)\n\n    assert result.approved is True\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#dont-over-mock","title":"DON'T: Over-Mock","text":"<pre><code># INCORRECT: Mocking everything (testing nothing)\n@pytest.mark.unit\ndef test_over_mocked(mocker: MockerFixture):\n    \"\"\"WRONG: So much mocking that test has no value.\"\"\"\n    mock_service = mocker.Mock()\n    mock_service.process.return_value = \"success\"\n\n    result = mock_service.process()\n    assert result == \"success\"  # This test proves nothing!\n\n\n# CORRECT: Test real logic with minimal mocking\n@pytest.mark.unit\ndef test_appropriate_mocking():\n    \"\"\"Test real calculation logic, mock only data source.\"\"\"\n    from finance_lending_api.domain.calculators import InterestCalculator\n\n    calculator = InterestCalculator()\n    interest = calculator.calculate(principal=10000, rate=0.05, years=2)\n\n    assert interest == 1000.0  # Tests real calculation logic\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#do-document-why-youre-mocking","title":"DO: Document Why You're Mocking","text":"<pre><code># CORRECT: Explain why dependency is mocked\n@pytest.mark.unit\nasync def test_user_creation(mocker: MockerFixture):\n    \"\"\"Test user creation logic.\n\n    Mocks:\n        - Redis: Avoid external cache dependency for unit test\n        - PostgreSQL HTTP client: Data service unavailable in unit test environment\n        - RabbitMQ: Event publishing tested separately in integration tests\n    \"\"\"\n    mock_redis = mocker.patch(\"finance_lending_api.integrations.redis.get\")\n    mock_postgres = mocker.patch(\"finance_lending_api.integrations.postgres_client.post\")\n    mock_rabbitmq = mocker.patch(\"finance_lending_api.events.publish\")\n\n    # Test business logic\n    ...\n</code></pre>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#checklist","title":"Checklist","text":"<ul> <li> Mock external dependencies (Redis, HTTP, databases, RabbitMQ) in unit tests</li> <li> Use <code>AsyncMock</code> for async functions and async context managers</li> <li> Patch at import location (where used), not where defined</li> <li> Use <code>mocker</code> fixture (pytest-mock) for cleaner syntax</li> <li> Assert mock calls with <code>assert_called_once_with()</code>, <code>assert_any_call()</code>, etc.</li> <li> Use real domain objects when possible, mock only boundaries</li> <li> Don't mock the code under test (mock dependencies, not business logic)</li> <li> Document why dependencies are mocked in test docstrings</li> <li> Prefer integration tests with real dependencies when testing integration logic</li> <li> Use <code>side_effect</code> for exceptions and sequential return values</li> <li> Reset mocks between tests (pytest-mock does this automatically)</li> <li> Don't over-mock (balance between isolation and realism)</li> </ul>"},{"location":"atomic/testing/unit-testing/mocking-strategies/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code> \u2014 Pytest configuration and basic setup</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Reusable test fixtures</li> <li><code>docs/atomic/testing/unit-testing/parametrized-tests.md</code> \u2014 Data-driven testing with parametrize</li> <li><code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> \u2014 Use real dependencies with Docker</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 Testing FastAPI endpoints</li> </ul>"},{"location":"atomic/testing/unit-testing/parametrized-tests/","title":"Parametrized Tests","text":"<p>Eliminate test duplication by running the same test logic with multiple input variations using pytest parametrization. Parametrized tests enable data-driven testing where a single test function executes multiple times with different argument sets, improving coverage while reducing code duplication.</p> <p>This document covers pytest.mark.parametrize patterns, fixture parametrization, test case naming strategies, and best practices for validation testing, edge case coverage, and business rule verification. Parametrization turns one test into dozens while keeping your test suite maintainable.</p> <p>Parametrization is essential for thorough testing of validators, calculators, parsers, and any function with multiple execution paths. Instead of writing 20 nearly-identical test functions, write one parametrized test with 20 test cases.</p>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#basic-parametrization","title":"Basic Parametrization","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#simple-parametrize","title":"Simple Parametrize","text":"<pre><code>import pytest\n\n\n# CORRECT: Parametrize with single parameter\n@pytest.mark.parametrize(\"email\", [\n    \"user@example.com\",\n    \"user.name@example.com\",\n    \"user+tag@example.co.uk\",\n])\n@pytest.mark.unit\ndef test_valid_emails(email: str):\n    \"\"\"Test that valid emails pass validation.\"\"\"\n    from finance_lending_api.domain.validators import is_valid_email\n    assert is_valid_email(email) is True\n\n\n# CORRECT: Parametrize with expected outcome\n@pytest.mark.parametrize(\"email,expected\", [\n    (\"user@example.com\", True),\n    (\"invalid-email\", False),\n    (\"user@\", False),\n    (\"@example.com\", False),\n    (\"user@.com\", False),\n])\n@pytest.mark.unit\ndef test_email_validation(email: str, expected: bool):\n    \"\"\"Test email validation with valid and invalid inputs.\"\"\"\n    from finance_lending_api.domain.validators import is_valid_email\n    assert is_valid_email(email) == expected\n\n\n# INCORRECT: Writing separate test for each case\n@pytest.mark.unit\ndef test_email_valid_1():  # WRONG: Duplicate test logic\n    assert is_valid_email(\"user@example.com\") is True\n\n@pytest.mark.unit\ndef test_email_valid_2():  # WRONG: Duplicate test logic\n    assert is_valid_email(\"user.name@example.com\") is True\n\n@pytest.mark.unit\ndef test_email_valid_3():  # WRONG: Duplicate test logic\n    assert is_valid_email(\"user+tag@example.co.uk\") is True\n# ... (repetitive)\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#multiple-parameters","title":"Multiple Parameters","text":"<pre><code># CORRECT: Parametrize with multiple parameters\n@pytest.mark.parametrize(\"principal,rate,years,expected_interest\", [\n    (10000, 0.05, 1, 500.0),\n    (10000, 0.05, 2, 1000.0),\n    (5000, 0.10, 1, 500.0),\n    (20000, 0.03, 3, 1800.0),\n    (0, 0.05, 1, 0.0),\n])\n@pytest.mark.unit\ndef test_simple_interest_calculation(\n    principal: float,\n    rate: float,\n    years: int,\n    expected_interest: float\n):\n    \"\"\"Test simple interest formula: I = P * R * T.\"\"\"\n    from finance_lending_api.domain.calculators import calculate_simple_interest\n\n    result = calculate_simple_interest(\n        principal=principal,\n        annual_rate=rate,\n        years=years\n    )\n\n    assert result == pytest.approx(expected_interest, rel=1e-2)\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#test-case-naming","title":"Test Case Naming","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#ids-for-readable-output","title":"IDs for Readable Output","text":"<pre><code># CORRECT: Use ids parameter for descriptive test names\n@pytest.mark.parametrize(\n    \"credit_score,expected_approved\",\n    [\n        (800, True),\n        (750, True),\n        (700, True),\n        (650, False),\n        (600, False),\n        (500, False),\n    ],\n    ids=[\n        \"excellent_credit\",\n        \"good_credit\",\n        \"fair_credit_approved\",\n        \"fair_credit_declined\",\n        \"poor_credit\",\n        \"very_poor_credit\",\n    ]\n)\n@pytest.mark.unit\ndef test_loan_approval_by_credit_score(credit_score: int, expected_approved: bool):\n    \"\"\"Test loan approval based on credit score threshold (700+).\"\"\"\n    from finance_lending_api.domain.services import LoanService\n\n    service = LoanService()\n    result = service.evaluate_loan(credit_score=credit_score, income=50000)\n\n    assert result.approved == expected_approved\n\n\n# Output:\n# test_loan_approval_by_credit_score[excellent_credit] PASSED\n# test_loan_approval_by_credit_score[good_credit] PASSED\n# test_loan_approval_by_credit_score[fair_credit_approved] PASSED\n# test_loan_approval_by_credit_score[fair_credit_declined] FAILED\n\n\n# INCORRECT: No ids (cryptic test output)\n@pytest.mark.parametrize(\n    \"credit_score,expected_approved\",\n    [(800, True), (750, True), (650, False)]\n)\n@pytest.mark.unit\ndef test_loan_approval(credit_score: int, expected_approved: bool):\n    # ...\n    pass\n\n# Output:\n# test_loan_approval[800-True] PASSED  # Hard to understand what this means\n# test_loan_approval[750-True] PASSED\n# test_loan_approval[650-False] FAILED\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#automatic-id-generation","title":"Automatic ID Generation","text":"<pre><code># CORRECT: Use pytest.param with id\n@pytest.mark.parametrize(\n    \"user_data,expected_error\",\n    [\n        pytest.param(\n            {\"email\": \"invalid\", \"name\": \"John\"},\n            \"Invalid email format\",\n            id=\"invalid_email\"\n        ),\n        pytest.param(\n            {\"email\": \"john@example.com\", \"name\": \"\"},\n            \"Name is required\",\n            id=\"missing_name\"\n        ),\n        pytest.param(\n            {\"email\": \"john@example.com\"},\n            \"Name is required\",\n            id=\"name_field_absent\"\n        ),\n    ]\n)\n@pytest.mark.unit\ndef test_user_validation_errors(user_data: dict, expected_error: str):\n    \"\"\"Test user input validation error messages.\"\"\"\n    from finance_lending_api.domain.validators import validate_user_data\n\n    with pytest.raises(ValueError, match=expected_error):\n        validate_user_data(user_data)\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#parametrizing-fixtures","title":"Parametrizing Fixtures","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#fixture-parametrization","title":"Fixture Parametrization","text":"<pre><code># CORRECT: Parametrize fixture to run tests with different configurations\n@pytest.fixture(params=[\"postgres\", \"mongo\"])\ndef database_client(request):\n    \"\"\"Provide different database clients.\"\"\"\n    if request.param == \"postgres\":\n        from finance_lending_api.integrations import PostgresClient\n        client = PostgresClient(\"http://localhost:8001\")\n    elif request.param == \"mongo\":\n        from finance_lending_api.integrations import MongoClient\n        client = MongoClient(\"http://localhost:8002\")\n\n    yield client\n    # Cleanup after test\n    client.close()\n\n\n@pytest.mark.integration\nasync def test_user_creation_across_databases(database_client):\n    \"\"\"Test user creation works with both PostgreSQL and MongoDB.\"\"\"\n    user = await database_client.create_user({\n        \"email\": \"test@example.com\",\n        \"name\": \"Test User\"\n    })\n\n    assert user[\"email\"] == \"test@example.com\"\n    assert \"id\" in user\n\n# This test runs twice automatically:\n# - test_user_creation_across_databases[postgres]\n# - test_user_creation_across_databases[mongo]\n\n\n# CORRECT: Parametrize fixture with IDs\n@pytest.fixture(\n    params=[\n        (\"redis://localhost:6379/0\", \"local\"),\n        (\"redis://redis-test:6379/1\", \"docker\"),\n    ],\n    ids=[\"local_redis\", \"docker_redis\"]\n)\ndef redis_url(request):\n    \"\"\"Provide different Redis connection URLs.\"\"\"\n    return request.param[0]\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#nested-parametrization","title":"Nested Parametrization","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#multiple-parametrize-decorators","title":"Multiple Parametrize Decorators","text":"<pre><code># CORRECT: Combine parametrize decorators (cartesian product)\n@pytest.mark.parametrize(\"credit_score\", [650, 700, 750, 800])\n@pytest.mark.parametrize(\"income\", [30000, 50000, 70000, 100000])\n@pytest.mark.unit\ndef test_loan_approval_matrix(credit_score: int, income: int):\n    \"\"\"Test loan approval with various credit scores and incomes.\n\n    This creates 4 * 4 = 16 test cases.\n    \"\"\"\n    from finance_lending_api.domain.services import LoanService\n\n    service = LoanService()\n    result = service.evaluate_loan(\n        credit_score=credit_score,\n        income=income,\n        requested_amount=10000\n    )\n\n    # Approval criteria: credit_score &gt;= 700 AND income &gt;= 50000\n    should_approve = credit_score &gt;= 700 and income &gt;= 50000\n    assert result.approved == should_approve\n\n\n# Output: 16 test cases\n# test_loan_approval_matrix[30000-650] PASSED\n# test_loan_approval_matrix[30000-700] PASSED\n# ...\n# test_loan_approval_matrix[100000-800] PASSED\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#complex-test-cases","title":"Complex Test Cases","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#parametrize-with-dictionaries","title":"Parametrize with Dictionaries","text":"<pre><code># CORRECT: Use dictionaries for complex test cases\n@pytest.mark.parametrize(\n    \"test_case\",\n    [\n        {\n            \"id\": \"approved_high_credit\",\n            \"input\": {\n                \"credit_score\": 800,\n                \"income\": 100000,\n                \"debt_ratio\": 0.2,\n                \"employment_years\": 5,\n            },\n            \"expected\": {\n                \"approved\": True,\n                \"interest_rate\": 3.5,\n                \"max_amount\": 50000,\n            }\n        },\n        {\n            \"id\": \"declined_low_credit\",\n            \"input\": {\n                \"credit_score\": 600,\n                \"income\": 50000,\n                \"debt_ratio\": 0.5,\n                \"employment_years\": 1,\n            },\n            \"expected\": {\n                \"approved\": False,\n                \"interest_rate\": None,\n                \"max_amount\": 0,\n            }\n        },\n        {\n            \"id\": \"approved_medium_risk\",\n            \"input\": {\n                \"credit_score\": 720,\n                \"income\": 60000,\n                \"debt_ratio\": 0.35,\n                \"employment_years\": 3,\n            },\n            \"expected\": {\n                \"approved\": True,\n                \"interest_rate\": 4.5,\n                \"max_amount\": 25000,\n            }\n        },\n    ],\n    ids=lambda tc: tc[\"id\"]\n)\n@pytest.mark.unit\ndef test_loan_underwriting(test_case: dict):\n    \"\"\"Test comprehensive loan underwriting logic.\"\"\"\n    from finance_lending_api.domain.services import UnderwritingService\n\n    service = UnderwritingService()\n    result = service.evaluate(**test_case[\"input\"])\n\n    assert result.approved == test_case[\"expected\"][\"approved\"]\n    assert result.interest_rate == test_case[\"expected\"][\"interest_rate\"]\n    assert result.max_amount == test_case[\"expected\"][\"max_amount\"]\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#parametrize-with-classes","title":"Parametrize with Classes","text":"<pre><code># CORRECT: Parametrize entire test class\n@pytest.mark.parametrize(\n    \"service_type\",\n    [\"fastapi\", \"aiogram\", \"worker\"],\n    ids=[\"fastapi_service\", \"aiogram_bot\", \"asyncio_worker\"]\n)\nclass TestServiceHealthChecks:\n    \"\"\"Test health checks across all service types.\"\"\"\n\n    @pytest.mark.integration\n    async def test_health_endpoint_returns_200(self, service_type: str):\n        \"\"\"All services should have working health endpoint.\"\"\"\n        from finance_lending_api.testing.utils import get_service_client\n\n        client = get_service_client(service_type)\n        response = await client.get(\"/health\")\n\n        assert response.status_code == 200\n        assert response.json()[\"status\"] == \"healthy\"\n\n    @pytest.mark.integration\n    async def test_metrics_endpoint_returns_prometheus_format(self, service_type: str):\n        \"\"\"All services should expose Prometheus metrics.\"\"\"\n        from finance_lending_api.testing.utils import get_service_client\n\n        client = get_service_client(service_type)\n        response = await client.get(\"/metrics\")\n\n        assert response.status_code == 200\n        assert \"# TYPE\" in response.text  # Prometheus format\n\n\n# This creates 6 tests (2 test methods * 3 service types):\n# TestServiceHealthChecks::test_health_endpoint_returns_200[fastapi_service]\n# TestServiceHealthChecks::test_health_endpoint_returns_200[aiogram_bot]\n# TestServiceHealthChecks::test_health_endpoint_returns_200[asyncio_worker]\n# TestServiceHealthChecks::test_metrics_endpoint_returns_prometheus_format[fastapi_service]\n# ...\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#edge-cases-and-boundary-testing","title":"Edge Cases and Boundary Testing","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#boundary-value-analysis","title":"Boundary Value Analysis","text":"<pre><code># CORRECT: Test boundary values explicitly\n@pytest.mark.parametrize(\n    \"age,expected_category\",\n    [\n        (0, \"invalid\"),\n        (1, \"child\"),\n        (17, \"child\"),\n        (18, \"adult\"),\n        (64, \"adult\"),\n        (65, \"senior\"),\n        (120, \"senior\"),\n        (121, \"invalid\"),\n    ],\n    ids=[\n        \"below_minimum\",\n        \"minimum_child\",\n        \"maximum_child\",\n        \"minimum_adult\",\n        \"maximum_adult\",\n        \"minimum_senior\",\n        \"maximum_age\",\n        \"above_maximum\",\n    ]\n)\n@pytest.mark.unit\ndef test_age_category_boundaries(age: int, expected_category: str):\n    \"\"\"Test age categorization at boundary values.\"\"\"\n    from finance_lending_api.domain.utils import categorize_age\n\n    if expected_category == \"invalid\":\n        with pytest.raises(ValueError):\n            categorize_age(age)\n    else:\n        result = categorize_age(age)\n        assert result == expected_category\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#exception-testing","title":"Exception Testing","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#parametrizing-expected-exceptions","title":"Parametrizing Expected Exceptions","text":"<pre><code># CORRECT: Parametrize exception scenarios\n@pytest.mark.parametrize(\n    \"amount,rate,term,expected_exception,error_message\",\n    [\n        (-1000, 0.05, 12, ValueError, \"Amount must be positive\"),\n        (10000, -0.05, 12, ValueError, \"Rate must be positive\"),\n        (10000, 0.05, 0, ValueError, \"Term must be at least 1 month\"),\n        (0, 0.05, 12, ValueError, \"Amount must be positive\"),\n        (10000, 0, 12, ValueError, \"Rate must be positive\"),\n    ],\n    ids=[\n        \"negative_amount\",\n        \"negative_rate\",\n        \"zero_term\",\n        \"zero_amount\",\n        \"zero_rate\",\n    ]\n)\n@pytest.mark.unit\ndef test_loan_calculator_validation(\n    amount: float,\n    rate: float,\n    term: int,\n    expected_exception: type,\n    error_message: str\n):\n    \"\"\"Test loan calculator input validation.\"\"\"\n    from finance_lending_api.domain.calculators import LoanCalculator\n\n    calculator = LoanCalculator()\n\n    with pytest.raises(expected_exception, match=error_message):\n        calculator.calculate_monthly_payment(\n            amount=amount,\n            annual_rate=rate,\n            term_months=term\n        )\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#async-parametrization","title":"Async Parametrization","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#parametrizing-async-tests","title":"Parametrizing Async Tests","text":"<pre><code># CORRECT: Parametrize async tests\n@pytest.mark.parametrize(\n    \"user_id,expected_found\",\n    [\n        (\"existing-user-123\", True),\n        (\"non-existent-user\", False),\n    ],\n    ids=[\"user_exists\", \"user_not_found\"]\n)\n@pytest.mark.asyncio\nasync def test_user_lookup(user_id: str, expected_found: bool, mocker):\n    \"\"\"Test user lookup with existing and non-existing users.\"\"\"\n    from finance_lending_api.domain.services import UserService\n\n    # Mock data service\n    mock_client = mocker.patch(\"finance_lending_api.integrations.postgres_client\")\n\n    if expected_found:\n        mock_client.get.return_value = {\"id\": user_id, \"name\": \"Test User\"}\n    else:\n        mock_client.get.return_value = None\n\n    service = UserService()\n    user = await service.get_user(user_id)\n\n    if expected_found:\n        assert user is not None\n        assert user[\"id\"] == user_id\n    else:\n        assert user is None\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#best-practices","title":"Best Practices","text":""},{"location":"atomic/testing/unit-testing/parametrized-tests/#do-use-descriptive-ids","title":"DO: Use Descriptive IDs","text":"<pre><code># CORRECT: IDs explain what is being tested\n@pytest.mark.parametrize(\n    \"input,expected\",\n    [\n        (\"+1234567890\", True),\n        (\"+44 20 7946 0958\", True),\n        (\"123\", False),\n        (\"\", False),\n    ],\n    ids=[\n        \"us_phone_valid\",\n        \"uk_phone_with_spaces_valid\",\n        \"too_short_invalid\",\n        \"empty_string_invalid\",\n    ]\n)\n@pytest.mark.unit\ndef test_phone_validation(input: str, expected: bool):\n    \"\"\"Test international phone number validation.\"\"\"\n    assert is_valid_phone(input) == expected\n\n\n# INCORRECT: Default IDs are unclear\n@pytest.mark.parametrize(\n    \"input,expected\",\n    [(\"+1234567890\", True), (\"123\", False)]\n)\n@pytest.mark.unit\ndef test_phone(input: str, expected: bool):\n    assert is_valid_phone(input) == expected\n\n# Output:\n# test_phone[+1234567890-True] PASSED  # What does this mean?\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#do-group-related-test-cases","title":"DO: Group Related Test Cases","text":"<pre><code># CORRECT: Group related scenarios\nvalid_emails = [\n    \"user@example.com\",\n    \"user.name@example.com\",\n    \"user+tag@example.co.uk\",\n]\n\ninvalid_emails = [\n    \"invalid\",\n    \"user@\",\n    \"@example.com\",\n    \"user@.com\",\n]\n\n@pytest.mark.parametrize(\"email\", valid_emails)\n@pytest.mark.unit\ndef test_valid_email_formats(email: str):\n    \"\"\"Test that valid email formats pass validation.\"\"\"\n    assert is_valid_email(email) is True\n\n\n@pytest.mark.parametrize(\"email\", invalid_emails)\n@pytest.mark.unit\ndef test_invalid_email_formats(email: str):\n    \"\"\"Test that invalid email formats fail validation.\"\"\"\n    assert is_valid_email(email) is False\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#dont-overuse-parametrization","title":"DON'T: Overuse Parametrization","text":"<pre><code># INCORRECT: Parametrizing unrelated tests\n@pytest.mark.parametrize(\n    \"test_case\",\n    [\n        (\"email_validation\", \"test@example.com\", True),\n        (\"age_validation\", 25, True),\n        (\"loan_calculation\", 10000, 500.0),\n    ]\n)\n@pytest.mark.unit\ndef test_everything(test_case: str, input: Any, expected: Any):\n    \"\"\"WRONG: Unrelated tests forced into parametrization.\"\"\"\n    if test_case == \"email_validation\":\n        assert is_valid_email(input) == expected\n    elif test_case == \"age_validation\":\n        assert is_valid_age(input) == expected\n    elif test_case == \"loan_calculation\":\n        assert calculate_interest(input) == expected\n\n\n# CORRECT: Separate tests for unrelated logic\n@pytest.mark.unit\ndef test_email_validation():\n    \"\"\"Test email validation.\"\"\"\n    assert is_valid_email(\"test@example.com\") is True\n\n\n@pytest.mark.unit\ndef test_age_validation():\n    \"\"\"Test age validation.\"\"\"\n    assert is_valid_age(25) is True\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#do-test-edge-cases","title":"DO: Test Edge Cases","text":"<pre><code># CORRECT: Include edge cases in parametrization\n@pytest.mark.parametrize(\n    \"amount,expected_fee\",\n    [\n        (0, 0.0),              # Edge: zero amount\n        (0.01, 0.01),          # Edge: minimum amount\n        (100, 1.0),            # Normal case\n        (999999, 9999.99),     # Edge: large amount\n        (1000000, 10000.0),    # Edge: maximum amount\n    ],\n    ids=[\"zero\", \"minimum\", \"normal\", \"large\", \"maximum\"]\n)\n@pytest.mark.unit\ndef test_transaction_fee_calculation(amount: float, expected_fee: float):\n    \"\"\"Test transaction fee (1%) including edge cases.\"\"\"\n    from finance_lending_api.domain.calculators import calculate_fee\n\n    result = calculate_fee(amount)\n    assert result == pytest.approx(expected_fee, rel=1e-2)\n</code></pre>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#checklist","title":"Checklist","text":"<ul> <li> Use <code>@pytest.mark.parametrize</code> for tests with multiple input variations</li> <li> Provide descriptive <code>ids</code> for test case names</li> <li> Test boundary values explicitly (min, max, zero, negative)</li> <li> Group related test cases in separate variables</li> <li> Use <code>pytest.param</code> with custom ids for complex cases</li> <li> Parametrize fixtures for testing with different configurations</li> <li> Combine multiple <code>@pytest.mark.parametrize</code> decorators for cartesian product</li> <li> Include edge cases and error scenarios in parametrization</li> <li> Use dictionaries for complex test cases with many fields</li> <li> Don't overuse parametrization for unrelated tests</li> <li> Keep parametrized test logic simple and focused</li> <li> Test both happy path and error scenarios</li> </ul>"},{"location":"atomic/testing/unit-testing/parametrized-tests/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code> \u2014 Pytest configuration and basic setup</li> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Reusable test fixtures (including parametrized fixtures)</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies in parametrized tests</li> <li><code>docs/atomic/testing/unit-testing/coverage-requirements.md</code> \u2014 Coverage standards and enforcement</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 Parametrizing API endpoint tests</li> </ul>"},{"location":"atomic/testing/unit-testing/pytest-setup/","title":"Pytest Setup","text":"<p>Configure pytest for unit testing with proper fixtures, markers, and coverage reporting. Pytest is the standard testing framework for Python services in this platform, providing powerful fixtures, parametrization, and plugin ecosystem.</p>"},{"location":"atomic/testing/unit-testing/pytest-setup/#configuration","title":"Configuration","text":"<p>Create <code>pytest.ini</code> in your project root to define test discovery patterns, markers, and default options:</p> <pre><code># pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\n\naddopts =\n    --verbose\n    --strict-markers\n    --cov=src\n    --cov-report=html\n    --cov-report=term\n    --cov-fail-under=80\n\nmarkers =\n    unit: Unit tests (fast, no external dependencies)\n    integration: Integration tests (require databases, Redis, RabbitMQ)\n    slow: Slow tests (&gt; 1 second)\n    asyncio: Async tests requiring asyncio event loop\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#coverage-configuration","title":"Coverage Configuration","text":"<p>Add <code>.coveragerc</code> to configure coverage reporting:</p> <pre><code># .coveragerc\n[run]\nsource = src\nomit =\n    */tests/*\n    */migrations/*\n    */__pycache__/*\n\n[report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\n    if TYPE_CHECKING:\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#project-structure","title":"Project Structure","text":"<p>Organize tests to mirror your source code structure:</p> <pre><code>project/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 finance_lending_api/\n\u2502       \u251c\u2500\u2500 domain/\n\u2502       \u2502   \u2514\u2500\u2500 user_service.py\n\u2502       \u251c\u2500\u2500 infrastructure/\n\u2502       \u2502   \u2514\u2500\u2500 repositories.py\n\u2502       \u2514\u2500\u2500 api/\n\u2502           \u2514\u2500\u2500 routers.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 unit/\n\u2502   \u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_user_service.py\n\u2502   \u2502   \u2514\u2500\u2500 infrastructure/\n\u2502   \u2502       \u2514\u2500\u2500 test_repositories.py\n\u2502   \u251c\u2500\u2500 integration/\n\u2502   \u2502   \u2514\u2500\u2500 test_postgres_integration.py\n\u2502   \u2514\u2500\u2500 conftest.py\n\u251c\u2500\u2500 pytest.ini\n\u251c\u2500\u2500 .coveragerc\n\u2514\u2500\u2500 pyproject.toml\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#dependencies","title":"Dependencies","text":"<p>Add pytest and plugins to <code>pyproject.toml</code>:</p> <pre><code>[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=8.0\",\n    \"pytest-asyncio&gt;=0.23\",\n    \"pytest-cov&gt;=4.1\",\n    \"pytest-mock&gt;=3.12\",\n    \"pytest-xdist&gt;=3.5\",  # parallel test execution\n    \"httpx&gt;=0.27\",        # for testing async HTTP\n]\n</code></pre> <p>Install test dependencies:</p> <pre><code>pip install -e \".[test]\"\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#basic-test-example","title":"Basic Test Example","text":"<pre><code># tests/unit/domain/test_user_service.py\nimport pytest\nfrom finance_lending_api.domain.user_service import UserService\nfrom finance_lending_api.domain.models import User\n\n\n# CORRECT: Clear test name, async, proper fixtures\n@pytest.mark.unit\n@pytest.mark.asyncio\nasync def test_create_user_validates_email():\n    \"\"\"Test that create_user validates email format.\"\"\"\n    service = UserService()\n\n    with pytest.raises(ValueError, match=\"Invalid email\"):\n        await service.create_user(email=\"invalid-email\", name=\"John Doe\")\n\n\n# CORRECT: Parametrized test for multiple cases\n@pytest.mark.unit\n@pytest.mark.parametrize(\"email,expected\", [\n    (\"user@example.com\", True),\n    (\"invalid\", False),\n    (\"user@\", False),\n    (\"@example.com\", False),\n])\ndef test_email_validation(email: str, expected: bool):\n    \"\"\"Test email validation with various inputs.\"\"\"\n    from finance_lending_api.utils import is_valid_email\n    assert is_valid_email(email) == expected\n\n\n# INCORRECT: No markers, unclear name, not async\ndef test_user():\n    user = create_user(\"test\")\n    assert user  # What are we testing?\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run only unit tests\npytest -m unit\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run in parallel (faster)\npytest -n auto\n\n# Run specific file\npytest tests/unit/domain/test_user_service.py\n\n# Run specific test\npytest tests/unit/domain/test_user_service.py::test_create_user_validates_email\n\n# Run with verbose output\npytest -vv\n\n# Stop on first failure\npytest -x\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#markers-usage","title":"Markers Usage","text":"<p>Mark tests appropriately for selective execution:</p> <pre><code>import pytest\n\n@pytest.mark.unit\ndef test_fast_operation():\n    \"\"\"Fast test with no external dependencies.\"\"\"\n    pass\n\n@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_database_operation():\n    \"\"\"Integration test requiring database.\"\"\"\n    pass\n\n@pytest.mark.slow\ndef test_expensive_computation():\n    \"\"\"Test that takes &gt; 1 second.\"\"\"\n    pass\n\n# Custom markers defined in pytest.ini\n@pytest.mark.unit\n@pytest.mark.asyncio\nasync def test_async_function():\n    \"\"\"Async test requiring event loop.\"\"\"\n    result = await some_async_function()\n    assert result is not None\n</code></pre>"},{"location":"atomic/testing/unit-testing/pytest-setup/#checklist","title":"Checklist","text":"<ul> <li> <code>pytest.ini</code> configured with test paths and markers</li> <li> <code>.coveragerc</code> configured for coverage reporting</li> <li> Test structure mirrors source code structure</li> <li> All tests have descriptive names (<code>test_&lt;what&gt;_&lt;scenario&gt;</code>)</li> <li> Tests marked appropriately (<code>@pytest.mark.unit</code>, etc.)</li> <li> Async tests use <code>@pytest.mark.asyncio</code></li> <li> Coverage target set (typically 80%+)</li> <li> Tests run successfully: <code>pytest -m unit</code></li> </ul>"},{"location":"atomic/testing/unit-testing/pytest-setup/#related-documents","title":"Related Documents","text":"<ul> <li><code>docs/atomic/testing/unit-testing/fixture-patterns.md</code> \u2014 Pytest fixture patterns and best practices</li> <li><code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2014 Mocking external dependencies in tests</li> <li><code>docs/atomic/testing/unit-testing/parametrized-tests.md</code> \u2014 Advanced parametrization techniques</li> <li><code>docs/atomic/testing/unit-testing/coverage-requirements.md</code> \u2014 Coverage standards and enforcement</li> <li><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2014 Testing FastAPI services</li> </ul>"},{"location":"checklists/service-naming-checklist/","title":"Service Naming Decision Checklist","text":"<p>Purpose: Machine-readable checklist for AI agents and developers to decide between 3-part and 4-part service naming.</p> <p>Related: Naming Conventions | Semantic Shortening Guide</p>"},{"location":"checklists/service-naming-checklist/#step-1-start-with-3-part-default","title":"Step 1: Start with 3-Part (Default)","text":"<p>Formula: <code>{context}_{domain}_{type}</code></p> <p>Examples: - <code>finance_lending_api</code> (P2P lending platform) - <code>healthcare_telemedicine_api</code> (Online consultation service) - <code>construction_house_bot</code> (House project management bot)</p> <p>Expected distribution: 80-90% of services should use 3-part naming.</p>"},{"location":"checklists/service-naming-checklist/#step-2-check-10-reasons-for-4-part","title":"Step 2: Check 10 Reasons for 4-Part","text":"<p>IMPORTANT: Use 4-part ONLY if at least ONE reason applies.</p>"},{"location":"checklists/service-naming-checklist/#checklist","title":"Checklist","text":"<ul> <li> Reason 1: Domain Ambiguity \u2014 Domain word implies 3+ operations?</li> <li>Examples: <code>fleet</code>, <code>analytics</code>, <code>communication</code>, <code>warehouse</code>, <code>delivery</code></li> <li> <p>Test: \"Can this domain mean tracking OR management OR maintenance OR...?\"</p> </li> <li> <p> Reason 2: Multiple Services per Domain \u2014 Need 2+ services in same <code>{context}_{domain}</code>?</p> </li> <li>Example: <code>logistics_fleet_tracking_api</code> AND <code>logistics_fleet_management_api</code></li> <li> <p>Test: \"Do I need to split this domain into separate microservices?\"</p> </li> <li> <p> Reason 3: Cross-Context Collision \u2014 Same domain word in different contexts?</p> </li> <li>Example: <code>communication_notification_worker</code> vs <code>system_notification_api</code></li> <li> <p>Test: \"Is this domain used in 2+ contexts with different meanings?\"</p> </li> <li> <p> Reason 4: Organizational Policy \u2014 Team requires explicit functions?</p> </li> <li>Check: Context Registry (<code>docs/atomic/architecture/context-registry.md</code>)</li> <li> <p>Test: \"Does our policy require explicit functions for this context?\"</p> </li> <li> <p> Reason 5: Technical Differentiation \u2014 Different technologies/providers?</p> </li> <li>Example: <code>finance_payment_stripe_api</code> vs <code>finance_payment_paypal_api</code></li> <li> <p>Test: \"Do I need separate services for different providers/technologies?\"</p> </li> <li> <p> Reason 6: Functional Split (Migration) \u2014 Blue-green with functional split?</p> </li> <li>Example: Monolith \u2192 <code>finance_lending_matching_api</code> + <code>finance_lending_approval_api</code></li> <li> <p>Test: \"Am I decomposing a monolith into functional areas?\"</p> </li> <li> <p> Reason 7: Legacy Terminology \u2014 Existing system has established terms?</p> </li> <li>Example: <code>OldERP.FleetTrackingModule</code> \u2192 <code>logistics_fleet_tracking_api</code></li> <li> <p>Test: \"Should I preserve legacy naming to avoid team confusion?\"</p> </li> <li> <p> Reason 8: Regulatory Requirements \u2014 Compliance requires separation?</p> </li> <li>Example: <code>finance_payment_processing_api</code> vs <code>finance_payment_storage_api</code> (PCI)</li> <li> <p>Test: \"Does regulator require explicit functional separation?\"</p> </li> <li> <p> Reason 9: Different SLA/Resources \u2014 Radically different infrastructure?</p> </li> <li>Example: <code>analytics_querying_api</code> (ms latency) vs <code>analytics_aggregation_worker</code> (hour latency)</li> <li> <p>Test: \"Do functions need completely different scaling strategies?\"</p> </li> <li> <p> Reason 10: Onboarding Clarity \u2014 New team members confused?</p> </li> <li>Example: Large platform (50+ services) where 3-part names are unclear</li> <li>Test: \"Would new developers struggle to understand this service from 3-part name?\"</li> </ul>"},{"location":"checklists/service-naming-checklist/#step-3-make-decision","title":"Step 3: Make Decision","text":""},{"location":"checklists/service-naming-checklist/#if-all-unchecked-use-3-part","title":"If ALL unchecked \u2192 Use 3-part \u2705","text":"<p>Pattern: <code>{context}_{domain}_{type}</code></p> <p>Rationale: Function is implied by context + domain.</p> <p>Examples: <pre><code>finance_lending_api          \u2190 lending = matching/approval (clear)\nhealthcare_telemedicine_api  \u2190 telemedicine = consultation (clear)\nconstruction_house_bot       \u2190 house = project management (clear)\nfinance_payment_worker       \u2190 payment = processing (clear)\n</code></pre></p>"},{"location":"checklists/service-naming-checklist/#if-at-least-one-checked-use-4-part","title":"If AT LEAST ONE checked \u2192 Use 4-part \u2705","text":"<p>Pattern: <code>{context}_{domain}_{function}_{type}</code></p> <p>Rationale: Domain is ambiguous, explicit function required.</p> <p>Examples: <pre><code>logistics_fleet_tracking_api         \u2190 fleet ambiguous (Reason 1)\nanalytics_reporting_api              \u2190 analytics ambiguous (Reason 1)\ncommunication_notification_worker    \u2190 communication ambiguous (Reason 1)\nfinance_payment_stripe_api           \u2190 multiple providers (Reason 5)\nhealthcare_patient_storage_api       \u2190 regulatory separation (Reason 8)\n</code></pre></p>"},{"location":"checklists/service-naming-checklist/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":""},{"location":"checklists/service-naming-checklist/#do-not-use-4-part-for","title":"\u274c DO NOT use 4-part for:","text":"<ol> <li>Multiple code features \u2014 Service has CRUD + search + export</li> <li>\u274c BAD: <code>construction_house_management_bot</code></li> <li> <p>\u2705 GOOD: <code>construction_house_bot</code> (management implied)</p> </li> <li> <p>Multiple endpoints \u2014 API has /create, /update, /delete routes</p> </li> <li>\u274c BAD: <code>finance_lending_operations_api</code></li> <li> <p>\u2705 GOOD: <code>finance_lending_api</code> (CRUD implied)</p> </li> <li> <p>Name seems short \u2014 Adding words for length</p> </li> <li>\u274c BAD: <code>finance_lending_platform_api</code></li> <li> <p>\u2705 GOOD: <code>finance_lending_api</code> (brevity is good)</p> </li> <li> <p>Symmetry with others \u2014 Matching other services' patterns</p> </li> <li>\u274c BAD: Forcing all services to 4-part for consistency</li> <li>\u2705 GOOD: Evaluate each service independently</li> </ol>"},{"location":"checklists/service-naming-checklist/#quick-examples-by-context","title":"Quick Examples by Context","text":""},{"location":"checklists/service-naming-checklist/#finance-mostly-3-part","title":"Finance (mostly 3-part)","text":"<pre><code>\u2705 finance_lending_api          # lending = matching/approval (clear)\n\u2705 finance_payment_api          # payment = processing (clear)\n\u2705 finance_crypto_api           # crypto = portfolio mgmt (clear)\n\u2705 finance_billing_api          # billing = invoicing (clear)\n</code></pre>"},{"location":"checklists/service-naming-checklist/#healthcare-mostly-3-part","title":"Healthcare (mostly 3-part)","text":"<pre><code>\u2705 healthcare_telemedicine_api  # telemedicine = consultation (clear)\n\u2705 healthcare_appointment_api   # appointment = booking (clear)\n\u2705 healthcare_pharmacy_api      # pharmacy = medication mgmt (clear)\n</code></pre>"},{"location":"checklists/service-naming-checklist/#logistics-often-4-part","title":"Logistics (often 4-part)","text":"<pre><code>\u2705 logistics_fleet_tracking_api      # fleet ambiguous \u2192 need function\n\u2705 logistics_delivery_routing_api    # delivery ambiguous \u2192 need function\n\u2705 logistics_warehouse_inventory_api # warehouse ambiguous \u2192 need function\n</code></pre>"},{"location":"checklists/service-naming-checklist/#analytics-often-4-part","title":"Analytics (often 4-part)","text":"<pre><code>\u2705 analytics_reporting_api           # analytics ambiguous \u2192 need function\n\u2705 analytics_querying_api            # analytics ambiguous \u2192 need function\n\u2705 analytics_aggregation_worker      # analytics ambiguous \u2192 need function\n</code></pre>"},{"location":"checklists/service-naming-checklist/#communication-often-4-part","title":"Communication (often 4-part)","text":"<pre><code>\u2705 communication_notification_worker # communication ambiguous \u2192 need function\n\u2705 communication_email_api           # communication ambiguous \u2192 need function\n\u2705 communication_webhook_api         # communication ambiguous \u2192 need function\n</code></pre>"},{"location":"checklists/service-naming-checklist/#for-ai-agents","title":"For AI Agents","text":""},{"location":"checklists/service-naming-checklist/#automated-decision-process","title":"Automated Decision Process","text":"<pre><code>def decide_naming_pattern(context: str, domain: str, type_: str) -&gt; str:\n    \"\"\"\n    Automated 3-part vs 4-part decision for AI agents.\n\n    Returns:\n        \"3-PART\" or \"4-PART_REQUIRED\"\n    \"\"\"\n    # Check Reason 1: Domain Ambiguity\n    ambiguous_domains = [\n        'fleet', 'analytics', 'data', 'communication', 'warehouse',\n        'delivery', 'content', 'user', 'document', 'event',\n        'monitoring', 'network', 'asset', 'inventory', 'customer'\n    ]\n\n    if domain in ambiguous_domains:\n        return \"4-PART_REQUIRED\"\n\n    # For other reasons (2-10), human judgment or explicit input needed\n    # Default to 3-part\n    return \"3-PART\"\n\n# Usage\nresult = decide_naming_pattern(\"finance\", \"lending\", \"api\")\n# Returns: \"3-PART\" \u2192 use finance_lending_api\n\nresult = decide_naming_pattern(\"logistics\", \"fleet\", \"api\")\n# Returns: \"4-PART_REQUIRED\" \u2192 use logistics_fleet_{function}_api\n</code></pre>"},{"location":"checklists/service-naming-checklist/#ai-prompt-template","title":"AI Prompt Template","text":"<p>When AI needs to name a service:</p> <pre><code>Context: {context}\nDomain: {domain}\nType: {type}\n\nStep 1: Check domain ambiguity\n- Is domain in ambiguous list? [YES/NO]\n- Can domain mean 3+ operations? [YES/NO]\n\nStep 2: Check other reasons (2-10)\n- [List any applicable reasons]\n\nStep 3: Decision\n- If domain ambiguous OR any reason applies \u2192 4-PART\n- Otherwise \u2192 3-PART\n\nResult: {chosen_pattern}\nRationale: {explanation}\n</code></pre>"},{"location":"checklists/service-naming-checklist/#validation","title":"Validation","text":"<p>After naming, verify:</p> <ul> <li> Pattern correct \u2014 3-part or 4-part as decided</li> <li> Separator correct \u2014 Underscores in code/data layer</li> <li> No abbreviations \u2014 Full words (e.g., <code>finance</code>, not <code>fin</code>)</li> <li> Function justified \u2014 If 4-part, cite specific reason (1-10)</li> <li> Documented \u2014 Add to Context Registry if new context</li> </ul>"},{"location":"checklists/service-naming-checklist/#expected-statistics","title":"Expected Statistics","text":"<p>Healthy project distribution: - 80-90% services: 3-part (clear domains) - 10-20% services: 4-part (ambiguous domains)</p> <p>Warning: If your project has &gt; 30% 4-part services \u2192 domains may be too generic. Consider refactoring domain decomposition.</p>"},{"location":"checklists/service-naming-checklist/#references","title":"References","text":"<ul> <li>Complete guide: Naming Conventions</li> <li>10 Reasons detailed: 10 Serious Reasons for 4-Part Naming</li> <li>Decision tree: Semantic Shortening Guide</li> <li>Context tracking: Context Registry</li> </ul> <p>Document Version: 1.0 Last Updated: 2025-10-03 Maintained By: Framework Core Team</p>"},{"location":"contributing/","title":"Contributing to AI Framework","text":"<p>Welcome! This directory contains resources for contributors to the AI Framework.</p>"},{"location":"contributing/#directory-structure","title":"\ud83d\udcc1 Directory Structure","text":"<pre><code>contributing/\n\u251c\u2500\u2500 README.md                      # This file - contribution overview\n\u251c\u2500\u2500 improvement-plans/             # Detailed plans for significant enhancements\n\u2502   \u251c\u2500\u2500 README.md                  # How to create and use improvement plans\n\u2502   \u2514\u2500\u2500 2025-01-*.md              # Active improvement plans\n\u251c\u2500\u2500 feature-proposals/             # Proposals for new framework capabilities (future)\n\u2514\u2500\u2500 refactoring-plans/             # Architectural refactoring plans (future)\n</code></pre>"},{"location":"contributing/#types-of-contributions","title":"\ud83c\udfaf Types of Contributions","text":""},{"location":"contributing/#1-improvement-plans-improvement-plans","title":"1. Improvement Plans (<code>improvement-plans/</code>)","text":"<p>Purpose: Coordinate complex, multi-phase enhancements</p> <p>Use for: - Framework-wide improvements (affecting docs, templates, workflows) - Multi-week efforts requiring coordination - Architectural changes or pattern introductions - Phased rollouts</p> <p>Examples: - Enforcing DRY/KISS/YAGNI principles across framework - Completing template coverage (shared utils, data services) - Adding automated quality gates - Implementing new anti-pattern detection</p> <p>Process: 1. Create plan document using template from <code>improvement-plans/README.md</code> 2. Submit PR for review (plan only, no code) 3. Iterate based on maintainer feedback 4. After approval, implement tasks from plan 5. Update plan progress regularly 6. Mark plan complete when all tasks validated</p> <p>\ud83d\udcd6 Learn more</p>"},{"location":"contributing/#2-feature-proposals-feature-proposals-coming-soon","title":"2. Feature Proposals (<code>feature-proposals/</code>) - Coming Soon","text":"<p>Purpose: Propose new capabilities for the framework</p> <p>Use for: - New service types (e.g., gRPC services, GraphQL APIs) - New integrations (e.g., Apache Kafka, Elasticsearch) - New maturity levels or architectural patterns - Major documentation additions</p> <p>Process: TBD</p>"},{"location":"contributing/#3-refactoring-plans-refactoring-plans-coming-soon","title":"3. Refactoring Plans (<code>refactoring-plans/</code>) - Coming Soon","text":"<p>Purpose: Plan significant architectural refactorings</p> <p>Use for: - Breaking changes to templates or workflows - Deprecating old patterns - Major documentation restructuring - Changing naming conventions</p> <p>Process: TBD</p>"},{"location":"contributing/#4-direct-contributions","title":"4. Direct Contributions","text":"<p>For smaller contributions, use standard GitHub workflow:</p> <p>Bug fixes: - Open issue describing bug - Submit PR with fix - Reference issue in PR description</p> <p>Documentation improvements: - Minor typo fixes: direct PR - New atomic docs: follow template in <code>docs/atomic/TEMPLATE.md</code> - Guide additions: discuss in issue first</p> <p>Template enhancements: - Small fixes: direct PR - New templates: create improvement plan</p>"},{"location":"contributing/#quick-start-guide","title":"\ud83d\ude80 Quick Start Guide","text":""},{"location":"contributing/#for-new-contributors","title":"For New Contributors","text":"<ol> <li>Read framework documentation:</li> <li>README - Framework overview</li> <li>ARCHITECTURE - Architectural principles</li> <li> <p>Agent Workflow - How AI uses framework</p> </li> <li> <p>Find contribution opportunities:</p> </li> <li>Check improvement-plans/ for active plans</li> <li>Look for \"good first issue\" or \"help wanted\" labels</li> <li> <p>Review incomplete templates in <code>../../templates/README.md</code></p> </li> <li> <p>Understand contribution workflow:</p> </li> <li>Read main CONTRIBUTING.md</li> <li>Review relevant plan document (if applicable)</li> <li> <p>Comment on issue/plan to claim task</p> </li> <li> <p>Set up development environment: <pre><code># Clone framework\ngit clone &lt;repo-url&gt;\ncd .ai-framework\n\n# Install docs dependencies (if contributing to docs)\npip install -r requirements-docs.txt\n\n# Preview docs locally\nmkdocs serve\n</code></pre></p> </li> <li> <p>Make your contribution:</p> </li> <li>Create feature branch: <code>git checkout -b feature/descriptive-name</code></li> <li>Make changes following style guides</li> <li>Test thoroughly (see below)</li> <li>Submit PR with clear description</li> </ol>"},{"location":"contributing/#testing-your-changes","title":"Testing Your Changes","text":"<p>Documentation changes: <pre><code># Check Markdown syntax\nmarkdownlint docs/\n\n# Build docs to check for errors\nmkdocs build --strict\n\n# Preview locally\nmkdocs serve\n# Visit http://127.0.0.1:8000\n</code></pre></p> <p>Template changes: <pre><code># Generate test project using your modified templates\npython scripts/generate-project.py \\\n  --templates ./templates \\\n  --maturity-level 2 \\\n  --business-ideas \"Test project for template validation\" \\\n  --output /tmp/test-generated\n\n# Validate generated project\ncd /tmp/test-generated\nmake lint         # Should pass\nmake test         # Should pass\ndocker-compose up # Should start without errors\n</code></pre></p> <p>Workflow changes: <pre><code># Run workflow validation script\npython scripts/validate-workflow.py\n\n# Test with AI agent (if you have access)\n# Follow instructions in docs/guides/testing-workflow-changes.md\n</code></pre></p>"},{"location":"contributing/#contribution-checklist","title":"\ud83d\udccb Contribution Checklist","text":"<p>Before submitting PR, verify:</p> <ul> <li> Code/docs follow style guide</li> <li>Markdown: CommonMark format, wrap at 120 chars</li> <li>Python templates: PEP 8, type hints, docstrings</li> <li> <p>YAML: 2-space indentation, alphabetized keys (where logical)</p> </li> <li> <p> Changes are documented</p> </li> <li>Update relevant atomic docs</li> <li>Add inline comments for complex logic</li> <li> <p>Update CHANGELOG.md if applicable</p> </li> <li> <p> Tests pass (for template/code changes)</p> </li> <li>Linting: <code>make lint</code></li> <li>Type checking: <code>mypy</code></li> <li>Unit tests: <code>pytest</code></li> <li> <p>Integration tests: <code>pytest tests/integration</code></p> </li> <li> <p> Backward compatibility maintained (unless breaking change is approved)</p> </li> <li>Existing templates still work</li> <li>Workflow stages remain compatible</li> <li> <p>Deprecated features have migration guide</p> </li> <li> <p> PR description is clear</p> </li> <li>References issue or improvement plan</li> <li>Explains \"why\" not just \"what\"</li> <li>Lists acceptance criteria satisfied</li> <li>Includes screenshots (for UI/docs changes)</li> </ul>"},{"location":"contributing/#style-guides","title":"\ud83c\udfa8 Style Guides","text":""},{"location":"contributing/#markdown-documentation","title":"Markdown Documentation","text":"<ul> <li>Use ATX-style headers (<code>#</code>, <code>##</code>, <code>###</code>)</li> <li>Wrap lines at 120 characters (use soft wrap in editor)</li> <li>Use fenced code blocks with language specifier</li> <li>Link to other docs using relative paths</li> <li>Use emoji sparingly (only for status indicators)</li> </ul> <p>Example: <pre><code>## Service Architecture\n\nThe framework uses a [hybrid approach](../atomic/architecture/improved-hybrid-overview.md) that combines:\n\n- **Data Services:** Direct database access (PostgreSQL, MongoDB)\n- **Business Services:** HTTP-only communication with data services\n\n```python\n# Example: Business service calling data service\nasync def get_user(user_id: int) -&gt; User:\n    response = await data_client.get(f\"/users/{user_id}\")\n    return User(**response.json())\n</code></pre></p> <p>For more details, see HTTP client patterns. <pre><code>### Template Code (Python)\n\nFollow framework conventions:\n- Type hints for all function signatures\n- Docstrings in Google style\n- Import order: standard lib \u2192 third party \u2192 local\n- Max line length: 100 characters\n- Use `async`/`await` for I/O operations\n\n**Example:**\n```python\n\"\"\"User service module for managing user operations.\"\"\"\n\nfrom typing import Optional\nimport logging\n\nfrom fastapi import HTTPException\nfrom pydantic import BaseModel\n\nfrom infrastructure.http_clients.data_client import DataClient\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass UserService:\n    \"\"\"Service for user management operations.\n\n    This service handles user CRUD operations by communicating\n    with the data service via HTTP.\n    \"\"\"\n\n    def __init__(self, data_client: DataClient) -&gt; None:\n        \"\"\"Initialize user service.\n\n        Args:\n            data_client: HTTP client for data service communication\n        \"\"\"\n        self._data_client = data_client\n\n    async def get_user(self, user_id: int) -&gt; Optional[UserDTO]:\n        \"\"\"Retrieve user by ID.\n\n        Args:\n            user_id: Unique identifier of the user\n\n        Returns:\n            User data transfer object, or None if not found\n\n        Raises:\n            HTTPException: If data service is unavailable\n        \"\"\"\n        try:\n            response = await self._data_client.get(f\"/users/{user_id}\")\n            return UserDTO(**response.json())\n        except HTTPException as e:\n            logger.error(f\"Failed to fetch user {user_id}: {e}\")\n            raise\n</code></pre></p>"},{"location":"contributing/#yaml-configuration","title":"YAML Configuration","text":"<ul> <li>2-space indentation</li> <li>Alphabetize keys (unless order matters, e.g., Docker Compose depends_on)</li> <li>Use anchors for repeated configuration</li> <li>Comment non-obvious settings</li> </ul> <p>Example: <pre><code>services:\n  business_api:\n    build:\n      context: ./services/business_api\n      dockerfile: Dockerfile\n    container_name: business_api\n    depends_on:\n      - data_postgres_api\n    environment:\n      DATA_SERVICE_URL: http://data_postgres_api:8001\n      LOG_LEVEL: ${LOG_LEVEL:-INFO}\n    ports:\n      - \"${API_PORT:-8000}:8000\"\n    restart: unless-stopped\n</code></pre></p>"},{"location":"contributing/#code-of-conduct","title":"\ud83e\udd1d Code of Conduct","text":"<p>All contributors must follow the Code of Conduct:</p> <ul> <li>Be respectful and inclusive</li> <li>Provide constructive feedback</li> <li>Focus on what's best for the framework and community</li> <li>Accept responsibility for mistakes</li> </ul>"},{"location":"contributing/#questions-or-need-help","title":"\u2753 Questions or Need Help?","text":"<ul> <li>Documentation questions: Check docs/INDEX.md for navigation</li> <li>Contribution process: Review this document and CONTRIBUTING.md</li> <li>Technical questions: Open GitHub Discussion or Issue</li> <li>Security vulnerabilities: See SECURITY.md</li> </ul>"},{"location":"contributing/#contribution-statistics","title":"\ud83d\udcca Contribution Statistics","text":"<p>Want to see contribution history?</p> <pre><code># Contributors by commit count\ngit shortlog -sn --no-merges\n\n# Recent contributions\ngit log --pretty=format:\"%h %an %ad %s\" --date=short -n 20\n\n# Files most frequently modified\ngit log --pretty=format: --name-only | sort | uniq -c | sort -rg | head -20\n</code></pre> <p>Thank you for contributing to the AI Framework! Your efforts help improve code generation quality for all users. \ud83c\udf89</p>"},{"location":"contributing/audit/project/","title":"Documentation Audit Prompt Template","text":""},{"location":"contributing/audit/project/#purpose","title":"Purpose","text":"<p>This prompt helps AI agents conduct comprehensive documentation audits to identify and fix structural, consistency, and content issues.</p>"},{"location":"contributing/audit/project/#execution-protocol-mandatory","title":"\ud83d\udd34 EXECUTION PROTOCOL (MANDATORY)","text":"<p>READ THIS SECTION FIRST BEFORE STARTING ANY AUDIT WORK</p>"},{"location":"contributing/audit/project/#critical-execution-rules","title":"Critical Execution Rules","text":"<ol> <li>DO NOT DELEGATE this audit to Task agent or any other agent</li> <li>You MUST run ALL validation commands yourself using Bash tool</li> <li>Task agents may interpret \"comprehensive\" as \"sample-based checking\"</li> <li> <p>Only direct execution ensures exhaustive validation (checking ALL files, not just samples)</p> </li> <li> <p>READ ENTIRE TEMPLATE before starting</p> </li> <li>Don't skip to OBJECTIVES and start immediately</li> <li>Read through Automation Script Template section (appears later in this document)</li> <li> <p>Understand the full scope: 17 objectives, validation commands, verification protocol</p> </li> <li> <p>RUN SMOKE TESTS FIRST (30 seconds) before deep audit</p> </li> <li>Understand documentation scope and identify critical issues quickly</li> <li> <p>See \"Smoke Tests\" section below</p> </li> <li> <p>EXECUTE validation commands sequentially for each objective</p> </li> <li>Don't just READ objectives - RUN the bash commands provided</li> <li>Each objective has \"VALIDATION COMMANDS\" section with exact commands to execute</li> <li> <p>Record outputs and analyze results</p> </li> <li> <p>VERIFY your audit results with spot checks</p> </li> <li>Pick 3 random issues from your findings</li> <li>Manually verify each one is real (not false positive)</li> <li>Include verification results in your report</li> </ol>"},{"location":"contributing/audit/project/#smoke-tests-run-first-30-seconds","title":"\ud83e\uddea Smoke Tests (Run First - 30 Seconds)","text":"<p>Purpose: Quick assessment of documentation health to identify critical issues before full audit.</p> <pre><code># ===================================================================\n# SMOKE TEST 1: Count total markdown files\n# ===================================================================\necho \"=== SMOKE TEST 1: Total Markdown Files ===\"\nfind docs -name \"*.md\" 2&gt;/dev/null | wc -l\n# Expected: ~150-250 files\n# If &lt; 50 or &gt; 500 \u2192 investigate scope\n\n# ===================================================================\n# SMOKE TEST 2: Count total markdown links\n# ===================================================================\necho \"=== SMOKE TEST 2: Total Markdown Links ===\"\ngrep -rho '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | wc -l\n# Expected: ~500-1500 links\n# This gives you scope of link validation task\n\n# ===================================================================\n# SMOKE TEST 3: \ud83d\udea8 CRITICAL - Check legacy/deprecated references\n# ===================================================================\necho \"=== SMOKE TEST 3: Legacy/Deprecated References (MUST BE 0) ===\"\ngrep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-docs\\|DEPRECATED\" docs/ README.md CLAUDE.md 2&gt;/dev/null | wc -l\n# Expected: 0\n# If &gt; 0 \u2192 CRITICAL ISSUE (blocks users/AI agents)\n\n# ===================================================================\n# SMOKE TEST 4: Quick sample of broken links (first 10 files only)\n# ===================================================================\necho \"=== SMOKE TEST 4: Broken Links Sample (first 10 files) ===\"\nfind docs -name \"*.md\" | head -10 | while read f; do\n  grep -Hn '\\[.*\\](.*\\.md' \"$f\" 2&gt;/dev/null | while IFS=: read -r file line link; do\n    path=$(echo \"$link\" | sed 's/.*(\\(.*\\.md\\).*/\\1/')\n    [ ! -f \"$path\" ] &amp;&amp; [ ! -f \"docs/$path\" ] &amp;&amp; echo \"BROKEN SAMPLE: $file:$line -&gt; $path\"\n  done\ndone | head -5\n# Expected: 0 broken links\n# If &gt; 0 \u2192 indicates systemic link problems (need full validation)\n\n# ===================================================================\n# SMOKE TEST 5: Check Stage 0 initialization docs exist\n# ===================================================================\necho \"=== SMOKE TEST 5: Stage 0 Documents (Critical for AI) ===\"\nfor doc in CLAUDE.md \\\n           docs/reference/agent-context-summary.md \\\n           docs/guides/ai-code-generation-master-workflow.md \\\n           docs/reference/maturity-levels.md; do\n  if [ -f \"$doc\" ]; then\n    echo \"\u2705 $doc\"\n  else\n    echo \"\ud83d\udea8 CRITICAL MISSING: $doc\"\n  fi\ndone\n</code></pre>"},{"location":"contributing/audit/project/#_1","title":"===================================================================","text":""},{"location":"contributing/audit/project/#smoke-test-6-check-pyprojecttoml-completeness","title":"SMOKE TEST 6: Check pyproject.toml completeness","text":""},{"location":"contributing/audit/project/#_2","title":"===================================================================","text":"<pre><code># If docs mention `uv run &lt;tool&gt;` commands, check pyproject.toml has configs\ngrep -rh \"uv run\" docs/ --include=\"*.md\" 2&gt;/dev/null | grep -q \"uv run\" &amp;&amp; \\\ntest -f pyproject.toml &amp;&amp; \\\ngrep -q \"\\[tool.ruff\\]\" pyproject.toml &amp;&amp; \\\ngrep -q \"\\[tool.mypy\\]\" pyproject.toml &amp;&amp; \\\ngrep -q \"\\[tool.pytest\" pyproject.toml &amp;&amp; \\\necho \"\u2705 pyproject.toml configured\" || echo \"\u26a0\ufe0f pyproject.toml missing tool configs\"\n\n# Expected: \u2705 (if docs mention quality commands)\n# If \u26a0\ufe0f \u2192 MEDIUM PRIORITY: Commands documented but tools not configured\n# This creates broken developer experience - commands fail despite being documented\n</code></pre>"},{"location":"contributing/audit/project/#_3","title":"===================================================================","text":""},{"location":"contributing/audit/project/#smoke-test-7-command-path-validation-silent-failure-detection","title":"SMOKE TEST 7: Command path validation (Silent failure detection)","text":""},{"location":"contributing/audit/project/#_4","title":"===================================================================","text":"<pre><code># Check if templates use src/ or app/ directory\necho \"=== SMOKE TEST 7: Command Path Validation (Silent Failures) ===\"\necho \"Template directory structure:\"\nfind templates/services -maxdepth 2 -type d -name \"src\" -o -name \"app\" 2&gt;/dev/null | head -10\n\n# Check coverage commands in docs\necho \"\"\necho \"Coverage commands in documentation:\"\ngrep -rh \"\\-\\-cov=\" docs/ 2&gt;/dev/null | grep -oh \"\\-\\-cov=[a-zA-Z_/]*\" | sort -u\n\n# Expected: Coverage paths must match actual template structure\n# CRITICAL: --cov=app (if templates use src/) \u2192 Silent failure (coverage=0%)\n# If mismatch found \u2192 CRITICAL ISSUE (blocks Stage 5 verification, wastes debugging time)\n</code></pre>"},{"location":"contributing/audit/project/#_5","title":"===================================================================","text":""},{"location":"contributing/audit/project/#smoke-test-8-check-phase-1-educational-guides-exist-phase-1-deliverables","title":"SMOKE TEST 8: Check Phase 1 educational guides exist (Phase 1 Deliverables)","text":""},{"location":"contributing/audit/project/#_6","title":"===================================================================","text":"<pre><code>echo \"=== SMOKE TEST 8: Phase 1 Guides (DRY/KISS/YAGNI, Migration, Quality Gates) ===\"\nfor doc in docs/guides/dry-kiss-yagni-principles.md \\\n           docs/guides/migration-guide-phase1.md \\\n           docs/quality/automated-quality-gates.md; do\n  if [ -f \"$doc\" ]; then\n    echo \"\u2705 $doc\"\n  else\n    echo \"\ud83d\udea8 CRITICAL MISSING: $doc (Phase 1 deliverable)\"\n  fi\ndone\n\n# Expected: All 3 files exist\n# If any missing \u2192 CRITICAL ISSUE (Phase 1 incomplete, blocks adoption)\n</code></pre>"},{"location":"contributing/audit/project/#_7","title":"===================================================================","text":""},{"location":"contributing/audit/project/#smoke-test-9-check-shared-utilities-template-exists-dry-enforcement-foundation","title":"SMOKE TEST 9: Check shared utilities template exists (DRY Enforcement Foundation)","text":""},{"location":"contributing/audit/project/#_8","title":"===================================================================","text":"<pre><code>echo \"=== SMOKE TEST 9: Shared Utilities Template ===\"\nUTILS_FILES=(\n  \"templates/shared/utils/__init__.py\"\n  \"templates/shared/utils/logger.py\"\n  \"templates/shared/utils/validators.py\"\n  \"templates/shared/utils/exceptions.py\"\n  \"templates/shared/utils/pagination.py\"\n  \"templates/shared/utils/request_id.py\"\n  \"templates/shared/utils/README.md\"\n)\n\nmissing=0\nfor file in \"${UTILS_FILES[@]}\"; do\n  if [ -f \"$file\" ]; then\n    echo \"\u2705 $file\"\n  else\n    echo \"\u274c MISSING: $file\"\n    missing=$((missing + 1))\n  fi\ndone\n\nif [ $missing -gt 0 ]; then\n  echo \"\ud83d\udea8 CRITICAL: $missing shared utility files missing (Phase 1 incomplete)\"\nfi\n\n# Expected: All 7 files exist\n# If missing \u2192 CRITICAL ISSUE (DRY enforcement broken, duplication continues)\n</code></pre>"},{"location":"contributing/audit/project/#_9","title":"===================================================================","text":""},{"location":"contributing/audit/project/#smoke-test-10-check-ci-quality-gates-exist-drykissyagni-enforcement","title":"SMOKE TEST 10: Check CI quality gates exist (DRY/KISS/YAGNI Enforcement)","text":""},{"location":"contributing/audit/project/#_10","title":"===================================================================","text":"<pre><code>echo \"=== SMOKE TEST 10: CI Quality Gates (DRY/KISS/YAGNI enforcement) ===\"\nif [ -f \"templates/ci-cd/.github/workflows/ci.yml\" ]; then\n  echo \"\u2705 CI workflow file exists\"\n\n  # Check for quality gate jobs\n  for job in check-duplication check-complexity check-dependencies; do\n    if grep -q \"^  $job:\" templates/ci-cd/.github/workflows/ci.yml; then\n      echo \"  \u2705 Job: $job\"\n    else\n      echo \"  \ud83d\udea8 MISSING JOB: $job (Phase 1 quality gate)\"\n    fi\n  done\n\n  # Check quality gates reference principles guide\n  if grep -q \"dry-kiss-yagni-principles.md\" templates/ci-cd/.github/workflows/ci.yml; then\n    echo \"  \u2705 References DRY/KISS/YAGNI guide\"\n  else\n    echo \"  \u26a0\ufe0f  Doesn't reference principles guide\"\n  fi\nelse\n  echo \"\ud83d\udea8 CRITICAL MISSING: templates/ci-cd/.github/workflows/ci.yml\"\nfi\n\n# Expected: CI workflow with 3 quality gate jobs\n# If missing \u2192 CRITICAL ISSUE (Phase 1 enforcement broken, no automated quality checks)\n</code></pre> <p>DECISION POINT based on smoke test results:</p> Smoke Test Result Action Test 3 (Legacy refs) &gt; 0 STOP. CRITICAL ISSUE FOUND. Report immediately, must fix before proceeding. Test 4 (Broken links sample) &gt; 0 HIGH PRIORITY. Note in report, proceed with full link validation. Test 5 (Stage 0 docs) Any missing CRITICAL. AI agents cannot work. Report immediately. Test 6 (pyproject.toml) \u26a0\ufe0f MEDIUM PRIORITY. Note config gap, proceed with audit. Test 7 (Command paths) Mismatch CRITICAL. Silent failures cause false negatives in CI/CD. Report immediately. Test 8 (Phase 1 guides) Any missing CRITICAL. Phase 1 incomplete. Report immediately, must fix before proceeding. Test 9 (Shared utils) Any missing CRITICAL. DRY enforcement broken. Report immediately. Test 10 (Quality gates) Jobs missing CRITICAL. Phase 1 quality enforcement missing. Report immediately. All tests pass \u2705 Proceed with full 18-objective audit."},{"location":"contributing/audit/project/#anti-patterns-to-avoid","title":"\u26a0\ufe0f Anti-Patterns to Avoid","text":"\u274c DON'T DO THIS \u2705 DO THIS INSTEAD Delegate entire audit to Task agent Run validation commands yourself using Bash tool Check 10 sample files and extrapolate to all Use <code>grep -r</code> and <code>find</code> to check ALL files exhaustively Assume \"Related Documents\" sections are optional metadata Explicitly grep for <code>\"legacy\\|deprecated\"</code> in all sections Trust \"Stage 0 works \u2192 everything works\" heuristic Run exhaustive validation (check all 1000+ links individually) Skip Automation Script Template section Read entire template including script examples Report health score without showing calculation Show exact formula: <code>100 - (CRITICAL\u00d73) - (HIGH\u00d71.5) - (MEDIUM\u00d70.5)</code> Say \"several files have issues\" (vague) Provide exact <code>file:line</code> locations for EVERY issue Assume configs are correct if they exist Cross-validate config values against actual usage in docs (Objective 16) Only check docs/ directory for issues Also check root-level configs (pyproject.toml, .env.example, docker-compose.yml, CONTRIBUTING.md) Trust commands work if they execute successfully Verify command paths match actual project structure (Objective 17) - silent failures return wrong results! Trust that \"template exists\" means it works Check template files have README, correct naming, and match documentation claims Trust quality gates exist means they work Test quality gates with sample code (jscpd/radon must run) - see Objective 18"},{"location":"contributing/audit/project/#full-audit-prompt","title":"Full Audit Prompt","text":"<pre><code>Conduct a comprehensive documentation audit of this project:\n\n## OBJECTIVES\n\n[Original 14 objectives content will follow, enhanced with VALIDATION COMMANDS sections]\n</code></pre>"},{"location":"contributing/audit/project/#objectives","title":"OBJECTIVES","text":""},{"location":"contributing/audit/project/#1-understand-project-purpose","title":"1. Understand Project Purpose","text":"<ul> <li>Read README.md, CLAUDE.md, and docs/INDEX.md</li> <li>Identify main project goals and target users</li> <li>Understand architecture and technology stack</li> </ul>"},{"location":"contributing/audit/project/#2-link-validation-mandatory-commands","title":"2. Link Validation \u26a1 MANDATORY COMMANDS","text":"<p>OBJECTIVE: Find ALL broken markdown links, including legacy/deprecated references</p> <p>VALIDATION COMMANDS (execute in order, do NOT skip):</p> <pre><code># ========================================\n# STEP 1: Check legacy/deprecated refs (CRITICAL)\n# ========================================\necho \"Step 1: Checking for legacy/deprecated references...\"\ngrep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\\|DEPRECATED\" docs/ README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/legacy_refs.txt\n\nLEGACY_COUNT=$(wc -l &lt; /tmp/legacy_refs.txt)\necho \"Found $LEGACY_COUNT legacy references\"\n\nif [ \"$LEGACY_COUNT\" -gt 0 ]; then\n  echo \"\ud83d\udea8 CRITICAL: Legacy references found!\"\n  head -20 /tmp/legacy_refs.txt  # Show first 20\nfi\n\n# ========================================\n# STEP 2: Extract ALL markdown links\n# ========================================\necho \"Step 2: Extracting all markdown links...\"\ngrep -rn '\\[.*\\](.*\\.md' docs/ README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/all_links.txt\n\nTOTAL_LINKS=$(wc -l &lt; /tmp/all_links.txt)\necho \"Found $TOTAL_LINKS total markdown links\"\n\n# ========================================\n# STEP 3: Check each link's target file exists\n# ========================================\necho \"Step 3: Validating link targets...\"\n&gt; /tmp/broken_links.txt  # Clear file\n\ngrep -rho '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u | while read -r ref; do\n  # Try: exact path, docs/ prefix, relative from docs/\n  if [ ! -f \"$ref\" ] &amp;&amp; [ ! -f \"docs/$ref\" ] &amp;&amp; [ ! -f \"$(dirname \"docs\")/$ref\" ]; then\n    # Find which files reference this broken link\n    grep -l \"$ref\" docs/**/*.md 2&gt;/dev/null | head -3 | while read -r file; do\n      line=$(grep -n \"$ref\" \"$file\" | head -1 | cut -d: -f1)\n      echo \"BROKEN: $file:$line -&gt; $ref\" &gt;&gt; /tmp/broken_links.txt\n    done\n  fi\ndone\n\nBROKEN_COUNT=$(wc -l &lt; /tmp/broken_links.txt)\necho \"Found $BROKEN_COUNT broken links\"\n\nif [ \"$BROKEN_COUNT\" -gt 0 ]; then\n  echo \"\u26a0\ufe0f HIGH PRIORITY: Broken links found!\"\n  head -30 /tmp/broken_links.txt  # Show first 30\nfi\n\n# ========================================\n# SUMMARY\n# ========================================\necho \"\"\necho \"=== LINK VALIDATION SUMMARY ===\"\necho \"Total links: $TOTAL_LINKS\"\necho \"Legacy references: $LEGACY_COUNT (MUST BE 0)\"\necho \"Broken links: $BROKEN_COUNT (MUST BE 0)\"\necho \"\"\n</code></pre> <p>EXPECTED RESULTS: - Legacy references: 0 (if &gt;0 \u2192 CRITICAL priority) - Broken links: 0 (if &gt;0 \u2192 HIGH priority)</p> <p>IF ISSUES FOUND:</p> <p>Priority Assignment: - Legacy references: CRITICAL (blocks AI agents, confuses users) - Broken links: HIGH (404 errors, navigation fails) - Broken anchors: MEDIUM (UX degradation)</p> <p>Impact: - Users clicking links get 404 errors - AI agents fail to navigate documentation - Broken Stage 0 sequence blocks all AI generation</p> <p>Fix (example for legacy links): <pre><code># Replace all legacy references (example):\nsed -i 's|docs/legacy/services/fastapi_rules.md|docs/atomic/services/fastapi/basic-setup.md|g' docs/atomic/**/*.md\nsed -i 's|docs/legacy/architecture/data-access-rules.md|docs/atomic/architecture/data-access-architecture.md|g' docs/atomic/**/*.md\n</code></pre></p> <p>Verification: <pre><code># After fix, re-run Step 1:\ngrep -rn \"docs/legacy\" docs/ | wc -l  # Should be 0\n</code></pre></p>"},{"location":"contributing/audit/project/#3-file-completeness","title":"3. File Completeness","text":"<ul> <li>Find all file references in documentation</li> <li>Verify each referenced file exists</li> <li>Check for missing templates, configs, or resources</li> <li>Identify orphaned documents not referenced anywhere</li> </ul>"},{"location":"contributing/audit/project/#4-structural-consistency","title":"4. Structural Consistency","text":"<ul> <li>Verify directory structure matches PROJECT_STRUCTURE.md</li> <li>Ensure all documents listed in INDEX.md exist</li> <li>Validate LINKS_REFERENCE.md has correct paths</li> <li>Check navigation consistency across guides</li> </ul>"},{"location":"contributing/audit/project/#5-content-quality","title":"5. Content Quality","text":"<ul> <li>Find contradictions between documents</li> <li>Identify outdated information or version mismatches</li> <li>Detect duplicated content across files</li> <li>Check naming convention consistency</li> </ul>"},{"location":"contributing/audit/project/#6-code-configuration","title":"6. Code &amp; Configuration","text":"<ul> <li>Validate .env.example files</li> <li>Check docker-compose configurations</li> <li>Verify requirements.txt or pyproject.toml</li> <li>Test sample code blocks where applicable</li> <li>Run shellcheck on all bash examples</li> <li>Validate Python code examples with pylint/flake8</li> <li>NEW: Validate CI quality gates exist and are functional (Phase 1)</li> <li>If a required tool is unavailable, record the skipped check and suggest a manual alternative</li> </ul>"},{"location":"contributing/audit/project/#7-language-readability","title":"7. Language &amp; Readability","text":"<ul> <li>Check spelling with aspell/hunspell</li> <li>Verify English-only content (no other languages)</li> <li>Calculate readability scores (Flesch-Kincaid, SMOG)</li> <li>Measure documentation complexity metrics</li> <li>Check technical terminology consistency</li> </ul>"},{"location":"contributing/audit/project/#8-version-consistency","title":"8. Version Consistency","text":"<ul> <li>Extract all technology versions mentioned</li> <li>Cross-reference with tech_stack.md</li> <li>Identify version conflicts or mismatches</li> <li>Check dependency compatibility matrix</li> <li>Verify Docker image tags alignment</li> </ul>"},{"location":"contributing/audit/project/#9-ai-navigation-workflow-validation-new-critical-for-ai-first-framework","title":"9. AI Navigation &amp; Workflow Validation (NEW - Critical for AI-first framework)","text":"<ul> <li>Verify Stage 0 initialization sequence (CLAUDE.md \u2192 agent-context-summary.md \u2192 workflow \u2192 maturity-levels.md)</li> <li>Validate Navigation Matrix accuracy (all referenced documents exist)</li> <li>Check workflow coherence (entry/exit criteria alignment)</li> <li>Detect circular dependencies in reading order</li> <li>Ensure maturity levels integrated into workflow stages</li> <li>Update the Stage 0 sequence to match the current repository structure before flagging inconsistencies</li> </ul>"},{"location":"contributing/audit/project/#10-submodule-path-validation-new-framework-as-submodule-model","title":"10. Submodule Path Validation (NEW - Framework-as-submodule model)","text":"<ul> <li>Ensure documentation works in standalone and submodule modes</li> <li>Detect hardcoded absolute paths that break in submodule</li> <li>Verify examples show both path variants where relevant</li> <li>Check CLAUDE.md guidance mentions both usage modes</li> </ul>"},{"location":"contributing/audit/project/#11-maturity-levels-consistency-new-core-framework-concept","title":"11. Maturity Levels Consistency (NEW - Core framework concept)","text":"<ul> <li>Verify features correctly marked per maturity level (\u2705/\u274c)</li> <li>Ensure conditional stage rules align with maturity-levels.md</li> <li>Check upgrade paths documented</li> <li>Validate time estimates consistency (5/10/15/30 min)</li> <li>Verify coverage thresholds per level (60%/75%/80%/85%)</li> </ul>"},{"location":"contributing/audit/project/#12-architectural-constraints-consistency-new-mandatory-patterns","title":"12. Architectural Constraints Consistency (NEW - Mandatory patterns)","text":"<ul> <li>Verify HTTP-only data access mentioned consistently</li> <li>Check service separation principles in examples</li> <li>Ensure API Gateway mandatory for production (Level 3+)</li> <li>Validate RabbitMQ mandatory for async communication</li> <li>Check DEFAULT TO 3-PART naming guidance consistency</li> </ul>"},{"location":"contributing/audit/project/#13-atomic-documentation-coverage-new-implementation-patterns","title":"13. Atomic Documentation Coverage (NEW - Implementation patterns)","text":"<ul> <li>Verify all atomic docs referenced in Navigation Matrix exist</li> <li>Check atomic docs cover all patterns mentioned in workflow</li> <li>Find orphaned atomic docs (not referenced anywhere)</li> <li>Validate atomic docs completeness per service type</li> </ul>"},{"location":"contributing/audit/project/#14-agent-toolbox-command-validation-new-executable-commands","title":"14. Agent Toolbox Command Validation (NEW - Executable commands)","text":"<ul> <li>Verify all commands in agent-toolbox.md are executable</li> <li>Check tool versions align with tech_stack.md</li> <li>Ensure development-commands.md consistent with agent-toolbox.md</li> <li>Test sample commands for syntax correctness</li> </ul>"},{"location":"contributing/audit/project/#15-obsolete-files-cleanup-new-maintenance-hygiene","title":"15. Obsolete Files &amp; Cleanup (NEW - Maintenance hygiene)","text":"<ul> <li>Find backup files (.bak, .backup, _backup.)</li> <li>Identify old version files (.old, _old., _v1.)</li> <li>Detect temporary files (.tmp, ~, .swp, .DS_Store)</li> <li>Check for duplicate scripts with same functionality</li> <li>Report files that should be removed or archived</li> </ul>"},{"location":"contributing/audit/project/#16-config-consistency-validation-mandatory-commands-new-cross-file-integrity","title":"16. Config Consistency Validation \u26a1 MANDATORY COMMANDS (NEW - Cross-file integrity)","text":"<p>CRITICAL: Configs and documentation must stay synchronized. Check:</p> <pre><code># ========================================\n# STEP 1: Docker Compose profile validation\n# ========================================\n# Extract profile names from docker-compose.yml\ngrep -E \"^\\s+profiles:\" docker-compose.yml 2&gt;/dev/null | awk '{print $2}' | tr -d '[]\"' | sort -u\n\n# Check docs use correct profile names\ngrep -rh \"profile\" docs/ --include=\"*.md\" | grep -E \"docker-compose.*--profile\" | grep -oE \"\\-\\-profile [a-z_-]+\" | awk '{print $2}' | sort -u\n\n# VALIDATION: Compare both outputs - must match exactly\n# COMMON ERROR: Docs say `--profile monitoring` but compose file has `observability`\n\n# ========================================\n# STEP 2: Database name consistency\n# ========================================\n# Extract from .env.example (or templates/infrastructure/.env.example if framework-as-submodule)\ngrep \"POSTGRES_DB\\|MONGO_DATABASE\" .env.example templates/infrastructure/.env.example 2&gt;/dev/null | grep -v \"^#\"\n\n# Check database names in documentation examples\ngrep -rh \"POSTGRES_DB\\|DATABASE_URL\\|MONGO_DATABASE\" docs/ --include=\"*.md\" | grep -E \"(POSTGRES_DB|DATABASE_URL|MONGO_DATABASE)=\" | sort -u\n\n# VALIDATION: DB names must match across configs and all doc examples\n# COMMON ERROR: .env.example has `myapp_db` but docs show `microservices_db`\n\n# ========================================\n# STEP 3: Credentials consistency\n# ========================================\n# Extract default credentials from .env.example\ngrep -E \"GRAFANA_PASSWORD|RABBITMQ_DEFAULT_PASS\" .env.example templates/infrastructure/.env.example 2&gt;/dev/null | grep -v \"^#\"\n\n# Check credentials in documentation\ngrep -rh \"admin123\\|changeme\\|password123\" docs/ --include=\"*.md\"\n\n# VALIDATION: If found weak/mismatched passwords \u2192 HIGH PRIORITY\n# EXPECTED: Docs should use same secure defaults as .env.example\n\n# ========================================\n# STEP 4: pyproject.toml completeness\n# ========================================\n# Check if docs instruct `uv run &lt;tool&gt;` commands\ngrep -rh \"uv run\" docs/ --include=\"*.md\" | grep -oE \"uv run [a-z]+\" | awk '{print $3}' | sort -u\n\n# Check if pyproject.toml configures those tools\ntest -f pyproject.toml &amp;&amp; for tool in ruff mypy pytest bandit; do\n  grep -q \"tool.$tool\" pyproject.toml &amp;&amp; echo \"\u2705 $tool\" || echo \"\u274c $tool MISSING\"\ndone\n\n# VALIDATION: Every tool mentioned in docs MUST be configured in pyproject.toml\n# COMMON ERROR: Docs say `uv run ruff` but pyproject.toml is empty\n\n# ========================================\n# STEP 5: Script references in CONTRIBUTING.md\n# ========================================\n# Extract all script paths from CONTRIBUTING.md\ngrep -oE \"\\./scripts/[a-z_-]+\\.sh\" CONTRIBUTING.md 2&gt;/dev/null | sort -u\n\n# Check each script exists\ngrep -oE \"\\./scripts/[a-z_-]+\\.sh\" CONTRIBUTING.md 2&gt;/dev/null | sort -u | while read script; do\n  test -f \"$script\" &amp;&amp; echo \"\u2705 $script\" || echo \"\u274c $script MISSING\"\ndone\n\n# VALIDATION: All referenced scripts must exist\n# COMMON ERROR: CONTRIBUTING.md references validate_docs.sh but only audit_docs.sh exists\n</code></pre> <p>Report Format: - Profile Mismatch: List any docker-compose profile names that don't match documentation - Database Name Mismatch: List config vs documentation discrepancies - Credential Issues: List any weak/mismatched credentials - Tool Config Gaps: List tools documented but not configured in pyproject.toml - Missing Scripts: List scripts referenced in CONTRIBUTING.md but not found on disk</p>"},{"location":"contributing/audit/project/#17-command-path-validation-mandatory-commands-new-silent-failure-prevention","title":"17. Command Path Validation \u26a1 MANDATORY COMMANDS (NEW - Silent failure prevention)","text":"<p>CRITICAL: Commands in documentation must reference actual directory structures in templates/services.</p> <p>PROBLEM PATTERN (Silent Failure): - Command executes successfully (exit 0) - Returns wrong result (e.g., coverage=0% when actual code exists) - No error message - appears to work but gives false negatives - Blocks quality gates and CI/CD pipelines</p> <p>ROOT CAUSE: Documentation commands reference non-existent paths (e.g., <code>--cov=app</code> when templates use <code>src/</code>).</p> <pre><code># ========================================\n# STEP 1: Verify template directory structure\n# ========================================\necho \"Step 1: Checking template directory structures...\"\nfind templates/services -maxdepth 2 -type d -name \"src\" -o -name \"app\" 2&gt;/dev/null\n\n# VALIDATION: Document ACTUAL directory names used in templates\n# COMMON: All templates use src/ (NOT app/)\n\n# ========================================\n# STEP 2: Check pytest coverage commands\n# ========================================\necho \"Step 2: Checking pytest coverage commands in docs...\"\ngrep -rn \"\\-\\-cov=\" docs/ 2&gt;/dev/null | grep -v \"^\\s*#\" | tee /tmp/coverage_commands.txt\n\n# Extract unique coverage paths\ngrep -oh \"\\-\\-cov=[a-zA-Z_/]*\" /tmp/coverage_commands.txt | sort -u\n\n# VALIDATION: Must match actual template structure\n# \u274c BAD: --cov=app (if templates use src/)\n# \u2705 GOOD: --cov=src\n\n# ========================================\n# STEP 3: Check Docker Compose service names\n# ========================================\necho \"Step 3: Validating Docker Compose service references...\"\n\n# Extract service names from docker-compose.yml\ngrep -E \"^\\s+[a-z_]+:\" docker-compose.yml 2&gt;/dev/null | awk '{print $1}' | tr -d ':' | sort &gt; /tmp/compose_services.txt\n\n# Extract service names referenced in docs\ngrep -rho \"docker-compose exec [a-z_]+\" docs/ 2&gt;/dev/null | awk '{print $3}' | sort -u &gt; /tmp/doc_services.txt\n\n# Find mismatches\ncomm -13 /tmp/compose_services.txt /tmp/doc_services.txt &gt; /tmp/service_mismatches.txt\n\n# VALIDATION: All service names in docs must exist in docker-compose.yml\n# COMMON ERROR: Docs reference `postgres_db` but compose has `postgres`\n\n# ========================================\n# STEP 4: Check environment variable paths\n# ========================================\necho \"Step 4: Checking environment variable paths...\"\n\n# Check for absolute paths in .env.example\ngrep -E \"^[A-Z_]+=/\" .env.example templates/infrastructure/.env.example 2&gt;/dev/null | grep -v \"^\\s*#\"\n\n# Check if docs reference those paths consistently\n# VALIDATION: Path variables must be consistent across configs and docs\n\n# ========================================\n# STEP 5: Check API endpoint paths in examples\n# ========================================\necho \"Step 5: Validating API endpoint examples...\"\n\n# Extract API paths from documentation examples\ngrep -rho \"http://localhost:[0-9]*/[a-z_/]*\" docs/ 2&gt;/dev/null | sort -u &gt; /tmp/doc_endpoints.txt\n\n# If main.py or routers exist, extract actual endpoint definitions\nfind templates/services -name \"main.py\" -o -name \"router*.py\" 2&gt;/dev/null | while read file; do\n  grep -oh \"@router\\.\\(get\\|post\\|put\\|delete\\)(\\\"[^\\\"]*\\\")\" \"$file\" 2&gt;/dev/null | sed 's/.*(\"\\(.*\\)\".*/\\1/'\ndone | sort -u &gt; /tmp/actual_endpoints.txt\n\n# VALIDATION: Document actual endpoints, not fictional examples\n</code></pre> <p>Report Format: - Template Structure: List actual src/ vs app/ usage across all templates - Coverage Path Mismatches: List any <code>--cov=</code> commands referencing non-existent directories - Service Name Mismatches: List docker-compose exec commands referencing non-existent services - Environment Path Issues: List absolute path mismatches between configs and docs - API Endpoint Discrepancies: List documented endpoints that don't match actual code</p> <p>WHY THIS IS CRITICAL: - Silent failures waste hours of debugging time - False negatives in CI/CD cause missed bugs in production - AI agents get stuck in Stage 5 (Quality Verification) with \"coverage=0%\" errors - New developers copy broken commands from documentation</p>"},{"location":"contributing/audit/project/#deliverables-enhanced","title":"DELIVERABLES (ENHANCED)","text":"<p>Create a detailed report with:</p>"},{"location":"contributing/audit/project/#1-executive-summary-mandatory-format-show-your-work","title":"1. Executive Summary (MANDATORY FORMAT - SHOW YOUR WORK)","text":""},{"location":"contributing/audit/project/#project-purpose","title":"Project Purpose","text":"<p>[1-2 paragraphs describing project goals and target users]</p>"},{"location":"contributing/audit/project/#health-score-calculation-must-show-calculation","title":"Health Score Calculation (MUST SHOW CALCULATION)","text":"<p>Formula: <pre><code>Health Score = 100 - (CRITICAL_count \u00d7 3) - (HIGH_count \u00d7 1.5) - (MEDIUM_count \u00d7 0.5) - (LOW_count \u00d7 0.1)\nMin score: 0 (cap negative scores at 0)\n</code></pre></p> <p>Calculation (SHOW THIS IN YOUR REPORT): <pre><code>Base:                    100 points\nCRITICAL issues (X):     X \u00d7 3  = -Y points\nHIGH issues (Z):         Z \u00d7 1.5 = -W points\nMEDIUM issues (M):       M \u00d7 0.5 = -N points\nLOW issues (L):          L \u00d7 0.1 = -K points\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFINAL HEALTH SCORE:      max(0, 100 - Y - W - N - K) = SCORE/100\n</code></pre></p> <p>Example: <pre><code>Base:                    100 points\nCRITICAL issues (64):    64 \u00d7 3  = -192 points\nHIGH issues (10):        10 \u00d7 1.5 = -15 points\nMEDIUM issues (5):       5 \u00d7 0.5 = -2.5 points\nLOW issues (2):          2 \u00d7 0.1 = -0.2 points\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSubtotal:                100 - 209.7 = -109.7\nFINAL HEALTH SCORE:      max(0, -109.7) = 0/100 (capped at 0)\n</code></pre></p>"},{"location":"contributing/audit/project/#total-issues-found-mandatory-table","title":"Total Issues Found (MANDATORY TABLE)","text":"Priority Count Top 3 Examples (file:line) Impact CRITICAL X <code>docs/foo.md:42</code>, <code>docs/bar.md:15</code>, <code>docs/baz.md:88</code> Blocks AI/users HIGH Y <code>docs/qux.md:23</code>, ... Affects quality MEDIUM Z <code>docs/lorem.md:67</code>, ... Usability issues LOW W <code>docs/ipsum.md:89</code>, ... Minor improvements TOTAL X+Y+Z+W"},{"location":"contributing/audit/project/#top-3-critical-issues-mandatory-detailed-format","title":"Top 3 Critical Issues (MANDATORY DETAILED FORMAT)","text":"<p>For EACH critical issue, provide this exact format:</p> <p>CRITICAL-01: [Brief one-line description]</p> <ul> <li>Priority: CRITICAL</li> <li>Location: <code>docs/atomic/architecture/data-access-architecture.md:66</code> (exact file:line)</li> <li>Description: Legacy reference to non-existent file <code>docs/legacy/architecture/data-access-rules.md</code></li> <li>Impact:</li> <li>Users clicking link get 404 error</li> <li>AI agents attempting to read referenced doc fail</li> <li>Breaks documentation navigation flow</li> <li>How Found:   <pre><code>grep -rn \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n# Output: 66:- Legacy reference: `docs/legacy/architecture/data-access-rules.mdc`\n</code></pre></li> <li>Fix:   <pre><code>sed -i 's|docs/legacy/architecture/data-access-rules.md|docs/atomic/architecture/data-access-architecture.md|g' \\\n  docs/atomic/architecture/data-access-architecture.md\n</code></pre></li> <li>Verification:   <pre><code>grep -n \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n# Expected output: (nothing - line should be removed/fixed)\n</code></pre></li> </ul> <p>[Repeat exact format for CRITICAL-02, CRITICAL-03]</p>"},{"location":"contributing/audit/project/#validation-commands-used-proof-of-work-mandatory","title":"Validation Commands Used (PROOF OF WORK - MANDATORY)","text":"<p>Smoke tests executed: <pre><code>1. find docs -name \"*.md\" | wc -l\n   Result: 200 markdown files found\n\n2. grep -rho '\\[.*\\](.*\\.md' docs/ | wc -l\n   Result: 1247 total markdown links found\n\n3. grep -rn \"docs/legacy\\|deprecated\" docs/ | wc -l\n   Result: 64 legacy references found (CRITICAL ISSUE)\n\n4. Broken links sample (first 10 files):\n   Result: 5 broken links found in sample \u2192 indicates systemic problem\n</code></pre></p> <p>Full validation commands executed: <pre><code># For Objective 2 (Link Validation):\n5. grep -rn \"docs/legacy\" docs/ &gt; /tmp/legacy_refs.txt\n   Result: 64 legacy references (see /tmp/legacy_refs.txt)\n\n6. grep -rho '\\[.*\\](.*\\.md' docs/ | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u &gt; /tmp/unique_refs.txt\n   Result: 487 unique file references\n\n7. [List OTHER commands you actually executed]\n   Result: [actual results]\n</code></pre></p> <p>Spot checks performed (MANDATORY - verify 3+ random issues): <pre><code># Spot Check 1: Verify docs/atomic/architecture/data-access-architecture.md:66\nCommand: sed -n '66p' docs/atomic/architecture/data-access-architecture.md\nOutput: \"- Legacy reference: `docs/legacy/architecture/data-access-rules.mdc`\"\nVerified: \u2705 Issue is real (legacy link exists at line 66)\n\n# Spot Check 2: Verify target file doesn't exist\nCommand: ls docs/legacy/architecture/data-access-rules.md 2&gt;&amp;1\nOutput: \"No such file or directory\"\nVerified: \u2705 Target file does not exist (404 error for users)\n\n# Spot Check 3: [third random issue verification]\nCommand: [command used]\nOutput: [actual output]\nVerified: \u2705 / \u274c [result]\n</code></pre></p>"},{"location":"contributing/audit/project/#2-issue-categories","title":"2. Issue Categories","text":"<p>[Original issue categories from template, keeping them as-is since they're already good]</p>"},{"location":"contributing/audit/project/#link-reference-issues","title":"Link &amp; Reference Issues","text":"<ul> <li>Broken internal links</li> <li>Invalid anchor references</li> <li>Missing referenced files</li> <li>Legacy/deprecated references (NEW - highest priority)</li> </ul>"},{"location":"contributing/audit/project/#content-quality-issues","title":"Content Quality Issues","text":"<ul> <li>Spelling errors with corrections</li> <li>Duplicate content locations</li> <li>Contradictory information</li> </ul> <p>[... rest of original issue categories ...]</p> <p>For each issue, provide: - Priority: CRITICAL / HIGH / MEDIUM / LOW - Location: Exact file:line (e.g., <code>docs/path/file.md:123</code>) - Description: What's broken and why it matters - Impact: How it affects users/AI agents - Fix: Exact bash commands or changes needed (not \"update the files\" - give EXACT commands) - Verification: Exact bash command to verify fix worked</p>"},{"location":"contributing/audit/project/#3-todo-list","title":"3. TODO List","text":"<p>Organize fixes into phases: - Phase 1: Quick Fixes (&lt; 1 hour) - Critical broken links, legacy refs, typos - Phase 2: Content Updates (1-4 hours) - Missing docs, inconsistencies - Phase 3: Structural (&gt; 4 hours) - Architecture changes, major rewrites</p> <p>For each task: - Estimated time - Priority level - Dependencies (what must be done first) - Exact validation command</p>"},{"location":"contributing/audit/project/#4-validation-commands","title":"4. Validation Commands","text":"<p>Provide bash commands to: - Check all markdown links - Verify file existence - Test anchor links - Compare expected vs actual structure</p>"},{"location":"contributing/audit/project/#5-whats-working-well","title":"5. What's Working Well","text":"<p>Highlight positive findings: - Good structure and organization - Consistent patterns - Comprehensive coverage - Well-maintained areas</p>"},{"location":"contributing/audit/project/#6-recommendations","title":"6. Recommendations","text":"<ul> <li>Immediate (this week)</li> <li>Short-term (this month)</li> <li>Long-term (when needed)</li> <li>CI/CD automation suggestions</li> </ul>"},{"location":"contributing/audit/project/#output-format","title":"OUTPUT FORMAT","text":""},{"location":"contributing/audit/project/#structure-requirements","title":"Structure Requirements","text":"<ol> <li>Use Markdown with clear section hierarchy</li> <li>Code blocks with syntax highlighting (<code>bash,</code>python, etc.)</li> <li>File paths format: <code>/path/to/file.md:123</code> (clickable in most IDEs)</li> <li>Tables for large datasets (issue lists, file inventories)</li> <li>Command examples showing exact fix commands with expected output</li> </ol>"},{"location":"contributing/audit/project/#example-output-structure","title":"Example Output Structure","text":"<pre><code>## Critical Issues (Priority: CRITICAL)\n\n### Issue 1: Broken Legacy Reference\n\n**File**: `docs/atomic/architecture/data-access-architecture.md:66`\n**Problem**: Reference to non-existent `docs/legacy/architecture/data-access-rules.md`\n**Impact**: Blocks users/AI agents trying to find data access rules\n**Category**: Link Validation\n\n**How Found**:\n```bash\ngrep -rn \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n</code></pre> <p>Fix Command: <pre><code>sed -i 's|docs/legacy/architecture/data-access-rules.md|docs/atomic/architecture/data-access-architecture.md|g' \\\n  docs/atomic/architecture/data-access-architecture.md\n</code></pre></p> <p>Verification: <pre><code>grep -n \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n# Expected: no output (issue fixed)\n</code></pre> <pre><code>---\n\n## CONSTRAINTS \u26a1 MANDATORY\n\n### Execution Constraints\n\n1. **DO NOT delegate this audit to Task agent**\n   - You MUST execute all validation commands yourself using Bash tool\n   - Delegation leads to incomplete audits (proven failure mode)\n\n2. **DO NOT use sample-based checking**\n   - Check ALL files, not 10% with extrapolation\n   - Use `find`, `grep -r`, `xargs -P` for exhaustive scans\n\n3. **DO NOT skip smoke tests**\n   - Run all 5 smoke tests before full audit\n   - If any smoke test shows critical issues, report immediately\n\n4. **DO NOT estimate health score**\n   - Calculate using exact formula: `100 - (CRITICAL\u00d73) - (HIGH\u00d71.5) - (MEDIUM\u00d70.5) - (LOW\u00d70.1)`\n   - Show calculation in report\n\n5. **DO NOT trust \"Related Documents\" sections without verification**\n   - These are NOT optional metadata\n   - Users/AI agents click these links expecting valid targets\n   - Broken \"Related Documents\" = CRITICAL issue\n\n### Reporting Constraints\n\n1. **MUST show validation commands used** (proof of work)\n2. **MUST perform 3+ spot checks** to verify issues are real\n3. **MUST include fix commands** for each issue (not just descriptions)\n4. **MUST include verification commands** showing how to confirm fix worked\n5. **MUST report file:line locations** for all issues (not just filenames)\n\n### Quality Constraints\n\n1. **Accuracy &gt; Speed**: Better to take 10 minutes and find all issues than 2 minutes with 50% false negatives\n2. **Explicit &gt; Implicit**: Show commands, outputs, calculations\n3. **Reproducible**: Any human/AI should be able to run your commands and get same results\n4. **Actionable**: Every issue should have clear fix command\n\n---\n\n## VERIFICATION PROTOCOL \u26a1 MANDATORY\n\nAfter completing the audit, perform these self-checks:\n\n### Automated Verification\n\n```bash\n# Check 1: Did you run smoke tests?\ngrep -q \"SMOKE TEST\" /tmp/audit_output.md\necho \"Smoke tests documented: $?\"  # Expected: 0 (yes)\n\n# Check 2: Did you show health score calculation?\ngrep -q \"100 - (CRITICAL\" /tmp/audit_output.md\necho \"Health score formula shown: $?\"  # Expected: 0 (yes)\n\n# Check 3: Did you perform spot checks?\ngrep -c \"Spot Check\" /tmp/audit_output.md\n# Expected: &gt;= 3\n\n# Check 4: Are all issues tagged with severity?\nISSUES=$(grep -c \"^### Issue\" /tmp/audit_output.md)\nSEVERITIES=$(grep -c \"Priority: \\(CRITICAL\\|HIGH\\|MEDIUM\\|LOW\\)\" /tmp/audit_output.md)\necho \"Issues: $ISSUES, Tagged: $SEVERITIES\"  # Should match\n\n# Check 5: Do all issues have fix commands?\nFIX_COMMANDS=$(grep -c \"**Fix Command**:\" /tmp/audit_output.md)\necho \"Issues with fixes: $ISSUES/$FIX_COMMANDS\"  # Should match\n</code></pre></p>"},{"location":"contributing/audit/project/#manual-spot-checks-pick-3-random-issues","title":"Manual Spot Checks (Pick 3 Random Issues)","text":"<p>For each spot check:</p> <ol> <li>Copy the \"How Found\" command \u2192 Run it yourself</li> <li>Verify the issue exists at reported file:line</li> <li>Copy the \"Fix Command\" \u2192 Run it in test environment</li> <li>Copy the \"Verification Command\" \u2192 Confirm fix works</li> <li>Document result in audit report</li> </ol> <p>Example Spot Check Documentation:</p> <pre><code>#### Spot Check 1: Legacy Reference Verification\n\n**Issue**: docs/atomic/architecture/data-access-architecture.md:66 references non-existent legacy file\n\n**Command Run**:\n```bash\nsed -n '66p' docs/atomic/architecture/data-access-architecture.md\n</code></pre> <p>Output: <pre><code>- Legacy reference: `docs/legacy/architecture/data-access-rules.md`\n</code></pre></p> <p>Verification: \u2705 Issue confirmed - line 66 contains broken legacy reference</p> <p>Fix Tested: \u2705 sed replacement works, file updated correctly <pre><code>### Self-Audit Checklist\n\nBefore submitting audit report, confirm:\n\n- [ ] All 5 smoke tests executed and documented\n- [ ] Health score calculation shown with formula\n- [ ] All validation commands listed (proof of work)\n- [ ] 3+ spot checks performed and documented\n- [ ] Every issue has: file:line, impact, category, how found, fix command, verification\n- [ ] No delegation used (all commands run directly by you)\n- [ ] Exhaustive checking used (not sample-based)\n- [ ] \"Related Documents\" sections validated (not skipped)\n\n**If ANY checklist item is unchecked \u2192 AUDIT IS INCOMPLETE**\n\n---\n\n## OBJECTIVES (Detailed)\n\n### 1. Documentation Completeness\n\n**Goal**: Ensure every required document exists and is accessible.\n\n**Validation Commands**:\n\n```bash\n# Check critical Stage 0 documents\nSTAGE0_DOCS=(\n  \"CLAUDE.md\"\n  \"docs/reference/agent-context-summary.md\"\n  \"docs/guides/ai-code-generation-master-workflow.md\"\n  \"docs/reference/maturity-levels.md\"\n)\n\nfor doc in \"${STAGE0_DOCS[@]}\"; do\n  if [ -f \"$doc\" ]; then\n    echo \"\u2705 $doc\"\n  else\n    echo \"\u274c MISSING (CRITICAL): $doc\"\n  fi\ndone\n\n# Check all documents referenced in ai-navigation-matrix.md\ngrep -oP '\\[.*?\\]\\(\\K[^)]+\\.md' docs/reference/ai-navigation-matrix.md | while read -r ref; do\n  if [ -f \"$ref\" ] || [ -f \"docs/$ref\" ]; then\n    echo \"\u2705 $ref\"\n  else\n    echo \"\u274c BROKEN REFERENCE: $ref (referenced in ai-navigation-matrix.md)\"\n  fi\ndone\n\n# ========================================\n# STEP 4: Check Phase 1 educational guides (Phase 1 Deliverables)\n# ========================================\necho \"\"\necho \"Step 4: Validating Phase 1 guides...\"\nPHASE1_GUIDES=(\n  \"docs/guides/dry-kiss-yagni-principles.md\"\n  \"docs/guides/migration-guide-phase1.md\"\n  \"docs/quality/automated-quality-gates.md\"\n)\n\n&gt; /tmp/missing_phase1_guides.txt\n\nfor guide in \"${PHASE1_GUIDES[@]}\"; do\n  if [ -f \"$guide\" ]; then\n    echo \"\u2705 $guide exists\"\n\n    # Check guide has required sections\n    case \"$guide\" in\n      *dry-kiss-yagni*)\n        # Check for DRY, KISS, YAGNI sections\n        grep -q \"## 1. DRY\\|^## DRY\" \"$guide\" &amp;&amp; echo \"  \u2705 DRY section\" || echo \"  \u274c DRY section missing\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"## 2. KISS\\|^## KISS\" \"$guide\" &amp;&amp; echo \"  \u2705 KISS section\" || echo \"  \u274c KISS section missing\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"## 3. YAGNI\\|^## YAGNI\" \"$guide\" &amp;&amp; echo \"  \u2705 YAGNI section\" || echo \"  \u274c YAGNI section missing\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"Automated Detection Tools\\|Detection Tools\" \"$guide\" &amp;&amp; echo \"  \u2705 Tools section\" || echo \"  \u274c Tools section missing\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        ;;\n      *migration-guide*)\n        # Check migration guide references all Phase 1 deliverables\n        grep -q \"shared/utils\\|shared utilities\" \"$guide\" &amp;&amp; echo \"  \u2705 References shared utilities\" || echo \"  \u274c Missing shared utils reference\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"template_data_postgres_api\\|PostgreSQL.*template\" \"$guide\" &amp;&amp; echo \"  \u2705 References PostgreSQL template\" || echo \"  \u274c Missing PostgreSQL template reference\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"quality-gates\\|quality gates\\|CI.*quality\" \"$guide\" &amp;&amp; echo \"  \u2705 References quality gates\" || echo \"  \u274c Missing quality gates reference\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        # Check for migration steps\n        grep -qE \"Phase [0-9]|Step [0-9]|### [0-9]\\.\" \"$guide\" &amp;&amp; echo \"  \u2705 Has structured steps\" || echo \"  \u274c Missing structured migration steps\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        ;;\n      *automated-quality-gates*)\n        # Check quality gates doc describes CI jobs\n        grep -q \"check-duplication\" \"$guide\" &amp;&amp; echo \"  \u2705 Documents duplication check\" || echo \"  \u274c Missing duplication check docs\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"check-complexity\" \"$guide\" &amp;&amp; echo \"  \u2705 Documents complexity check\" || echo \"  \u274c Missing complexity check docs\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        grep -q \"check-dependencies\" \"$guide\" &amp;&amp; echo \"  \u2705 Documents dependency check\" || echo \"  \u274c Missing dependency check docs\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        # Check for threshold documentation\n        grep -q \"threshold.*10\\|10%.*duplication\" \"$guide\" &amp;&amp; echo \"  \u2705 DRY threshold documented\" || echo \"  \u274c DRY threshold missing\" &gt;&gt; /tmp/missing_phase1_guides.txt\n        ;;\n    esac\n  else\n    echo \"\u274c CRITICAL: $guide missing (Phase 1 deliverable)\" &gt;&gt; /tmp/missing_phase1_guides.txt\n  fi\ndone\n\nPHASE1_ISSUES=$(wc -l &lt; /tmp/missing_phase1_guides.txt)\necho \"Phase 1 guide issues: $PHASE1_ISSUES\"\n\nif [ \"$PHASE1_ISSUES\" -gt 0 ]; then\n  echo \"\ud83d\udea8 CRITICAL: Phase 1 documentation incomplete!\"\n  cat /tmp/missing_phase1_guides.txt\nfi\n</code></pre></p> <p>Expected Outcome: List of missing/broken documents with severity ratings, plus Phase 1 guide validation showing: - Which Phase 1 guides exist (DRY/KISS/YAGNI, migration, quality gates) - Whether guides have required sections (principles, steps, deliverable references) - Whether guides reference each other (migration guide \u2192 quality gates, principles)</p>"},{"location":"contributing/audit/project/#2-link-validation-already-detailed-above","title":"2. Link Validation \u26a1 ALREADY DETAILED ABOVE","text":"<p>(See previous section with step-by-step validation commands)</p>"},{"location":"contributing/audit/project/#3-structural-consistency","title":"3. Structural Consistency","text":"<p>Goal: Verify all documents follow framework structure patterns.</p> <p>Validation Commands:</p> <pre><code># Check atomic/* structure\nEXPECTED_ATOMIC_DIRS=(\n  \"architecture\"\n  \"databases\"\n  \"infrastructure\"\n  \"integrations\"\n  \"observability\"\n  \"services\"\n  \"testing\"\n)\n\nfor dir in \"${EXPECTED_ATOMIC_DIRS[@]}\"; do\n  if [ -d \"docs/atomic/$dir\" ]; then\n    README_COUNT=$(find \"docs/atomic/$dir\" -name \"README.md\" | wc -l)\n    echo \"\u2705 docs/atomic/$dir exists (READMEs: $README_COUNT)\"\n  else\n    echo \"\u274c MISSING: docs/atomic/$dir\"\n  fi\ndone\n\n# Check service documentation completeness\nfor svc_dir in docs/atomic/services/*/; do\n  svc_name=$(basename \"$svc_dir\")\n  echo \"=== Checking $svc_name ===\"\n\n  # Required files\n  [ -f \"$svc_dir/README.md\" ] &amp;&amp; echo \"  \u2705 README.md\" || echo \"  \u274c README.md\"\n  [ -f \"$svc_dir/basic-setup.md\" ] &amp;&amp; echo \"  \u2705 basic-setup.md\" || echo \"  \u26a0\ufe0f  basic-setup.md\"\n\n  # Check for code examples\n  if grep -q '```python\\|```yaml\\|```bash' \"$svc_dir\"/*.md 2&gt;/dev/null; then\n    echo \"  \u2705 Contains code examples\"\n  else\n    echo \"  \u26a0\ufe0f  No code examples found\"\n  fi\ndone\n</code></pre> <p>Expected Outcome: Structural consistency report with missing directories/files.</p>"},{"location":"contributing/audit/project/#4-content-quality","title":"4. Content Quality","text":"<p>Goal: Validate code examples, check for TODOs, verify English language.</p> <p>Validation Commands:</p> <pre><code># Find TODO markers\ngrep -rn \"TODO\\|FIXME\\|XXX\\|HACK\\|WIP\" docs/ README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/todos.txt\nTODO_COUNT=$(wc -l &lt; /tmp/todos.txt)\necho \"TODO markers found: $TODO_COUNT\"\nif [ $TODO_COUNT -gt 0 ]; then\n  echo \"\u26a0\ufe0f  Incomplete documentation detected\"\n  head -10 /tmp/todos.txt\nfi\n\n# Validate Python code blocks\ngrep -rn '```python' docs/ | cut -d: -f1 | sort -u | while read -r file; do\n  # Extract Python code blocks and validate syntax\n  awk '/```python/,/```/' \"$file\" | grep -v '```' &gt; /tmp/code_check.py\n  if [ -s /tmp/code_check.py ]; then\n    python3 -m py_compile /tmp/code_check.py 2&gt;/dev/null\n    if [ $? -eq 0 ]; then\n      echo \"\u2705 $file - Python syntax valid\"\n    else\n      echo \"\u274c $file - Python syntax errors\"\n    fi\n  fi\ndone\n\n# Validate bash code blocks\nfind docs/ -name \"*.md\" -exec grep -l '```bash' {} \\; | while read -r file; do\n  # Extract bash blocks and check with shellcheck (if available)\n  if command -v shellcheck &amp;&gt;/dev/null; then\n    awk '/```bash/,/```/' \"$file\" | grep -v '```' &gt; /tmp/code_check.sh\n    if [ -s /tmp/code_check.sh ]; then\n      shellcheck /tmp/code_check.sh 2&gt;/dev/null &amp;&amp; echo \"\u2705 $file - Bash valid\" || echo \"\u26a0\ufe0f  $file - Bash warnings\"\n    fi\n  fi\ndone\n\n# Check for non-English content (basic heuristic)\ngrep -rn '[\u0430-\u044f\u0410-\u042f\u0451\u0401]' docs/ README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/non_english.txt\nNON_ENGLISH=$(wc -l &lt; /tmp/non_english.txt)\nif [ $NON_ENGLISH -gt 0 ]; then\n  echo \"\u26a0\ufe0f  Non-English content detected ($NON_ENGLISH instances)\"\n  head -5 /tmp/non_english.txt\nfi\n</code></pre> <p>Expected Outcome: Content quality report with syntax errors, TODOs, language issues.</p>"},{"location":"contributing/audit/project/#5-ai-navigation-integrity","title":"5. AI Navigation Integrity","text":"<p>Goal: Verify AI agents can navigate documentation per Master Workflow.</p> <p>Validation Commands:</p> <pre><code># Verify Stage 0 initialization sequence\necho \"=== Verifying Stage 0 Initialization Sequence ===\"\n\nSTAGE0_ORDER=(\n  \"CLAUDE.md\"\n  \"docs/reference/agent-context-summary.md\"\n  \"docs/guides/ai-code-generation-master-workflow.md\"\n  \"docs/reference/maturity-levels.md\"\n)\n\nfor i in \"${!STAGE0_ORDER[@]}\"; do\n  doc=\"${STAGE0_ORDER[$i]}\"\n  if [ -f \"$doc\" ]; then\n    echo \"Step $((i+1)): \u2705 $doc\"\n\n    # Check file is readable and non-empty\n    if [ ! -s \"$doc\" ]; then\n      echo \"  \u274c CRITICAL: File is empty\"\n    fi\n\n    # Check Stage 0 documents reference each other correctly\n    if [ $i -lt ${#STAGE0_ORDER[@]}-1 ]; then\n      next_doc=\"${STAGE0_ORDER[$((i+1))]}\"\n      if grep -q \"$next_doc\" \"$doc\"; then\n        echo \"  \u2705 References next document: $next_doc\"\n      else\n        echo \"  \u26a0\ufe0f  Does not reference next document: $next_doc\"\n      fi\n    fi\n  else\n    echo \"Step $((i+1)): \u274c CRITICAL - $doc MISSING\"\n  fi\ndone\n\n# Verify ai-navigation-matrix.md completeness\nif [ -f \"docs/reference/ai-navigation-matrix.md\" ]; then\n  echo \"=== Checking AI Navigation Matrix ===\"\n\n  # Check for all 7 stages\n  for stage in {0..6}; do\n    if grep -q \"Stage $stage\" docs/reference/ai-navigation-matrix.md; then\n      echo \"  \u2705 Stage $stage documented\"\n    else\n      echo \"  \u274c Stage $stage missing\"\n    fi\n  done\n\n  # Check matrix has Required Docs, Outputs, Tools columns\n  if grep -q \"Required Documents\\|Primary Documents\\|Key Documents\" docs/reference/ai-navigation-matrix.md; then\n    echo \"  \u2705 Required Documents column present\"\n  else\n    echo \"  \u26a0\ufe0f  Required Documents column missing/unclear\"\n  fi\nelse\n  echo \"\u274c CRITICAL: docs/reference/ai-navigation-matrix.md missing\"\nfi\n</code></pre> <p>Expected Outcome: AI navigation integrity report with broken Stage 0 sequence or matrix issues.</p>"},{"location":"contributing/audit/project/#objective-6-extension-ci-quality-gates-validation-phase-1-code-configuration","title":"Objective 6 Extension: CI Quality Gates Validation (Phase 1 - Code &amp; Configuration)","text":"<p>Goal: Validate CI quality gates exist and enforce DRY/KISS/YAGNI principles automatically.</p> <p>Validation Commands:</p> <pre><code># ========================================\n# Objective 6 Extension: CI Quality Gates Validation (Phase 1)\n# ========================================\n\necho \"=== Checking CI Quality Gates Configuration ===\"\n\nCI_FILE=\"templates/ci-cd/.github/workflows/ci.yml\"\n\nif [ ! -f \"$CI_FILE\" ]; then\n  echo \"\u274c CRITICAL: $CI_FILE missing (Phase 1 deliverable)\"\n  exit 1\nfi\n\n# STEP 1: Verify quality gate jobs exist\necho \"Step 1: Checking quality gate jobs...\"\nQUALITY_JOBS=(\n  \"check-duplication:Check Code Duplication (DRY)\"\n  \"check-complexity:Check Code Complexity (KISS)\"\n  \"check-dependencies:Check Dependency Bloat (YAGNI)\"\n)\n\n&gt; /tmp/missing_quality_jobs.txt\n\nfor job_spec in \"${QUALITY_JOBS[@]}\"; do\n  job_id=\"${job_spec%%:*}\"\n  job_name=\"${job_spec#*:}\"\n\n  if grep -q \"^  $job_id:\" \"$CI_FILE\"; then\n    echo \"\u2705 Job exists: $job_id\"\n\n    # Check job has descriptive name\n    if grep -A1 \"^  $job_id:\" \"$CI_FILE\" | grep -q \"name:\"; then\n      echo \"  \u2705 Job has name field\"\n    else\n      echo \"  \u26a0\ufe0f  Job name unclear\" &gt;&gt; /tmp/missing_quality_jobs.txt\n    fi\n  else\n    echo \"\u274c CRITICAL: Job missing: $job_id\" &gt;&gt; /tmp/missing_quality_jobs.txt\n  fi\ndone\n\n# STEP 2: Verify quality gates use correct tools\necho \"Step 2: Checking quality gate tools...\"\n\n# Check check-duplication uses jscpd\nif grep -A20 \"^  check-duplication:\" \"$CI_FILE\" | grep -q \"jscpd\"; then\n  echo \"\u2705 check-duplication uses jscpd\"\nelse\n  echo \"\u274c check-duplication doesn't use jscpd\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# Check check-complexity uses radon\nif grep -A20 \"^  check-complexity:\" \"$CI_FILE\" | grep -q \"radon\"; then\n  echo \"\u2705 check-complexity uses radon\"\nelse\n  echo \"\u274c check-complexity doesn't use radon\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# STEP 3: Verify quality gates reference principles guide\necho \"Step 3: Checking quality gates reference DRY/KISS/YAGNI guide...\"\n\nif grep -q \"docs/guides/dry-kiss-yagni-principles.md\\|dry-kiss-yagni-principles\" \"$CI_FILE\"; then\n  echo \"\u2705 CI workflow references DRY/KISS/YAGNI principles guide\"\n\n  # Count references (should be 3: one per principle)\n  ref_count=$(grep -c \"dry-kiss-yagni-principles\" \"$CI_FILE\")\n  if [ $ref_count -ge 3 ]; then\n    echo \"  \u2705 Multiple references found ($ref_count) - likely one per principle\"\n  else\n    echo \"  \u26a0\ufe0f  Only $ref_count reference(s) found (expected 3+)\" &gt;&gt; /tmp/missing_quality_jobs.txt\n  fi\nelse\n  echo \"\u274c CI doesn't reference principles guide\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# STEP 4: Verify quality gate thresholds\necho \"Step 4: Checking quality gate thresholds...\"\n\n# DRY: 10% duplication threshold\nif grep -q \"threshold.*10\" \"$CI_FILE\" &amp;&amp; grep -B5 -A5 \"threshold.*10\" \"$CI_FILE\" | grep -q \"jscpd\"; then\n  echo \"\u2705 DRY threshold: 10% duplication\"\nelse\n  echo \"\u26a0\ufe0f  DRY threshold unclear or missing\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# KISS: McCabe complexity &lt; 10\nif grep -q \"min.*B\\|--min B\" \"$CI_FILE\" &amp;&amp; grep -B5 -A5 \"min.*B\" \"$CI_FILE\" | grep -q \"radon cc\"; then\n  echo \"\u2705 KISS threshold: McCabe complexity Grade B (&lt; 10)\"\nelse\n  echo \"\u26a0\ufe0f  KISS complexity threshold unclear\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# YAGNI: Dependency count thresholds\nif grep -q \"threshold=30\\|threshold=50\" \"$CI_FILE\"; then\n  echo \"\u2705 YAGNI threshold: 30/50 dependencies\"\nelse\n  echo \"\u26a0\ufe0f  YAGNI dependency threshold unclear\" &gt;&gt; /tmp/missing_quality_jobs.txt\nfi\n\n# STEP 5: Verify quality gates fail build on violation\necho \"Step 5: Checking quality gates fail build...\"\n\nfor job in check-duplication check-complexity check-dependencies; do\n  if grep -A30 \"^  $job:\" \"$CI_FILE\" | grep -q \"exit 1\"; then\n    echo \"\u2705 $job fails build on violation\"\n  else\n    echo \"\u26a0\ufe0f  $job might not fail build\" &gt;&gt; /tmp/missing_quality_jobs.txt\n  fi\ndone\n\n# SUMMARY\nQUALITY_ISSUES=$(wc -l &lt; /tmp/missing_quality_jobs.txt)\necho \"\"\necho \"=== CI Quality Gates Validation Summary ===\"\necho \"Issues found: $QUALITY_ISSUES\"\n\nif [ \"$QUALITY_ISSUES\" -gt 0 ]; then\n  echo \"\ud83d\udea8 CRITICAL: CI quality gates incomplete/broken!\"\n  cat /tmp/missing_quality_jobs.txt\nelse\n  echo \"\u2705 All CI quality gates properly configured\"\nfi\n</code></pre> <p>Expected Outcome: Report showing: - Which quality gate jobs exist (check-duplication, check-complexity, check-dependencies) - Whether correct tools are used (jscpd, radon) - Whether gates reference DRY/KISS/YAGNI principles guide - Whether thresholds match Phase 1 specification (10%, Grade B, 30/50) - Whether gates fail build on violation</p> <p>Priority Assignment: - Missing quality gate jobs: CRITICAL (Phase 1 enforcement broken) - Wrong tools used: CRITICAL (gates won't work) - Missing principles guide references: HIGH (developers can't learn how to fix) - Wrong thresholds: MEDIUM (gates work but wrong standards) - No build failure: HIGH (gates don't enforce anything)</p>"},{"location":"contributing/audit/project/#6-maturity-level-coverage","title":"6. Maturity Level Coverage","text":"<p>Goal: Ensure all 4 maturity levels are documented with clear guidance.</p> <p>Validation Commands:</p> <pre><code># Check maturity-levels.md completeness\nif [ -f \"docs/reference/maturity-levels.md\" ]; then\n  echo \"=== Checking Maturity Levels Documentation ===\"\n\n  LEVELS=(\"Level 1\" \"Level 2\" \"Level 3\" \"Level 4\")\n  KEYWORDS=(\"PoC\" \"Development\" \"Pre-Production\" \"Production\")\n\n  for i in \"${!LEVELS[@]}\"; do\n    level=\"${LEVELS[$i]}\"\n    keyword=\"${KEYWORDS[$i]}\"\n\n    if grep -qi \"$level.*$keyword\\|$keyword.*$level\" docs/reference/maturity-levels.md; then\n      echo \"  \u2705 $level ($keyword) documented\"\n    else\n      echo \"  \u274c $level ($keyword) missing or unclear\"\n    fi\n  done\n\n  # Check for time estimates\n  if grep -E \"~?[0-9]+\\s*(min|minute)\" docs/reference/maturity-levels.md | grep -q .; then\n    echo \"  \u2705 Time estimates present\"\n  else\n    echo \"  \u26a0\ufe0f  Time estimates missing\"\n  fi\n\n  # Check for quality criteria differences\n  if grep -qi \"quality.*criteria\\|quality.*gate\\|testing.*requirement\" docs/reference/maturity-levels.md; then\n    echo \"  \u2705 Quality criteria documented\"\n  else\n    echo \"  \u26a0\ufe0f  Quality criteria not clearly documented\"\n  fi\nelse\n  echo \"\u274c CRITICAL: docs/reference/maturity-levels.md missing\"\nfi\n\n# Check conditional-stage-rules.md\nif [ -f \"docs/reference/conditional-stage-rules.md\" ]; then\n  echo \"=== Checking Conditional Stage Rules ===\"\n\n  # Verify rules exist for each level\n  for level in {1..4}; do\n    if grep -q \"Level $level\" docs/reference/conditional-stage-rules.md; then\n      echo \"  \u2705 Level $level rules present\"\n    else\n      echo \"  \u26a0\ufe0f  Level $level rules missing\"\n    fi\n  done\nelse\n  echo \"\u26a0\ufe0f  docs/reference/conditional-stage-rules.md missing (optional but recommended)\"\nfi\n</code></pre> <p>Expected Outcome: Maturity level coverage report with missing guidance or inconsistencies.</p>"},{"location":"contributing/audit/project/#7-architecture-constraint-visibility","title":"7. Architecture Constraint Visibility","text":"<p>Goal: Ensure mandatory constraints are clear and discoverable.</p> <p>Validation Commands:</p> <pre><code># Check architecture-guide.md for mandatory constraints\nif [ -f \"docs/guides/architecture-guide.md\" ]; then\n  echo \"=== Checking Architecture Constraints ===\"\n\n  CONSTRAINTS=(\n    \"HTTP-only data access\"\n    \"Service separation\"\n    \"Nginx.*gateway.*mandatory\\|API gateway.*mandatory\"\n    \"RabbitMQ.*mandatory\"\n    \"3-part naming\"\n  )\n\n  for constraint in \"${CONSTRAINTS[@]}\"; do\n    if grep -qi \"$constraint\" docs/guides/architecture-guide.md; then\n      echo \"  \u2705 Constraint documented: $constraint\"\n    else\n      echo \"  \u26a0\ufe0f  Constraint unclear: $constraint\"\n    fi\n  done\n\n  # Check if constraints are marked as MANDATORY\n  MANDATORY_COUNT=$(grep -ci \"MANDATORY\\|REQUIRED\\|MUST\" docs/guides/architecture-guide.md)\n  echo \"  \u2139\ufe0f  'MANDATORY/REQUIRED/MUST' mentions: $MANDATORY_COUNT\"\nelse\n  echo \"\u274c CRITICAL: docs/guides/architecture-guide.md missing\"\nfi\n\n# Check service-separation-principles.md\nif [ -f \"docs/atomic/architecture/service-separation-principles.md\" ]; then\n  echo \"  \u2705 Service separation principles documented\"\nelse\n  echo \"  \u26a0\ufe0f  docs/atomic/architecture/service-separation-principles.md missing\"\nfi\n\n# Check data-access-architecture.md\nif [ -f \"docs/atomic/architecture/data-access-architecture.md\" ]; then\n  echo \"  \u2705 Data access architecture documented\"\n\n  # Verify no legacy references (critical for this file)\n  if grep -qi \"docs/legacy\\|deprecated\" docs/atomic/architecture/data-access-architecture.md; then\n    echo \"  \u274c CRITICAL: Contains legacy/deprecated references\"\n  fi\nelse\n  echo \"  \u26a0\ufe0f  docs/atomic/architecture/data-access-architecture.md missing\"\nfi\n</code></pre> <p>Expected Outcome: Architecture constraint visibility report.</p>"},{"location":"contributing/audit/project/#8-naming-convention-clarity","title":"8. Naming Convention Clarity","text":"<p>Goal: Verify naming conventions (3-part vs 4-part) are clear and unambiguous.</p> <p>Validation Commands:</p> <pre><code># Check naming convention documentation\necho \"=== Checking Naming Conventions ===\"\n\n# Primary naming docs\nif [ -f \"docs/atomic/architecture/naming/README.md\" ]; then\n  echo \"\u2705 Main naming guide exists\"\n\n  # Check for 3-part default guidance\n  if grep -qi \"default.*3-part\\|3-part.*default\" docs/atomic/architecture/naming/README.md; then\n    echo \"  \u2705 3-part default clearly stated\"\n  else\n    echo \"  \u26a0\ufe0f  3-part default not clearly stated\"\n  fi\n\n  # Check for 4-part guidance\n  if grep -qi \"4-part.*when\\|when.*4-part\\|4-part.*only\" docs/atomic/architecture/naming/README.md; then\n    echo \"  \u2705 4-part usage guidance present\"\n  else\n    echo \"  \u26a0\ufe0f  4-part usage guidance unclear\"\n  fi\nelse\n  echo \"\u274c docs/atomic/architecture/naming/README.md missing\"\nfi\n\n# Check service-naming-checklist.md\nif [ -f \"docs/checklists/service-naming-checklist.md\" ]; then\n  echo \"\u2705 Service naming checklist exists\"\nelse\n  echo \"\u26a0\ufe0f  docs/checklists/service-naming-checklist.md missing\"\nfi\n\n# Check 10 reasons doc\nif [ -f \"docs/atomic/architecture/naming/naming-4part-reasons.md\" ]; then\n  echo \"\u2705 4-part naming reasons documented\"\n\n  # Verify it actually has ~10 reasons\n  REASON_COUNT=$(grep -c \"^###\\s*[0-9]\" docs/atomic/architecture/naming/naming-4part-reasons.md)\n  echo \"  \u2139\ufe0f  Number of reasons found: $REASON_COUNT\"\n  if [ $REASON_COUNT -lt 8 ]; then\n    echo \"  \u26a0\ufe0f  Expected ~10 reasons, found $REASON_COUNT\"\n  fi\nelse\n  echo \"\u26a0\ufe0f  docs/atomic/architecture/naming/naming-4part-reasons.md missing\"\nfi\n\n# Check template naming guide\nif [ -f \"docs/guides/template-naming-guide.md\" ]; then\n  echo \"\u2705 Template naming guide exists\"\nelse\n  echo \"\u26a0\ufe0f  docs/guides/template-naming-guide.md missing\"\nfi\n</code></pre> <p>Expected Outcome: Naming convention clarity report.</p>"},{"location":"contributing/audit/project/#9-template-completeness","title":"9. Template Completeness","text":"<p>Goal: Verify all promised service templates exist and are documented.</p> <p>Validation Commands:</p> <pre><code># Check for template services\necho \"=== Checking Service Templates ===\"\n\nTEMPLATES=(\n  \"template_business_api\"\n  \"template_business_bot\"\n  \"template_business_worker\"\n  \"template_data_postgres_api\"\n  \"template_data_mongo_api\"\n)\n\nfor template in \"${TEMPLATES[@]}\"; do\n  if [ -d \"$template\" ]; then\n    echo \"\u2705 $template/ directory exists\"\n\n    # Check for README\n    if [ -f \"$template/README.md\" ]; then\n      echo \"  \u2705 README.md present\"\n\n      # Check README has key sections\n      if grep -qi \"usage\\|quick start\\|getting started\" \"$template/README.md\"; then\n        echo \"    \u2705 Usage instructions present\"\n      else\n        echo \"    \u26a0\ufe0f  Usage instructions missing\"\n      fi\n\n      if grep -qi \"architecture\\|structure\" \"$template/README.md\"; then\n        echo \"    \u2705 Architecture notes present\"\n      else\n        echo \"    \u26a0\ufe0f  Architecture notes missing\"\n      fi\n    else\n      echo \"  \u274c README.md missing\"\n    fi\n\n    # Check for pyproject.toml or package.json\n    if [ -f \"$template/pyproject.toml\" ] || [ -f \"$template/package.json\" ]; then\n      echo \"  \u2705 Dependency configuration present\"\n    else\n      echo \"  \u26a0\ufe0f  Dependency configuration missing\"\n    fi\n  else\n    echo \"\u274c $template/ directory missing\"\n  fi\ndone\n\n# Check template documentation\nif [ -f \"docs/guides/template-naming-guide.md\" ]; then\n  # Verify guide mentions all templates\n  for template in \"${TEMPLATES[@]}\"; do\n    if grep -q \"$template\" docs/guides/template-naming-guide.md; then\n      echo \"  \u2705 $template documented in guide\"\n    else\n      echo \"  \u26a0\ufe0f  $template not mentioned in guide\"\n    fi\n  done\nfi\n\n# ========================================\n# PHASE 1 ADDITION: Check shared utilities template\n# ========================================\necho \"\"\necho \"=== Checking Shared Utilities Template (Phase 1) ===\"\n\nSHARED_UTILS_DIR=\"templates/shared/utils\"\nif [ ! -d \"$SHARED_UTILS_DIR\" ]; then\n  echo \"\u274c CRITICAL: $SHARED_UTILS_DIR missing (Phase 1 deliverable)\"\nelse\n  echo \"\u2705 $SHARED_UTILS_DIR exists\"\n\n  # Check required files\n  UTILS_FILES=(\n    \"__init__.py\"\n    \"logger.py\"\n    \"validators.py\"\n    \"exceptions.py\"\n    \"pagination.py\"\n    \"request_id.py\"\n    \"README.md\"\n  )\n\n  missing=0\n  for file in \"${UTILS_FILES[@]}\"; do\n    if [ -f \"$SHARED_UTILS_DIR/$file\" ]; then\n      echo \"  \u2705 $file\"\n    else\n      echo \"  \u274c MISSING: $file\"\n      missing=$((missing + 1))\n    fi\n  done\n\n  # Check README has usage examples\n  if [ -f \"$SHARED_UTILS_DIR/README.md\" ]; then\n    if grep -q \"Before (WRONG\\|After (CORRECT\\|## Usage\\|## Module Documentation\" \"$SHARED_UTILS_DIR/README.md\"; then\n      echo \"    \u2705 README has usage examples and module documentation\"\n    else\n      echo \"    \u26a0\ufe0f  README missing usage examples or module docs\"\n    fi\n\n    if grep -q \"Migration Guide\\|## Migration\" \"$SHARED_UTILS_DIR/README.md\"; then\n      echo \"    \u2705 README has migration guide\"\n    else\n      echo \"    \u26a0\ufe0f  README missing migration guide\"\n    fi\n  fi\n\n  # Check files have type hints\n  for file in logger.py validators.py exceptions.py pagination.py request_id.py; do\n    if [ -f \"$SHARED_UTILS_DIR/$file\" ]; then\n      if grep -q \"def.*-&gt;.*:\\|: .*=\\|^from typing import\" \"$SHARED_UTILS_DIR/$file\"; then\n        echo \"  \u2705 $file has type hints\"\n      else\n        echo \"  \u26a0\ufe0f  $file might be missing type hints\"\n      fi\n    fi\n  done\n\n  # Report summary\n  if [ $missing -gt 0 ]; then\n    echo \"\"\n    echo \"\ud83d\udea8 CRITICAL: $missing shared utility files missing\"\n  fi\nfi\n\n# ========================================\n# PHASE 1 ENHANCEMENT: Enhanced PostgreSQL template validation\n# ========================================\necho \"\"\necho \"=== Enhanced PostgreSQL Template Validation (Phase 1) ===\"\n\nPOSTGRES_TEMPLATE=\"templates/services/template_data_postgres_api\"\n\nif [ -d \"$POSTGRES_TEMPLATE\" ]; then\n  echo \"\u2705 $POSTGRES_TEMPLATE exists\"\n\n  # Check critical Phase 1 deliverable files\n  PHASE1_FILES=(\n    \"Dockerfile\"\n    \"requirements.txt\"\n    \"requirements-dev.txt\"\n    \"pytest.ini\"\n    \"alembic.ini\"\n    \"alembic/env.py\"\n    \"alembic/script.py.mako\"\n    \"src/main.py\"\n    \"src/core/config.py\"\n    \"src/core/database.py\"\n    \"src/models/base.py\"\n    \"src/repositories/base_repository.py\"\n    \"src/schemas/base.py\"\n    \"src/api/v1/health.py\"\n    \"tests/conftest.py\"\n    \"tests/unit/__init__.py\"\n    \"tests/integration/__init__.py\"\n    \"README.md\"\n  )\n\n  postgres_missing=0\n  for file in \"${PHASE1_FILES[@]}\"; do\n    if [ -f \"$POSTGRES_TEMPLATE/$file\" ]; then\n      echo \"  \u2705 $file\"\n    else\n      echo \"  \u274c CRITICAL MISSING: $file\"\n      postgres_missing=$((postgres_missing + 1))\n    fi\n  done\n\n  # Check README documents key features\n  if [ -f \"$POSTGRES_TEMPLATE/README.md\" ]; then\n    echo \"\"\n    echo \"Checking README completeness...\"\n\n    REQUIRED_SECTIONS=(\n      \"Purpose\\|\ud83c\udfaf Purpose\"\n      \"What's Included\\|\ud83d\udce6 What's Included\"\n      \"Quick Start\\|Usage\"\n      \"Alembic\\|migrations\"\n      \"Generic CRUD\\|repository\\|BaseRepository\"\n    )\n\n    for section in \"${REQUIRED_SECTIONS[@]}\"; do\n      if grep -Eqi \"$section\" \"$POSTGRES_TEMPLATE/README.md\"; then\n        section_name=\"${section%%\\\\|*}\"\n        echo \"  \u2705 README section: $section_name\"\n      else\n        echo \"  \u26a0\ufe0f  README missing section: ${section%%\\\\|*}\"\n      fi\n    done\n  fi\n\n  # Check for type safety (mypy compliance)\n  if grep -rq \"from typing import\\|-&gt; .*:\\|: .*=\" \"$POSTGRES_TEMPLATE/src\"/*.py 2&gt;/dev/null; then\n    echo \"  \u2705 Source files have type hints\"\n  else\n    echo \"  \u26a0\ufe0f  Source files might be missing type hints\"\n  fi\n\n  # Check for Alembic setup completeness\n  if [ -f \"$POSTGRES_TEMPLATE/alembic/env.py\" ]; then\n    if grep -q \"async\\|AsyncEngine\" \"$POSTGRES_TEMPLATE/alembic/env.py\"; then\n      echo \"  \u2705 Alembic configured for async SQLAlchemy\"\n    else\n      echo \"  \u26a0\ufe0f  Alembic might not be configured for async\"\n    fi\n  fi\n\n  # Check for BaseRepository implementation\n  if [ -f \"$POSTGRES_TEMPLATE/src/repositories/base_repository.py\" ]; then\n    if grep -q \"Generic\\|TypeVar\\|get_by_id\\|create\\|update\\|delete\" \"$POSTGRES_TEMPLATE/src/repositories/base_repository.py\"; then\n      echo \"  \u2705 BaseRepository has Generic CRUD operations\"\n    else\n      echo \"  \u26a0\ufe0f  BaseRepository might be incomplete\"\n    fi\n  fi\n\n  # Report summary\n  if [ $postgres_missing -gt 0 ]; then\n    echo \"\"\n    echo \"\ud83d\udea8 CRITICAL: $postgres_missing PostgreSQL template files missing\"\n    echo \"   Template claims 27 files but some are missing\"\n  else\n    echo \"\"\n    echo \"\u2705 PostgreSQL template appears complete (18 core files validated)\"\n  fi\nelse\n  echo \"\u274c CRITICAL: $POSTGRES_TEMPLATE missing (Phase 1 deliverable)\"\nfi\n</code></pre> <p>Expected Outcome: Template completeness report with missing templates or documentation, plus Phase 1 additions: - Shared utilities template validation (7 files, type hints, usage examples) - Enhanced PostgreSQL template validation (27 files, Alembic setup, BaseRepository, type safety)</p>"},{"location":"contributing/audit/project/#10-development-workflow-documentation","title":"10. Development Workflow Documentation","text":"<p>Goal: Ensure development commands are clear and complete.</p> <p>Validation Commands:</p> <pre><code># Check development-commands.md\nif [ -f \"docs/guides/development-commands.md\" ]; then\n  echo \"=== Checking Development Commands Documentation ===\"\n\n  COMMAND_CATEGORIES=(\n    \"setup\\|install\\|init\"\n    \"test\\|pytest\"\n    \"lint\\|ruff\\|mypy\"\n    \"format\\|black\\|isort\"\n    \"security\\|bandit\"\n    \"coverage\"\n    \"docker\\|compose\"\n    \"migration\\|alembic\"\n  )\n\n  for category in \"${COMMAND_CATEGORIES[@]}\"; do\n    if grep -Eqi \"$category\" docs/guides/development-commands.md; then\n      echo \"  \u2705 Category documented: $category\"\n    else\n      echo \"  \u26a0\ufe0f  Category missing/unclear: $category\"\n    fi\n  done\n\n  # Check for actual command examples\n  CODE_BLOCK_COUNT=$(grep -c '```' docs/guides/development-commands.md)\n  echo \"  \u2139\ufe0f  Code blocks found: $((CODE_BLOCK_COUNT / 2))\"\n  if [ $CODE_BLOCK_COUNT -lt 20 ]; then\n    echo \"  \u26a0\ufe0f  Few code examples (expected 10+ command blocks)\"\n  fi\nelse\n  echo \"\u274c CRITICAL: docs/guides/development-commands.md missing\"\nfi\n\n# Check agent-toolbox.md (machine-readable commands)\nif [ -f \"docs/reference/agent-toolbox.md\" ]; then\n  echo \"\u2705 Agent toolbox exists (machine-readable commands)\"\nelse\n  echo \"\u26a0\ufe0f  docs/reference/agent-toolbox.md missing\"\nfi\n</code></pre> <p>Expected Outcome: Development workflow documentation completeness report.</p>"},{"location":"contributing/audit/project/#11-14-additional-objectives","title":"11-14. Additional Objectives","text":"<p>(Infrastructure, testing, observability, shared components - follow same pattern as above with validation commands for each)</p>"},{"location":"contributing/audit/project/#quick-audit-5-minutes","title":"QUICK AUDIT (5 Minutes)","text":"<p>For rapid health checks, run only smoke tests + critical validations:</p> <pre><code>#!/bin/bash\n# Quick audit script (5 minutes max)\n\necho \"=== QUICK DOCUMENTATION AUDIT ===\"\necho \"Started: $(date)\"\n\n# 1. Smoke Tests\necho -e \"\\n### SMOKE TESTS ###\"\n\n# Smoke 1: File counts\nMD_COUNT=$(find docs/ -name \"*.md\" 2&gt;/dev/null | wc -l)\necho \"Markdown files: $MD_COUNT\"\n\n# Smoke 2: Link count\nLINK_COUNT=$(grep -roh '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | wc -l)\necho \"Total links: $LINK_COUNT\"\n\n# Smoke 3: Legacy references (CRITICAL)\nLEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" docs/ README.md CLAUDE.md 2&gt;/dev/null | wc -l)\necho \"Legacy references: $LEGACY_COUNT\"\nif [ $LEGACY_COUNT -gt 0 ]; then\n  echo \"  \ud83d\udea8 CRITICAL: Found $LEGACY_COUNT legacy references\"\nfi\n\n# Smoke 4: Broken link sample\necho \"Sample broken links (first 3):\"\ngrep -rho '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u | while read -r ref; do\n  if [ ! -f \"$ref\" ] &amp;&amp; [ ! -f \"docs/$ref\" ]; then\n    echo \"  \u274c $ref\"\n  fi\ndone | head -3\n\n# Smoke 5: Stage 0 files\necho -e \"\\nStage 0 initialization files:\"\nfor doc in \"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\"; do\n  if [ -f \"$doc\" ]; then\n    echo \"  \u2705 $doc\"\n  else\n    echo \"  \u274c $doc (CRITICAL)\"\n  fi\ndone\n\n# 2. Critical Validations Only\necho -e \"\\n### CRITICAL VALIDATIONS ###\"\n\n# Check architecture guide exists\n[ -f \"docs/guides/architecture-guide.md\" ] &amp;&amp; echo \"\u2705 Architecture guide\" || echo \"\u274c Architecture guide (CRITICAL)\"\n\n# Check AI workflow exists\n[ -f \"docs/guides/ai-code-generation-master-workflow.md\" ] &amp;&amp; echo \"\u2705 AI workflow\" || echo \"\u274c AI workflow (CRITICAL)\"\n\n# Check navigation matrix\n[ -f \"docs/reference/ai-navigation-matrix.md\" ] &amp;&amp; echo \"\u2705 Navigation matrix\" || echo \"\u274c Navigation matrix (CRITICAL)\"\n\necho -e \"\\nCompleted: $(date)\"\necho -e \"\\n\ud83d\udca1 Run full audit for detailed analysis: bash scripts/audit_docs.sh --full\"\n</code></pre> <p>Usage: <pre><code>bash scripts/quick_audit.sh\n</code></pre></p>"},{"location":"contributing/audit/project/#focused-audits","title":"FOCUSED AUDITS","text":""},{"location":"contributing/audit/project/#audit-only-links","title":"Audit Only Links","text":"<pre><code># Link-only audit\nbash scripts/audit_docs.sh --links\n</code></pre>"},{"location":"contributing/audit/project/#audit-only-structure","title":"Audit Only Structure","text":"<pre><code># Structure-only audit\nbash scripts/audit_docs.sh --structure\n</code></pre>"},{"location":"contributing/audit/project/#audit-only-ai-navigation","title":"Audit Only AI Navigation","text":"<pre><code># AI navigation audit\nbash scripts/audit_docs.sh --ai-navigation\n</code></pre>"},{"location":"contributing/audit/project/#automation-script-template","title":"AUTOMATION SCRIPT TEMPLATE","text":"<p>Create <code>scripts/audit_docs.sh</code> for reusable auditing:</p> <pre><code>#!/bin/bash\n\n# scripts/audit_docs.sh - Comprehensive documentation audit automation\n# Usage:\n#   ./scripts/audit_docs.sh --full      # Full audit\n#   ./scripts/audit_docs.sh --quick     # 5-minute audit\n#   ./scripts/audit_docs.sh --links     # Link validation only\n#   ./scripts/audit_docs.sh --structure # Structure validation only\n\nset -euo pipefail\n\n# Configuration\nDOCS_DIR=\"docs\"\nOUTPUT_DIR=\"audit_reports\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"$OUTPUT_DIR/audit_${TIMESTAMP}.md\"\n\n# Create output directory\nmkdir -p \"$OUTPUT_DIR\"\n\n# Logging helper\nlog() {\n  echo \"[$(date +%H:%M:%S)] $*\" | tee -a \"$REPORT_FILE\"\n}\n\n# Smoke tests function\nrun_smoke_tests() {\n  log \"=== SMOKE TESTS ===\"\n\n  log \"Smoke 1: File counts\"\n  MD_COUNT=$(find \"$DOCS_DIR\" -name \"*.md\" 2&gt;/dev/null | wc -l)\n  log \"  Markdown files: $MD_COUNT\"\n\n  log \"Smoke 2: Link count\"\n  LINK_COUNT=$(grep -roh '\\[.*\\](.*\\.md' \"$DOCS_DIR\" 2&gt;/dev/null | wc -l)\n  log \"  Total links: $LINK_COUNT\"\n\n  log \"Smoke 3: \ud83d\udea8 Legacy references (CRITICAL)\"\n  LEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | wc -l)\n  log \"  Legacy references: $LEGACY_COUNT\"\n  if [ \"$LEGACY_COUNT\" -gt 0 ]; then\n    log \"  \ud83d\udea8 CRITICAL: Found $LEGACY_COUNT legacy references\"\n    grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | head -10 | tee -a \"$REPORT_FILE\"\n  fi\n\n  log \"Smoke 4: Broken link sample\"\n  BROKEN_SAMPLE=$(grep -rho '\\[.*\\](.*\\.md' \"$DOCS_DIR\" 2&gt;/dev/null | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u | while read -r ref; do\n    if [ ! -f \"$ref\" ] &amp;&amp; [ ! -f \"$DOCS_DIR/$ref\" ]; then\n      echo \"  \u274c $ref\"\n    fi\n  done | head -3)\n  log \"$BROKEN_SAMPLE\"\n\n  log \"Smoke 5: Stage 0 files\"\n  for doc in \"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\"; do\n    if [ -f \"$doc\" ]; then\n      log \"  \u2705 $doc\"\n    else\n      log \"  \u274c $doc (CRITICAL)\"\n    fi\n  done\n}\n\n# Link validation function\nvalidate_links() {\n  log \"=== LINK VALIDATION ===\"\n\n  # Extract all markdown links\n  grep -rn '\\[.*\\](.*\\.md' \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/all_links_$$.txt || true\n  TOTAL_LINKS=$(wc -l &lt; /tmp/all_links_$$.txt)\n  log \"Total links found: $TOTAL_LINKS\"\n\n  # Validate each unique target\n  grep -rho '\\[.*\\](.*\\.md' \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | \\\n    sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u &gt; /tmp/unique_targets_$$.txt || true\n\n  BROKEN=0\n  while read -r target; do\n    if [ ! -f \"$target\" ] &amp;&amp; [ ! -f \"$DOCS_DIR/$target\" ]; then\n      log \"  \u274c Broken: $target\"\n      ((BROKEN++))\n\n      # Show which files reference this broken link\n      grep -l \"$target\" \"$DOCS_DIR\"/**/*.md README.md CLAUDE.md 2&gt;/dev/null | head -3 | while read -r file; do\n        LINE=$(grep -n \"$target\" \"$file\" | head -1 | cut -d: -f1)\n        log \"      Referenced in: $file:$LINE\"\n      done\n    fi\n  done &lt; /tmp/unique_targets_$$.txt\n\n  log \"Broken links: $BROKEN\"\n  rm -f /tmp/all_links_$$.txt /tmp/unique_targets_$$.txt\n}\n\n# Structure validation function\nvalidate_structure() {\n  log \"=== STRUCTURE VALIDATION ===\"\n\n  # Check atomic/* structure\n  EXPECTED_DIRS=(\"architecture\" \"databases\" \"infrastructure\" \"integrations\" \"observability\" \"services\" \"testing\")\n\n  for dir in \"${EXPECTED_DIRS[@]}\"; do\n    if [ -d \"$DOCS_DIR/atomic/$dir\" ]; then\n      README_COUNT=$(find \"$DOCS_DIR/atomic/$dir\" -name \"README.md\" | wc -l)\n      log \"  \u2705 $DOCS_DIR/atomic/$dir (READMEs: $README_COUNT)\"\n    else\n      log \"  \u274c $DOCS_DIR/atomic/$dir missing\"\n    fi\n  done\n}\n\n# AI navigation validation function\nvalidate_ai_navigation() {\n  log \"=== AI NAVIGATION VALIDATION ===\"\n\n  # Verify Stage 0 sequence\n  STAGE0_DOCS=(\"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\")\n\n  for i in \"${!STAGE0_DOCS[@]}\"; do\n    doc=\"${STAGE0_DOCS[$i]}\"\n    if [ -f \"$doc\" ]; then\n      log \"  Step $((i+1)): \u2705 $doc\"\n    else\n      log \"  Step $((i+1)): \u274c CRITICAL - $doc missing\"\n    fi\n  done\n\n  # Check navigation matrix\n  if [ -f \"docs/reference/ai-navigation-matrix.md\" ]; then\n    log \"  \u2705 AI navigation matrix exists\"\n\n    # Check for all 7 stages\n    for stage in {0..6}; do\n      if grep -q \"Stage $stage\" docs/reference/ai-navigation-matrix.md; then\n        log \"    \u2705 Stage $stage documented\"\n      else\n        log \"    \u274c Stage $stage missing\"\n      fi\n    done\n  else\n    log \"  \u274c CRITICAL: AI navigation matrix missing\"\n  fi\n}\n\n# Main execution\nMODE=\"${1:---full}\"\n\ncase \"$MODE\" in\n  --quick)\n    log \"Starting QUICK AUDIT\"\n    run_smoke_tests\n    ;;\n  --links)\n    log \"Starting LINK VALIDATION\"\n    validate_links\n    ;;\n  --structure)\n    log \"Starting STRUCTURE VALIDATION\"\n    validate_structure\n    ;;\n  --ai-navigation)\n    log \"Starting AI NAVIGATION VALIDATION\"\n    validate_ai_navigation\n    ;;\n  --full)\n    log \"Starting FULL AUDIT\"\n    run_smoke_tests\n    validate_links\n    validate_structure\n    validate_ai_navigation\n    log \"=== FULL AUDIT COMPLETE ===\"\n    log \"Report saved to: $REPORT_FILE\"\n    ;;\n  *)\n    echo \"Usage: $0 [--full|--quick|--links|--structure|--ai-navigation]\"\n    exit 1\n    ;;\nesac\n\nlog \"Audit completed at $(date)\"\n</code></pre> <p>Make executable: <pre><code>chmod +x scripts/audit_docs.sh\n</code></pre></p>"},{"location":"contributing/audit/project/#cicd-integration","title":"CI/CD INTEGRATION","text":""},{"location":"contributing/audit/project/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code># .github/workflows/docs-audit.yml\nname: Documentation Audit\n\non:\n  push:\n    paths:\n      - 'docs/**'\n      - '*.md'\n  pull_request:\n    paths:\n      - 'docs/**'\n      - '*.md'\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Quick Audit\n        run: |\n          bash scripts/audit_docs.sh --quick\n\n      - name: Check for Critical Issues\n        run: |\n          # Fail if legacy references found\n          LEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\" docs/ 2&gt;/dev/null | wc -l)\n          if [ $LEGACY_COUNT -gt 0 ]; then\n            echo \"::error::Found $LEGACY_COUNT legacy references\"\n            exit 1\n          fi\n\n      - name: Upload Audit Report\n        uses: actions/upload-artifact@v3\n        with:\n          name: audit-report\n          path: audit_reports/\n</code></pre>"},{"location":"contributing/audit/project/#usage-examples","title":"USAGE EXAMPLES","text":""},{"location":"contributing/audit/project/#example-1-first-time-audit","title":"Example 1: First-Time Audit","text":"<pre><code># Clone repository\ncd /path/to/doc4microservices\n\n# Run full audit\nbash scripts/audit_docs.sh --full\n\n# Review report\ncat audit_reports/audit_*.md | less\n\n# Fix critical issues first\ngrep \"CRITICAL\" audit_reports/audit_*.md\n</code></pre>"},{"location":"contributing/audit/project/#example-2-pre-commit-audit","title":"Example 2: Pre-Commit Audit","text":"<pre><code># Quick check before committing docs\nbash scripts/audit_docs.sh --quick\n\n# If issues found, run focused audit\nbash scripts/audit_docs.sh --links\n</code></pre>"},{"location":"contributing/audit/project/#example-3-cicd-integration","title":"Example 3: CI/CD Integration","text":"<pre><code># In CI pipeline\nbash scripts/audit_docs.sh --quick\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -ne 0 ]; then\n  echo \"Documentation audit failed\"\n  exit 1\nfi\n</code></pre>"},{"location":"contributing/audit/project/#maintenance-schedule","title":"MAINTENANCE SCHEDULE","text":""},{"location":"contributing/audit/project/#daily-automated","title":"Daily (Automated)","text":"<ul> <li>Quick audit (5 min) on every commit touching <code>docs/</code> or <code>*.md</code></li> <li>Check for broken links only</li> </ul>"},{"location":"contributing/audit/project/#weekly-automated","title":"Weekly (Automated)","text":"<ul> <li>Full audit with all 14 objectives</li> <li>Generate trend report (compare with previous week)</li> </ul>"},{"location":"contributing/audit/project/#monthly-manual","title":"Monthly (Manual)","text":"<ul> <li>Review accumulated issues</li> <li>Prioritize fixes</li> <li>Update audit template if needed</li> </ul>"},{"location":"contributing/audit/project/#quarterly-manual","title":"Quarterly (Manual)","text":"<ul> <li>Deep content quality review</li> <li>Update validation commands</li> <li>Review and update this audit template</li> </ul>"},{"location":"contributing/audit/project/#shell-scripting-best-practices","title":"SHELL SCRIPTING BEST PRACTICES","text":"<p>When writing validation scripts:</p> <ol> <li> <p>Use <code>find -print0 | xargs -0</code> for file operations (handles spaces)    <pre><code>find docs/ -name \"*.md\" -print0 | xargs -0 grep -l \"pattern\"\n</code></pre></p> </li> <li> <p>Avoid <code>while read</code> loops when possible (slow for large datasets)    <pre><code># Bad: slow\nls *.md | while read file; do grep pattern \"$file\"; done\n\n# Good: parallel processing\ngrep -r pattern *.md\n</code></pre></p> </li> <li> <p>Use parallel processing for independent checks    <pre><code>find docs/ -name \"*.md\" -print0 | xargs -0 -P 8 -I {} bash -c 'check_file \"$@\"' _ {}\n</code></pre></p> </li> <li> <p>Capture errors properly <pre><code>grep -r pattern docs/ 2&gt;/dev/null || echo \"Pattern not found\"\n</code></pre></p> </li> <li> <p>Use temporary files for complex pipelines    <pre><code>grep -r pattern docs/ &gt; /tmp/results.txt\nprocess_results &lt; /tmp/results.txt\nrm /tmp/results.txt\n</code></pre></p> </li> </ol>"},{"location":"contributing/audit/project/#notes","title":"NOTES","text":""},{"location":"contributing/audit/project/#why-this-template-is-critical","title":"Why This Template is Critical","text":"<p>This audit template prevents systemic documentation failures by:</p> <ol> <li>Forcing direct execution (no delegation to unreliable agents)</li> <li>Requiring exhaustive checking (no sample-based estimation)</li> <li>Providing explicit validation commands (no room for interpretation)</li> <li>Mandating smoke tests (catch critical issues in 30 seconds)</li> <li>Requiring proof of work (show commands used, spot checks performed)</li> </ol>"},{"location":"contributing/audit/project/#lessons-from-previous-failures","title":"Lessons from Previous Failures","text":"<p>Failure Mode 1: Link Validation Bypass (v1.0)</p> <p>The original template allowed an AI agent to miss 64+ critical broken legacy links because: - Delegation was permitted \u2192 Task agent used sample-based checking - No explicit validation commands \u2192 Agent estimated instead of executing - Smoke tests came too late \u2192 Critical issues not caught early - No spot check requirements \u2192 No verification that issues were real - Health score calculation not enforced \u2192 Agent estimated 72/100 (actual: ~0/100)</p> <p>Fix: V2 template added mandatory Bash execution, explicit validation commands, and smoke tests.</p> <p>Failure Mode 2: Config Mismatch Detection Failure (October 2025)</p> <p>An audit using V2 template missed 5 critical config consistency issues affecting 40% of critical files: - Issue: Docker Compose profile <code>monitoring</code> vs documentation <code>observability</code> (2 files) - Issue: Database names <code>myapp_db</code> vs <code>microservices_db</code> (4 files) - Issue: Empty pyproject.toml despite docs requiring <code>uv run ruff/mypy/pytest</code> commands - Issue: CONTRIBUTING.md referenced non-existent <code>validate_docs.sh</code> (19 occurrences) - Issue: Weak credentials <code>admin123</code> vs secure defaults <code>admin</code> (3 files)</p> <p>Root cause: - Template focused on docs/ directory only \u2192 Missed root-level config files - No cross-validation between config files and documentation - Assumed configs were correct if they existed - No validation that documented commands actually work</p> <p>Impact: Users following documentation would encounter immediate failures: - <code>docker-compose up --profile monitoring</code> fails (profile doesn't exist) - Database connection examples fail (wrong DB names) - Quality commands fail (<code>uv run ruff</code> \u2192 pyproject.toml not configured) - Contributors run wrong scripts (validate_docs.sh doesn't exist)</p> <p>Fix: Added Objective 16 (Config Consistency Validation), Smoke Test 6 (pyproject.toml check), and anti-patterns for config cross-validation.</p> <p>Failure Mode 3: Command Path Validation Failure - Silent Failures (October 2025)</p> <p>Critical issue discovered post-v2.1 where documented commands executed successfully but returned wrong results: - Issue: Coverage commands used <code>--cov=app</code> but all 5 templates use <code>src/</code> directory - Impact: Commands returned coverage=0% (false negative) despite actual code existing - Affected files: 6 occurrences across 3 critical documentation files:   - docs/quality/agent-verification-checklist.md (Stage 5 quality gates)   - docs/guides/development-commands.md (canonical command reference)   - docs/reference/agent-toolbox.md (machine-readable commands)</p> <p>Silent Failure Pattern (most dangerous type): - \u2705 Command executes successfully (exit code 0) - \u2705 No error message displayed - \u274c Returns wrong result (coverage=0% when should be 70-85%) - \u274c Appears to work but gives false negatives - \u274c Blocks AI agent Stage 5 (Quality Verification) with cryptic \"coverage below threshold\" errors - \u274c Wastes hours of debugging time (developers think code has no tests, not that command is wrong)</p> <p>Root cause: - Commands documented without validating against actual project structure - No smoke test for path validation - Template structure (src/ vs app/) not cross-checked with commands - Trusted that \"command executes\" means \"command works correctly\"</p> <p>Real-world impact timeline: - Day 1: Developer copies <code>pytest --cov=app</code> from docs - Day 1: Runs command \u2192 sees \"coverage=0%\" \u2192 confused (code clearly exists) - Day 1-3: Debugs pytest config, test discovery, assumes bug in coverage tool - Day 3: AI agent hits same issue in Stage 5 \u2192 reports \"Cannot meet 80% threshold\" (has 0%) - Day 4: Manual review discovers path mismatch (should be <code>--cov=src</code>) - Total time wasted: 4 developer-days debugging a 1-character documentation error</p> <p>Prevention required: 1. Objective 17: Command Path Validation (cross-check commands against actual structure) 2. Smoke Test 7: Quick path mismatch detection (10 seconds vs 4 days debugging) 3. CI Workflow: <code>.github/workflows/docs-command-validation.yml</code> blocks PRs with wrong paths 4. Anti-pattern: Don't trust \"command succeeds\" \u2192 verify results match expectations</p> <p>Fix: Added Objective 17 (Command Path Validation), Smoke Test 7 (path mismatch detection), CI workflow for automated prevention, and anti-pattern for trusting successful execution.</p> <p>This V2.2 template fixes ALL known failure modes.</p>"},{"location":"contributing/audit/project/#when-to-update-this-template","title":"When to Update This Template","text":"<p>Update this template when: - New documentation categories added (e.g., \"deployment-guides/\") - New quality criteria introduced (e.g., \"check for AI-readability\") - New tools adopted (e.g., \"vale\" for prose linting) - Audit failure modes discovered (add to CONSTRAINTS) - Framework structure changes (update expected directories)</p>"},{"location":"contributing/audit/project/#recovery-from-audit-failures","title":"Recovery from Audit Failures","text":"<p>If an audit using this template still misses critical issues:</p> <ol> <li>Root cause analysis (ultrathink):</li> <li>Which objective failed?</li> <li>Was validation command inadequate?</li> <li> <p>Was constraint unclear?</p> </li> <li> <p>Template fix:</p> </li> <li>Update validation commands</li> <li>Add explicit constraint</li> <li> <p>Add to anti-patterns section</p> </li> <li> <p>Verify fix:</p> </li> <li>Re-run audit with updated template</li> <li> <p>Confirm issue now caught</p> </li> <li> <p>Document lesson:</p> </li> <li>Add to \"Lessons from Previous Failures\" section</li> <li>Update CI/CD checks</li> </ol>"},{"location":"contributing/audit/project/#end-of-template","title":"END OF TEMPLATE","text":"<p>Version: 2.2 Last Updated: 2025-10-13 Changelog: - v2.2 (2025-10-13): Added Objective 17 (Command Path Validation - silent failure prevention), Smoke Test 7 (command path mismatch detection), anti-pattern for trusting successful command execution, Failure Mode 3 case study (--cov=app\u2192src issue) - v2.1 (2025-10-11): Added Objective 16 (Config Consistency Validation), Smoke Test 6 (pyproject.toml), anti-patterns for config validation, Failure Mode 2 case study - v2.0 (2025-10-11): Complete rewrite with mandatory execution protocol, explicit validation commands, smoke tests, verification protocol - v1.0 (2025-10-10): Original template (proved insufficient - missed 64+ critical issues)</p>"},{"location":"contributing/audit/project/#11-infrastructure-integration-documentation","title":"11. Infrastructure Integration Documentation","text":"<p>Goal: Verify all infrastructure components are documented with examples.</p> <p>Validation Commands:</p> <pre><code># Check infrastructure documentation\necho \"=== Checking Infrastructure Documentation ===\"\n\nINFRA_COMPONENTS=(\n  \"postgres\"\n  \"redis\"\n  \"rabbitmq\"\n  \"nginx\"\n  \"docker\"\n)\n\nfor component in \"${INFRA_COMPONENTS[@]}\"; do\n  echo \"Checking: $component\"\n\n  # Check docs/atomic/integrations/ or docs/atomic/infrastructure/\n  if [ -d \"docs/atomic/integrations/$component\" ] || [ -d \"docs/atomic/infrastructure/$component\" ]; then\n    echo \"  \u2705 Documentation directory exists\"\n\n    # Check for README\n    README_PATH=$(find docs/atomic/integrations/$component docs/atomic/infrastructure/$component -name \"README.md\" 2&gt;/dev/null | head -1)\n    if [ -n \"$README_PATH\" ]; then\n      echo \"  \u2705 README.md present: $README_PATH\"\n\n      # Check for code examples\n      if grep -q '```' \"$README_PATH\"; then\n        echo \"    \u2705 Contains code examples\"\n      else\n        echo \"    \u26a0\ufe0f  No code examples\"\n      fi\n    else\n      echo \"  \u26a0\ufe0f  README.md missing\"\n    fi\n  else\n    echo \"  \u26a0\ufe0f  No documentation directory for $component\"\n  fi\ndone\n</code></pre> <p>Expected Outcome: Infrastructure documentation completeness report.</p>"},{"location":"contributing/audit/project/#12-testing-documentation","title":"12. Testing Documentation","text":"<p>Goal: Verify testing patterns, examples, and coverage requirements are documented.</p> <p>Validation Commands:</p> <pre><code># Check testing documentation\necho \"=== Checking Testing Documentation ===\"\n\nif [ -d \"docs/atomic/testing\" ]; then\n  echo \"\u2705 Testing documentation directory exists\"\n\n  # Check for key testing topics\n  TESTING_TOPICS=(\n    \"unit.*test\\|test.*unit\"\n    \"integration.*test\\|test.*integration\"\n    \"pytest\"\n    \"coverage\"\n    \"mock\\|fixture\"\n  )\n\n  for topic in \"${TESTING_TOPICS[@]}\"; do\n    if grep -rqi \"$topic\" docs/atomic/testing/; then\n      echo \"  \u2705 Topic documented: $topic\"\n    else\n      echo \"  \u26a0\ufe0f  Topic missing/unclear: $topic\"\n    fi\n  done\n\n  # Check for coverage thresholds\n  if grep -rE \"coverage.*[0-9]+%|[0-9]+%.*coverage\" docs/atomic/testing/ docs/guides/development-commands.md 2&gt;/dev/null | grep -q .; then\n    echo \"  \u2705 Coverage thresholds documented\"\n  else\n    echo \"  \u26a0\ufe0f  Coverage thresholds not clearly documented\"\n  fi\nelse\n  echo \"\u26a0\ufe0f  docs/atomic/testing/ directory missing\"\nfi\n</code></pre> <p>Expected Outcome: Testing documentation completeness report.</p>"},{"location":"contributing/audit/project/#13-observability-documentation","title":"13. Observability Documentation","text":"<p>Goal: Verify logging, metrics, tracing, and error tracking are documented.</p> <p>Validation Commands:</p> <pre><code># Check observability documentation\necho \"=== Checking Observability Documentation ===\"\n\nif [ -d \"docs/atomic/observability\" ]; then\n  echo \"\u2705 Observability documentation directory exists\"\n\n  # Check for pillars of observability\n  OBSERVABILITY_PILLARS=(\n    \"logging\\|logs\"\n    \"metrics\\|prometheus\"\n    \"tracing\\|jaeger\\|opentelemetry\"\n    \"error.*tracking\\|sentry\"\n    \"elk\\|elasticsearch\"\n  )\n\n  for pillar in \"${OBSERVABILITY_PILLARS[@]}\"; do\n    if grep -rqi \"$pillar\" docs/atomic/observability/; then\n      echo \"  \u2705 Pillar documented: $pillar\"\n    else\n      echo \"  \u26a0\ufe0f  Pillar missing/unclear: $pillar\"\n    fi\n  done\n\n  # Check for structured logging examples\n  if grep -rq \"structlog\\|json.*log\\|structured.*log\" docs/atomic/observability/; then\n    echo \"  \u2705 Structured logging documented\"\n  else\n    echo \"  \u26a0\ufe0f  Structured logging not documented\"\n  fi\nelse\n  echo \"\u26a0\ufe0f  docs/atomic/observability/ directory missing\"\nfi\n</code></pre> <p>Expected Outcome: Observability documentation completeness report.</p>"},{"location":"contributing/audit/project/#14-shared-components-documentation","title":"14. Shared Components Documentation","text":"<p>Goal: Verify shared configuration, utilities, and DI patterns are documented.</p> <p>Validation Commands:</p> <pre><code># Check shared components documentation\necho \"=== Checking Shared Components Documentation ===\"\n\nif [ -f \"docs/guides/shared-components.md\" ]; then\n  echo \"\u2705 Shared components guide exists\"\n\n  # Check for key shared component topics\n  SHARED_TOPICS=(\n    \"config\\|configuration\\|settings\"\n    \"dependency.*injection\\|DI\"\n    \"logging.*setup\"\n    \"database.*pool\\|connection.*pool\"\n    \"middleware\"\n  )\n\n  for topic in \"${SHARED_TOPICS[@]}\"; do\n    if grep -Eqi \"$topic\" docs/guides/shared-components.md; then\n      echo \"  \u2705 Topic documented: $topic\"\n    else\n      echo \"  \u26a0\ufe0f  Topic missing: $topic\"\n    fi\n  done\nelse\n  echo \"\u26a0\ufe0f  docs/guides/shared-components.md missing\"\nfi\n\n# Check for src/core/ documentation\nif grep -rq \"src/core\\|core/config.py\\|core/logging.py\" docs/; then\n  echo \"  \u2705 src/core/ patterns documented\"\nelse\n  echo \"  \u26a0\ufe0f  src/core/ patterns not documented\"\nfi\n</code></pre> <p>Expected Outcome: Shared components documentation report.</p>"},{"location":"contributing/audit/project/#15-obsolete-files-cleanup","title":"15. Obsolete Files &amp; Cleanup","text":"<p>Goal: Identify backup files, old versions, temp files, and duplicate scripts that should be removed.</p> <p>Validation Commands:</p> <pre><code># Check for obsolete files\necho \"=== Checking for Obsolete Files ===\"\n\n# 1. Backup files\necho \"Step 1: Checking backup files...\"\nfind . -type f \\( -name \"*.bak\" -o -name \"*.backup\" -o -name \"*_backup.*\" -o -name \"*~\" \\) \\\n  ! -path \"./.git/*\" ! -path \"./node_modules/*\" 2&gt;/dev/null &gt; /tmp/backups.txt\n\nBACKUP_COUNT=$(wc -l &lt; /tmp/backups.txt)\nif [ $BACKUP_COUNT -gt 0 ]; then\n  echo \"  \u26a0\ufe0f  Found $BACKUP_COUNT backup files:\"\n  cat /tmp/backups.txt | head -10\n  if [ $BACKUP_COUNT -gt 10 ]; then\n    echo \"  ... and $((BACKUP_COUNT - 10)) more\"\n  fi\nelse\n  echo \"  \u2705 No backup files found\"\nfi\n\n# 2. Old version files\necho \"Step 2: Checking old version files...\"\nfind . -type f \\( -name \"*.old\" -o -name \"*_old.*\" -o -name \"*_v[0-9].*\" -o -name \"*.deprecated\" \\) \\\n  ! -path \"./.git/*\" ! -path \"./node_modules/*\" 2&gt;/dev/null &gt; /tmp/old_versions.txt\n\nOLD_COUNT=$(wc -l &lt; /tmp/old_versions.txt)\nif [ $OLD_COUNT -gt 0 ]; then\n  echo \"  \u26a0\ufe0f  Found $OLD_COUNT old version files:\"\n  cat /tmp/old_versions.txt | head -10\n  if [ $OLD_COUNT -gt 10 ]; then\n    echo \"  ... and $((OLD_COUNT - 10)) more\"\n  fi\nelse\n  echo \"  \u2705 No old version files found\"\nfi\n\n# 3. Temporary files\necho \"Step 3: Checking temporary files...\"\nfind . -type f \\( -name \"*.tmp\" -o -name \"*.swp\" -o -name \".DS_Store\" -o -name \"Thumbs.db\" \\) \\\n  ! -path \"./.git/*\" ! -path \"./node_modules/*\" 2&gt;/dev/null &gt; /tmp/temp_files.txt\n\nTEMP_COUNT=$(wc -l &lt; /tmp/temp_files.txt)\nif [ $TEMP_COUNT -gt 0 ]; then\n  echo \"  \u26a0\ufe0f  Found $TEMP_COUNT temporary files:\"\n  cat /tmp/temp_files.txt | head -10\n  if [ $TEMP_COUNT -gt 10 ]; then\n    echo \"  ... and $((TEMP_COUNT - 10)) more\"\n  fi\nelse\n  echo \"  \u2705 No temporary files found\"\nfi\n\n# 4. Duplicate scripts (same functionality)\necho \"Step 4: Checking for duplicate scripts...\"\nif [ -d \"scripts/\" ]; then\n  # Look for scripts with similar names/purposes\n  SCRIPTS=$(find scripts/ -type f \\( -name \"*.sh\" -o -name \"*.py\" \\) 2&gt;/dev/null)\n\n  # Check for audit/validate/check duplicates\n  AUDIT_COUNT=$(echo \"$SCRIPTS\" | grep -iE \"audit|validate|check\" | wc -l)\n  if [ $AUDIT_COUNT -gt 1 ]; then\n    echo \"  \u26a0\ufe0f  Found $AUDIT_COUNT scripts with audit/validate/check functionality:\"\n    echo \"$SCRIPTS\" | grep -iE \"audit|validate|check\"\n    echo \"  \u2139\ufe0f  Manual review recommended to identify duplicates\"\n  else\n    echo \"  \u2705 No obvious duplicate scripts found\"\n  fi\nelse\n  echo \"  \u2139\ufe0f  No scripts/ directory found\"\nfi\n\n# 5. Summary\necho \"\"\necho \"=== OBSOLETE FILES SUMMARY ===\"\necho \"Backup files: $BACKUP_COUNT\"\necho \"Old versions: $OLD_COUNT\"\necho \"Temp files: $TEMP_COUNT\"\necho \"Scripts to review: $AUDIT_COUNT\"\necho \"\"\n\nTOTAL_OBSOLETE=$((BACKUP_COUNT + OLD_COUNT + TEMP_COUNT))\nif [ $TOTAL_OBSOLETE -gt 0 ]; then\n  echo \"\u26a0\ufe0f  Total obsolete files: $TOTAL_OBSOLETE (recommend cleanup)\"\nelse\n  echo \"\u2705 No obsolete files found - project is clean!\"\nfi\n</code></pre> <p>Expected Outcome: Obsolete files report with recommendations for cleanup.</p> <p>Priority Assignment: - Backup files: MEDIUM (clutter, confusion about which is current) - Old versions: MEDIUM (git already keeps history) - Temp files: LOW (usually ignored, but bloat repo size) - Duplicate scripts: MEDIUM (maintenance overhead)</p> <p>Impact: - Backup files confuse contributors (\"which file is current?\") - Old versions are redundant (git history keeps all versions) - Temp files increase repository size unnecessarily - Duplicate scripts create maintenance burden</p> <p>Fix Commands:</p> <pre><code># IMPORTANT: Review files before deletion!\n# List files first:\ncat /tmp/backups.txt\ncat /tmp/old_versions.txt\ncat /tmp/temp_files.txt\n\n# If safe to delete:\n\n# Remove backup files\nwhile read -r file; do\n  echo \"Removing backup: $file\"\n  rm \"$file\"\ndone &lt; /tmp/backups.txt\n\n# Remove old versions\nwhile read -r file; do\n  echo \"Removing old version: $file\"\n  rm \"$file\"\ndone &lt; /tmp/old_versions.txt\n\n# Remove temporary files\nwhile read -r file; do\n  echo \"Removing temp file: $file\"\n  rm \"$file\"\ndone &lt; /tmp/temp_files.txt\n\n# For duplicate scripts: rename old one\n# Example:\nmv scripts/old_audit.sh scripts/old_audit.sh.deprecated\n</code></pre> <p>Verification:</p> <pre><code># Re-run checks - should show 0 files\nfind . -name \"*.bak\" ! -path \"./.git/*\" | wc -l  # Expected: 0\nfind . -name \"*.old\" ! -path \"./.git/*\" | wc -l  # Expected: 0\nfind . -name \"*.tmp\" ! -path \"./.git/*\" | wc -l  # Expected: 0\n</code></pre>"},{"location":"contributing/audit/project/#18-quality-gates-functional-testing-new-phase-1-enforcement-validation","title":"18. Quality Gates Functional Testing (NEW - Phase 1 Enforcement Validation)","text":"<p>Goal: Test that CI quality gates actually work and enforce DRY/KISS/YAGNI principles correctly.</p> <p>PROBLEM PATTERN (False Positive): - Quality gate job exists in CI workflow - Tools aren't installed or configured correctly - Quality checks pass when they should fail (or vice versa) - Provides false sense of quality assurance</p> <p>ROOT CAUSE: Presence of CI job doesn't guarantee it works correctly.</p> <p>Validation Commands:</p> <pre><code># ========================================\n# STEP 1: Test jscpd (duplication detection) works\n# ========================================\necho \"Step 1: Testing jscpd duplication detection...\"\n\n# Check if jscpd is available\nif command -v jscpd &amp;&gt; /dev/null; then\n  echo \"\u2705 jscpd is installed\"\n\n  # Test on framework code\n  echo \"Testing on services/ and shared/ directories...\"\n  jscpd services/ shared/ templates/ --threshold 100 --format \"python\" --reporters \"console\" 2&gt;&amp;1 | tee /tmp/jscpd_test.txt\n\n  # Check output is parseable\n  if grep -q \"duplicated lines\\|duplication\\|Files analyzed\" /tmp/jscpd_test.txt; then\n    echo \"\u2705 jscpd produces parseable output\"\n  else\n    echo \"\u274c jscpd output unclear or error occurred\"\n  fi\nelse\n  echo \"\u26a0\ufe0f  jscpd not installed - cannot test DRY enforcement\"\n  echo \"   Install with: npm install -g jscpd\"\nfi\n\n# ========================================\n# STEP 2: Test radon (complexity analysis) works\n# ========================================\necho \"\"\necho \"Step 2: Testing radon complexity analysis...\"\n\n# Check if radon is available\nif command -v radon &amp;&gt; /dev/null; then\n  echo \"\u2705 radon is installed\"\n\n  # Test cyclomatic complexity\n  echo \"Testing cyclomatic complexity on services/...\"\n  radon cc services/ templates/ --min A --total-average 2&gt;&amp;1 | tee /tmp/radon_cc_test.txt\n\n  if grep -q \"Average complexity\\|blocks analyzed\" /tmp/radon_cc_test.txt; then\n    echo \"\u2705 radon cc produces parseable output\"\n  else\n    echo \"\u274c radon cc output unclear or error occurred\"\n  fi\n\n  # Test maintainability index\n  echo \"Testing maintainability index on services/...\"\n  radon mi services/ templates/ --show 2&gt;&amp;1 | tee /tmp/radon_mi_test.txt\n\n  if grep -q \"Maintainability Index\\|\\.py -\" /tmp/radon_mi_test.txt; then\n    echo \"\u2705 radon mi produces parseable output\"\n  else\n    echo \"\u274c radon mi output unclear or error occurred\"\n  fi\nelse\n  echo \"\u26a0\ufe0f  radon not installed - cannot test KISS enforcement\"\n  echo \"   Install with: pip install radon\"\nfi\n\n# ========================================\n# STEP 3: Test quality gate thresholds are appropriate\n# ========================================\necho \"\"\necho \"Step 3: Testing quality gate thresholds...\"\n\nCI_FILE=\"templates/ci-cd/.github/workflows/ci.yml\"\n\nif [ ! -f \"$CI_FILE\" ]; then\n  echo \"\u274c CI workflow file missing - cannot validate thresholds\"\nelse\n  # Extract actual thresholds from CI workflow\n  echo \"Extracting thresholds from CI workflow...\"\n\n  # DRY threshold\n  dry_threshold=$(grep -A10 \"check-duplication\" \"$CI_FILE\" | grep -oP \"threshold\\s+\\K[0-9]+\" | head -1)\n  if [ -n \"$dry_threshold\" ]; then\n    echo \"\u2705 DRY threshold: $dry_threshold% duplication\"\n\n    if [ $dry_threshold -eq 10 ]; then\n      echo \"  \u2705 Threshold matches Phase 1 requirement (10%)\"\n    else\n      echo \"  \u26a0\ufe0f  Threshold is $dry_threshold% (Phase 1 specifies 10%)\"\n    fi\n  else\n    echo \"\u274c DRY threshold not found in CI workflow\"\n  fi\n\n  # KISS threshold (McCabe complexity)\n  if grep -q \"min.*B\\|--min B\" \"$CI_FILE\" &amp;&amp; grep -B5 -A5 \"min.*B\\|--min B\" \"$CI_FILE\" | grep -q \"radon cc\"; then\n    echo \"\u2705 KISS threshold: Grade B (McCabe &lt; 10)\"\n    echo \"  \u2705 Threshold matches Phase 1 requirement\"\n  else\n    echo \"\u274c KISS complexity threshold unclear in CI workflow\"\n  fi\n\n  # YAGNI thresholds (dependency counts)\n  yagni_thresholds=$(grep -oP \"threshold=\\K[0-9]+\" \"$CI_FILE\" | sort -u | tr '\\n' ', ')\n  if [ -n \"$yagni_thresholds\" ]; then\n    echo \"\u2705 YAGNI thresholds: $yagni_thresholds\"\n\n    if echo \"$yagni_thresholds\" | grep -q \"30\" &amp;&amp; echo \"$yagni_thresholds\" | grep -q \"50\"; then\n      echo \"  \u2705 Thresholds match Phase 1 requirements (30 for data services, 50 for business)\"\n    else\n      echo \"  \u26a0\ufe0f  Thresholds don't match Phase 1 specification\"\n    fi\n  else\n    echo \"\u274c YAGNI thresholds not found in CI workflow\"\n  fi\nfi\n\n# ========================================\n# STEP 4: Verify quality gates produce actionable feedback\n# ========================================\necho \"\"\necho \"Step 4: Checking quality gates provide actionable feedback...\"\n\nif [ -f \"$CI_FILE\" ]; then\n  # Check if quality gates reference documentation\n  if grep -q \"docs/guides/dry-kiss-yagni-principles.md\\|dry-kiss-yagni-principles\" \"$CI_FILE\"; then\n    echo \"\u2705 Quality gates reference DRY/KISS/YAGNI principles guide\"\n\n    # Count \"Learn more:\" references\n    learn_more_count=$(grep -c \"Learn more\\|docs/guides/dry-kiss-yagni-principles\\|docs/quality/automated-quality-gates\" \"$CI_FILE\")\n    if [ $learn_more_count -ge 3 ]; then\n      echo \"  \u2705 Multiple documentation references ($learn_more_count) - helps developers fix issues\"\n    else\n      echo \"  \u26a0\ufe0f  Only $learn_more_count documentation reference(s) - consider adding more\"\n    fi\n  else\n    echo \"\u274c Quality gates don't reference principles documentation\"\n    echo \"   Developers won't know how to fix violations\"\n  fi\n\n  # Check if quality gates provide fix suggestions\n  if grep -q \"Consider.*:\\|\ud83d\udca1\\|Improve by:\\|Fix:\" \"$CI_FILE\"; then\n    suggestion_count=$(grep -c \"Consider.*:\\|\ud83d\udca1\\|Improve by:\\|Fix:\" \"$CI_FILE\")\n    echo \"\u2705 Quality gates provide $suggestion_count fix suggestions\"\n  else\n    echo \"\u26a0\ufe0f  Quality gates might not provide actionable fix suggestions\"\n  fi\nfi\n\n# ========================================\n# SUMMARY\n# ========================================\necho \"\"\necho \"=== Quality Gates Functional Testing Summary ===\"\necho \"jscpd available: $(command -v jscpd &amp;&gt; /dev/null &amp;&amp; echo 'YES' || echo 'NO')\"\necho \"radon available: $(command -v radon &amp;&gt; /dev/null &amp;&amp; echo 'YES' || echo 'NO')\"\necho \"DRY threshold: ${dry_threshold:-UNKNOWN}%\"\necho \"KISS threshold: Grade B (McCabe &lt; 10)\"\necho \"YAGNI thresholds: ${yagni_thresholds:-UNKNOWN}\"\necho \"\"\n\n# VALIDATION: Quality gates are functional if:\n# 1. Tools are available (jscpd, radon)\n# 2. Thresholds match Phase 1 specification\n# 3. Gates reference documentation\n# 4. Gates provide actionable feedback\n</code></pre> <p>Expected Outcome: Functional testing report showing: - Tool Availability: Which quality tools are installed and working (jscpd, radon) - Threshold Validation: Confirm thresholds match Phase 1 specification (10%, Grade B, 30/50) - Output Quality: Verify tools produce parseable, actionable output - Documentation Links: Confirm quality gates reference principles guide - Fix Suggestions: Verify gates provide actionable guidance on violations</p> <p>Priority Assignment: - Tools not available: HIGH (quality gates can't run) - Wrong thresholds: MEDIUM (gates work but enforce wrong standards) - No documentation links: HIGH (developers can't learn how to fix) - No fix suggestions: MEDIUM (gates identify issues but don't help fix)</p> <p>WHY THIS IS CRITICAL: - Ensures quality gates actually enforce standards (not just cosmetic) - Validates thresholds are appropriate for framework maturity - Confirms developers get actionable feedback on how to fix violations - Prevents false sense of quality assurance from non-functional gates</p>"},{"location":"contributing/audit/project/#deliverables","title":"DELIVERABLES","text":""},{"location":"contributing/audit/project/#1-executive-summary-mandatory-format-show-your-work_1","title":"1. Executive Summary (MANDATORY FORMAT - SHOW YOUR WORK)","text":""},{"location":"contributing/audit/project/#health-score-calculation-must-show-calculation_1","title":"Health Score Calculation (MUST SHOW CALCULATION)","text":"<p>Formula: <pre><code>Health Score = 100 - (CRITICAL_count \u00d7 3) - (HIGH_count \u00d7 1.5) - (MEDIUM_count \u00d7 0.5) - (LOW_count \u00d7 0.1)\n</code></pre></p> <p>Calculation (SHOW THIS IN YOUR REPORT): <pre><code>Base:                    100 points\nCRITICAL issues (64):    64 \u00d7 3  = -192 points\nHIGH issues (10):        10 \u00d7 1.5 = -15 points\nMEDIUM issues (5):       5 \u00d7 0.5 = -2.5 points\nLOW issues (3):          3 \u00d7 0.1 = -0.3 points\nFINAL HEALTH SCORE:      max(0, 100 - 209.8) = 0/100\n</code></pre></p>"},{"location":"contributing/audit/project/#validation-commands-used-proof-of-work-mandatory_1","title":"Validation Commands Used (PROOF OF WORK - MANDATORY)","text":"<p>Must list ALL commands executed:</p> <pre><code># Example (replace with actual commands you ran):\ngrep -rn \"docs/legacy\" docs/ README.md CLAUDE.md 2&gt;/dev/null | wc -l\nfind docs/ -name \"*.md\" -print0 | xargs -0 grep -l \"pattern\"\nfor doc in \"${STAGE0_DOCS[@]}\"; do [ -f \"$doc\" ] &amp;&amp; echo \"\u2705\" || echo \"\u274c\"; done\n</code></pre> <p>Spot checks performed (MANDATORY - verify 3+ random issues):</p> <p>Pick 3+ random issues from your findings and verify them manually:</p> <pre><code>#### Spot Check 1: Verify docs/atomic/architecture/data-access-architecture.md:66\n\n**Command Run**:\n```bash\nsed -n '66p' docs/atomic/architecture/data-access-architecture.md\n</code></pre> <p>Output: <pre><code>- Legacy reference: `docs/legacy/architecture/data-access-rules.md`\n</code></pre></p> <p>Verified: \u2705 Issue is real - line 66 contains broken legacy reference Fix Tested: \u2705 sed replacement command works correctly <pre><code>#### Issue Summary Table\n\n| Severity | Count | Weight | Score Impact |\n|----------|-------|--------|--------------|\n| CRITICAL | 64    | 3.0    | -192         |\n| HIGH     | 10    | 1.5    | -15          |\n| MEDIUM   | 5     | 0.5    | -2.5         |\n| LOW      | 3     | 0.1    | -0.3         |\n| **Total**| **82**| -      | **-209.8**   |\n\n**Health Score**: 0/100 (Critical - immediate action required)\n\n#### Top 5 Critical Issues\n\n1. **64 Broken Legacy References** - blocks users/AI agents from finding current docs\n2. **Missing Stage 0 Document** - AI initialization fails\n3. **Broken AI Navigation Matrix** - Stage 2-4 links point to non-existent files\n4. **Missing Service Templates** - 4 out of 5 promised templates don't exist\n5. **Architecture Constraints Unclear** - HTTP-only data access not emphasized\n\n---\n\n### 2. Detailed Findings by Objective\n\nFor each objective (1-14), provide:\n\n#### Objective N: [Objective Name]\n\n**Status**: \u2705 Passed / \u26a0\ufe0f  Issues Found / \u274c Critical Issues\n\n**Issues Found**: [count]\n\n**Detailed Issues**:\n\n##### Issue N.1: [Issue Title]\n\n**File**: `/path/to/file.md:123`\n**Priority**: CRITICAL | HIGH | MEDIUM | LOW\n**Category**: Link Validation | Structure | Content Quality | etc.\n\n**Problem Description**:\nClear explanation of what's wrong and why it matters.\n\n**Impact**:\nWho is affected (users, AI agents, developers) and how.\n\n**How Found**:\n```bash\ngrep -rn \"pattern\" docs/file.md\n</code></pre></p> <p>Fix Command: <pre><code>sed -i 's/old/new/g' docs/file.md\n# OR\nmv docs/old.md docs/new.md &amp;&amp; find docs/ -name \"*.md\" -exec sed -i 's|old.md|new.md|g' {} \\;\n</code></pre></p> <p>Verification: <pre><code>grep -n \"old\" docs/file.md  # Expected: no output\n# OR\ntest -f docs/new.md &amp;&amp; echo \"\u2705 File exists\" || echo \"\u274c Still missing\"\n</code></pre></p> <p>Related Issues: [Link to related issues if applicable]</p>"},{"location":"contributing/audit/project/#3-actionable-recommendations","title":"3. Actionable Recommendations","text":""},{"location":"contributing/audit/project/#immediate-actions-within-24-hours","title":"Immediate Actions (Within 24 Hours)","text":"<ol> <li>Fix all CRITICAL issues (64 broken legacy links, missing Stage 0 docs)</li> <li>Priority: P0</li> <li>Estimated effort: 2-3 hours</li> <li> <p>Blocking: Yes (AI agents cannot navigate documentation)</p> </li> <li> <p>Update AI Navigation Matrix</p> </li> <li>Priority: P0</li> <li>Estimated effort: 1 hour</li> <li>Blocking: Yes (Stage 1-6 broken)</li> </ol>"},{"location":"contributing/audit/project/#short-term-actions-within-1-week","title":"Short-Term Actions (Within 1 Week)","text":"<ol> <li>Add missing service templates</li> <li>Priority: P1</li> <li>Estimated effort: 4-6 hours</li> <li> <p>Blocking: Partially (80% of service types cannot be generated)</p> </li> <li> <p>Fix HIGH priority issues</p> </li> <li>Priority: P1</li> <li>Estimated effort: 3-4 hours</li> </ol>"},{"location":"contributing/audit/project/#long-term-actions-within-1-month","title":"Long-Term Actions (Within 1 Month)","text":"<ol> <li>Address MEDIUM and LOW issues</li> <li>Priority: P2</li> <li> <p>Estimated effort: 5-8 hours</p> </li> <li> <p>Implement automated audit in CI/CD</p> </li> <li>Priority: P2</li> <li>Estimated effort: 2-3 hours</li> </ol>"},{"location":"contributing/audit/project/#4-automation-recommendations","title":"4. Automation Recommendations","text":""},{"location":"contributing/audit/project/#create-audit-script","title":"Create Audit Script","text":"<pre><code># Save as scripts/audit_docs.sh\n# (Use AUTOMATION SCRIPT TEMPLATE section below)\n</code></pre>"},{"location":"contributing/audit/project/#add-to-cicd","title":"Add to CI/CD","text":"<pre><code># .github/workflows/docs-audit.yml\n# (Use CI/CD INTEGRATION section below)\n</code></pre>"},{"location":"contributing/audit/project/#schedule-regular-audits","title":"Schedule Regular Audits","text":"<ul> <li>Daily: Quick audit (5 min) on documentation changes</li> <li>Weekly: Full audit (15 min) with trend analysis</li> <li>Monthly: Manual review of accumulated issues</li> </ul>"},{"location":"contributing/audit/project/#5-trend-analysis-optional-for-regular-audits","title":"5. Trend Analysis (Optional - For Regular Audits)","text":"<p>Compare current audit with previous audits:</p> Metric Previous Current Change Total Issues 95 82 -13 \u2705 CRITICAL Issues 70 64 -6 \u2705 HIGH Issues 12 10 -2 \u2705 Health Score 0/100 0/100 0 Documentation Files 187 203 +16 Total Links 1,245 1,389 +144 Broken Link Rate 5.1% 4.6% -0.5% \u2705 <p>Analysis: Overall trend is positive - 13 fewer issues despite 16 new documentation files. However, CRITICAL issue count is still too high (target: 0).</p>"},{"location":"contributing/audit/project/#output-format_1","title":"OUTPUT FORMAT","text":""},{"location":"contributing/audit/project/#structure-requirements_1","title":"Structure Requirements","text":"<ol> <li>Use Markdown with clear section hierarchy</li> <li>Code blocks with syntax highlighting (<code>bash,</code>python, etc.)</li> <li>File paths format: <code>/path/to/file.md:123</code> (clickable in most IDEs)</li> <li>Tables for large datasets (issue lists, file inventories)</li> <li>Command examples showing exact fix commands with expected output</li> </ol>"},{"location":"contributing/audit/project/#example-output-structure_1","title":"Example Output Structure","text":"<pre><code>## Critical Issues (Priority: CRITICAL)\n\n### Issue 1: Broken Legacy Reference\n\n**File**: `docs/atomic/architecture/data-access-architecture.md:66`\n**Problem**: Reference to non-existent `docs/legacy/architecture/data-access-rules.md`\n**Impact**: Blocks users/AI agents trying to find data access rules\n**Category**: Link Validation\n\n**How Found**:\n```bash\ngrep -rn \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n</code></pre> <p>Fix Command: <pre><code>sed -i 's|docs/legacy/architecture/data-access-rules.md|docs/atomic/architecture/data-access-architecture.md|g' \\\n  docs/atomic/architecture/data-access-architecture.md\n</code></pre></p> <p>Verification: <pre><code>grep -n \"docs/legacy\" docs/atomic/architecture/data-access-architecture.md\n# Expected: no output (issue fixed)\n</code></pre> <pre><code>---\n\n## CONSTRAINTS \u26a1 MANDATORY\n\n### Execution Constraints\n\n1. **DO NOT delegate this audit to Task agent**\n   - You MUST execute all validation commands yourself using Bash tool\n   - Delegation leads to incomplete audits (proven failure mode)\n\n2. **DO NOT use sample-based checking**\n   - Check ALL files, not 10% with extrapolation\n   - Use `find`, `grep -r`, `xargs -P` for exhaustive scans\n\n3. **DO NOT skip smoke tests**\n   - Run all 5 smoke tests before full audit\n   - If any smoke test shows critical issues, report immediately\n\n4. **DO NOT estimate health score**\n   - Calculate using exact formula: `100 - (CRITICAL\u00d73) - (HIGH\u00d71.5) - (MEDIUM\u00d70.5) - (LOW\u00d70.1)`\n   - Show calculation in report\n\n5. **DO NOT trust \"Related Documents\" sections without verification**\n   - These are NOT optional metadata\n   - Users/AI agents click these links expecting valid targets\n   - Broken \"Related Documents\" = CRITICAL issue\n\n### Reporting Constraints\n\n1. **MUST show validation commands used** (proof of work)\n2. **MUST perform 3+ spot checks** to verify issues are real\n3. **MUST include fix commands** for each issue (not just descriptions)\n4. **MUST include verification commands** showing how to confirm fix worked\n5. **MUST report file:line locations** for all issues (not just filenames)\n\n### Quality Constraints\n\n1. **Accuracy &gt; Speed**: Better to take 10 minutes and find all issues than 2 minutes with 50% false negatives\n2. **Explicit &gt; Implicit**: Show commands, outputs, calculations\n3. **Reproducible**: Any human/AI should be able to run your commands and get same results\n4. **Actionable**: Every issue should have clear fix command\n\n---\n\n## VERIFICATION PROTOCOL \u26a1 MANDATORY\n\nAfter completing the audit, perform these self-checks:\n\n### Automated Verification\n\n```bash\n# Save your audit report to /tmp/audit_output.md first\n\n# Check 1: Did you run smoke tests?\ngrep -q \"SMOKE TEST\" /tmp/audit_output.md\necho \"Smoke tests documented: $?\"  # Expected: 0 (yes)\n\n# Check 2: Did you show health score calculation?\ngrep -q \"100 - (CRITICAL\" /tmp/audit_output.md\necho \"Health score formula shown: $?\"  # Expected: 0 (yes)\n\n# Check 3: Did you perform spot checks?\ngrep -c \"Spot Check\" /tmp/audit_output.md\n# Expected: &gt;= 3\n\n# Check 4: Are all issues tagged with severity?\nISSUES=$(grep -c \"^### Issue\" /tmp/audit_output.md)\nSEVERITIES=$(grep -c \"Priority: \\(CRITICAL\\|HIGH\\|MEDIUM\\|LOW\\)\" /tmp/audit_output.md)\necho \"Issues: $ISSUES, Tagged: $SEVERITIES\"  # Should match\n\n# Check 5: Do all issues have fix commands?\nFIX_COMMANDS=$(grep -c \"**Fix Command**:\" /tmp/audit_output.md)\necho \"Issues with fixes: $ISSUES/$FIX_COMMANDS\"  # Should match\n</code></pre></p>"},{"location":"contributing/audit/project/#manual-spot-checks-pick-3-random-issues_1","title":"Manual Spot Checks (Pick 3 Random Issues)","text":"<p>For each spot check:</p> <ol> <li>Copy the \"How Found\" command \u2192 Run it yourself</li> <li>Verify the issue exists at reported file:line</li> <li>Copy the \"Fix Command\" \u2192 Run it in test environment</li> <li>Copy the \"Verification Command\" \u2192 Confirm fix works</li> <li>Document result in audit report</li> </ol> <p>Example Spot Check Documentation:</p> <pre><code>#### Spot Check 1: Legacy Reference Verification\n\n**Issue**: docs/atomic/architecture/data-access-architecture.md:66 references non-existent legacy file\n\n**Command Run**:\n```bash\nsed -n '66p' docs/atomic/architecture/data-access-architecture.md\n</code></pre> <p>Output: <pre><code>- Legacy reference: `docs/legacy/architecture/data-access-rules.md`\n</code></pre></p> <p>Verification: \u2705 Issue confirmed - line 66 contains broken legacy reference</p> <p>Fix Tested: \u2705 sed replacement works, file updated correctly <pre><code>### Self-Audit Checklist\n\nBefore submitting audit report, confirm:\n\n- [ ] All 5 smoke tests executed and documented\n- [ ] Health score calculation shown with formula\n- [ ] All validation commands listed (proof of work)\n- [ ] 3+ spot checks performed and documented\n- [ ] Every issue has: file:line, impact, category, how found, fix command, verification\n- [ ] No delegation used (all commands run directly by you)\n- [ ] Exhaustive checking used (not sample-based)\n- [ ] \"Related Documents\" sections validated (not skipped)\n\n**If ANY checklist item is unchecked \u2192 AUDIT IS INCOMPLETE**\n\n---\n\n## QUICK AUDIT (5 Minutes)\n\nFor rapid health checks, run only smoke tests + critical validations:\n\n```bash\n#!/bin/bash\n# Quick audit script (5 minutes max)\n\necho \"=== QUICK DOCUMENTATION AUDIT ===\"\necho \"Started: $(date)\"\n\n# 1. Smoke Tests\necho -e \"\\n### SMOKE TESTS ###\"\n\n# Smoke 1: File counts\nMD_COUNT=$(find docs/ -name \"*.md\" 2&gt;/dev/null | wc -l)\necho \"Markdown files: $MD_COUNT\"\n\n# Smoke 2: Link count\nLINK_COUNT=$(grep -roh '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | wc -l)\necho \"Total links: $LINK_COUNT\"\n\n# Smoke 3: Legacy references (CRITICAL)\nLEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" docs/ README.md CLAUDE.md 2&gt;/dev/null | wc -l)\necho \"Legacy references: $LEGACY_COUNT\"\nif [ $LEGACY_COUNT -gt 0 ]; then\n  echo \"  \ud83d\udea8 CRITICAL: Found $LEGACY_COUNT legacy references\"\nfi\n\n# Smoke 4: Broken link sample\necho \"Sample broken links (first 3):\"\ngrep -rho '\\[.*\\](.*\\.md' docs/ 2&gt;/dev/null | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u | while read -r ref; do\n  if [ ! -f \"$ref\" ] &amp;&amp; [ ! -f \"docs/$ref\" ]; then\n    echo \"  \u274c $ref\"\n  fi\ndone | head -3\n\n# Smoke 5: Stage 0 files\necho -e \"\\nStage 0 initialization files:\"\nfor doc in \"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\"; do\n  if [ -f \"$doc\" ]; then\n    echo \"  \u2705 $doc\"\n  else\n    echo \"  \u274c $doc (CRITICAL)\"\n  fi\ndone\n\n# 2. Critical Validations Only\necho -e \"\\n### CRITICAL VALIDATIONS ###\"\n\n# Check architecture guide exists\n[ -f \"docs/guides/architecture-guide.md\" ] &amp;&amp; echo \"\u2705 Architecture guide\" || echo \"\u274c Architecture guide (CRITICAL)\"\n\n# Check AI workflow exists\n[ -f \"docs/guides/ai-code-generation-master-workflow.md\" ] &amp;&amp; echo \"\u2705 AI workflow\" || echo \"\u274c AI workflow (CRITICAL)\"\n\n# Check navigation matrix\n[ -f \"docs/reference/ai-navigation-matrix.md\" ] &amp;&amp; echo \"\u2705 Navigation matrix\" || echo \"\u274c Navigation matrix (CRITICAL)\"\n\necho -e \"\\nCompleted: $(date)\"\necho -e \"\\n\ud83d\udca1 Run full audit for detailed analysis: bash scripts/audit_docs.sh --full\"\n</code></pre></p> <p>Usage: <pre><code>bash scripts/quick_audit.sh\n</code></pre></p>"},{"location":"contributing/audit/project/#focused-audits_1","title":"FOCUSED AUDITS","text":""},{"location":"contributing/audit/project/#audit-only-links_1","title":"Audit Only Links","text":"<pre><code># Link-only audit\nbash scripts/audit_docs.sh --links\n</code></pre>"},{"location":"contributing/audit/project/#audit-only-structure_1","title":"Audit Only Structure","text":"<pre><code># Structure-only audit\nbash scripts/audit_docs.sh --structure\n</code></pre>"},{"location":"contributing/audit/project/#audit-only-ai-navigation_1","title":"Audit Only AI Navigation","text":"<pre><code># AI navigation audit\nbash scripts/audit_docs.sh --ai-navigation\n</code></pre>"},{"location":"contributing/audit/project/#automation-script-template_1","title":"AUTOMATION SCRIPT TEMPLATE","text":"<p>Create <code>scripts/audit_docs.sh</code> for reusable auditing:</p> <pre><code>#!/bin/bash\n\n# scripts/audit_docs.sh - Comprehensive documentation audit automation\n# Usage:\n#   ./scripts/audit_docs.sh --full      # Full audit\n#   ./scripts/audit_docs.sh --quick     # 5-minute audit\n#   ./scripts/audit_docs.sh --links     # Link validation only\n#   ./scripts/audit_docs.sh --structure # Structure validation only\n\nset -euo pipefail\n\n# Configuration\nDOCS_DIR=\"docs\"\nOUTPUT_DIR=\"audit_reports\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"$OUTPUT_DIR/audit_${TIMESTAMP}.md\"\n\n# Create output directory\nmkdir -p \"$OUTPUT_DIR\"\n\n# Logging helper\nlog() {\n  echo \"[$(date +%H:%M:%S)] $*\" | tee -a \"$REPORT_FILE\"\n}\n\n# Smoke tests function\nrun_smoke_tests() {\n  log \"=== SMOKE TESTS ===\"\n\n  log \"Smoke 1: File counts\"\n  MD_COUNT=$(find \"$DOCS_DIR\" -name \"*.md\" 2&gt;/dev/null | wc -l)\n  log \"  Markdown files: $MD_COUNT\"\n\n  log \"Smoke 2: Link count\"\n  LINK_COUNT=$(grep -roh '\\[.*\\](.*\\.md' \"$DOCS_DIR\" 2&gt;/dev/null | wc -l)\n  log \"  Total links: $LINK_COUNT\"\n\n  log \"Smoke 3: \ud83d\udea8 Legacy references (CRITICAL)\"\n  LEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | wc -l)\n  log \"  Legacy references: $LEGACY_COUNT\"\n  if [ \"$LEGACY_COUNT\" -gt 0 ]; then\n    log \"  \ud83d\udea8 CRITICAL: Found $LEGACY_COUNT legacy references\"\n    grep -rn \"docs/legacy\\|/legacy/\\|deprecated\\|old-\" \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | head -10 | tee -a \"$REPORT_FILE\"\n  fi\n\n  log \"Smoke 4: Broken link sample\"\n  BROKEN_SAMPLE=$(grep -rho '\\[.*\\](.*\\.md' \"$DOCS_DIR\" 2&gt;/dev/null | sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u | while read -r ref; do\n    if [ ! -f \"$ref\" ] &amp;&amp; [ ! -f \"$DOCS_DIR/$ref\" ]; then\n      echo \"  \u274c $ref\"\n    fi\n  done | head -3)\n  log \"$BROKEN_SAMPLE\"\n\n  log \"Smoke 5: Stage 0 files\"\n  for doc in \"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\"; do\n    if [ -f \"$doc\" ]; then\n      log \"  \u2705 $doc\"\n    else\n      log \"  \u274c $doc (CRITICAL)\"\n    fi\n  done\n}\n\n# Link validation function\nvalidate_links() {\n  log \"=== LINK VALIDATION ===\"\n\n  # Extract all markdown links\n  grep -rn '\\[.*\\](.*\\.md' \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null &gt; /tmp/all_links_$$.txt || true\n  TOTAL_LINKS=$(wc -l &lt; /tmp/all_links_$$.txt)\n  log \"Total links found: $TOTAL_LINKS\"\n\n  # Validate each unique target\n  grep -rho '\\[.*\\](.*\\.md' \"$DOCS_DIR\" README.md CLAUDE.md 2&gt;/dev/null | \\\n    sed 's/.*(\\(.*\\.md\\).*/\\1/' | sort -u &gt; /tmp/unique_targets_$$.txt || true\n\n  BROKEN=0\n  while read -r target; do\n    if [ ! -f \"$target\" ] &amp;&amp; [ ! -f \"$DOCS_DIR/$target\" ]; then\n      log \"  \u274c Broken: $target\"\n      ((BROKEN++))\n\n      # Show which files reference this broken link\n      grep -l \"$target\" \"$DOCS_DIR\"/**/*.md README.md CLAUDE.md 2&gt;/dev/null | head -3 | while read -r file; do\n        LINE=$(grep -n \"$target\" \"$file\" | head -1 | cut -d: -f1)\n        log \"      Referenced in: $file:$LINE\"\n      done\n    fi\n  done &lt; /tmp/unique_targets_$$.txt\n\n  log \"Broken links: $BROKEN\"\n  rm -f /tmp/all_links_$$.txt /tmp/unique_targets_$$.txt\n}\n\n# Structure validation function\nvalidate_structure() {\n  log \"=== STRUCTURE VALIDATION ===\"\n\n  # Check atomic/* structure\n  EXPECTED_DIRS=(\"architecture\" \"databases\" \"infrastructure\" \"integrations\" \"observability\" \"services\" \"testing\")\n\n  for dir in \"${EXPECTED_DIRS[@]}\"; do\n    if [ -d \"$DOCS_DIR/atomic/$dir\" ]; then\n      README_COUNT=$(find \"$DOCS_DIR/atomic/$dir\" -name \"README.md\" | wc -l)\n      log \"  \u2705 $DOCS_DIR/atomic/$dir (READMEs: $README_COUNT)\"\n    else\n      log \"  \u274c $DOCS_DIR/atomic/$dir missing\"\n    fi\n  done\n}\n\n# AI navigation validation function\nvalidate_ai_navigation() {\n  log \"=== AI NAVIGATION VALIDATION ===\"\n\n  # Verify Stage 0 sequence\n  STAGE0_DOCS=(\"CLAUDE.md\" \"docs/reference/agent-context-summary.md\" \"docs/guides/ai-code-generation-master-workflow.md\" \"docs/reference/maturity-levels.md\")\n\n  for i in \"${!STAGE0_DOCS[@]}\"; do\n    doc=\"${STAGE0_DOCS[$i]}\"\n    if [ -f \"$doc\" ]; then\n      log \"  Step $((i+1)): \u2705 $doc\"\n    else\n      log \"  Step $((i+1)): \u274c CRITICAL - $doc missing\"\n    fi\n  done\n\n  # Check navigation matrix\n  if [ -f \"docs/reference/ai-navigation-matrix.md\" ]; then\n    log \"  \u2705 AI navigation matrix exists\"\n\n    # Check for all 7 stages\n    for stage in {0..6}; do\n      if grep -q \"Stage $stage\" docs/reference/ai-navigation-matrix.md; then\n        log \"    \u2705 Stage $stage documented\"\n      else\n        log \"    \u274c Stage $stage missing\"\n      fi\n    done\n  else\n    log \"  \u274c CRITICAL: AI navigation matrix missing\"\n  fi\n}\n\n# Main execution\nMODE=\"${1:---full}\"\n\ncase \"$MODE\" in\n  --quick)\n    log \"Starting QUICK AUDIT\"\n    run_smoke_tests\n    ;;\n  --links)\n    log \"Starting LINK VALIDATION\"\n    validate_links\n    ;;\n  --structure)\n    log \"Starting STRUCTURE VALIDATION\"\n    validate_structure\n    ;;\n  --ai-navigation)\n    log \"Starting AI NAVIGATION VALIDATION\"\n    validate_ai_navigation\n    ;;\n  --full)\n    log \"Starting FULL AUDIT\"\n    run_smoke_tests\n    validate_links\n    validate_structure\n    validate_ai_navigation\n    log \"=== FULL AUDIT COMPLETE ===\"\n    log \"Report saved to: $REPORT_FILE\"\n    ;;\n  *)\n    echo \"Usage: $0 [--full|--quick|--links|--structure|--ai-navigation]\"\n    exit 1\n    ;;\nesac\n\nlog \"Audit completed at $(date)\"\n</code></pre> <p>Make executable: <pre><code>chmod +x scripts/audit_docs.sh\n</code></pre></p>"},{"location":"contributing/audit/project/#cicd-integration_1","title":"CI/CD INTEGRATION","text":""},{"location":"contributing/audit/project/#github-actions-example_1","title":"GitHub Actions Example","text":"<pre><code># .github/workflows/docs-audit.yml\nname: Documentation Audit\n\non:\n  push:\n    paths:\n      - 'docs/**'\n      - '*.md'\n  pull_request:\n    paths:\n      - 'docs/**'\n      - '*.md'\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Quick Audit\n        run: |\n          bash scripts/audit_docs.sh --quick\n\n      - name: Check for Critical Issues\n        run: |\n          # Fail if legacy references found\n          LEGACY_COUNT=$(grep -rn \"docs/legacy\\|/legacy/\" docs/ 2&gt;/dev/null | wc -l)\n          if [ $LEGACY_COUNT -gt 0 ]; then\n            echo \"::error::Found $LEGACY_COUNT legacy references\"\n            exit 1\n          fi\n\n      - name: Upload Audit Report\n        uses: actions/upload-artifact@v3\n        with:\n          name: audit-report\n          path: audit_reports/\n</code></pre>"},{"location":"contributing/audit/project/#usage-examples_1","title":"USAGE EXAMPLES","text":""},{"location":"contributing/audit/project/#example-1-first-time-audit_1","title":"Example 1: First-Time Audit","text":"<pre><code># Clone repository\ncd /path/to/doc4microservices\n\n# Run full audit\nbash scripts/audit_docs.sh --full\n\n# Review report\ncat audit_reports/audit_*.md | less\n\n# Fix critical issues first\ngrep \"CRITICAL\" audit_reports/audit_*.md\n</code></pre>"},{"location":"contributing/audit/project/#example-2-pre-commit-audit_1","title":"Example 2: Pre-Commit Audit","text":"<pre><code># Quick check before committing docs\nbash scripts/audit_docs.sh --quick\n\n# If issues found, run focused audit\nbash scripts/audit_docs.sh --links\n</code></pre>"},{"location":"contributing/audit/project/#example-3-cicd-integration_1","title":"Example 3: CI/CD Integration","text":"<pre><code># In CI pipeline\nbash scripts/audit_docs.sh --quick\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -ne 0 ]; then\n  echo \"Documentation audit failed\"\n  exit 1\nfi\n</code></pre>"},{"location":"contributing/audit/project/#maintenance-schedule_1","title":"MAINTENANCE SCHEDULE","text":""},{"location":"contributing/audit/project/#daily-automated_1","title":"Daily (Automated)","text":"<ul> <li>Quick audit (5 min) on every commit touching <code>docs/</code> or <code>*.md</code></li> <li>Check for broken links only</li> </ul>"},{"location":"contributing/audit/project/#weekly-automated_1","title":"Weekly (Automated)","text":"<ul> <li>Full audit with all 14 objectives</li> <li>Generate trend report (compare with previous week)</li> </ul>"},{"location":"contributing/audit/project/#monthly-manual_1","title":"Monthly (Manual)","text":"<ul> <li>Review accumulated issues</li> <li>Prioritize fixes</li> <li>Update audit template if needed</li> </ul>"},{"location":"contributing/audit/project/#quarterly-manual_1","title":"Quarterly (Manual)","text":"<ul> <li>Deep content quality review</li> <li>Update validation commands</li> <li>Review and update this audit template</li> </ul>"},{"location":"contributing/audit/project/#shell-scripting-best-practices_1","title":"SHELL SCRIPTING BEST PRACTICES","text":"<p>When writing validation scripts:</p> <ol> <li> <p>Use <code>find -print0 | xargs -0</code> for file operations (handles spaces)    <pre><code>find docs/ -name \"*.md\" -print0 | xargs -0 grep -l \"pattern\"\n</code></pre></p> </li> <li> <p>Avoid <code>while read</code> loops when possible (slow for large datasets)    <pre><code># Bad: slow\nls *.md | while read file; do grep pattern \"$file\"; done\n\n# Good: parallel processing\ngrep -r pattern *.md\n</code></pre></p> </li> <li> <p>Use parallel processing for independent checks    <pre><code>find docs/ -name \"*.md\" -print0 | xargs -0 -P 8 -I {} bash -c 'check_file \"$@\"' _ {}\n</code></pre></p> </li> <li> <p>Capture errors properly <pre><code>grep -r pattern docs/ 2&gt;/dev/null || echo \"Pattern not found\"\n</code></pre></p> </li> <li> <p>Use temporary files for complex pipelines    <pre><code>grep -r pattern docs/ &gt; /tmp/results.txt\nprocess_results &lt; /tmp/results.txt\nrm /tmp/results.txt\n</code></pre></p> </li> </ol>"},{"location":"contributing/audit/project/#notes_1","title":"NOTES","text":""},{"location":"contributing/audit/project/#why-this-template-is-critical_1","title":"Why This Template is Critical","text":"<p>This audit template prevents systemic documentation failures by:</p> <ol> <li>Forcing direct execution (no delegation to unreliable agents)</li> <li>Requiring exhaustive checking (no sample-based estimation)</li> <li>Providing explicit validation commands (no room for interpretation)</li> <li>Mandating smoke tests (catch critical issues in 30 seconds)</li> <li>Requiring proof of work (show commands used, spot checks performed)</li> </ol>"},{"location":"contributing/audit/project/#lessons-from-previous-failures_1","title":"Lessons from Previous Failures","text":"<p>Failure Mode 1: Link Validation Bypass (v1.0)</p> <p>The original template allowed an AI agent to miss 64+ critical broken legacy links because: - Delegation was permitted \u2192 Task agent used sample-based checking - No explicit validation commands \u2192 Agent estimated instead of executing - Smoke tests came too late \u2192 Critical issues not caught early - No spot check requirements \u2192 No verification that issues were real - Health score calculation not enforced \u2192 Agent estimated 72/100 (actual: ~0/100)</p> <p>Fix: V2 template added mandatory Bash execution, explicit validation commands, and smoke tests.</p> <p>Failure Mode 2: Config Mismatch Detection Failure (October 2025)</p> <p>An audit using V2 template missed 5 critical config consistency issues affecting 40% of critical files: - Issue: Docker Compose profile <code>monitoring</code> vs documentation <code>observability</code> (2 files) - Issue: Database names <code>myapp_db</code> vs <code>microservices_db</code> (4 files) - Issue: Empty pyproject.toml despite docs requiring <code>uv run ruff/mypy/pytest</code> commands - Issue: CONTRIBUTING.md referenced non-existent <code>validate_docs.sh</code> (19 occurrences) - Issue: Weak credentials <code>admin123</code> vs secure defaults <code>admin</code> (3 files)</p> <p>Root cause: - Template focused on docs/ directory only \u2192 Missed root-level config files - No cross-validation between config files and documentation - Assumed configs were correct if they existed - No validation that documented commands actually work</p> <p>Impact: Users following documentation would encounter immediate failures: - <code>docker-compose up --profile monitoring</code> fails (profile doesn't exist) - Database connection examples fail (wrong DB names) - Quality commands fail (<code>uv run ruff</code> \u2192 pyproject.toml not configured) - Contributors run wrong scripts (validate_docs.sh doesn't exist)</p> <p>Fix: Added Objective 16 (Config Consistency Validation), Smoke Test 6 (pyproject.toml check), and anti-patterns for config cross-validation.</p> <p>Failure Mode 3: Command Path Validation Failure - Silent Failures (October 2025)</p> <p>Critical issue discovered post-v2.1 where documented commands executed successfully but returned wrong results: - Issue: Coverage commands used <code>--cov=app</code> but all 5 templates use <code>src/</code> directory - Impact: Commands returned coverage=0% (false negative) despite actual code existing - Affected files: 6 occurrences across 3 critical documentation files:   - docs/quality/agent-verification-checklist.md (Stage 5 quality gates)   - docs/guides/development-commands.md (canonical command reference)   - docs/reference/agent-toolbox.md (machine-readable commands)</p> <p>Silent Failure Pattern (most dangerous type): - \u2705 Command executes successfully (exit code 0) - \u2705 No error message displayed - \u274c Returns wrong result (coverage=0% when should be 70-85%) - \u274c Appears to work but gives false negatives - \u274c Blocks AI agent Stage 5 (Quality Verification) with cryptic \"coverage below threshold\" errors - \u274c Wastes hours of debugging time (developers think code has no tests, not that command is wrong)</p> <p>Root cause: - Commands documented without validating against actual project structure - No smoke test for path validation - Template structure (src/ vs app/) not cross-checked with commands - Trusted that \"command executes\" means \"command works correctly\"</p> <p>Real-world impact timeline: - Day 1: Developer copies <code>pytest --cov=app</code> from docs - Day 1: Runs command \u2192 sees \"coverage=0%\" \u2192 confused (code clearly exists) - Day 1-3: Debugs pytest config, test discovery, assumes bug in coverage tool - Day 3: AI agent hits same issue in Stage 5 \u2192 reports \"Cannot meet 80% threshold\" (has 0%) - Day 4: Manual review discovers path mismatch (should be <code>--cov=src</code>) - Total time wasted: 4 developer-days debugging a 1-character documentation error</p> <p>Prevention required: 1. Objective 17: Command Path Validation (cross-check commands against actual structure) 2. Smoke Test 7: Quick path mismatch detection (10 seconds vs 4 days debugging) 3. CI Workflow: <code>.github/workflows/docs-command-validation.yml</code> blocks PRs with wrong paths 4. Anti-pattern: Don't trust \"command succeeds\" \u2192 verify results match expectations</p> <p>Fix: Added Objective 17 (Command Path Validation), Smoke Test 7 (path mismatch detection), CI workflow for automated prevention, and anti-pattern for trusting successful execution.</p> <p>This V2.2 template fixes ALL known failure modes.</p>"},{"location":"contributing/audit/project/#when-to-update-this-template_1","title":"When to Update This Template","text":"<p>Update this template when: - New documentation categories added (e.g., \"deployment-guides/\") - New quality criteria introduced (e.g., \"check for AI-readability\") - New tools adopted (e.g., \"vale\" for prose linting) - Audit failure modes discovered (add to CONSTRAINTS) - Framework structure changes (update expected directories)</p>"},{"location":"contributing/audit/project/#recovery-from-audit-failures_1","title":"Recovery from Audit Failures","text":"<p>If an audit using this template still misses critical issues:</p> <ol> <li>Root cause analysis (ultrathink):</li> <li>Which objective failed?</li> <li>Was validation command inadequate?</li> <li> <p>Was constraint unclear?</p> </li> <li> <p>Template fix:</p> </li> <li>Update validation commands</li> <li>Add explicit constraint</li> <li> <p>Add to anti-patterns section</p> </li> <li> <p>Verify fix:</p> </li> <li>Re-run audit with updated template</li> <li> <p>Confirm issue now caught</p> </li> <li> <p>Document lesson:</p> </li> <li>Add to \"Lessons from Previous Failures\" section</li> <li>Update CI/CD checks</li> </ol>"},{"location":"contributing/audit/project/#end-of-template_1","title":"END OF TEMPLATE","text":"<p>Version: 2.2 Last Updated: 2025-10-13 Changelog: - v2.2 (2025-10-13): Added Objective 17 (Command Path Validation - silent failure prevention), Smoke Test 7 (command path mismatch detection), anti-pattern for trusting successful command execution, Failure Mode 3 case study (--cov=app\u2192src issue) - v2.1 (2025-10-11): Added Objective 16 (Config Consistency Validation), Smoke Test 6 (pyproject.toml), anti-patterns for config validation, Failure Mode 2 case study - v2.0 (2025-10-11): Complete rewrite with mandatory execution protocol, explicit validation commands, smoke tests, verification protocol - v1.0 (2025-10-10): Original template (proved insufficient - missed 64+ critical issues)</p>"},{"location":"contributing/improvement-plans/","title":"Improvement Plans","text":"<p>This directory contains detailed implementation plans for significant improvements to the AI Framework.</p>"},{"location":"contributing/improvement-plans/#purpose","title":"Purpose","text":"<p>Improvement plans are living documents that: - Guide implementation of complex, multi-phase enhancements - Track progress against defined milestones and acceptance criteria - Document decisions and rationale for future contributors - Enable collaboration by providing clear roadmaps for contributions</p>"},{"location":"contributing/improvement-plans/#when-to-create-an-improvement-plan","title":"When to Create an Improvement Plan","text":"<p>Create an improvement plan when:</p> <ul> <li>The change affects multiple framework components (docs, templates, workflows)</li> <li>Implementation requires 3+ weeks of effort or 10+ files modified</li> <li>The improvement introduces new architectural patterns or significant refactoring</li> <li>Multiple contributors will work on related tasks</li> <li>The change requires phased rollout or deprecation strategy</li> </ul> <p>For smaller changes, use: - Pull requests with clear descriptions for isolated fixes - Feature proposals (see <code>../feature-proposals/</code>) for new capabilities - GitHub issues for bug reports or small enhancements</p>"},{"location":"contributing/improvement-plans/#improvement-plan-structure","title":"Improvement Plan Structure","text":"<p>Each improvement plan should follow this template:</p> <pre><code># [Title]: [Brief Description]\n\n## Executive Summary\n[2-3 paragraphs: problem, solution, impact]\n\n## Problem Statement\n[Detailed description with evidence]\n\n## Goals and Success Criteria\n[Measurable objectives]\n\n## Detailed Implementation Plan\n### Phase 1: [Name]\n- Task 1: [Description]\n  - Files: [list]\n  - Acceptance Criteria: [list]\n  - Estimated Time: [hours/days]\n\n### Phase 2: [Name]\n[...]\n\n## Implementation Details\n[Code examples, architectural decisions, trade-offs]\n\n## Testing and Validation\n[How to verify success]\n\n## Rollout Strategy\n[Deployment approach, backward compatibility]\n\n## Risks and Mitigations\n[Potential issues and solutions]\n\n## Timeline\n[Gantt chart or milestone table]\n</code></pre>"},{"location":"contributing/improvement-plans/#file-naming-convention","title":"File Naming Convention","text":"<p>Use this format: <code>YYYY-MM-{descriptive-name}.md</code></p> <p>Examples: - <code>2025-01-dry-kiss-yagni-enforcement.md</code> - Improving principle enforcement - <code>2025-02-template-completion-phase1.md</code> - Completing service templates - <code>2025-03-observability-upgrade.md</code> - Enhanced monitoring/tracing</p> <p>Rationale: - Date prefix enables chronological sorting - Descriptive name aids searchability - Consistent format improves discoverability</p>"},{"location":"contributing/improvement-plans/#workflow","title":"Workflow","text":""},{"location":"contributing/improvement-plans/#1-planning-phase","title":"1. Planning Phase","text":"<ol> <li>Create improvement plan document</li> <li>Use template structure above</li> <li>Break work into phases (Critical \u2192 High \u2192 Medium priority)</li> <li> <p>Define acceptance criteria for each task</p> </li> <li> <p>Review with maintainers</p> </li> <li>Open PR with the plan document (no code changes yet)</li> <li>Get feedback on scope, approach, priorities</li> <li> <p>Iterate until consensus is reached</p> </li> <li> <p>Merge approved plan</p> </li> <li>Plan document goes into this directory</li> <li>Creates shared roadmap for contributors</li> </ol>"},{"location":"contributing/improvement-plans/#2-implementation-phase","title":"2. Implementation Phase","text":"<ol> <li>Claim tasks from plan</li> <li>Comment on plan PR or create tracking issue</li> <li> <p>Link your implementation PRs to the plan</p> </li> <li> <p>Update plan status</p> </li> <li>Mark tasks as \"In Progress\" or \"Completed\"</li> <li>Document any deviations or learnings</li> <li> <p>Update timeline if needed</p> </li> <li> <p>Submit implementation PRs</p> </li> <li>Reference plan document in PR description</li> <li>Follow checklist from plan's acceptance criteria</li> </ol>"},{"location":"contributing/improvement-plans/#3-completion-phase","title":"3. Completion Phase","text":"<ol> <li>Validate success criteria</li> <li>Run all tests from \"Testing and Validation\" section</li> <li> <p>Verify all acceptance criteria are met</p> </li> <li> <p>Update plan status</p> </li> <li>Mark plan as \"Completed\" or \"Superseded\"</li> <li> <p>Document final outcomes and lessons learned</p> </li> <li> <p>Archive or close</p> </li> <li>Plan remains in directory as historical record</li> <li>Inform future similar improvements</li> </ol>"},{"location":"contributing/improvement-plans/#tracking-progress","title":"Tracking Progress","text":"<p>Use these status indicators in plan documents:</p> Status Symbol Meaning Not Started \u23f8\ufe0f Task defined but work hasn't begun In Progress \ud83d\udd04 Actively being implemented Blocked \ud83d\udeab Waiting on dependency or decision Completed \u2705 Task finished and validated Deferred \u23ed\ufe0f Postponed to future phase Cancelled \u274c No longer relevant or needed <p>Update frequency: At least weekly during active implementation</p>"},{"location":"contributing/improvement-plans/#example-updating-a-plan","title":"Example: Updating a Plan","text":"<pre><code>### Phase 1: Critical Improvements\n\n- Task 1: Create DRY/KISS/YAGNI principles guide\n-  - Status: \u23f8\ufe0f Not Started\n+  - Status: \u2705 Completed\n+  - Completed by: @contributor-name\n+  - PR: #123\n-  - Estimated Time: 6 hours\n+  - Actual Time: 8 hours\n+  - Notes: Added extra examples based on reviewer feedback\n\n- Task 2: Implement shared utilities\n-  - Status: \u23f8\ufe0f Not Started\n+  - Status: \ud83d\udd04 In Progress (60% complete)\n+  - In Progress by: @another-contributor\n+  - PR: #124 (draft)\n   - Estimated Time: 12 hours\n+  - Blockers: Waiting on decision about logger format (see issue #125)\n</code></pre>"},{"location":"contributing/improvement-plans/#related-documents","title":"Related Documents","text":"<ul> <li>Main Contributing Guide - Overall contribution workflow</li> <li>Feature Proposals - Propose new framework features</li> <li>Refactoring Plans - Architectural refactorings</li> <li>Agent Workflow - Framework usage</li> </ul>"},{"location":"contributing/improvement-plans/#questions","title":"Questions?","text":"<p>If you have questions about creating or implementing an improvement plan:</p> <ol> <li>Check existing plans for examples</li> <li>Review CONTRIBUTING.md</li> <li>Open a discussion in GitHub Issues</li> <li>Tag maintainers in your plan PR</li> </ol> <p>Remember: Improvement plans are living documents. Update them as implementation progresses and learnings emerge!</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/","title":"Improvement Plan: DRY, KISS, YAGNI Principles Enforcement","text":"<p>Status: \u23f8\ufe0f Not Started Created: 2025-01-07 Owner: Framework Maintainers Priority: Critical Estimated Effort: 80-120 hours (10-15 working days)</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#executive-summary","title":"Executive Summary","text":""},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#problem","title":"Problem","text":"<p>The AI Framework currently enforces DRY, KISS, and YAGNI principles implicitly through architecture (HTTP-only data access, maturity levels, conditional phases), but lacks explicit documentation and tooling to help AI agents understand and apply these principles during code generation.</p> <p>Key findings from comprehensive audit: - \u274c Zero files mention \"DRY\", \"KISS\", or \"YAGNI\" terminology - \u274c Shared utilities templates 0% complete \u2192 agents duplicate code - \u274c Data service templates 0% complete \u2192 agents reinvent data layer - \u274c No automated CI checks for code duplication or complexity - \u274c 4 critical anti-patterns undocumented</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#solution","title":"Solution","text":"<p>Implement comprehensive DRY/KISS/YAGNI enforcement through:</p> <ol> <li>Educational Documentation - Explicit guides linking principles to architecture</li> <li>Complete Templates - Shared utilities and data service templates (0% \u2192 100%)</li> <li>Automated Quality Gates - CI checks for duplication, complexity, dependency bloat</li> <li>Anti-Pattern Documentation - Add 4 missing anti-patterns with detection methods</li> <li>Workflow Enhancements - Feature necessity validation in Stage 1</li> </ol>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#impact","title":"Impact","text":"<p>Before (Current State): - Agents duplicate logger/validator/pagination code in every service - No automated detection of DRY/KISS/YAGNI violations - Agents may over-engineer solutions without understanding simplicity enforcement - Missing guidance causes inconsistent implementations</p> <p>After (Target State): - Agents understand WHY architecture enforces principles - Shared utilities eliminate 80% of code duplication - CI pipeline blocks PRs with high complexity or duplication - Consistent, principle-compliant code generation across all projects</p> <p>Metrics: - Code duplication: Current ~25% \u2192 Target &lt;10% - Average function complexity: Current McCabe 12 \u2192 Target &lt;10 - Template coverage: Current 40% \u2192 Target 100% - Documentation completeness: Current 0 principle guides \u2192 Target 3 comprehensive guides</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#problem-statement","title":"Problem Statement","text":""},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#current-state-analysis","title":"Current State Analysis","text":""},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#1-missing-educational-documentation","title":"1. Missing Educational Documentation","text":"<p>Evidence: <pre><code># Search for principle terminology in framework\n$ grep -ri \"DRY\\|Don't Repeat Yourself\" .ai-framework/docs/\n# Result: 1 mention in code-review-checklist.md (line 118) - no explanation\n\n$ grep -ri \"KISS\\|Keep It Simple\" .ai-framework/docs/\n# Result: 0 mentions\n\n$ grep -ri \"YAGNI\\|You Aren't Gonna Need It\" .ai-framework/docs/\n# Result: 0 mentions\n</code></pre></p> <p>Impact: - AI agents don't understand WHY HTTP-only pattern = DRY enforcement - No link between maturity levels and KISS/YAGNI principles - Agents may violate principles unknowingly</p> <p>Location: <code>.ai-framework/docs/guides/</code> - missing principle guides</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#2-incomplete-templates-force-code-duplication","title":"2. Incomplete Templates Force Code Duplication","text":"<p>Evidence from templates/README.md analysis:</p> Template Component Completion Impact <code>shared/utils/</code> 0% Every service duplicates logger, validators, pagination <code>template_data_postgres_api/</code> 0% Agents reinvent SQLAlchemy setup, Alembic migrations <code>template_data_mongo_api/</code> 0% Agents reinvent Motor setup, aggregation patterns <code>template_business_api/</code> 40% Missing 8 critical files (logging, middleware, health) <code>template_business_bot/</code> 0% No Aiogram bot template available <code>template_business_worker/</code> 0% No background worker template available <p>Example Duplication Pattern:</p> <p>Without shared/utils/logger.py, every service duplicates: <pre><code># services/auth_api/src/core/logging_config.py\nimport logging\nimport sys\nfrom pythonjsonlogger import jsonlogger\n\ndef setup_logging(level: str = \"INFO\") -&gt; None:\n    handler = logging.StreamHandler(sys.stdout)\n    formatter = jsonlogger.JsonFormatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n    )\n    handler.setFormatter(formatter)\n    logging.root.addHandler(handler)\n    logging.root.setLevel(level)\n\n# services/user_api/src/core/logging_config.py\n# ^^^ EXACT SAME CODE DUPLICATED ^^^\n\n# services/payment_api/src/core/logging_config.py\n# ^^^ EXACT SAME CODE DUPLICATED ^^^\n</code></pre></p> <p>Impact: - ~500 lines of duplicated code per 5-service project - Bug fixes require changing N files (inconsistency risk) - Violates DRY principle</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#3-no-automated-quality-gates","title":"3. No Automated Quality Gates","text":"<p>Evidence from CI template analysis:</p> <p>Current <code>.ai-framework/templates/ci-cd/.github/workflows/ci.yml</code>: <pre><code>jobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Lint with Ruff\n        run: ruff check .\n\n      - name: Type check with Mypy\n        run: mypy src/\n\n      - name: Run tests\n        run: pytest tests/ --cov=src --cov-report=xml\n</code></pre></p> <p>Missing checks: - \u274c Code duplication detection (jscpd, cloc) - \u274c Cyclomatic complexity limits (radon cc) - \u274c Maintainability index (radon mi) - \u274c Dependency count limits - \u274c File size limits</p> <p>Impact: - KISS violations (complex functions) slip through - DRY violations (duplicated code) not caught - YAGNI violations (unused dependencies) accumulate</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#4-missing-anti-patterns","title":"4. Missing Anti-Patterns","text":"<p>Current anti-pattern coverage: 6 documented Missing critical anti-patterns: 4</p> Anti-Pattern Principle Priority Current Status Copy-Paste Programming DRY \ud83d\udfe0 HIGH \u274c Not documented God Object KISS \ud83d\udfe0 HIGH \u274c Not documented Speculative Generality YAGNI \ud83d\udfe1 MEDIUM \u274c Not documented Premature Infrastructure KISS + YAGNI \ud83d\udfe0 HIGH \u274c Not documented <p>Impact: Agents repeat these mistakes without guidance on detection/prevention</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#goals-and-success-criteria","title":"Goals and Success Criteria","text":""},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#primary-goals","title":"Primary Goals","text":"<ol> <li>Make principles explicit and teachable</li> <li>\u2705 Success: AI agents can explain WHY architecture enforces DRY/KISS/YAGNI</li> <li> <p>\u2705 Measurement: Agent responses reference principle guides when making decisions</p> </li> <li> <p>Eliminate shared code duplication</p> </li> <li>\u2705 Success: Code duplication drops from ~25% to &lt;10% in generated projects</li> <li> <p>\u2705 Measurement: <code>jscpd</code> reports duplication &lt;10% threshold</p> </li> <li> <p>Prevent complexity violations</p> </li> <li>\u2705 Success: 100% of functions have McCabe complexity &lt;10</li> <li> <p>\u2705 Measurement: <code>radon cc --min B</code> passes in CI</p> </li> <li> <p>Complete template coverage</p> </li> <li>\u2705 Success: All 6 service templates at 100% completion</li> <li> <p>\u2705 Measurement: <code>templates/README.md</code> shows 100% for all components</p> </li> <li> <p>Automate principle enforcement</p> </li> <li>\u2705 Success: CI pipeline blocks PRs violating DRY/KISS/YAGNI</li> <li>\u2705 Measurement: CI config includes 5+ principle-specific checks</li> </ol>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#secondary-goals","title":"Secondary Goals","text":"<ol> <li>Document upgrade triggers for maturity levels</li> <li>\u2705 Success: Developers know WHEN to upgrade (evidence-driven)</li> <li> <p>\u2705 Measurement: maturity-levels.md includes \"Upgrade Triggers\" section</p> </li> <li> <p>Add feature necessity validation</p> </li> <li>\u2705 Success: Stage 1 challenges unnecessary features</li> <li> <p>\u2705 Measurement: Workflow includes \"Feature Necessity Challenge\" step</p> </li> <li> <p>Expand anti-pattern library</p> </li> <li>\u2705 Success: 10 total anti-patterns documented (current 6 + new 4)</li> <li>\u2705 Measurement: INDEX.md lists all 10 with monitoring commands</li> </ol>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#detailed-implementation-plan","title":"Detailed Implementation Plan","text":""},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#phase-1-critical-improvements-p0","title":"Phase 1: Critical Improvements (P0)","text":"<p>Estimated Effort: 40-50 hours Target Completion: Week 1-2</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#task-11-create-drykissyagni-principles-guide","title":"Task 1.1: Create DRY/KISS/YAGNI Principles Guide","text":"<p>Status: \u23f8\ufe0f Not Started Priority: \ud83d\udd34 CRITICAL Estimated Time: 8 hours Owner: TBD</p> <p>Objective: Create comprehensive educational guide linking principles to framework architecture.</p> <p>Files to Create: - <code>.ai-framework/docs/guides/dry-kiss-yagni-principles.md</code></p> <p>Acceptance Criteria: - [ ] Document explains DRY principle with 3+ examples (correct vs. wrong) - [ ] Document explains KISS principle with maturity level examples - [ ] Document explains YAGNI principle with feature justification template - [ ] Links to architecture docs (HTTP-only pattern, maturity levels) - [ ] Includes automated detection commands for each principle - [ ] Cross-referenced from AGENTS.md and ARCHITECTURE.md - [ ] Reviewed by 2+ maintainers</p> <p>Implementation Details:</p> <p>File structure: <pre><code># DRY, KISS, YAGNI Principles\n\n## Table of Contents\n1. DRY (Don't Repeat Yourself)\n2. KISS (Keep It Simple, Stupid)\n3. YAGNI (You Aren't Gonna Need It)\n4. How Framework Enforces Principles\n5. Automated Detection Tools\n6. Related Documents\n\n## 1. DRY (Don't Repeat Yourself)\n\n### Definition\nEvery piece of knowledge must have a single, unambiguous representation in the system.\n\n### How Framework Enforces DRY\n\n**Architectural Pattern: HTTP-Only Data Access**\n\nThe framework enforces DRY by requiring all business services to access data via HTTP:\n\n\u2705 **CORRECT - Single Source of Truth:**\n```python\n# Business Service: auth_api/src/services/user_service.py\nclass UserService:\n    def __init__(self, data_client: DataClient):\n        self._data_client = data_client\n\n    async def get_user(self, user_id: int) -&gt; User:\n        # HTTP call to data service (single source of truth)\n        response = await self._data_client.get(f\"/users/{user_id}\")\n        return User(**response.json())\n\n# Data Service: data_postgres_api/src/repositories/user_repository.py\nclass UserRepository:\n    def __init__(self, db: Session):\n        self._db = db\n\n    async def get_by_id(self, user_id: int) -&gt; UserModel:\n        # Only place with direct database access\n        return self._db.query(UserModel).filter(UserModel.id == user_id).first()\n</code></pre></p> <p>\u274c WRONG - Duplicated Database Logic: <pre><code># Business Service 1: auth_api/src/services/user_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # Direct database access - VIOLATES ARCHITECTURE\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n\n# Business Service 2: profile_api/src/services/profile_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # DUPLICATED: Same query in different service\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n\n# Business Service 3: payment_api/src/services/payment_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # DUPLICATED AGAIN: Now bug fixes require changing 3 places\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n</code></pre></p> <p>Why This Matters: - Single source of truth for database operations - Bug fix in UserRepository.get_by_id automatically fixes all consumers - No possibility of inconsistent query logic across services - Easier connection pool management (one pool, not N pools)</p> <p>[... continue with more examples ...]</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#automated-detection","title":"Automated Detection","text":"<p>Check code duplication percentage: <pre><code># Install jscpd\nnpm install -g jscpd\n\n# Scan for duplicates (fail if &gt;10%)\njscpd src/ --threshold 10 --exitCode 1\n\n# Detailed report\njscpd src/ --format html --output ./jscpd-report\n</code></pre></p> <p>Find similar files: <pre><code># Using cloc\ncloc --by-file --csv src/ | awk -F',' '$5 &gt; 80 {print $2, $5\"%\"}'\n# Output shows files with &gt;80% similarity\n</code></pre></p> <p>Find duplicated functions: <pre><code># Using PMD CPD\npmd cpd --minimum-tokens 50 --files src/ --language python\n</code></pre></p> <p>[... continue for KISS and YAGNI ...] <pre><code>**Testing:**\n```bash\n# Validate Markdown syntax\nmarkdownlint docs/guides/dry-kiss-yagni-principles.md\n\n# Check links are valid\nmarkdown-link-check docs/guides/dry-kiss-yagni-principles.md\n\n# Preview in mkdocs\nmkdocs serve\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#task-12-implement-shared-utilities-template","title":"Task 1.2: Implement Shared Utilities Template","text":"<p>Status: \u23f8\ufe0f Not Started Priority: \ud83d\udd34 CRITICAL Estimated Time: 12 hours Owner: TBD</p> <p>Objective: Create reusable shared utilities to eliminate duplication across all services.</p> <p>Files to Create: 1. <code>.ai-framework/templates/shared/utils/__init__.py</code> 2. <code>.ai-framework/templates/shared/utils/logger.py</code> 3. <code>.ai-framework/templates/shared/utils/validators.py</code> 4. <code>.ai-framework/templates/shared/utils/exceptions.py</code> 5. <code>.ai-framework/templates/shared/utils/pagination.py</code> 6. <code>.ai-framework/templates/shared/utils/request_id.py</code> 7. <code>.ai-framework/templates/shared/utils/README.md</code></p> <p>Files to Update: - <code>.ai-framework/templates/README.md</code> (update completion status to 100%)</p> <p>Acceptance Criteria: - [ ] logger.py provides structured JSON logging factory - [ ] validators.py includes 10+ common validators (email, phone, UUID, etc.) - [ ] exceptions.py defines base exception hierarchy - [ ] pagination.py supports both offset and cursor pagination - [ ] request_id.py manages correlation IDs across service boundaries - [ ] All files have 100% type hint coverage - [ ] All files have comprehensive docstrings (Google style) - [ ] README.md documents usage patterns for each utility - [ ] Unit tests achieve 100% coverage - [ ] No business logic or project-specific code</p> <p>Implementation Details:</p> <p>1. logger.py - Structured JSON Logging</p> <pre><code>\"\"\"Centralized logging configuration for all services.\n\nThis module provides a factory for creating structured JSON loggers\nwith consistent formatting across the microservices ecosystem.\n\"\"\"\n\nimport logging\nimport sys\nfrom typing import Optional\n\nfrom pythonjsonlogger import jsonlogger\n\n\ndef create_logger(\n    name: str,\n    level: str = \"INFO\",\n    include_request_id: bool = True,\n) -&gt; logging.Logger:\n    \"\"\"Create structured JSON logger.\n\n    Args:\n        name: Logger name (typically __name__ of calling module)\n        level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n        include_request_id: Whether to include request_id in log format\n\n    Returns:\n        Configured logger instance with JSON formatting\n\n    Example:\n        &gt;&gt;&gt; from shared.utils.logger import create_logger\n        &gt;&gt;&gt; logger = create_logger(__name__)\n        &gt;&gt;&gt; logger.info(\"User authenticated\", extra={\"user_id\": 123})\n        # Output: {\"asctime\": \"2025-01-07T10:30:00\", \"name\": \"auth_service\",\n        #          \"levelname\": \"INFO\", \"message\": \"User authenticated\",\n        #          \"user_id\": 123, \"request_id\": \"abc-123\"}\n    \"\"\"\n    logger = logging.getLogger(name)\n\n    # Avoid duplicate handlers if logger already configured\n    if logger.handlers:\n        return logger\n\n    logger.setLevel(level.upper())\n\n    handler = logging.StreamHandler(sys.stdout)\n\n    # Build format string\n    format_fields = [\n        \"%(asctime)s\",\n        \"%(name)s\",\n        \"%(levelname)s\",\n        \"%(message)s\",\n    ]\n\n    if include_request_id:\n        format_fields.append(\"%(request_id)s\")\n\n    formatter = jsonlogger.JsonFormatter(\" \".join(format_fields))\n    handler.setFormatter(formatter)\n\n    logger.addHandler(handler)\n\n    return logger\n\n\nclass RequestIdFilter(logging.Filter):\n    \"\"\"Inject request_id into all log records.\n\n    This filter should be added to loggers in API services\n    to automatically include correlation IDs in logs.\n    \"\"\"\n\n    def __init__(self, get_request_id_func) -&gt; None:\n        \"\"\"Initialize filter with request ID getter function.\n\n        Args:\n            get_request_id_func: Callable that returns current request ID\n        \"\"\"\n        super().__init__()\n        self._get_request_id = get_request_id_func\n\n    def filter(self, record: logging.LogRecord) -&gt; bool:\n        \"\"\"Add request_id to log record.\n\n        Args:\n            record: Log record to modify\n\n        Returns:\n            True (always pass through)\n        \"\"\"\n        record.request_id = self._get_request_id() or \"no-request-id\"\n        return True\n\n\ndef configure_uvicorn_logging(level: str = \"INFO\") -&gt; None:\n    \"\"\"Configure uvicorn access logs to use JSON format.\n\n    Call this in FastAPI startup event to ensure consistent\n    log formatting for HTTP access logs.\n\n    Args:\n        level: Logging level for uvicorn loggers\n\n    Example:\n        &gt;&gt;&gt; from fastapi import FastAPI\n        &gt;&gt;&gt; app = FastAPI()\n        &gt;&gt;&gt; @app.on_event(\"startup\")\n        &gt;&gt;&gt; async def startup():\n        &gt;&gt;&gt;     configure_uvicorn_logging()\n    \"\"\"\n    uvicorn_loggers = [\n        \"uvicorn\",\n        \"uvicorn.access\",\n        \"uvicorn.error\",\n    ]\n\n    for logger_name in uvicorn_loggers:\n        logger = logging.getLogger(logger_name)\n        logger.handlers.clear()\n\n        handler = logging.StreamHandler(sys.stdout)\n        formatter = jsonlogger.JsonFormatter(\n            \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n        )\n        handler.setFormatter(formatter)\n\n        logger.addHandler(handler)\n        logger.setLevel(level.upper())\n</code></pre> <p>2. validators.py - Reusable Validation Functions</p> <pre><code>\"\"\"Common validation functions used across services.\n\nProvides reusable validators for email, phone, UUID, and other\ncommon data types. Use these instead of duplicating validation logic.\n\"\"\"\n\nimport re\nfrom typing import Optional\nfrom uuid import UUID\n\n\ndef is_valid_email(email: str) -&gt; bool:\n    \"\"\"Validate email address format.\n\n    Args:\n        email: Email address to validate\n\n    Returns:\n        True if email format is valid, False otherwise\n\n    Example:\n        &gt;&gt;&gt; is_valid_email(\"user@example.com\")\n        True\n        &gt;&gt;&gt; is_valid_email(\"invalid-email\")\n        False\n    \"\"\"\n    if not email or len(email) &gt; 254:\n        return False\n\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\n\ndef is_valid_phone(phone: str, country_code: str = \"US\") -&gt; bool:\n    \"\"\"Validate phone number format.\n\n    Args:\n        phone: Phone number to validate\n        country_code: ISO 3166-1 alpha-2 country code\n\n    Returns:\n        True if phone format is valid for country, False otherwise\n\n    Example:\n        &gt;&gt;&gt; is_valid_phone(\"+1-555-123-4567\", \"US\")\n        True\n        &gt;&gt;&gt; is_valid_phone(\"123\", \"US\")\n        False\n\n    Note:\n        For production, consider using phonenumbers library for\n        comprehensive international phone validation.\n    \"\"\"\n    # Remove common separators\n    cleaned = re.sub(r'[\\s\\-\\(\\)\\.]', '', phone)\n\n    if country_code == \"US\":\n        # US: 10 digits, optional +1 prefix\n        pattern = r'^(\\+1)?[2-9]\\d{9}$'\n        return bool(re.match(pattern, cleaned))\n\n    # Generic: 7-15 digits, optional + prefix\n    pattern = r'^\\+?\\d{7,15}$'\n    return bool(re.match(pattern, cleaned))\n\n\ndef is_valid_uuid(value: str) -&gt; bool:\n    \"\"\"Validate UUID format.\n\n    Args:\n        value: String to validate as UUID\n\n    Returns:\n        True if valid UUID format, False otherwise\n\n    Example:\n        &gt;&gt;&gt; is_valid_uuid(\"123e4567-e89b-12d3-a456-426614174000\")\n        True\n        &gt;&gt;&gt; is_valid_uuid(\"invalid-uuid\")\n        False\n    \"\"\"\n    try:\n        UUID(value)\n        return True\n    except (ValueError, AttributeError):\n        return False\n\n\ndef is_valid_url(url: str, require_https: bool = False) -&gt; bool:\n    \"\"\"Validate URL format.\n\n    Args:\n        url: URL string to validate\n        require_https: If True, only accept HTTPS URLs\n\n    Returns:\n        True if valid URL format, False otherwise\n\n    Example:\n        &gt;&gt;&gt; is_valid_url(\"https://example.com/path\")\n        True\n        &gt;&gt;&gt; is_valid_url(\"not-a-url\")\n        False\n    \"\"\"\n    if require_https:\n        pattern = r'^https://[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(/.*)?$'\n    else:\n        pattern = r'^https?://[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(/.*)?$'\n\n    return bool(re.match(pattern, url))\n\n\ndef validate_password_strength(\n    password: str,\n    min_length: int = 8,\n    require_uppercase: bool = True,\n    require_lowercase: bool = True,\n    require_digit: bool = True,\n    require_special: bool = True,\n) -&gt; tuple[bool, Optional[str]]:\n    \"\"\"Validate password meets strength requirements.\n\n    Args:\n        password: Password to validate\n        min_length: Minimum password length\n        require_uppercase: Require at least one uppercase letter\n        require_lowercase: Require at least one lowercase letter\n        require_digit: Require at least one digit\n        require_special: Require at least one special character\n\n    Returns:\n        Tuple of (is_valid, error_message)\n        error_message is None if valid\n\n    Example:\n        &gt;&gt;&gt; validate_password_strength(\"Weak123!\")\n        (True, None)\n        &gt;&gt;&gt; validate_password_strength(\"weak\")\n        (False, \"Password must be at least 8 characters\")\n    \"\"\"\n    if len(password) &lt; min_length:\n        return False, f\"Password must be at least {min_length} characters\"\n\n    if require_uppercase and not re.search(r'[A-Z]', password):\n        return False, \"Password must contain at least one uppercase letter\"\n\n    if require_lowercase and not re.search(r'[a-z]', password):\n        return False, \"Password must contain at least one lowercase letter\"\n\n    if require_digit and not re.search(r'\\d', password):\n        return False, \"Password must contain at least one digit\"\n\n    if require_special and not re.search(r'[!@#$%^&amp;*(),.?\":{}|&lt;&gt;]', password):\n        return False, \"Password must contain at least one special character\"\n\n    return True, None\n\n\n# Add more validators: is_valid_slug, is_valid_hex_color, etc.\n</code></pre> <p>3. exceptions.py - Base Exception Hierarchy</p> <pre><code>\"\"\"Base exception classes for framework services.\n\nProvides consistent exception hierarchy with proper HTTP status code\nmapping for API services.\n\"\"\"\n\nfrom typing import Optional, Any\n\n\nclass BaseServiceException(Exception):\n    \"\"\"Base exception for all service errors.\n\n    All custom exceptions should inherit from this class\n    to enable consistent error handling.\n\n    Attributes:\n        message: Human-readable error message\n        error_code: Machine-readable error code (e.g., \"USER_NOT_FOUND\")\n        status_code: HTTP status code for API responses\n        details: Additional error context\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        error_code: str,\n        status_code: int = 500,\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"Initialize service exception.\n\n        Args:\n            message: Error message for users/logs\n            error_code: Structured error code\n            status_code: HTTP status code\n            details: Optional additional context\n        \"\"\"\n        super().__init__(message)\n        self.message = message\n        self.error_code = error_code\n        self.status_code = status_code\n        self.details = details or {}\n\n\nclass NotFoundError(BaseServiceException):\n    \"\"\"Resource not found (HTTP 404).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Resource not found\",\n        error_code: str = \"NOT_FOUND\",\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=404,\n            details=details,\n        )\n\n\nclass ValidationError(BaseServiceException):\n    \"\"\"Validation failed (HTTP 422).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Validation failed\",\n        error_code: str = \"VALIDATION_ERROR\",\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=422,\n            details=details,\n        )\n\n\nclass UnauthorizedError(BaseServiceException):\n    \"\"\"Authentication required (HTTP 401).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Authentication required\",\n        error_code: str = \"UNAUTHORIZED\",\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=401,\n            details=details,\n        )\n\n\nclass ForbiddenError(BaseServiceException):\n    \"\"\"Permission denied (HTTP 403).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Permission denied\",\n        error_code: str = \"FORBIDDEN\",\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=403,\n            details=details,\n        )\n\n\nclass ConflictError(BaseServiceException):\n    \"\"\"Resource conflict (HTTP 409).\n\n    Example: Trying to create user with existing email.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Resource conflict\",\n        error_code: str = \"CONFLICT\",\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=409,\n            details=details,\n        )\n\n\nclass ExternalServiceError(BaseServiceException):\n    \"\"\"External service call failed (HTTP 502/503).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"External service unavailable\",\n        error_code: str = \"EXTERNAL_SERVICE_ERROR\",\n        status_code: int = 503,\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=status_code,\n            details=details,\n        )\n\n\nclass RateLimitError(BaseServiceException):\n    \"\"\"Rate limit exceeded (HTTP 429).\"\"\"\n\n    def __init__(\n        self,\n        message: str = \"Rate limit exceeded\",\n        error_code: str = \"RATE_LIMIT_EXCEEDED\",\n        retry_after: Optional[int] = None,\n        details: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        details = details or {}\n        if retry_after:\n            details[\"retry_after\"] = retry_after\n\n        super().__init__(\n            message=message,\n            error_code=error_code,\n            status_code=429,\n            details=details,\n        )\n</code></pre> <p>4. pagination.py - Offset and Cursor Pagination</p> <pre><code>\"\"\"Pagination utilities for API responses.\n\nSupports both offset-based and cursor-based pagination patterns.\n\"\"\"\n\nfrom typing import Generic, TypeVar, Optional\nfrom pydantic import BaseModel, Field\n\n\nT = TypeVar(\"T\")\n\n\nclass OffsetPaginationParams(BaseModel):\n    \"\"\"Query parameters for offset-based pagination.\n\n    Example:\n        GET /users?limit=20&amp;offset=40\n    \"\"\"\n\n    limit: int = Field(default=20, ge=1, le=100, description=\"Items per page\")\n    offset: int = Field(default=0, ge=0, description=\"Items to skip\")\n\n    @property\n    def skip(self) -&gt; int:\n        \"\"\"Alias for offset (used in database queries).\"\"\"\n        return self.offset\n\n\nclass OffsetPaginatedResponse(BaseModel, Generic[T]):\n    \"\"\"Response structure for offset-based pagination.\n\n    Attributes:\n        items: List of items for current page\n        total: Total number of items across all pages\n        limit: Items per page\n        offset: Current offset\n        has_next: Whether there are more pages\n    \"\"\"\n\n    items: list[T]\n    total: int\n    limit: int\n    offset: int\n\n    @property\n    def has_next(self) -&gt; bool:\n        \"\"\"Check if there are more pages.\"\"\"\n        return self.offset + self.limit &lt; self.total\n\n    @property\n    def has_previous(self) -&gt; bool:\n        \"\"\"Check if there is a previous page.\"\"\"\n        return self.offset &gt; 0\n\n\nclass CursorPaginationParams(BaseModel):\n    \"\"\"Query parameters for cursor-based pagination.\n\n    Cursor pagination is more efficient for large datasets\n    and prevents issues with concurrent modifications.\n\n    Example:\n        GET /posts?limit=20&amp;cursor=eyJpZCI6MTIzfQ\n    \"\"\"\n\n    limit: int = Field(default=20, ge=1, le=100, description=\"Items per page\")\n    cursor: Optional[str] = Field(default=None, description=\"Pagination cursor\")\n\n\nclass CursorPaginatedResponse(BaseModel, Generic[T]):\n    \"\"\"Response structure for cursor-based pagination.\n\n    Attributes:\n        items: List of items for current page\n        next_cursor: Cursor for next page (None if last page)\n        has_next: Whether there are more pages\n    \"\"\"\n\n    items: list[T]\n    next_cursor: Optional[str] = None\n\n    @property\n    def has_next(self) -&gt; bool:\n        \"\"\"Check if there are more pages.\"\"\"\n        return self.next_cursor is not None\n\n\ndef create_cursor(entity_id: int) -&gt; str:\n    \"\"\"Create base64-encoded cursor from entity ID.\n\n    Args:\n        entity_id: ID of last entity in current page\n\n    Returns:\n        Base64-encoded cursor string\n\n    Example:\n        &gt;&gt;&gt; create_cursor(123)\n        'eyJpZCI6MTIzfQ=='\n    \"\"\"\n    import base64\n    import json\n\n    cursor_data = {\"id\": entity_id}\n    cursor_json = json.dumps(cursor_data)\n    return base64.b64encode(cursor_json.encode()).decode()\n\n\ndef parse_cursor(cursor: str) -&gt; dict:\n    \"\"\"Parse base64-encoded cursor to extract entity ID.\n\n    Args:\n        cursor: Base64-encoded cursor string\n\n    Returns:\n        Dictionary with cursor data (contains 'id' key)\n\n    Raises:\n        ValueError: If cursor format is invalid\n\n    Example:\n        &gt;&gt;&gt; parse_cursor('eyJpZCI6MTIzfQ==')\n        {'id': 123}\n    \"\"\"\n    import base64\n    import json\n\n    try:\n        cursor_json = base64.b64decode(cursor.encode()).decode()\n        return json.loads(cursor_json)\n    except (ValueError, KeyError) as e:\n        raise ValueError(f\"Invalid cursor format: {e}\")\n</code></pre> <p>5. request_id.py - Correlation ID Management</p> <pre><code>\"\"\"Request ID (correlation ID) management for distributed tracing.\n\nProvides context variables for propagating request IDs across\nasync function calls and service boundaries.\n\"\"\"\n\nimport uuid\nfrom contextvars import ContextVar\nfrom typing import Optional\n\n\n# Context variable for current request ID\n_request_id_ctx_var: ContextVar[Optional[str]] = ContextVar(\n    \"request_id\", default=None\n)\n\n\ndef generate_request_id() -&gt; str:\n    \"\"\"Generate new UUID-based request ID.\n\n    Returns:\n        UUID string in format: req_xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n\n    Example:\n        &gt;&gt;&gt; generate_request_id()\n        'req_123e4567-e89b-12d3-a456-426614174000'\n    \"\"\"\n    return f\"req_{uuid.uuid4()}\"\n\n\ndef set_request_id(request_id: str) -&gt; None:\n    \"\"\"Set request ID in context.\n\n    This should be called at the start of request processing\n    (e.g., in FastAPI middleware or Aiogram middleware).\n\n    Args:\n        request_id: Request ID to set\n\n    Example:\n        &gt;&gt;&gt; set_request_id(\"req_123\")\n        &gt;&gt;&gt; get_request_id()\n        'req_123'\n    \"\"\"\n    _request_id_ctx_var.set(request_id)\n\n\ndef get_request_id() -&gt; Optional[str]:\n    \"\"\"Get current request ID from context.\n\n    Returns:\n        Current request ID, or None if not set\n\n    Example:\n        &gt;&gt;&gt; set_request_id(\"req_123\")\n        &gt;&gt;&gt; get_request_id()\n        'req_123'\n    \"\"\"\n    return _request_id_ctx_var.get()\n\n\ndef get_or_generate_request_id() -&gt; str:\n    \"\"\"Get current request ID or generate new one.\n\n    This is useful for background tasks that may not have\n    a request ID set in context.\n\n    Returns:\n        Current request ID or newly generated one\n\n    Example:\n        &gt;&gt;&gt; get_or_generate_request_id()  # No request ID set\n        'req_abc-123...'\n        &gt;&gt;&gt; set_request_id(\"req_xyz\")\n        &gt;&gt;&gt; get_or_generate_request_id()  # Request ID is set\n        'req_xyz'\n    \"\"\"\n    request_id = get_request_id()\n    if request_id is None:\n        request_id = generate_request_id()\n        set_request_id(request_id)\n    return request_id\n</code></pre> <p>6. shared/utils/README.md - Usage Documentation</p> <pre><code># Shared Utilities\n\nReusable utility functions and classes used across all framework services.\n\n## Purpose\n\nThese utilities eliminate code duplication by providing:\n- \u2705 Structured JSON logging (no duplication of logging setup)\n- \u2705 Common validators (no duplication of email/phone/UUID validation)\n- \u2705 Base exception hierarchy (consistent error handling)\n- \u2705 Pagination helpers (no duplication of pagination logic)\n- \u2705 Request ID management (distributed tracing support)\n\n## Design Principles\n\n**100% Universal:**\n- No business logic\n- No project-specific code\n- No database or external service dependencies\n\n**Type-Safe:**\n- 100% type hint coverage\n- Passes mypy strict mode\n\n**Well-Tested:**\n- 100% test coverage\n- Comprehensive docstrings with examples\n\n## Usage Guide\n\n### Logger\n\n**Problem:** Every service duplicates logging configuration\n\n**Solution:** Use `create_logger` factory\n\n```python\n# \u274c BEFORE - Duplicated in every service\nimport logging\nimport sys\nfrom pythonjsonlogger import jsonlogger\n\nhandler = logging.StreamHandler(sys.stdout)\nformatter = jsonlogger.JsonFormatter(\"%(asctime)s %(name)s ...\")\nhandler.setFormatter(formatter)\nlogger = logging.getLogger(__name__)\nlogger.addHandler(handler)\n\n# \u2705 AFTER - One line, consistent across all services\nfrom shared.utils.logger import create_logger\n\nlogger = create_logger(__name__)\nlogger.info(\"User authenticated\", extra={\"user_id\": 123})\n</code></pre> <p>[... continue with usage examples for each utility ...] <pre><code>**Testing Strategy:**\n\n```python\n# tests/unit/shared/utils/test_logger.py\nimport pytest\nimport logging\nimport json\nfrom io import StringIO\n\nfrom shared.utils.logger import create_logger, configure_uvicorn_logging\n\n\ndef test_create_logger_json_format(caplog):\n    \"\"\"Logger should output JSON formatted logs.\"\"\"\n    logger = create_logger(\"test_service\", level=\"INFO\")\n\n    with caplog.at_level(logging.INFO):\n        logger.info(\"Test message\", extra={\"user_id\": 123})\n\n    log_output = caplog.records[0]\n    assert log_output.name == \"test_service\"\n    assert log_output.levelname == \"INFO\"\n    assert log_output.getMessage() == \"Test message\"\n    # Verify JSON structure in formatter output\n\n\ndef test_create_logger_no_duplicate_handlers():\n    \"\"\"Creating logger twice should not add duplicate handlers.\"\"\"\n    logger1 = create_logger(\"test_service\")\n    initial_handlers = len(logger1.handlers)\n\n    logger2 = create_logger(\"test_service\")\n    final_handlers = len(logger2.handlers)\n\n    assert initial_handlers == final_handlers == 1\n\n\n# ... more tests for validators, exceptions, pagination, request_id ...\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#task-13-implement-data-service-template-postgresql","title":"Task 1.3: Implement Data Service Template (PostgreSQL)","text":"<p>Status: \u23f8\ufe0f Not Started Priority: \ud83d\udd34 CRITICAL Estimated Time: 16 hours Owner: TBD</p> <p>Objective: Create complete PostgreSQL data service template to eliminate reinventing data layer.</p> <p>Files to Create: Directory structure: <pre><code>templates/services/template_data_postgres_api/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 pytest.ini\n\u251c\u2500\u2500 .env.example\n\u251c\u2500\u2500 alembic/\n\u2502   \u251c\u2500\u2500 env.py\n\u2502   \u251c\u2500\u2500 script.py.mako\n\u2502   \u2514\u2500\u2500 versions/\n\u2502       \u2514\u2500\u2500 001_initial_schema.py\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py                        # FastAPI app\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 config.py                  # Settings\n\u2502   \u2502   \u251c\u2500\u2500 database.py                # SQLAlchemy setup\n\u2502   \u2502   \u2514\u2500\u2500 logging_config.py          # Uses shared/utils/logger\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 base.py                    # SQLAlchemy Base + mixins\n\u2502   \u251c\u2500\u2500 repositories/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 base_repository.py         # Generic CRUD repository\n\u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 base.py                    # Pydantic base schemas\n\u2502   \u2514\u2500\u2500 api/\n\u2502       \u2514\u2500\u2500 v1/\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 health.py              # Health check endpoint\n\u2502           \u2514\u2500\u2500 router.py              # Main router\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 conftest.py                    # Shared fixtures\n    \u251c\u2500\u2500 unit/\n    \u2502   \u2514\u2500\u2500 repositories/\n    \u2502       \u2514\u2500\u2500 test_base_repository.py\n    \u2514\u2500\u2500 integration/\n        \u2514\u2500\u2500 test_database_connection.py\n</code></pre></p> <p>Acceptance Criteria: - [ ] SQLAlchemy 2.0+ with async support - [ ] Base model with id, created_at, updated_at columns - [ ] Generic repository with CRUD operations (create, get, list, update, delete) - [ ] Alembic migrations configured - [ ] Health check endpoint verifies database connectivity - [ ] Integration tests use Testcontainers for PostgreSQL - [ ] Connection pooling configured (min 5, max 20) - [ ] All database operations use async/await - [ ] 100% type hint coverage - [ ] Comprehensive docstrings</p> <p>Implementation Details:</p> <p>core/database.py - SQLAlchemy Async Setup</p> <pre><code>\"\"\"Database connection and session management.\n\nProvides async SQLAlchemy engine and session factory with\nconnection pooling and health check support.\n\"\"\"\n\nfrom typing import AsyncGenerator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import (\n    AsyncSession,\n    AsyncEngine,\n    create_async_engine,\n    async_sessionmaker,\n)\nfrom sqlalchemy.pool import NullPool, QueuePool\n\nfrom core.config import settings\nfrom shared.utils.logger import create_logger\n\n\nlogger = create_logger(__name__)\n\n\ndef create_engine() -&gt; AsyncEngine:\n    \"\"\"Create async SQLAlchemy engine with connection pooling.\n\n    Returns:\n        Configured async engine instance\n\n    Configuration:\n        - Pool size: 5-20 connections (min-max)\n        - Pool pre-ping: True (verify connections before use)\n        - Echo: True in development (log SQL queries)\n        - Connect args: prepared statements disabled for better compatibility\n    \"\"\"\n    return create_async_engine(\n        settings.DATABASE_URL,\n        echo=settings.DEBUG,\n        poolclass=QueuePool if not settings.TESTING else NullPool,\n        pool_size=5,\n        max_overflow=15,\n        pool_pre_ping=True,\n        connect_args={\n            \"prepared_statement_cache_size\": 0,  # Disable for pgbouncer compatibility\n        },\n    )\n\n\n# Global engine instance (created once at startup)\nengine: AsyncEngine = create_engine()\n\n# Session factory\nAsyncSessionLocal = async_sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n)\n\n\nasync def get_session() -&gt; AsyncGenerator[AsyncSession, None]:\n    \"\"\"Dependency for FastAPI endpoints to get database session.\n\n    Yields:\n        Async session instance\n\n    Example:\n        &gt;&gt;&gt; from fastapi import Depends\n        &gt;&gt;&gt; @app.get(\"/users/{user_id}\")\n        &gt;&gt;&gt; async def get_user(\n        &gt;&gt;&gt;     user_id: int,\n        &gt;&gt;&gt;     session: AsyncSession = Depends(get_session)\n        &gt;&gt;&gt; ):\n        &gt;&gt;&gt;     user = await session.get(UserModel, user_id)\n        &gt;&gt;&gt;     return user\n    \"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception as e:\n            await session.rollback()\n            logger.error(f\"Database session error: {e}\")\n            raise\n        finally:\n            await session.close()\n\n\nasync def check_database_connection() -&gt; bool:\n    \"\"\"Check if database is accessible.\n\n    Returns:\n        True if database connection successful, False otherwise\n\n    Used by health check endpoint to verify database status.\n    \"\"\"\n    try:\n        async with AsyncSessionLocal() as session:\n            await session.execute(\"SELECT 1\")\n            return True\n    except Exception as e:\n        logger.error(f\"Database health check failed: {e}\")\n        return False\n\n\n@asynccontextmanager\nasync def get_session_context():\n    \"\"\"Context manager for manual session management.\n\n    Use when you need explicit transaction control outside\n    of FastAPI dependency injection.\n\n    Example:\n        &gt;&gt;&gt; async with get_session_context() as session:\n        &gt;&gt;&gt;     user = await session.get(UserModel, 1)\n        &gt;&gt;&gt;     user.name = \"Updated\"\n        &gt;&gt;&gt;     # Committed automatically on context exit\n    \"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n</code></pre> <p>models/base.py - Base Model with Timestamp Mixins</p> <pre><code>\"\"\"Base SQLAlchemy model and mixins.\n\nProvides base model class with common columns and utility methods.\n\"\"\"\n\nfrom datetime import datetime\nfrom typing import Any\n\nfrom sqlalchemy import Column, Integer, DateTime\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import declared_attr\n\n\nclass CustomBase:\n    \"\"\"Base class with common columns and methods.\"\"\"\n\n    # Primary key (all tables have 'id')\n    id = Column(Integer, primary_key=True, index=True)\n\n    @declared_attr\n    def __tablename__(cls) -&gt; str:\n        \"\"\"Generate __tablename__ from class name.\n\n        Example:\n            UserModel -&gt; user_model\n            PostComment -&gt; post_comment\n        \"\"\"\n        import re\n        # Convert CamelCase to snake_case\n        name = cls.__name__\n        return re.sub(r'(?&lt;!^)(?=[A-Z])', '_', name).lower()\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert model instance to dictionary.\n\n        Returns:\n            Dictionary with all column values\n\n        Example:\n            &gt;&gt;&gt; user = UserModel(id=1, email=\"user@example.com\")\n            &gt;&gt;&gt; user.to_dict()\n            {'id': 1, 'email': 'user@example.com', 'created_at': '...'}\n        \"\"\"\n        return {\n            column.name: getattr(self, column.name)\n            for column in self.__table__.columns\n        }\n\n\nBase = declarative_base(cls=CustomBase)\n\n\nclass TimestampMixin:\n    \"\"\"Mixin for created_at and updated_at timestamps.\n\n    Usage:\n        &gt;&gt;&gt; class UserModel(Base, TimestampMixin):\n        &gt;&gt;&gt;     email = Column(String, unique=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Automatically has created_at and updated_at columns\n    \"\"\"\n\n    created_at = Column(\n        DateTime,\n        default=datetime.utcnow,\n        nullable=False,\n        doc=\"Timestamp when record was created\",\n    )\n\n    updated_at = Column(\n        DateTime,\n        default=datetime.utcnow,\n        onupdate=datetime.utcnow,\n        nullable=False,\n        doc=\"Timestamp when record was last updated\",\n    )\n</code></pre> <p>repositories/base_repository.py - Generic CRUD Repository</p> <pre><code>\"\"\"Base repository with generic CRUD operations.\n\nProvides reusable repository pattern for all models, eliminating\ncode duplication for common database operations.\n\"\"\"\n\nfrom typing import Generic, TypeVar, Type, Optional, Sequence\n\nfrom sqlalchemy import select, update, delete\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom models.base import Base\n\n\nModelType = TypeVar(\"ModelType\", bound=Base)\n\n\nclass BaseRepository(Generic[ModelType]):\n    \"\"\"Generic repository with CRUD operations.\n\n    This repository implements common database operations that work\n    with any SQLAlchemy model. Inherit from this class for\n    model-specific repositories.\n\n    Example:\n        &gt;&gt;&gt; class UserRepository(BaseRepository[UserModel]):\n        &gt;&gt;&gt;     def __init__(self, session: AsyncSession):\n        &gt;&gt;&gt;         super().__init__(UserModel, session)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt;     async def get_by_email(self, email: str) -&gt; Optional[UserModel]:\n        &gt;&gt;&gt;         result = await self._session.execute(\n        &gt;&gt;&gt;             select(self._model).where(self._model.email == email)\n        &gt;&gt;&gt;         )\n        &gt;&gt;&gt;         return result.scalar_one_or_none()\n    \"\"\"\n\n    def __init__(self, model: Type[ModelType], session: AsyncSession) -&gt; None:\n        \"\"\"Initialize repository.\n\n        Args:\n            model: SQLAlchemy model class\n            session: Async database session\n        \"\"\"\n        self._model = model\n        self._session = session\n\n    async def get_by_id(self, id: int) -&gt; Optional[ModelType]:\n        \"\"\"Get single record by ID.\n\n        Args:\n            id: Primary key value\n\n        Returns:\n            Model instance or None if not found\n        \"\"\"\n        result = await self._session.execute(\n            select(self._model).where(self._model.id == id)\n        )\n        return result.scalar_one_or_none()\n\n    async def get_all(\n        self,\n        skip: int = 0,\n        limit: int = 100,\n    ) -&gt; Sequence[ModelType]:\n        \"\"\"Get all records with pagination.\n\n        Args:\n            skip: Number of records to skip\n            limit: Maximum number of records to return\n\n        Returns:\n            List of model instances\n        \"\"\"\n        result = await self._session.execute(\n            select(self._model).offset(skip).limit(limit)\n        )\n        return result.scalars().all()\n\n    async def create(self, **kwargs) -&gt; ModelType:\n        \"\"\"Create new record.\n\n        Args:\n            **kwargs: Column values for new record\n\n        Returns:\n            Created model instance with generated ID\n\n        Example:\n            &gt;&gt;&gt; user = await repo.create(email=\"user@example.com\", name=\"John\")\n            &gt;&gt;&gt; print(user.id)  # Auto-generated ID\n            1\n        \"\"\"\n        instance = self._model(**kwargs)\n        self._session.add(instance)\n        await self._session.flush()  # Generate ID\n        await self._session.refresh(instance)  # Load defaults\n        return instance\n\n    async def update(self, id: int, **kwargs) -&gt; Optional[ModelType]:\n        \"\"\"Update existing record.\n\n        Args:\n            id: Primary key of record to update\n            **kwargs: Column values to update\n\n        Returns:\n            Updated model instance or None if not found\n\n        Example:\n            &gt;&gt;&gt; user = await repo.update(1, name=\"Jane\", email=\"jane@example.com\")\n        \"\"\"\n        await self._session.execute(\n            update(self._model)\n            .where(self._model.id == id)\n            .values(**kwargs)\n        )\n        return await self.get_by_id(id)\n\n    async def delete(self, id: int) -&gt; bool:\n        \"\"\"Delete record by ID.\n\n        Args:\n            id: Primary key of record to delete\n\n        Returns:\n            True if record was deleted, False if not found\n\n        Example:\n            &gt;&gt;&gt; deleted = await repo.delete(1)\n            &gt;&gt;&gt; print(deleted)\n            True\n        \"\"\"\n        result = await self._session.execute(\n            delete(self._model).where(self._model.id == id)\n        )\n        return result.rowcount &gt; 0\n\n    async def count(self) -&gt; int:\n        \"\"\"Count total number of records.\n\n        Returns:\n            Total record count\n\n        Example:\n            &gt;&gt;&gt; total = await repo.count()\n            &gt;&gt;&gt; print(f\"Total users: {total}\")\n            Total users: 150\n        \"\"\"\n        result = await self._session.execute(\n            select(func.count()).select_from(self._model)\n        )\n        return result.scalar()\n</code></pre> <p>[... Continue with alembic setup, health check endpoint, tests ...]</p> <p>Testing Strategy:</p> <pre><code># tests/integration/test_database_connection.py\nimport pytest\nfrom testcontainers.postgres import PostgresContainer\n\nfrom core.database import create_engine, check_database_connection\n\n\n@pytest.fixture(scope=\"module\")\ndef postgres_container():\n    \"\"\"Start PostgreSQL container for tests.\"\"\"\n    with PostgresContainer(\"postgres:15\") as postgres:\n        yield postgres\n\n\n@pytest.fixture\ndef database_url(postgres_container):\n    \"\"\"Get database URL from container.\"\"\"\n    return postgres_container.get_connection_url().replace(\n        \"psycopg2\", \"asyncpg\"\n    )\n\n\n@pytest.mark.asyncio\nasync def test_database_connection(database_url, monkeypatch):\n    \"\"\"Database connection should succeed with valid credentials.\"\"\"\n    monkeypatch.setenv(\"DATABASE_URL\", database_url)\n\n    is_connected = await check_database_connection()\n\n    assert is_connected is True\n\n\n@pytest.mark.asyncio\nasync def test_database_connection_failure(monkeypatch):\n    \"\"\"Database connection should fail with invalid credentials.\"\"\"\n    monkeypatch.setenv(\"DATABASE_URL\", \"postgresql+asyncpg://invalid:invalid@localhost:5432/invalid\")\n\n    is_connected = await check_database_connection()\n\n    assert is_connected is False\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#task-14-add-automated-quality-gates-to-ci-pipeline","title":"Task 1.4: Add Automated Quality Gates to CI Pipeline","text":"<p>Status: \u23f8\ufe0f Not Started Priority: \ud83d\udd34 CRITICAL Estimated Time: 4 hours Owner: TBD</p> <p>Objective: Add automated checks to CI pipeline to enforce DRY/KISS/YAGNI principles.</p> <p>Files to Update: - <code>.ai-framework/templates/ci-cd/.github/workflows/ci.yml</code></p> <p>Acceptance Criteria: - [ ] CI checks code duplication with jscpd (fail if &gt;10%) - [ ] CI checks cyclomatic complexity with radon (fail if any function &gt;10) - [ ] CI checks maintainability index with radon (fail if any file 30 for Level 1-2) - [ ] CI checks file size (fail if any file &gt;500 lines) - [ ] All checks have clear error messages explaining violations - [ ] Documentation updated with CI check descriptions <p>Implementation Details:</p> <p>Updated CI Workflow:</p> <pre><code>name: CI Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  # Existing jobs\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install ruff mypy\n          pip install -r requirements.txt\n\n      - name: Lint with Ruff\n        run: ruff check .\n\n      - name: Type check with Mypy\n        run: mypy src/ --strict\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install pytest pytest-cov pytest-asyncio\n          pip install -r requirements.txt\n\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ \\\n            --cov=src \\\n            --cov-report=xml \\\n            --cov-report=term-missing \\\n            --cov-fail-under=80\n\n  # NEW: DRY/KISS/YAGNI Enforcement Jobs\n  check-duplication:\n    name: Check Code Duplication (DRY)\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install jscpd\n        run: npm install -g jscpd\n\n      - name: Check for code duplication\n        run: |\n          echo \"Checking code duplication (DRY principle)...\"\n          echo \"Threshold: 10% (will fail if higher)\"\n\n          jscpd src/ \\\n            --threshold 10 \\\n            --format \"python\" \\\n            --reporters \"console,html\" \\\n            --output \"./jscpd-report\" \\\n            --exitCode 1 || {\n              echo \"\"\n              echo \"\u274c DRY VIOLATION: Code duplication exceeds 10% threshold\"\n              echo \"\"\n              echo \"Duplicated code violates the DRY (Don't Repeat Yourself) principle.\"\n              echo \"Consider extracting shared code to:\"\n              echo \"  - shared/utils/ for reusable utilities\"\n              echo \"  - infrastructure/ for HTTP clients, messaging, etc.\"\n              echo \"  - Base classes for common patterns\"\n              echo \"\"\n              echo \"See detailed report in jscpd-report/jscpd-report.html\"\n              echo \"\"\n              echo \"Learn more: docs/guides/dry-kiss-yagni-principles.md#dry\"\n              exit 1\n            }\n\n      - name: Upload duplication report\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: jscpd-report\n          path: ./jscpd-report\n\n  check-complexity:\n    name: Check Code Complexity (KISS)\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install radon\n        run: pip install radon\n\n      - name: Check cyclomatic complexity\n        run: |\n          echo \"Checking cyclomatic complexity (KISS principle)...\"\n          echo \"Threshold: McCabe complexity &lt; 10 for all functions\"\n\n          radon cc src/ --min B --total-average --show-complexity || {\n            echo \"\"\n            echo \"\u274c KISS VIOLATION: Functions with complexity &gt;= 10 detected\"\n            echo \"\"\n            echo \"Complex functions violate the KISS (Keep It Simple) principle.\"\n            echo \"Consider refactoring by:\"\n            echo \"  - Breaking large functions into smaller ones\"\n            echo \"  - Extracting conditional logic into separate functions\"\n            echo \"  - Using early returns to reduce nesting\"\n            echo \"  - Applying strategy pattern for complex conditionals\"\n            echo \"\"\n            echo \"Learn more: docs/guides/dry-kiss-yagni-principles.md#kiss\"\n            exit 1\n          }\n\n      - name: Check maintainability index\n        run: |\n          echo \"Checking maintainability index (KISS principle)...\"\n          echo \"Threshold: Grade B or better (MI &gt;= 20)\"\n\n          radon mi src/ --min B --show || {\n            echo \"\"\n            echo \"\u274c KISS VIOLATION: Low maintainability index detected\"\n            echo \"\"\n            echo \"Low maintainability indicates overly complex code.\"\n            echo \"Maintainability Index considers:\"\n            echo \"  - Cyclomatic complexity\"\n            echo \"  - Lines of code\"\n            echo \"  - Halstead volume\"\n            echo \"  - Comment density\"\n            echo \"\"\n            echo \"Learn more: docs/guides/dry-kiss-yagni-principles.md#kiss\"\n            exit 1\n          }\n\n      - name: Check file sizes\n        run: |\n          echo \"Checking file sizes (KISS principle)...\"\n          echo \"Threshold: No file &gt; 500 lines\"\n\n          large_files=$(find src/ -name \"*.py\" -type f -exec wc -l {} \\; | awk '$1 &gt; 500 {print $2, \"(\"$1\" lines)\"}')\n\n          if [ -n \"$large_files\" ]; then\n            echo \"\"\n            echo \"\u274c KISS VIOLATION: Files exceeding 500 lines detected\"\n            echo \"\"\n            echo \"$large_files\"\n            echo \"\"\n            echo \"Large files are harder to understand and maintain.\"\n            echo \"Consider splitting into:\"\n            echo \"  - Multiple focused modules\"\n            echo \"  - Separate classes with single responsibilities\"\n            echo \"  - Service layer + repository layer\"\n            echo \"\"\n            echo \"Learn more: docs/guides/dry-kiss-yagni-principles.md#kiss\"\n            exit 1\n          fi\n\n  check-dependencies:\n    name: Check Dependency Bloat (YAGNI)\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Check dependency count\n        run: |\n          echo \"Checking dependency count (YAGNI principle)...\"\n\n          # Count non-comment, non-empty lines in requirements.txt\n          dep_count=$(grep -v '^#' requirements.txt | grep -v '^$' | wc -l)\n\n          echo \"Total dependencies: $dep_count\"\n\n          # Threshold varies by maturity level\n          # Level 1-2: max 30, Level 3-4: max 50\n          # For template validation, use Level 2 threshold\n          threshold=30\n\n          if [ $dep_count -gt $threshold ]; then\n            echo \"\"\n            echo \"\u274c YAGNI VIOLATION: Too many dependencies ($dep_count &gt; $threshold)\"\n            echo \"\"\n            echo \"Excessive dependencies indicate:\"\n            echo \"  - Features that aren't needed yet (YAGNI)\"\n            echo \"  - Increased attack surface\"\n            echo \"  - Slower installation and docker builds\"\n            echo \"\"\n            echo \"Review each dependency:\"\n            echo \"  - Is it required for current maturity level?\"\n            echo \"  - Can we use stdlib instead?\"\n            echo \"  - Are there unused dependencies from earlier iterations?\"\n            echo \"\"\n            echo \"Learn more: docs/guides/dry-kiss-yagni-principles.md#yagni\"\n            exit 1\n          fi\n\n      - name: Check for unused dependencies\n        run: |\n          pip install pip-check || true\n\n          echo \"Checking for unused dependencies...\"\n          pip-check --verbose || {\n            echo \"\"\n            echo \"\u26a0\ufe0f  WARNING: Some dependencies may be unused\"\n            echo \"Consider running: pip-autoremove to clean up\"\n          }\n\n  # Summary job\n  quality-gates:\n    name: Quality Gates Summary\n    runs-on: ubuntu-latest\n    needs: [lint, test, check-duplication, check-complexity, check-dependencies]\n    if: always()\n    steps:\n      - name: Check all gates passed\n        run: |\n          echo \"Quality Gates Status:\"\n          echo \"  - Linting: ${{ needs.lint.result }}\"\n          echo \"  - Tests: ${{ needs.test.result }}\"\n          echo \"  - DRY (Duplication): ${{ needs.check-duplication.result }}\"\n          echo \"  - KISS (Complexity): ${{ needs.check-complexity.result }}\"\n          echo \"  - YAGNI (Dependencies): ${{ needs.check-dependencies.result }}\"\n\n          if [[ \"${{ needs.lint.result }}\" != \"success\" ]] || \\\n             [[ \"${{ needs.test.result }}\" != \"success\" ]] || \\\n             [[ \"${{ needs.check-duplication.result }}\" != \"success\" ]] || \\\n             [[ \"${{ needs.check-complexity.result }}\" != \"success\" ]] || \\\n             [[ \"${{ needs.check-dependencies.result }}\" != \"success\" ]]; then\n            echo \"\"\n            echo \"\u274c Quality gates failed. See job details above.\"\n            exit 1\n          fi\n\n          echo \"\"\n          echo \"\u2705 All quality gates passed!\"\n</code></pre> <p>Documentation Update:</p> <p>Create <code>.ai-framework/docs/quality/automated-quality-gates.md</code>:</p> <pre><code># Automated Quality Gates\n\n## Overview\n\nThe CI pipeline enforces DRY, KISS, and YAGNI principles through automated checks.\n\n## Quality Gate Jobs\n\n### 1. check-duplication (DRY Enforcement)\n\n**Tool:** jscpd (JavaScript Copy/Paste Detector)\n**Threshold:** 10% duplication max\n**Fails if:** Code duplication exceeds threshold\n\n**What it checks:**\n- Duplicated code blocks across files\n- Copy-paste patterns\n- Similar code structures\n\n**How to fix:**\n```bash\n# Generate duplication report locally\nnpm install -g jscpd\njscpd src/ --reporters \"console,html\" --output \"./report\"\nopen report/jscpd-report.html\n\n# Common fixes:\n# 1. Extract to shared/utils/\n# 2. Create base classes\n# 3. Use composition over duplication\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#2-check-complexity-kiss-enforcement","title":"2. check-complexity (KISS Enforcement)","text":"<p>Tool: radon Thresholds: - McCabe complexity &lt; 10 per function - Maintainability Index &gt;= 20 (Grade B) - File size &lt; 500 lines</p> <p>Fails if: Any function/file exceeds thresholds</p> <p>What it checks: - Cyclomatic complexity (number of code paths) - Maintainability index (composite metric) - File sizes</p> <p>How to fix: <pre><code># Check complexity locally\npip install radon\nradon cc src/ --show-complexity\nradon mi src/ --show\n\n# Find large files\nfind src/ -name \"*.py\" -exec wc -l {} \\; | sort -rn | head -10\n\n# Common fixes:\n# 1. Extract methods (Replace Temp with Query)\n# 2. Use early returns (Guard Clauses)\n# 3. Apply strategy pattern\n# 4. Split large classes\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#3-check-dependencies-yagni-enforcement","title":"3. check-dependencies (YAGNI Enforcement)","text":"<p>Tool: grep + pip-check Thresholds: - Level 1-2: max 30 dependencies - Level 3-4: max 50 dependencies</p> <p>Fails if: Dependency count exceeds threshold</p> <p>What it checks: - Total number of dependencies - Unused dependencies</p> <p>How to fix: <pre><code># Check dependencies locally\nwc -l &lt; requirements.txt\n\n# Find unused dependencies\npip install pip-check\npip-check\n\n# Remove unused\npip install pip-autoremove\npip-autoremove &lt;package-name&gt; -y\n\n# Common fixes:\n# 1. Remove dev dependencies from production requirements\n# 2. Use stdlib alternatives\n# 3. Remove dependencies from earlier iterations\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#running-checks-locally","title":"Running Checks Locally","text":"<p>Before pushing, run all checks:</p> <pre><code># Install tools\nnpm install -g jscpd\npip install radon pip-check\n\n# Run checks\nmake quality-check  # If Makefile configured\n\n# Or manually:\njscpd src/ --threshold 10\nradon cc src/ --min B\nradon mi src/ --min B\nfind src/ -name \"*.py\" -exec wc -l {} \\; | awk '$1&gt;500'\nwc -l &lt; requirements.txt\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#ci-badge","title":"CI Badge","text":"<p>Add to README.md:</p> <pre><code>![Quality Gates](https://github.com/your-org/your-repo/actions/workflows/ci.yml/badge.svg)\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#related-documents","title":"Related Documents","text":"<ul> <li>DRY/KISS/YAGNI Principles</li> <li>Code Review Checklist <pre><code>---\n\n### Phase 2: High Priority Improvements (P1)\n\n**Estimated Effort:** 24-30 hours\n**Target Completion:** Week 3\n\n---\n\n#### Task 2.1: Complete Business API Template\n\n**Status:** \u23f8\ufe0f Not Started\n**Priority:** \ud83d\udfe0 HIGH\n**Estimated Time:** 8 hours\n**Owner:** TBD\n\n**Objective:**\nComplete template_business_api/ from 40% to 100% completion.\n\n**Files to Create:**\n1. `src/core/logging_config.py` - Uses shared/utils/logger\n2. `src/core/middleware.py` - Request ID, error handling, CORS\n3. `src/api/v1/health_router.py` - Health check endpoints\n4. `src/infrastructure/http_clients/data_client.py` - HTTP client for data service\n5. `src/infrastructure/http_clients/base_client.py` - Reusable HTTP client base\n6. `src/infrastructure/rabbitmq/publisher.py` - Event publishing\n7. `src/infrastructure/rabbitmq/consumer.py` - Event consumption\n8. `tests/conftest.py` - Shared test fixtures\n\n**Files to Update:**\n- `src/main.py` - Register middleware and routers\n- `templates/README.md` - Update completion status\n\n**Acceptance Criteria:**\n- [ ] All 8 missing files created with comprehensive implementation\n- [ ] Middleware injects request_id into all requests\n- [ ] Middleware handles BaseServiceException with proper HTTP responses\n- [ ] Health check verifies connectivity to data service and RabbitMQ\n- [ ] HTTP client uses httpx with connection pooling\n- [ ] RabbitMQ publisher/consumer use aio-pika\n- [ ] All files fully type-hinted and documented\n- [ ] Unit tests cover 100% of new code\n- [ ] Integration tests verify end-to-end flows\n\n**Implementation Details:**\n\n*src/core/middleware.py*\n\n```python\n\"\"\"FastAPI middleware for request ID injection and error handling.\"\"\"\n\nfrom typing import Callable\nfrom fastapi import Request, Response\nfrom fastapi.responses import JSONResponse\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nfrom shared.utils.request_id import (\n    generate_request_id,\n    set_request_id,\n    get_request_id,\n)\nfrom shared.utils.exceptions import BaseServiceException\nfrom shared.utils.logger import create_logger\n\n\nlogger = create_logger(__name__)\n\n\nclass RequestIdMiddleware(BaseHTTPMiddleware):\n    \"\"\"Inject correlation ID into requests and responses.\n\n    This middleware:\n    1. Extracts X-Request-ID header from incoming request (if present)\n    2. Generates new request ID if not provided\n    3. Sets request ID in context for logging\n    4. Adds X-Request-ID header to response\n    \"\"\"\n\n    async def dispatch(\n        self,\n        request: Request,\n        call_next: Callable,\n    ) -&gt; Response:\n        \"\"\"Process request with request ID injection.\n\n        Args:\n            request: Incoming HTTP request\n            call_next: Next middleware/route handler\n\n        Returns:\n            HTTP response with X-Request-ID header\n        \"\"\"\n        # Extract or generate request ID\n        request_id = request.headers.get(\"X-Request-ID\")\n        if not request_id:\n            request_id = generate_request_id()\n\n        # Set in context for logging\n        set_request_id(request_id)\n\n        # Log request\n        logger.info(\n            f\"{request.method} {request.url.path}\",\n            extra={\n                \"method\": request.method,\n                \"path\": request.url.path,\n                \"query_params\": str(request.query_params),\n            },\n        )\n\n        # Process request\n        response = await call_next(request)\n\n        # Add request ID to response\n        response.headers[\"X-Request-ID\"] = request_id\n\n        # Log response\n        logger.info(\n            f\"Response {response.status_code}\",\n            extra={\n                \"status_code\": response.status_code,\n            },\n        )\n\n        return response\n\n\nclass ExceptionHandlerMiddleware(BaseHTTPMiddleware):\n    \"\"\"Global exception handler for BaseServiceException.\n\n    Converts service exceptions to proper HTTP JSON responses\n    with consistent error structure.\n    \"\"\"\n\n    async def dispatch(\n        self,\n        request: Request,\n        call_next: Callable,\n    ) -&gt; Response:\n        \"\"\"Handle exceptions and convert to JSON responses.\n\n        Args:\n            request: Incoming HTTP request\n            call_next: Next middleware/route handler\n\n        Returns:\n            HTTP response (success or error)\n        \"\"\"\n        try:\n            response = await call_next(request)\n            return response\n\n        except BaseServiceException as e:\n            # Expected service exceptions\n            logger.warning(\n                f\"Service exception: {e.message}\",\n                extra={\n                    \"error_code\": e.error_code,\n                    \"status_code\": e.status_code,\n                    \"details\": e.details,\n                },\n            )\n\n            return JSONResponse(\n                status_code=e.status_code,\n                content={\n                    \"error\": {\n                        \"code\": e.error_code,\n                        \"message\": e.message,\n                        \"details\": e.details,\n                        \"request_id\": get_request_id(),\n                    }\n                },\n                headers={\"X-Request-ID\": get_request_id()},\n            )\n\n        except Exception as e:\n            # Unexpected exceptions\n            logger.error(\n                f\"Unhandled exception: {str(e)}\",\n                exc_info=True,\n                extra={\"exception_type\": type(e).__name__},\n            )\n\n            return JSONResponse(\n                status_code=500,\n                content={\n                    \"error\": {\n                        \"code\": \"INTERNAL_SERVER_ERROR\",\n                        \"message\": \"An unexpected error occurred\",\n                        \"request_id\": get_request_id(),\n                    }\n                },\n                headers={\"X-Request-ID\": get_request_id()},\n            )\n</code></pre></li> </ul> <p>src/api/v1/health_router.py</p> <pre><code>\"\"\"Health check endpoints for monitoring and orchestration.\"\"\"\n\nfrom fastapi import APIRouter, Depends\nfrom pydantic import BaseModel\n\nfrom infrastructure.http_clients.data_client import DataClient, get_data_client\nfrom infrastructure.rabbitmq.publisher import check_rabbitmq_connection\nfrom shared.utils.logger import create_logger\n\n\nlogger = create_logger(__name__)\nrouter = APIRouter(prefix=\"/health\", tags=[\"health\"])\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Health check response structure.\"\"\"\n\n    status: str\n    version: str\n    checks: dict[str, str]\n\n\n@router.get(\"/\", response_model=HealthResponse)\nasync def health_check():\n    \"\"\"Basic health check (liveness probe).\n\n    Returns 200 if service is running.\n    Use this for Kubernetes liveness probe.\n\n    Returns:\n        Health status\n    \"\"\"\n    return HealthResponse(\n        status=\"healthy\",\n        version=\"1.0.0\",  # TODO: Get from config\n        checks={},\n    )\n\n\n@router.get(\"/ready\", response_model=HealthResponse)\nasync def readiness_check(\n    data_client: DataClient = Depends(get_data_client),\n):\n    \"\"\"Readiness check (readiness probe).\n\n    Verifies connectivity to all dependencies:\n    - Data service (PostgreSQL via HTTP)\n    - RabbitMQ (message broker)\n\n    Use this for Kubernetes readiness probe.\n\n    Returns:\n        Health status with dependency checks\n\n    Raises:\n        HTTPException: 503 if any dependency is unhealthy\n    \"\"\"\n    checks = {}\n    all_healthy = True\n\n    # Check data service\n    try:\n        await data_client.health_check()\n        checks[\"data_service\"] = \"healthy\"\n    except Exception as e:\n        logger.error(f\"Data service health check failed: {e}\")\n        checks[\"data_service\"] = \"unhealthy\"\n        all_healthy = False\n\n    # Check RabbitMQ\n    try:\n        is_connected = await check_rabbitmq_connection()\n        checks[\"rabbitmq\"] = \"healthy\" if is_connected else \"unhealthy\"\n        if not is_connected:\n            all_healthy = False\n    except Exception as e:\n        logger.error(f\"RabbitMQ health check failed: {e}\")\n        checks[\"rabbitmq\"] = \"unhealthy\"\n        all_healthy = False\n\n    status_code = 200 if all_healthy else 503\n\n    return HealthResponse(\n        status=\"healthy\" if all_healthy else \"unhealthy\",\n        version=\"1.0.0\",\n        checks=checks,\n    )\n</code></pre> <p>[... Continue with HTTP client, RabbitMQ publisher/consumer, tests ...]</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#task-22-add-anti-patterns-to-documentation","title":"Task 2.2: Add Anti-Patterns to Documentation","text":"<p>Status: \u23f8\ufe0f Not Started Priority: \ud83d\udfe0 HIGH Estimated Time: 8 hours Owner: TBD</p> <p>Objective: Document 4 missing anti-patterns related to DRY/KISS/YAGNI violations.</p> <p>Files to Create: 1. <code>docs/atomic/architecture/anti-patterns/copy-paste-programming.md</code> 2. <code>docs/atomic/architecture/anti-patterns/god-object.md</code> 3. <code>docs/atomic/architecture/anti-patterns/speculative-generality.md</code> 4. <code>docs/atomic/architecture/anti-patterns/premature-infrastructure.md</code></p> <p>Files to Update: - <code>docs/INDEX.md</code> - Add new anti-patterns to quick reference - <code>docs/atomic/testing/quality-assurance/code-review-checklist.md</code> - Reference new anti-patterns</p> <p>Acceptance Criteria: - [ ] Each anti-pattern follows TEMPLATE.md structure - [ ] Includes problem, symptom, impact, WRONG example, WHY section, CORRECT solution - [ ] Includes monitoring commands (grep, radon, cloc, etc.) - [ ] Links to related anti-patterns and architecture docs - [ ] Added to INDEX.md with priority classification - [ ] Reviewed by 2+ maintainers</p> <p>Implementation Details:</p> <p>copy-paste-programming.md Structure:</p> <pre><code># Anti-Pattern: Copy-Paste Programming\n\n## Problem\n\nCode is duplicated across multiple files instead of being extracted to shared utilities or base classes.\n\n## Symptom\n\n- Same validation logic appears in 5 different endpoints\n- Multiple services have identical logger configuration code\n- Bug fix requires changing N files (risk of inconsistency)\n- Code duplication percentage &gt; 10%\n\n## Impact\n\n**Technical:**\n- Bug fixes require changing multiple files\n- Inconsistent implementations (forgot to update one file)\n- Higher maintenance burden\n- Larger codebase\n\n**Business:**\n- Slower feature development (change N places)\n- More bugs (missed updates)\n- Higher technical debt\n\n## Example (WRONG)\n\n```python\n# services/auth_api/src/api/v1/users.py\n@router.post(\"/users\")\nasync def create_user(data: UserCreate):\n    # Duplicated validation\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    ...\n\n# services/profile_api/src/api/v1/profiles.py\n@router.put(\"/profiles\")\nasync def update_profile(data: ProfileUpdate):\n    # DUPLICATED: Same email validation\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    ...\n\n# services/notification_api/src/api/v1/subscriptions.py\n@router.post(\"/subscriptions\")\nasync def subscribe(data: SubscriptionCreate):\n    # DUPLICATED AGAIN: Third copy of same validation\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    ...\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#why-this-matters","title":"Why This Matters","text":"<ul> <li>Single Source of Truth: DRY principle violated</li> <li>Maintenance Nightmare: Email regex bug requires fixing 3+ files</li> <li>Inconsistency Risk: Developer updates 2 files, forgets third \u2192 inconsistent behavior</li> <li>Testing Burden: Must test same logic in 3+ test files</li> </ul>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#solution-correct","title":"Solution (CORRECT)","text":"<p>Extract to shared/utils/:</p> <pre><code># shared/utils/validators.py\ndef is_valid_email(email: str) -&gt; bool:\n    \"\"\"Validate email address format.\"\"\"\n    return bool(re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', email))\n\n# services/auth_api/src/api/v1/users.py\nfrom shared.utils.validators import is_valid_email\n\n@router.post(\"/users\")\nasync def create_user(data: UserCreate):\n    if not is_valid_email(data.email):\n        raise ValidationError(\"Invalid email\")\n    ...\n\n# services/profile_api/src/api/v1/profiles.py\nfrom shared.utils.validators import is_valid_email\n\n@router.put(\"/profiles\")\nasync def update_profile(data: ProfileUpdate):\n    if not is_valid_email(data.email):\n        raise ValidationError(\"Invalid email\")\n    ...\n\n# services/notification_api/src/api/v1/subscriptions.py\nfrom shared.utils.validators import is_valid_email\n\n@router.post(\"/subscriptions\")\nasync def subscribe(data: SubscriptionCreate):\n    if not is_valid_email(data.email):\n        raise ValidationError(\"Invalid email\")\n    ...\n</code></pre> <p>Benefits: - Single source of truth for email validation - Bug fix in one place \u2192 automatic fix everywhere - Consistent behavior guaranteed - Test once in shared/utils/test_validators.py</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#architecture-rule","title":"Architecture Rule","text":"<p>Rule: Extract shared code to <code>shared/utils/</code> when: 1. Same logic appears in 2+ places (Rule of Three) 2. Logic is pure (no business context) 3. Logic is stable (won't change per service)</p> <p>Examples of what goes in shared/utils/: - Validators (email, phone, UUID) - Logging configuration - Pagination helpers - Exception classes - Request ID management</p> <p>Examples of what stays in services: - Business logic (user registration flow) - Domain-specific validation (e.g., \"premium users can have 10 profiles\") - Service-specific configuration</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#monitoring","title":"Monitoring","text":"<p>Detect code duplication:</p> <pre><code># Install jscpd\nnpm install -g jscpd\n\n# Scan for duplicates\njscpd src/ --threshold 10 --reporters \"console,html\" --output \"./report\"\n\n# Open HTML report\nopen report/jscpd-report.html\n</code></pre> <p>Detect similar files:</p> <pre><code># Using cloc\ncloc --by-file --csv src/ | awk -F',' '$5 &gt; 80 {print $2, \"(\"$5\"% similar)\"}'\n</code></pre> <p>Find duplicated imports (common symptom):</p> <pre><code># If 5 files import same things, might indicate duplication\ngrep -r \"from shared.utils import\" src/ | sort | uniq -c | sort -rn\n</code></pre>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#related-anti-patterns","title":"Related Anti-Patterns","text":"<ul> <li>Speculative Generality - Opposite extreme (over-abstraction)</li> <li>HTTP Client Proliferation - Specific case of this pattern</li> <li>Connection Pool Misuse - Specific case of this pattern</li> </ul>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#related-principles","title":"Related Principles","text":"<ul> <li>DRY Principle - Don't Repeat Yourself</li> <li>HTTP-Only Data Access - Architectural DRY enforcement</li> <li>Shared Utilities - Where to put extracted code</li> </ul> <p>Classification: \ud83d\udfe0 HIGH Priority Principle: DRY (Don't Repeat Yourself) Detection: Automated (jscpd in CI) <pre><code>[... Similar structure for god-object.md, speculative-generality.md, premature-infrastructure.md ...]\n\n---\n\n#### Task 2.3: Add Upgrade Triggers to Maturity Levels\n\n**Status:** \u23f8\ufe0f Not Started\n**Priority:** \ud83d\udfe0 HIGH\n**Estimated Time:** 4 hours\n**Owner:** TBD\n\n**Objective:**\nDocument evidence-driven upgrade triggers for maturity levels.\n\n**Files to Update:**\n- `docs/reference/maturity-levels.md`\n\n**Acceptance Criteria:**\n- [ ] Section \"When to Upgrade Levels\" added with specific metrics\n- [ ] Each upgrade (1\u21922, 2\u21923, 3\u21924) has 3-5 concrete triggers\n- [ ] Triggers are measurable (team size, user count, deployment status)\n- [ ] Anti-pattern \"Premature Infrastructure\" linked\n- [ ] Examples show both correct and premature upgrades\n\n**Implementation Details:**\n\n*Add new section to maturity-levels.md:*\n\n```markdown\n## When to Upgrade Maturity Levels\n\n**IMPORTANT:** Upgrade levels based on **evidence**, not speculation.\n\n### Level 1 \u2192 Level 2 (PoC \u2192 Development)\n\nUpgrade when you have **evidence** of at least 3 of these:\n\n\u2705 **Team Growth:**\n- Team grows to 3+ developers\n- Need coordination across multiple contributors\n- Code reviews becoming frequent\n\n\u2705 **Debugging Complexity:**\n- Debugging takes &gt;2 hours due to lack of request IDs\n- Need to trace requests across service boundaries\n- Support team struggles to correlate logs\n\n\u2705 **Stakeholder Requirements:**\n- Stakeholders request API documentation (Swagger)\n- Need to share API contract with frontend/mobile team\n- QA team needs structured health checks\n\n\u2705 **Development Velocity:**\n- Developing new features without tests is becoming risky\n- Need test coverage to enable refactoring\n- Regression bugs appearing frequently\n\n**Example (CORRECT):**\n```markdown\nScenario: Started with Level 1 PoC, launched to 5 beta users\nEvidence after 2 weeks:\n- Team grew from 1 to 4 developers\n- Spent 3 hours debugging issue without request IDs\n- Frontend team requested Swagger docs\n\nDecision: Upgrade to Level 2 \u2705\n</code></pre></p> <p>Example (PREMATURE): <pre><code>Scenario: Just started project, solo developer\nReasoning: \"We might need request IDs later\"\n\nDecision: Stay at Level 1 until evidence shows need \u2705\nPremature upgrade wastes time generating unused infrastructure \u274c\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#level-2-level-3-development-pre-production","title":"Level 2 \u2192 Level 3 (Development \u2192 Pre-Production)","text":"<p>Upgrade when you have evidence of at least 3 of these:</p> <p>\u2705 Production Deployment: - Preparing for production launch - Need HTTPS/TLS for security - Compliance requires encrypted connections</p> <p>\u2705 Monitoring Requirements: - Need to monitor uptime (SLA commitment) - Business stakeholders request latency metrics - On-call engineer needs Prometheus alerts</p> <p>\u2705 Load Requirements: - Traffic exceeds 100 requests/second - Need Nginx load balancing across multiple instances - Single instance hitting resource limits</p> <p>\u2705 Security Audit: - Security audit requires HTTPS - PCI/HIPAA compliance requires TLS - Penetration test findings require hardening</p> <p>Example (CORRECT): <pre><code>Scenario: Level 2 app in development for 2 months\nEvidence:\n- Launching to production in 1 week\n- CTO requires uptime monitoring (99% SLA)\n- Security audit mandated HTTPS\n\nDecision: Upgrade to Level 3 \u2705\n</code></pre></p> <p>Example (PREMATURE - Anti-Pattern): <pre><code>Scenario: Still in PoC phase, 0 users\nReasoning: \"Let's set up monitoring from the start\"\n\nDecision: Stay at Level 1 or 2 until production launch \u2705\nLevel 3 infrastructure (Nginx, Prometheus, SSL) adds 10+ minutes\nto generation time and complexity. Wait for evidence. \u274c\n\nSee: [Premature Infrastructure anti-pattern](../atomic/architecture/anti-patterns/premature-infrastructure.md)\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#level-3-level-4-pre-production-production","title":"Level 3 \u2192 Level 4 (Pre-Production \u2192 Production)","text":"<p>Upgrade when you have evidence of at least 4 of these:</p> <p>\u2705 Scale: - Daily active users &gt; 1,000 - Request rate &gt; 1,000 requests/second - Multiple regions or availability zones needed</p> <p>\u2705 Compliance: - GDPR/HIPAA requires audit logging (ELK) - Need to track \"who did what when\" for regulatory compliance - Legal team requires log retention for N years</p> <p>\u2705 Team Maturity: - 10+ developers across multiple teams - Need staging + production environments - CI/CD required for frequent deployments</p> <p>\u2705 Observability: - Need distributed tracing (Jaeger) for debugging - Request spans cross 5+ microservices - Support team requires detailed trace analysis</p> <p>\u2705 Business Critical: - Downtime costs &gt; $1,000/hour - SLA commitment 99.9%+ uptime - On-call rotation with PagerDuty</p> <p>Example (CORRECT): <pre><code>Scenario: Level 3 app running in production for 6 months\nEvidence:\n- 5,000 DAU (daily active users)\n- GDPR compliance audit requires ELK\n- 15 developers, need CI/CD\n- Request tracing across 6 microservices is difficult\n\nDecision: Upgrade to Level 4 \u2705\n</code></pre></p> <p>Example (TOO EARLY): <pre><code>Scenario: Level 3 app, launched 2 weeks ago, 50 users\nReasoning: \"We plan to scale to 10,000 users\"\n\nDecision: Wait for actual scale \u2705\nLevel 4 infrastructure (ELK, Jaeger, multi-env CI/CD) is complex.\nAdds 15+ minutes to generation, significant operational overhead.\nUpgrade when evidence shows need (actual scale, compliance requirement). \u274c\n</code></pre></p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#anti-pattern-premature-infrastructure","title":"Anti-Pattern: Premature Infrastructure","text":"<p>Problem: Generating Level 4 infrastructure for Level 1 use case</p> <p>Symptom: - PoC project with Kubernetes, service mesh, distributed tracing - Solo developer project with ELK stack, Prometheus, Grafana - MVP with CI/CD for 5 environments - 30-minute project generation time for 0 users</p> <p>Impact: - Slow iteration (long generation time) - High operational complexity - Wasted time configuring unused infrastructure - Cognitive overload for developers</p> <p>Solution: - Start at Level 1 (PoC) unless evidence shows higher level needed - Upgrade incrementally based on metrics - See \"When to Upgrade Levels\" section above</p> <p>See full anti-pattern: Premature Infrastructure <pre><code>---\n\n### Phase 3: Medium Priority Improvements (P2)\n\n**Estimated Effort:** 16-20 hours\n**Target Completion:** Week 4\n\n---\n\n#### Task 3.1: Enhance Stage 1 with Feature Necessity Validation\n\n**Status:** \u23f8\ufe0f Not Started\n**Priority:** \ud83d\udfe1 MEDIUM\n**Estimated Time:** 4 hours\n**Owner:** TBD\n\n**Objective:**\nAdd feature prioritization and necessity challenge to Stage 1 (Prompt Validation).\n\n**Files to Update:**\n- `docs/guides/ai-code-generation-master-workflow.md`\n\n**Acceptance Criteria:**\n- [ ] Stage 1 includes \"Feature Necessity Challenge\" step\n- [ ] AI must ask \"Which features are absolutely required for MVP?\"\n- [ ] Applies MoSCoW prioritization (Must/Should/Could/Won't)\n- [ ] Blocks Stage 2 until features prioritized\n- [ ] Documents evidence/justification for each \"Must Have\" feature\n\n**Implementation Details:**\n\n[Continue with detailed implementation...]\n\n---\n\n#### Task 3.2: Create Consolidated DRY/KISS/YAGNI Checklist\n\n[Continue with details...]\n\n---\n\n#### Task 3.3: Create Interactive Maturity Level Selector Script\n\n[Continue with details...]\n\n---\n\n#### Task 3.4: Implement Anti-Pattern Detector Script\n\n[Continue with details...]\n\n---\n\n## Testing and Validation\n\n### Test Plan\n\n**Phase 1 Testing:**\n1. Generate project at Level 1 with new templates\n2. Verify shared/utils/ are used (no duplication)\n3. Run CI pipeline, verify quality gates pass\n4. Measure code duplication (&lt;10%)\n5. Verify all functions McCabe &lt; 10\n\n**Phase 2 Testing:**\n1. Generate business API project, verify all 8 files present\n2. Test middleware: request ID injection, exception handling\n3. Verify health checks work with mocked dependencies\n4. Review anti-pattern docs with 3+ contributors\n\n**Phase 3 Testing:**\n1. Test Stage 1 feature prioritization with sample prompts\n2. Validate consolidated checklist completeness\n3. Run maturity level selector script with various inputs\n\n### Success Metrics\n\n| Metric | Baseline | Target | Measurement |\n|--------|----------|--------|-------------|\n| Code Duplication | ~25% | &lt;10% | jscpd report |\n| Avg Function Complexity | McCabe 12 | McCabe &lt;10 | radon cc |\n| Template Completion | 40% | 100% | templates/README.md |\n| Principle Documentation | 0 guides | 3 guides | docs/guides/ |\n| Anti-Patterns Documented | 6 | 10 | docs/INDEX.md |\n| CI Quality Gates | 2 | 7 | .github/workflows/ci.yml |\n\n---\n\n## Rollout Strategy\n\n### Phase 1: Critical Foundation (Week 1-2)\n\n**Deliverables:**\n- DRY/KISS/YAGNI principles guide\n- Shared utilities template (100%)\n- Data service template (100%)\n- CI quality gates\n\n**Rollout:**\n1. Merge improvements to `develop` branch\n2. Generate 2-3 test projects, validate templates\n3. Update CHANGELOG.md with breaking changes (if any)\n4. Merge to `main`\n5. Tag release: `v0.2.0-principles-enforcement`\n\n**Communication:**\n- Announcement in framework repository README\n- Migration guide for existing projects\n\n### Phase 2: Enhanced Templates &amp; Docs (Week 3)\n\n**Deliverables:**\n- Business API template (100%)\n- 4 new anti-patterns\n- Maturity level upgrade triggers\n\n**Rollout:**\n1. Merge to `develop`\n2. Generate 5 test projects (different maturity levels)\n3. Validate anti-pattern docs with code examples\n4. Merge to `main`\n5. Tag release: `v0.3.0-complete-templates`\n\n### Phase 3: Workflow &amp; Tooling (Week 4)\n\n**Deliverables:**\n- Enhanced Stage 1 workflow\n- Consolidated checklist\n- Helper scripts\n\n**Rollout:**\n1. Test new Stage 1 with 10+ sample prompts\n2. Validate scripts work across platforms\n3. Merge to `develop`, then `main`\n4. Tag release: `v0.4.0-enhanced-workflow`\n\n---\n\n## Risks and Mitigations\n\n### Risk 1: Breaking Changes to Existing Templates\n\n**Probability:** MEDIUM\n**Impact:** HIGH\n\n**Mitigation:**\n- Maintain backward compatibility where possible\n- Provide migration guide for breaking changes\n- Version templates (v1, v2) if necessary\n- Test with existing projects before release\n\n### Risk 2: CI Checks Too Strict\n\n**Probability:** MEDIUM\n**Impact:** MEDIUM\n\n**Symptom:** Legitimate code fails CI (false positives)\n\n**Mitigation:**\n- Start with warning-only mode for first 2 weeks\n- Collect feedback, adjust thresholds\n- Allow configuration override in .ci-config.yml\n- Document how to disable specific checks\n\n### Risk 3: Incomplete Template Testing\n\n**Probability:** LOW\n**Impact:** HIGH\n\n**Symptom:** Generated projects fail at runtime\n\n**Mitigation:**\n- Generate 10+ test projects per template\n- Run full test suite on each generated project\n- Deploy to test environment, verify functionality\n- Automated template validation in CI\n\n### Risk 4: Documentation Overload\n\n**Probability:** LOW\n**Impact:** MEDIUM\n\n**Symptom:** Contributors overwhelmed by documentation volume\n\n**Mitigation:**\n- Create clear navigation in INDEX.md\n- Add \"Quick Start\" sections to long docs\n- Use examples liberally\n- Create video walkthroughs (optional)\n\n---\n\n## Timeline\n</code></pre> Week 1: \u251c\u2500\u2500 Task 1.1: DRY/KISS/YAGNI principles guide (8h) \u251c\u2500\u2500 Task 1.2: Shared utilities template (12h) \u2514\u2500\u2500 Task 1.3: Data service template - Part 1 (16h)</p> <p>Week 2: \u251c\u2500\u2500 Task 1.3: Data service template - Part 2 (complete) \u251c\u2500\u2500 Task 1.4: CI quality gates (4h) \u2514\u2500\u2500 Phase 1 testing &amp; rollout (8h)</p> <p>Week 3: \u251c\u2500\u2500 Task 2.1: Complete business API template (8h) \u251c\u2500\u2500 Task 2.2: Add anti-patterns (8h) \u251c\u2500\u2500 Task 2.3: Maturity level upgrade triggers (4h) \u2514\u2500\u2500 Phase 2 testing &amp; rollout (4h)</p> <p>Week 4: \u251c\u2500\u2500 Task 3.1: Feature necessity validation (4h) \u251c\u2500\u2500 Task 3.2: Consolidated checklist (3h) \u251c\u2500\u2500 Task 3.3: Maturity level selector (4h) \u251c\u2500\u2500 Task 3.4: Anti-pattern detector (5h) \u2514\u2500\u2500 Phase 3 testing &amp; rollout (4h) ```</p> <p>Total Estimated Effort: 80-120 hours (2-3 weeks for 2-person team)</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#status-tracking","title":"Status Tracking","text":"<p>Use this section to track progress:</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#phase-1-status-completed-2025-11-07","title":"Phase 1 Status \u2705 COMPLETED (2025-11-07)","text":"<ul> <li> Task 1.1: DRY/KISS/YAGNI principles guide (commit: cb8bbcf)</li> <li> Task 1.2: Shared utilities template (commit: 4ed25a5)</li> <li> Task 1.3: Data service template (PostgreSQL) (commit: d7f017c)</li> <li> Task 1.4: CI quality gates (commit: c474d19)</li> </ul> <p>Quality Gates Test Results: - Code Duplication: 0% (threshold: &lt;10%) \u2705 - Cyclomatic Complexity: Average A (1.79) \u2705 - Maintainability Index: All files Grade B or better \u2705 - File Size: All files &lt;500 lines \u2705 - Dependencies: 11-27 (thresholds: 30-50) \u2705</p> <p>Deliverables: - 38 new files created - 3,500+ lines of documentation and code - CHANGELOG.md updated - All tests passed</p>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#phase-2-status","title":"Phase 2 Status","text":"<ul> <li> Task 2.1: Complete business API template</li> <li> Task 2.2: Add anti-patterns</li> <li> Task 2.3: Maturity level upgrade triggers</li> </ul>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#phase-3-status","title":"Phase 3 Status","text":"<ul> <li> Task 3.1: Feature necessity validation</li> <li> Task 3.2: Consolidated checklist</li> <li> Task 3.3: Maturity level selector</li> <li> Task 3.4: Anti-pattern detector</li> </ul>"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#contributors","title":"Contributors","text":"Name Role Tasks TBD Lead Overall coordination, Phase 1 TBD Developer Templates (Phase 1-2) TBD Documentation Docs (Phase 2) TBD DevOps CI/CD (Phase 1)"},{"location":"contributing/improvement-plans/2025-01-dry-kiss-yagni-enforcement/#references","title":"References","text":"<ul> <li>CONTRIBUTING.md - Contribution guidelines</li> <li>ARCHITECTURE.md - Framework architecture</li> <li>Maturity Levels - Current maturity level documentation</li> <li>Agent Workflow - AI agent workflow</li> <li>Quality Standards - Quality requirements</li> </ul> <p>Document Version: 1.1 Last Updated: 2025-11-07 Status: Phase 1 Complete \u2705 | Phase 2 &amp; 3 Pending</p>"},{"location":"guides/ai-code-generation-master-workflow/","title":"AI Code Generation Master Workflow","text":"<p>PURPOSE: This is the single source of truth for AI agents generating production-ready microservices applications. This document unifies the complete end-to-end process from initial user prompt to production deployment.</p>"},{"location":"guides/ai-code-generation-master-workflow/#quick-navigation","title":"Quick Navigation","text":"Need Go To Start here Part 1: AI Reading Order Understand the process Part 2: 7-Stage Workflow Know what to read when Part 3: Navigation Matrix See a complete example Part 4: Example Walkthrough Troubleshoot issues Part 5: Common Issues"},{"location":"guides/ai-code-generation-master-workflow/#part-1-ai-reading-order","title":"Part 1: AI Reading Order","text":""},{"location":"guides/ai-code-generation-master-workflow/#initialization-sequence-mandatory","title":"Initialization Sequence (MANDATORY)","text":"<p>When an AI agent starts working with this framework, it MUST read documents in this exact order:</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-0-initialization-before-receiving-user-prompt","title":"Stage 0: Initialization (Before receiving user prompt)","text":"<p>Read these 4 documents in order: 1. AGENTS.md \u2014 Entry point, framework overview 2. docs/reference/agent-context-summary.md \u2014 Critical rules snapshot 3. THIS DOCUMENT \u2014 Complete workflow process 4. docs/reference/maturity-levels.md \u2014 4 maturity levels (PoC to Production)</p> <p>Purpose: Load framework context before starting work.</p> <p>Details: See Stage 0: AI Initialization in Part 2 for complete description.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-1-6-dynamic-reading-during-workflow-execution","title":"Stage 1-6: Dynamic Reading (During workflow execution)","text":"<p>After initialization, AI reads documents on-demand based on the current workflow stage. See Part 3: Navigation Matrix for exact document mapping per stage.</p> <p>Key principle: Don't read everything upfront. Read what's needed for the current stage.</p>"},{"location":"guides/ai-code-generation-master-workflow/#core-document-categories","title":"Core Document Categories","text":""},{"location":"guides/ai-code-generation-master-workflow/#workflow-process-when-to-do-what","title":"Workflow &amp; Process (when to do what)","text":"<ul> <li><code>ai-code-generation-master-workflow.md</code> \u2190 you are here</li> <li><code>prompt-validation-guide.md</code></li> <li><code>agent-verification-checklist.md</code></li> </ul>"},{"location":"guides/ai-code-generation-master-workflow/#architecture-rules-what-constraints-to-follow","title":"Architecture &amp; Rules (what constraints to follow)","text":"<ul> <li><code>architecture-guide.md</code> \u2190 MANDATORY, canonical architecture source</li> <li><code>docs/atomic/architecture/*</code> \u2190 atomic architecture rules</li> <li><code>docs/atomic/services/*</code> \u2190 service implementation patterns</li> <li><code>docs/atomic/integrations/*</code> \u2190 integration patterns</li> </ul>"},{"location":"guides/ai-code-generation-master-workflow/#templates-tools-how-to-structure-outputs","title":"Templates &amp; Tools (how to structure outputs)","text":"<ul> <li><code>requirements-intake-template.md</code></li> <li><code>implementation-plan-template.md</code></li> <li><code>qa-report-template.md</code></li> <li><code>agent-toolbox.md</code></li> <li><code>prompt-templates.md</code></li> </ul>"},{"location":"guides/ai-code-generation-master-workflow/#reference-lookup-information","title":"Reference (lookup information)","text":"<ul> <li><code>tech_stack.md</code> \u2190 technology versions</li> <li><code>project-structure.md</code> \u2190 directory layout</li> <li><code>troubleshooting.md</code> \u2190 diagnostics</li> <li><code>deliverables-catalog.md</code> \u2190 expected artifacts</li> </ul>"},{"location":"guides/ai-code-generation-master-workflow/#part-2-7-stage-workflow-process","title":"Part 2: 7-Stage Workflow Process","text":""},{"location":"guides/ai-code-generation-master-workflow/#overview-diagram","title":"Overview Diagram","text":"<pre><code>graph TB\n    START[User Provides Business Idea] --&gt; S0[Stage 0: AI Initialization]\n    S0 --&gt; S1[Stage 1: Prompt Validation]\n    S1 --&gt;|Missing Info| ASK1[Ask Clarification]\n    ASK1 --&gt; S1\n    S1 --&gt;|Complete| S2[Stage 2: Requirements Intake]\n    S2 --&gt; S3[Stage 3: Architecture Mapping &amp; Planning]\n    S3 --&gt;|Plan Approval| S4[Stage 4: Code Generation]\n    S4 --&gt; S5[Stage 5: Quality Verification]\n    S5 --&gt;|Tests Fail| S4\n    S5 --&gt;|Tests Pass| S6[Stage 6: QA Report &amp; Handoff]\n    S6 --&gt; END[Production-Ready Application]</code></pre>"},{"location":"guides/ai-code-generation-master-workflow/#stage-0-ai-initialization","title":"Stage 0: AI Initialization","text":"<p>Entry Criteria: AI agent assigned to a new task.</p> <p>AI Actions: 1. Read <code>AGENTS.md</code> \u2192 understand framework model 2. Read <code>agent-context-summary.md</code> \u2192 load critical rules 3. Read this document \u2192 understand workflow 4. Load context about:    - Improved Hybrid Approach (centralized data services)    - Mandatory constraints (HTTP-only, service separation)    - Available templates and tools</p> <p>Documents Read: - <code>AGENTS.md</code> - <code>docs/reference/agent-context-summary.md</code> - <code>docs/guides/ai-code-generation-master-workflow.md</code> (this file) - <code>docs/reference/maturity-levels.md</code></p> <p>AI Generates: Nothing yet (loading phase).</p> <p>Exit Criteria: AI has complete context about framework architecture, process, and maturity level options.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-1-prompt-validation","title":"Stage 1: Prompt Validation","text":"<p>Entry Criteria: User provides initial business idea/requirement.</p> <p>AI Actions: 1. Read <code>prompt-validation-guide.md</code> 2. Check user prompt against mandatory fields:    - \u2705 Business context (problem, users, success metrics)    - \u2705 Functional requirements (features, capabilities)    - \u2705 Non-functional constraints (performance, security, scale)    - \u2705 Target maturity level (1-PoC, 2-Development, 3-Pre-Production, 4-Production)    - \u2705 Optional modules (Workers, Bot, MongoDB, RabbitMQ, Redis, etc.)    - \u2705 Dependencies &amp; integrations (external systems)    - \u2705 Scope boundaries (what's in/out of scope)    - \u2705 Expected deliverables    - \u2705 Acceptance criteria 3. If ANY field is missing \u2192 ask clarification using <code>prompt-templates.md</code>    - IMPORTANT: If maturity level is missing, ask user to choose level 1-4    - IMPORTANT: If optional modules not mentioned, ask explicitly: \"Do you need any optional modules (Workers, Bot, MongoDB, RabbitMQ, Redis) or just core (FastAPI + PostgreSQL)?\"    - Default to \"none\" (core only) if user confirms, but must ask explicitly 4. If ALL fields present \u2192 proceed to Stage 2</p> <p>Documents Read: - <code>docs/guides/prompt-validation-guide.md</code> - <code>docs/reference/prompt-templates.md</code> (if clarification needed) - <code>docs/reference/maturity-levels.md</code> (for level explanation)</p> <p>AI Generates: - Selected maturity level (1-4) - Selected optional modules (list or \"none\") - Validation note (if complete) - OR clarification request (if incomplete)</p> <p>Example Clarification: <pre><code>## \ud83d\udd0d Prompt Validation: Missing Information\n\nYour business idea is interesting, but I need additional details:\n\n**Missing**:\n1. **Target maturity level**: Choose level (see maturity-levels.md):\n   - **Level 1 - PoC** (~5 min): Core functionality only, no logging/metrics\n   - **Level 2 - Development** (~10 min): + Structured logging, health checks\n   - **Level 3 - Pre-Production** (~15 min): + Nginx, SSL, Prometheus metrics\n   - **Level 4 - Production** (~30 min): + OAuth/JWT, ELK, tracing, CI/CD\n\n   **Your choice (1-4)**: _____\n\n2. **Optional modules**: Which additional services do you need?\n   - [ ] Background Workers (AsyncIO)\n   - [ ] Telegram Bot (Aiogram)\n   - [ ] MongoDB (NoSQL database)\n   - [ ] RabbitMQ (event messaging)\n   - [ ] Redis (caching)\n\n   **Your selection (comma-separated or \"none\")**: _____\n\n3. **Scale expectations**: How many users in first year? Expected daily transactions?\n4. **Authentication method**: JWT, OAuth2, magic links?\n\nPlease provide these details so I can ensure architecture alignment.\n</code></pre></p> <p>Exit Criteria: All mandatory fields confirmed, maturity level selected.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-2-requirements-clarification-intake","title":"Stage 2: Requirements Clarification &amp; Intake","text":"<p>Entry Criteria: Prompt validation passed.</p> <p>AI Actions: 1. Read architecture documents:    - <code>architecture-guide.md</code> \u2190 verify compatibility    - <code>docs/atomic/architecture/improved-hybrid-overview.md</code>    - <code>docs/atomic/architecture/service-separation-principles.md</code>    - <code>docs/atomic/architecture/data-access-architecture.md</code> 2. Read <code>tech_stack.md</code> \u2190 verify technology compatibility 3. Analyze user requirements against framework capabilities 4. Map requirements to service types:    - FastAPI service? (REST API)    - Aiogram service? (Telegram bot)    - AsyncIO workers? (background jobs)    - Data services? (PostgreSQL/MongoDB) 5. Identify potential architectural conflicts 6. Fill <code>requirements-intake-template.md</code>:    - Business Context &amp; Objectives    - Target Configuration (maturity level, optional modules, estimated time)    - IMPORTANT: Assign unique Req IDs (FR-001, UI-001, NF-001) to EVERY requirement for traceability    - Functional Requirements (table format with Req ID, Feature, Priority, Description, Acceptance Criteria, Implementation Status)    - UI/UX Requirements (for UI-heavy projects, with Req ID column)    - Non-Functional Requirements (measurable constraints only, with Req ID)    - Requirements Summary (count total FR, UI, NF requirements for coverage tracking)    - Non-Functional Constraints (general, not measurable)    - Dependencies &amp; Integrations    - Data &amp; Storage Considerations    - Scope Boundaries    - Expected Deliverables    - Acceptance Criteria    - Risks &amp; Open Questions</p> <p>Documents Read: - <code>docs/guides/requirements-intake-template.md</code> - <code>docs/guides/architecture-guide.md</code> - <code>docs/reference/tech_stack.md</code> - <code>docs/reference/maturity-levels.md</code> (for level features) - <code>docs/atomic/architecture/*</code> (as needed)</p> <p>AI Generates: - Completed Requirements Intake document with maturity level confirmed</p> <p>Example Output: <pre><code># Requirements Intake: P2P Lending Platform\n\n**Generated**: 2025-10-01\n**Framework**: doc4microservices v1.0\n\n## Target Configuration\n- **Maturity Level**: 3 - Pre-Production\n- **Optional Modules**: Workers, Bot\n- **Estimated Generation Time**: ~15-20 minutes (base 15 min + 2 modules)\n- **Reference**: See `docs/reference/maturity-levels.md` for level details\n\n## Business Context &amp; Objectives\n- **Problem**: Users need peer-to-peer lending with transparent terms\n- **Target Users**: Borrowers (need loans), Lenders (invest money)\n- **Success Metrics**: 1K users in year 1, 50 loans/day, &lt;200ms API latency\n\n## Functional Requirements\n| Feature | Priority | Description | Acceptance Notes |\n|---------|----------|-------------|------------------|\n| User registration with KYC | Must | Government ID verification | Onfido integration |\n| Loan marketplace | Must | Browse/search available loans | Filters by amount, term, rate |\n| Automated payments | Must | Monthly via Stripe | Webhook handling |\n| Credit scoring | Must | Internal algorithm | 3 factors: history, ratio, age |\n\n## Non-Functional Constraints\n- **Performance**: &lt;200ms p95 API latency, 99.9% uptime\n- **Security**: JWT + 2FA, HTTPS only, PII encryption\n- **Compliance**: GDPR (EU), FCA (UK), 7-year retention\n- **Architecture**: \u2705 Improved Hybrid Approach compatible\n\n## Architecture Mapping\n**Services Needed**:\n- \u2705 FastAPI service (Port 8000) - REST API\n- \u2705 Aiogram service - Notifications\n- \u2705 AsyncIO worker - Payment processing, credit scoring\n- \u2705 PostgreSQL data service (Port 8001) - Transactional data\n- \u2705 MongoDB data service (Port 8002) - Analytics, audit logs\n\n**Infrastructure**:\n- \u2705 PostgreSQL 16, MongoDB 7, Redis 7, RabbitMQ 3\n- \u2705 Nginx API Gateway (TLS, rate limiting)\n\n[... rest of template ...]\n</code></pre></p> <p>Exit Criteria: Requirements document reviewed and approved by user.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-3-architecture-mapping-planning","title":"Stage 3: Architecture Mapping &amp; Planning","text":"<p>Entry Criteria: Requirements Intake approved.</p> <p>AI Actions: 1. Read <code>implementation-plan-template.md</code> 2. Read <code>maturity-levels.md</code> and <code>conditional-stage-rules.md</code> to understand what features to include 3. IF Level 1 (PoC): Perform scope reduction:    - List ALL features from requirements    - Prioritize by business criticality    - Select top 20-30% most critical features for Level 1    - Plan 100% complete implementation for selected features only    - Exclude remaining features entirely (not partially, not with TODOs)    - Quality gate: every UI element must have handler, every FSM state must have complete flow, every endpoint must be fully implemented    - Remember: Level 1 = fewer features, NOT partial features 4. Read <code>use-case-implementation-guide.md</code> 5. Read naming convention documents (MANDATORY for all service naming decisions):    - <code>docs/checklists/service-naming-checklist.md</code> \u2014 quick decision guide    - <code>docs/atomic/architecture/naming/README.md</code> Section 2.3 \u2014 10 serious reasons for 4-part naming 6. Read service-specific atomic docs based on services needed AND maturity level:    - If FastAPI \u2192 read <code>docs/atomic/services/fastapi/*</code>    - If Aiogram \u2192 read <code>docs/atomic/services/aiogram/*</code>    - If Workers \u2192 read <code>docs/atomic/services/asyncio-workers/*</code>    - Always read <code>docs/atomic/services/data-services/*</code>    - If Level \u2265 2 \u2192 read <code>docs/atomic/observability/logging/*</code>    - If Level \u2265 3 \u2192 read <code>docs/atomic/infrastructure/api-gateway/*</code>, <code>docs/atomic/observability/metrics/*</code>    - If Level = 4 \u2192 read <code>docs/atomic/observability/elk-stack/*</code>, <code>docs/atomic/observability/tracing/*</code> 7. Read integration atomic docs:    - <code>docs/atomic/integrations/redis/*</code>    - <code>docs/atomic/integrations/rabbitmq/*</code>    - <code>docs/atomic/integrations/http-communication/*</code> 8. CRITICAL: Create Requirements Traceability Matrix:    - Extract ALL Req IDs (FR-, UI-, NF-) from completed Requirements Intake    - Map EACH Req ID \u2192 Phase \u2192 Specific Tasks    - Document mapping in <code>implementation-plan-template.md</code> \u00a7 Requirements Traceability Matrix    - Verify no orphaned requirements (all Req IDs from Stage 2 appear in RTM) 9. Create implementation plan with **CONDITIONAL phases* based on maturity level:    - Phase 1: Infrastructure setup (Docker, services scaffolding) \u2014 ALL levels    - Phase 2: Data layer (PostgreSQL/MongoDB services with repositories) \u2014 ALL levels    - Phase 3: Business logic (FastAPI endpoints, use cases) \u2014 ALL levels    - Phase 4: Background workers (credit scoring, payment processing) \u2014 IF user requested    - Phase 5: Telegram bot (notifications, commands) \u2014 IF user requested    - Phase 6: Testing &amp; quality (unit, integration, e2e tests) \u2014 ALL levels (criteria vary by level) 9. Map each phase to:    - Specific tasks    - Atomic documents to follow    - Commands from <code>agent-toolbox.md</code>    - Required At Level (which sub-stages to execute)    - Definition of Done 10. Add \"Maturity Level Features\" section showing:    - \u2705 Included features at selected level    - \u274c Skipped features (available at higher levels)    - Upgrade path if user wants to add features later 11. Identify risks and mitigations 12. Create ADR if significant architectural decisions needed:     Create ADR when:     - Technology choice deviates from framework defaults (e.g., using Redis Streams instead of RabbitMQ)     - Multiple implementation approaches exist (e.g., sync vs async, REST vs GraphQL)     - User requires custom integration pattern not covered by atomic docs     - Security/compliance requirements mandate specific approach     - Database choice differs from PostgreSQL (e.g., using MySQL, CockroachDB)</p> <pre><code>**Skip ADR when:**\n- Following standard framework patterns (FastAPI + PostgreSQL + HTTP-only)\n- All decisions align with `architecture-guide.md`\n- Using template services with standard naming (`{context}_{domain}_{type}`)\n</code></pre> <p>Documents Read: - <code>docs/guides/implementation-plan-template.md</code> - <code>docs/reference/maturity-levels.md</code> (for feature mapping) - <code>docs/reference/conditional-stage-rules.md</code> (for sub-stage logic) - <code>docs/guides/use-case-implementation-guide.md</code> - <code>docs/checklists/service-naming-checklist.md</code> (MANDATORY) - <code>docs/atomic/architecture/naming/README.md</code> Section 2.3 (MANDATORY) - <code>docs/atomic/services/**/*</code> (based on required services AND level) - <code>docs/atomic/integrations/**/*</code> (based on integrations) - <code>docs/reference/agent-toolbox.md</code> - <code>docs/reference/architecture-decision-log-template.md</code> (if needed)</p> <p>AI Generates: - Implementation Plan (populated template) with:   - Maturity Level Features section   - Conditional phases clearly marked   - Estimated time based on level and modules - Optional ADR documents</p> <p>Example Plan Structure: <pre><code># Implementation Plan: P2P Lending Platform\n\n## Phase 1: Infrastructure Setup (Week 1)\n**Duration**: 3 days\n\n**Tasks**:\n1. **Project structure creation** (MANDATORY FIRST STEP)\n   - Read `docs/reference/project-structure.md` \u00a7 Creating the Project Structure\n   - Execute mkdir commands to create complete directory tree\n   - Create all services with DDD/Hexagonal layers (`src/{api,application,domain,infrastructure,schemas,core}/`)\n   - Create `shared/`, `tests/` subdirectories\n   - **DoD**: All directories exist, verified with `tree -L 3 -d services/`\n\n2. Infrastructure configuration\n   - Generate docker-compose.yml (5 services)\n   - Generate .env.example from templates\n   - Generate Makefile with development commands\n   - **DoD**: `docker-compose up` succeeds, all containers healthy\n\n3. Service scaffolding\n   - Generate Dockerfiles for each service\n   - Generate requirements.txt for each service\n   - **DoD**: All services respond to health checks\n\n**References**:\n- `docs/atomic/infrastructure/containerization/docker-compose-setup.md`\n- `docs/atomic/services/fastapi/basic-setup.md`\n- `docs/atomic/services/data-services/postgres-service-setup.md`\n\n## Phase 2: Data Layer (Week 2)\n[... detailed breakdown ...]\n</code></pre></p> <p>Exit Criteria: Implementation plan reviewed and approved by user.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-4-code-generation-phase-by-phase","title":"Stage 4: Code Generation (Phase-by-Phase)","text":"<p>Entry Criteria: Implementation plan approved.</p> <p>AI Actions:</p> <p>For EACH phase in the implementation plan:</p> <ol> <li>Check maturity level and read <code>conditional-stage-rules.md</code> to determine which sub-stages to execute</li> <li>Read relevant atomic documents for current phase AND maturity level</li> <li>Generate code following patterns from atomic docs</li> <li>Follow DDD/Hexagonal Architecture:</li> <li>Domain layer (entities, value objects)</li> <li>Application layer (use cases, DTOs)</li> <li>Infrastructure layer (repositories, HTTP clients, message brokers)</li> <li>Follow DEFAULT TO 3-PART naming philosophy \u2014 Use <code>{context}_{domain}_{type}</code>. Add <code>{function}</code> ONLY when domain is ambiguous (burden of proof). Check <code>service-naming-checklist.md</code> or <code>naming-conventions.md</code> Section 2.3 for 10 reasons</li> <li>Use AGENT_TOOLBOX commands to validate</li> <li>Commit after each logical unit with clear messages</li> </ol> <p>IMPORTANT: Stage 4 is now CONDITIONAL. AI must execute only the sub-stages required for the selected maturity level. See <code>ai-navigation-matrix.md</code> for complete sub-stage breakdown.</p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-by-phase-breakdown","title":"Phase-by-Phase Breakdown","text":""},{"location":"guides/ai-code-generation-master-workflow/#phase-1-infrastructure-setup","title":"Phase 1: Infrastructure Setup","text":"<p>CRITICAL: Project Structure Creation Must Be First Step</p> <p>AI Reads: - <code>docs/reference/project-structure.md</code> (\u00a7Creating the Project Structure) \u2014 READ THIS FIRST - <code>docs/atomic/architecture/project-structure-patterns.md</code> (DDD/Hexagonal layers) - <code>docs/atomic/infrastructure/containerization/docker-compose-setup.md</code> - <code>docs/atomic/infrastructure/containerization/dockerfile-patterns.md</code> - <code>docs/atomic/infrastructure/configuration/environment-variables.md</code></p> <p>AI Generates (in this order):</p> <ol> <li>Complete directory structure (MANDATORY FIRST STEP):</li> <li>Execute mkdir commands from project-structure.md \u00a7 Creating the Project Structure</li> <li>Create all services with <code>src/{api,application,domain,infrastructure,schemas,core}/</code></li> <li>Create <code>shared/{dtos,events,utils}/</code></li> <li>Create <code>tests/{unit,integration,service}/</code> for each service</li> <li>Create conditional directories based on maturity level (nginx/ for Level 3+, infrastructure/ for Level 3+)</li> <li> <p>DoD: All directories exist and verified with <code>tree -L 3 -d services/</code></p> </li> <li> <p>Infrastructure configuration files:</p> </li> <li><code>docker-compose.yml</code> (development)</li> <li><code>docker-compose.prod.yml</code> (production, Level 3+)</li> <li><code>.env.example</code></li> <li><code>Makefile</code> (development commands)</li> <li>Service-specific Dockerfiles</li> </ol> <p>Validation: <pre><code>docker-compose up -d\ndocker-compose ps  # All services \"healthy\"\n</code></pre></p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-2-data-layer","title":"Phase 2: Data Layer","text":"<p>AI Reads: - <code>docs/atomic/services/data-services/postgres-service-setup.md</code> - <code>docs/atomic/services/data-services/repository-patterns.md</code> - <code>docs/atomic/services/data-services/http-api-design.md</code> - <code>docs/atomic/databases/postgresql/sqlalchemy-integration.md</code></p> <p>AI Generates: - PostgreSQL service:   - <code>services/template_data_postgres_api/src/models/user.py</code> (SQLAlchemy models)   - <code>services/template_data_postgres_api/src/repositories/user_repository.py</code>   - <code>services/template_data_postgres_api/src/api/v1/users_router.py</code> (HTTP API)   - <code>services/template_data_postgres_api/alembic/versions/001_create_users.py</code> (migration) - MongoDB service:   - <code>services/template_data_mongo_api/src/models/audit_log.py</code> (Motor models)   - <code>services/template_data_mongo_api/src/repositories/audit_repository.py</code>   - <code>services/template_data_mongo_api/src/api/v1/audit_router.py</code></p> <p>Validation: <pre><code># Test PostgreSQL service\ncurl http://localhost:8001/health\n# Returns: {\"status\":\"ok\",\"database\":\"connected\"}\n\n# Test MongoDB service\ncurl http://localhost:8002/health\n</code></pre></p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-3-business-logic-fastapi-service","title":"Phase 3: Business Logic (FastAPI Service)","text":"<p>AI Reads: - <code>docs/atomic/services/fastapi/application-factory.md</code> - <code>docs/atomic/services/fastapi/routing-patterns.md</code> - <code>docs/atomic/services/fastapi/dependency-injection.md</code> - <code>docs/atomic/architecture/ddd-hexagonal-principles.md</code> - <code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code></p> <p>AI Generates: - Domain layer:   - <code>services/template_business_api/src/domain/entities/loan.py</code>   - <code>services/template_business_api/src/domain/value_objects/amount.py</code> - Application layer:   - <code>services/template_business_api/src/application/use_cases/create_loan.py</code>   - <code>services/template_business_api/src/application/dtos/loan_dto.py</code> - Infrastructure layer:   - <code>services/template_business_api/src/infrastructure/http_clients/postgres_client.py</code>   - <code>services/template_business_api/src/infrastructure/rabbitmq/event_publisher.py</code> - API layer:   - <code>services/template_business_api/src/api/v1/loans_router.py</code></p> <p>Key Pattern (HTTP-only data access): <pre><code># services/template_business_api/src/application/use_cases/create_loan.py\nclass CreateLoanUseCase:\n    def __init__(self, postgres_client: PostgresHTTPClient):\n        self.postgres_client = postgres_client  # HTTP client, NOT direct DB\n\n    async def execute(self, loan_data: CreateLoanDTO, user_id: str) -&gt; Loan:\n        # Call data service over HTTP\n        user = await self.postgres_client.get_user(user_id)\n\n        # Validate business rules\n        if user.kyc_status != \"approved\":\n            raise ValidationError(\"KYC must be approved\")\n\n        active_loans = await self.postgres_client.count_active_loans(user_id)\n        if active_loans &gt;= 3:\n            raise ValidationError(\"Maximum 3 active loans\")\n\n        # Create loan via HTTP\n        loan = await self.postgres_client.create_loan({\n            \"borrower_id\": user_id,\n            \"amount\": loan_data.amount,\n            \"duration\": loan_data.duration\n        })\n\n        # Publish event\n        await self.event_publisher.publish(\"loan.created\", loan)\n\n        return Loan.from_dict(loan)\n</code></pre></p> <p>Validation: <pre><code>uv run ruff check services/template_business_api/\nuv run mypy services/template_business_api/\nuv run pytest services/template_business_api/tests/\n</code></pre></p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-4-background-workers","title":"Phase 4: Background Workers","text":"<p>AI Reads: - <code>docs/atomic/services/asyncio-workers/main-function-patterns.md</code> - <code>docs/atomic/services/asyncio-workers/task-management.md</code> - <code>docs/atomic/integrations/rabbitmq/message-consuming.md</code></p> <p>AI Generates: - <code>services/template_business_worker/src/workers/credit_score_worker.py</code> - <code>services/template_business_worker/src/workers/payment_reminder_worker.py</code> - <code>services/template_business_worker/src/main.py</code> (orchestrator)</p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-5-telegram-bot","title":"Phase 5: Telegram Bot","text":"<p>AI Reads: - <code>docs/atomic/services/aiogram/bot-initialization.md</code> - <code>docs/atomic/services/aiogram/handler-patterns.md</code> - <code>docs/atomic/integrations/rabbitmq/aiogram-integration.md</code></p> <p>AI Generates: - <code>services/template_business_bot/src/handlers/commands.py</code> - <code>services/template_business_bot/src/handlers/notifications.py</code> - <code>services/template_business_bot/src/main.py</code></p>"},{"location":"guides/ai-code-generation-master-workflow/#phase-6-testing-quality","title":"Phase 6: Testing &amp; Quality","text":"<p>AI Reads: - <code>docs/atomic/testing/unit-testing/pytest-setup.md</code> - <code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> - <code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code></p> <p>AI Generates: - Unit tests for all layers - Integration tests with testcontainers - End-to-end tests - <code>pytest.ini</code>, <code>conftest.py</code></p> <p>Validation (MANDATORY before Stage 5): <pre><code>uv run ruff check .\nuv run ruff format . --check\nuv run mypy .\nuv run bandit -r .\nuv run pytest --cov=src --cov-report=html --cov-report=xml\n</code></pre></p> <p>Exit Criteria: All code generated, all tests pass, coverage \u2265 level-dependent threshold: - Level 1 (PoC): \u2265 60% - Level 2 (Development): \u2265 75% - Level 3 (Pre-Production): \u2265 80% - Level 4 (Production): \u2265 85%</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-5-quality-verification","title":"Stage 5: Quality Verification","text":"<p>Entry Criteria: Code generation complete.</p> <p>AI Actions: 1. Read <code>agent-verification-checklist.md</code> 2. Read <code>maturity-levels.md</code> to understand level-specific criteria (coverage thresholds, security requirements, etc.) 3. Execute ALL checks in order:    - Requirements coverage (100% or stakeholder-approved descope) \u2014 CRITICAL: PRIMARY QUALITY GATE    - Environment checks (Python version, UV installed)    - Static analysis (Ruff, Mypy, Bandit)    - Testing (pytest with coverage \u2014 threshold varies by level)    - Artifact validation (project structure, 3-part naming by default) 4. Requirements Coverage Verification (NEW \u2014 see <code>agent-verification-checklist.md</code> \u00a7 Requirements Coverage Verification):    - Extract all Req IDs from Stage 2 (Requirements Intake)    - Verify EACH Req ID has Status \"\u2705 Done\" in Implementation Plan RTM (Stage 3)    - Verify Evidence (code file path) exists for each requirement    - Calculate coverage: implemented / total \u00d7 100%    - GATE: If coverage &lt; 100% \u2192 BLOCK Stage 6 (unless stakeholder approves descope) 5. Capture evidence for each check 5. If ANY check fails:    - Fix the issue    - Re-run failed check    - Document fix in commit message 6. Generate coverage reports:    - <code>htmlcov/index.html</code> (HTML report)    - <code>coverage.xml</code> (CI/CD integration)</p> <p>Documents Read: - <code>docs/quality/agent-verification-checklist.md</code> - <code>docs/reference/maturity-levels.md</code> (for level-specific criteria) - <code>docs/reference/agent-toolbox.md</code> (quality commands) - <code>docs/reference/troubleshooting.md</code> (if issues found)</p> <p>AI Generates: - Completed verification checklist (markdown) - Coverage reports (HTML + XML) - Evidence links (logs, screenshots)</p> <p>Example Checklist Output: <pre><code># Verification Checklist: P2P Lending Platform\n\n**Date**: 2025-10-01\n**Maturity Level**: 3 - Pre-Production\n**Status**: \u2705 PASSED\n\n## Static Analysis &amp; Security\n| Check | Command | Result | Evidence |\n|-------|---------|--------|----------|\n| Linting | `uv run ruff check .` | \u2705 PASS | 0 errors |\n| Formatting | `uv run ruff format . --check` | \u2705 PASS | No drift |\n| Type checking | `uv run mypy .` | \u2705 PASS | 0 type errors |\n| Security scan | `uv run bandit -r .` | \u2705 PASS | 0 high severity |\n\n## Testing &amp; Coverage\n| Check | Command | Result | Evidence |\n|-------|---------|--------|----------|\n| Unit tests | `uv run pytest` | \u2705 PASS | 287 passed, 0 failed |\n| Coverage | `pytest --cov=src` | \u2705 82% | htmlcov/index.html |\n| **Coverage threshold** | **Level 3 requires \u2265 80%** | **\u2705 MET** | 82% \u2265 80% |\n\n## Artifact Validation\n| Check | Result | Notes |\n|-------|--------|-------|\n| Project structure | \u2705 PASS | Follows project-structure.md |\n| Naming conventions | \u2705 PASS | All snake_case for code |\n| Documentation | \u2705 PASS | README, API docs generated |\n| Maturity features | \u2705 VERIFIED | Nginx \u2705, SSL \u2705, Metrics \u2705 (Level 3) |\n</code></pre></p> <p>Exit Criteria: ALL checks pass, coverage \u2265 level-dependent threshold (60%/75%/80%/85%).</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-6-qa-report-handoff","title":"Stage 6: QA Report &amp; Handoff","text":"<p>Entry Criteria: Verification complete, all checks passed.</p> <p>AI Actions: 1. Read <code>qa-report-template.md</code> 2. Compile final QA report:    - Executive summary (status, accomplishments, issues)    - Verification checklist summary    - Test &amp; coverage details    - Defects &amp; risks (if any)    - Deliverables summary 3. Update <code>deliverables-catalog.md</code> with artifact locations 4. Create handoff package:    - Source code (GitHub repo)    - Requirements Intake document    - Implementation Plan    - QA Report    - Coverage reports    - Deployment guide</p> <p>Documents Read: - <code>docs/quality/qa-report-template.md</code> - <code>docs/reference/deliverables-catalog.md</code></p> <p>AI Generates: - QA Report (markdown) - Deliverables summary - Deployment instructions</p> <p>Example QA Report: <pre><code># QA Report: P2P Lending Platform\n\n**Date**: 2025-10-01\n**Status**: \u2705 READY FOR DEPLOYMENT\n\n## Executive Summary\nSuccessfully delivered production-ready P2P lending platform following Improved Hybrid Approach architecture.\n\n**Key Accomplishments**:\n- 5 microservices (API, Bot, Worker, PostgreSQL, MongoDB)\n- 24 API endpoints with full OpenAPI docs\n- 287 tests with 87% coverage\n- All security &amp; quality gates passed\n- GDPR compliance verified\n\n**Outstanding Issues**: None\n\n**Recommendation**: APPROVED for production deployment\n\n## Deliverables Summary\n- \u2705 Source code: `/services/**/*.py` (12,450 lines)\n- \u2705 Infrastructure: `docker-compose.yml`, `Makefile`\n- \u2705 Tests: 287 tests, 87% coverage\n- \u2705 Documentation: README.md, API docs (Swagger)\n- \u2705 Requirements Intake: `artifacts/requirements/intake.md`\n- \u2705 Implementation Plan: `artifacts/plans/implementation-plan.md`\n\n## Next Steps\n1. Deploy to staging: `make ENV=staging deploy`\n2. Configure production .env\n3. Run smoke tests\n4. Deploy to production: `make ENV=prod deploy`\n\n[... full report ...]\n</code></pre></p> <p>Exit Criteria: QA report approved, handoff complete.</p>"},{"location":"guides/ai-code-generation-master-workflow/#part-3-navigation-matrix","title":"Part 3: Navigation Matrix","text":"<p>This matrix shows exactly what AI should read at each stage and what it should generate.</p> Stage Phase Documents to Read AI Generates Templates/Tools Success Criteria 0 Initialization <code>AGENTS.md</code><code>agent-context-summary.md</code><code>ai-code-generation-master-workflow.md</code> - - Context loaded 1 Prompt Validation <code>prompt-validation-guide.md</code><code>prompt-templates.md</code> (if needed) Validation note OR clarification request <code>prompt-templates.md</code> All mandatory fields present 2 Requirements Intake <code>requirements-intake-template.md</code><code>architecture-guide.md</code><code>tech_stack.md</code><code>atomic/architecture/*</code> Requirements Intake document <code>prompt-templates.md</code> Requirements approved 3 Planning <code>implementation-plan-template.md</code><code>use-case-implementation-guide.md</code><code>atomic/services/**/*</code> (relevant)<code>atomic/integrations/**/*</code> (relevant) Implementation PlanOptional ADR <code>architecture-decision-log-template.md</code><code>agent-toolbox.md</code> Plan approved 4.1 Infrastructure <code>atomic/infrastructure/containerization/*</code><code>atomic/infrastructure/configuration/*</code> Docker Compose filesDockerfilesMakefiles <code>agent-toolbox.md</code> <code>docker-compose up</code> succeeds 4.2 Data Layer <code>atomic/services/data-services/*</code><code>atomic/databases/postgresql/*</code><code>atomic/databases/postgresql-advanced/*</code> SQLAlchemy modelsRepositoriesHTTP APIsMigrations <code>agent-toolbox.md</code> Data services healthy 4.3 Business Logic <code>atomic/services/fastapi/*</code><code>atomic/architecture/ddd-hexagonal-principles.md</code><code>atomic/integrations/http-communication/*</code> Domain entitiesUse casesAPI routersHTTP clients <code>agent-toolbox.md</code> API endpoints working 4.4 Workers <code>atomic/services/asyncio-workers/*</code><code>atomic/integrations/rabbitmq/*</code> Worker implementationsEvent consumers <code>agent-toolbox.md</code> Workers processing events 4.5 Telegram Bot <code>atomic/services/aiogram/*</code><code>atomic/integrations/rabbitmq/aiogram-integration.md</code> Bot handlersCommandsNotifications <code>agent-toolbox.md</code> Bot responding to commands 4.6 Testing <code>atomic/testing/unit-testing/*</code><code>atomic/testing/integration-testing/*</code><code>atomic/testing/service-testing/*</code> Unit testsIntegration tests<code>pytest.ini</code><code>conftest.py</code> <code>agent-toolbox.md</code> Tests pass, coverage \u226580% 5 Verification <code>agent-verification-checklist.md</code><code>troubleshooting.md</code> (if needed) Completed checklistCoverage reportsEvidence logs <code>agent-toolbox.md</code> All checks pass 6 Handoff <code>qa-report-template.md</code><code>deliverables-catalog.md</code> QA ReportDeliverables summaryDeployment guide - Stakeholder sign-off <p>Usage: At each stage, AI looks up this row and reads ONLY the listed documents.</p>"},{"location":"guides/ai-code-generation-master-workflow/#part-4-example-walkthrough-p2p-lending","title":"Part 4: Example Walkthrough (P2P Lending)","text":"<p>This section shows a condensed example of the complete workflow for a P2P lending platform.</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-0-initialization","title":"Stage 0: Initialization","text":"<p>AI reads: AGENTS.md \u2192 agent-context-summary.md \u2192 ai-code-generation-master-workflow.md</p> <p>AI learns: - Framework uses Improved Hybrid Approach - Data services provide HTTP APIs (no direct DB access) - Service types must run in separate containers - RabbitMQ for async communication</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-1-prompt-validation_1","title":"Stage 1: Prompt Validation","text":"<p>User prompt: <pre><code>I want to build a P2P lending platform where users can:\n- Lend money to each other\n- Create loan requests\n- Make payments with automatic interest calculation\n- Track credit scores\n- Get notifications via Telegram bot\n</code></pre></p> <p>AI checks: Missing fields detected - \u274c Authentication method - \u274c Payment gateway - \u274c Scale expectations - \u274c Compliance requirements</p> <p>AI response: <pre><code>## \ud83d\udd0d Prompt Validation: Additional Information Needed\n\n**Missing Details**:\n1. Authentication: JWT, OAuth2, or magic links?\n2. Payment gateway: Stripe, PayPal, cryptocurrency?\n3. Scale: Expected users and transactions in year 1?\n4. Compliance: GDPR, FCA, AML requirements?\n\nPlease provide these details to proceed.\n</code></pre></p> <p>User provides: <pre><code>1. JWT + 2FA via SMS\n2. Stripe for payments\n3. Target 1K users, 50 loans/day\n4. GDPR (EU) + FCA (UK) compliance, 7-year retention\n</code></pre></p> <p>AI validates: \u2705 All fields now present \u2192 proceed to Stage 2</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-2-requirements-intake","title":"Stage 2: Requirements Intake","text":"<p>AI reads: - <code>architecture-guide.md</code> \u2192 verify P2P lending fits Improved Hybrid - <code>tech_stack.md</code> \u2192 check Stripe SDK available</p> <p>AI analyzes: - \u2705 Fits Improved Hybrid (transactional + analytics data) - \u2705 Requires: FastAPI (REST API) + Aiogram (notifications) + Worker (payments) - \u2705 Requires: PostgreSQL (loans, users, payments) + MongoDB (audit logs) - \u2705 External: Stripe, Twilio (2FA), Onfido (KYC)</p> <p>AI generates (Requirements Intake excerpt): <pre><code>## Architecture Mapping\n**Services Needed**:\n- FastAPI service (Port 8000) - REST API\n- Aiogram service - Telegram notifications\n- AsyncIO worker - Payment processing, credit scoring\n- PostgreSQL service (Port 8001) - Users, loans, payments\n- MongoDB service (Port 8002) - Audit logs, analytics\n\n**Data Model** (PostgreSQL):\n- users (id, email, kyc_status, credit_score)\n- loans (id, borrower_id, amount, duration, interest_rate, status)\n- payments (id, loan_id, amount, due_date, paid_date)\n- escrow_accounts (id, loan_id, balance)\n\n**Events** (RabbitMQ):\n- user.registered \u2192 send KYC email\n- loan.created \u2192 notify potential lenders\n- payment.due \u2192 send reminder (Telegram + email)\n- payment.received \u2192 update credit score\n</code></pre></p> <p>User approves \u2192 Stage 3</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-3-implementation-planning","title":"Stage 3: Implementation Planning","text":"<p>AI reads: - <code>atomic/services/fastapi/basic-setup.md</code> - <code>atomic/services/data-services/postgres-service-setup.md</code> - <code>atomic/integrations/rabbitmq/exchange-queue-declaration.md</code></p> <p>AI generates (Implementation Plan excerpt): <pre><code>## Phase 1: Infrastructure (Week 1)\n**Tasks**:\n1. Project initialization\n   - Generate structure per project-structure.md\n   - Configure docker-compose.yml (5 services)\n   - Setup .env with Stripe/Twilio/Onfido keys\n\n2. Service scaffolding\n   - Create services/{api,bot,worker,db_postgres,db_mongo}\n   - Follow atomic/services/*/basic-setup.md\n   - **DoD**: `docker-compose up` \u2192 all healthy\n\n## Phase 2: Data Layer (Week 2)\n**Tasks**:\n1. PostgreSQL service implementation\n   - Models: User, Loan, Payment, EscrowAccount\n   - Repositories: CRUD + active_loans_count\n   - HTTP API: POST /users, GET /loans, etc.\n   - Follow: atomic/services/data-services/postgres-service-setup.md\n   - **DoD**: curl http://localhost:8001/health \u2192 200 OK\n\n2. MongoDB service implementation\n   - Models: AuditLog, CreditScoreHistory\n   - Follow: atomic/services/data-services/mongo-service-setup.md\n\n## Phase 3: Business Logic (Week 3-4)\n**Tasks**:\n1. Loan creation use case\n   - Domain: domain/entities/loan.py\n   - Application: use_cases/create_loan.py\n   - Infrastructure: http_clients/postgres_client.py\n   - API: api/v1/loans_router.py\n   - Follow: atomic/services/fastapi/routing-patterns.md\n   - **DoD**: POST /api/v1/loans creates loan via HTTP to data service\n\n[... 6 phases total ...]\n</code></pre></p> <p>User approves \u2192 Stage 4</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-4-code-generation-excerpt-phase-3","title":"Stage 4: Code Generation (Excerpt - Phase 3)","text":"<p>AI reads: - <code>atomic/services/fastapi/routing-patterns.md</code> - <code>atomic/architecture/ddd-hexagonal-principles.md</code> - <code>atomic/integrations/http-communication/business-to-data-calls.md</code></p> <p>AI generates:</p> <p>File 1: <code>services/template_business_api/src/domain/entities/loan.py</code> <pre><code>\"\"\"Loan domain entity.\"\"\"\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom decimal import Decimal\n\n@dataclass\nclass Loan:\n    \"\"\"Loan aggregate root.\"\"\"\n    id: str\n    borrower_id: str\n    amount: Decimal\n    duration_months: int\n    interest_rate: Decimal\n    status: str  # \"pending\", \"active\", \"completed\", \"defaulted\"\n    created_at: datetime\n\n    def validate_creation(self, borrower_active_loans: int) -&gt; None:\n        \"\"\"Validate loan creation rules.\"\"\"\n        if borrower_active_loans &gt;= 3:\n            raise ValueError(\"Borrower cannot have more than 3 active loans\")\n\n        if self.amount &lt; Decimal(\"100\") or self.amount &gt; Decimal(\"50000\"):\n            raise ValueError(\"Loan amount must be between \u20ac100 and \u20ac50,000\")\n\n        if self.duration_months &lt; 1 or self.duration_months &gt; 60:\n            raise ValueError(\"Loan duration must be between 1 and 60 months\")\n</code></pre></p> <p>File 2: <code>services/template_business_api/src/application/use_cases/create_loan.py</code> <pre><code>\"\"\"Create loan use case.\"\"\"\nfrom decimal import Decimal\nfrom .....domain.entities.loan import Loan\nfrom .....infrastructure.http_clients.postgres_client import PostgresHTTPClient\nfrom .....infrastructure.rabbitmq.event_publisher import EventPublisher\n\nclass CreateLoanUseCase:\n    \"\"\"Business logic for creating a loan request.\"\"\"\n\n    def __init__(\n        self,\n        postgres_client: PostgresHTTPClient,\n        event_publisher: EventPublisher\n    ):\n        self.postgres_client = postgres_client\n        self.event_publisher = event_publisher\n\n    async def execute(self, borrower_id: str, amount: Decimal, duration: int) -&gt; Loan:\n        \"\"\"Create a loan request.\"\"\"\n        # Step 1: Fetch borrower via HTTP (no direct DB!)\n        borrower = await self.postgres_client.get_user(borrower_id)\n\n        # Step 2: Validate KYC\n        if borrower[\"kyc_status\"] != \"approved\":\n            raise ValueError(\"KYC must be approved before creating a loan\")\n\n        # Step 3: Check active loans limit\n        active_count = await self.postgres_client.count_active_loans(borrower_id)\n\n        # Step 4: Create loan entity\n        loan = Loan(\n            id=generate_id(),\n            borrower_id=borrower_id,\n            amount=amount,\n            duration_months=duration,\n            interest_rate=Decimal(\"0.05\"),  # 5% default\n            status=\"pending\",\n            created_at=datetime.utcnow()\n        )\n\n        # Step 5: Validate business rules\n        loan.validate_creation(active_count)\n\n        # Step 6: Persist via HTTP\n        loan_dict = await self.postgres_client.create_loan(loan.__dict__)\n\n        # Step 7: Publish event\n        await self.event_publisher.publish(\"loan.created\", loan_dict)\n\n        return Loan(**loan_dict)\n</code></pre></p> <p>File 3: <code>services/template_business_api/src/api/v1/loans_router.py</code> <pre><code>\"\"\"Loans API router.\"\"\"\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom pydantic import BaseModel\nfrom decimal import Decimal\n\nfrom .....application.use_cases.create_loan import CreateLoanUseCase\nfrom .....infrastructure.dependencies import get_create_loan_use_case\n\nrouter = APIRouter(prefix=\"/api/v1/loans\", tags=[\"loans\"])\n\nclass CreateLoanRequest(BaseModel):\n    amount: Decimal\n    duration_months: int\n\n@router.post(\"/\", status_code=status.HTTP_201_CREATED)\nasync def create_loan(\n    request: CreateLoanRequest,\n    user_id: str = Depends(get_current_user_id),\n    use_case: CreateLoanUseCase = Depends(get_create_loan_use_case)\n):\n    \"\"\"Create a new loan request.\"\"\"\n    try:\n        loan = await use_case.execute(\n            borrower_id=user_id,\n            amount=request.amount,\n            duration=request.duration_months\n        )\n        return loan\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre></p> <p>AI validates: <pre><code>uv run ruff check services/template_business_api/\nuv run mypy services/template_business_api/\n</code></pre></p> <p>Result: \u2705 No errors \u2192 commit code</p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-5-quality-verification_1","title":"Stage 5: Quality Verification","text":"<p>AI reads: <code>agent-verification-checklist.md</code></p> <p>AI executes: <pre><code># Static analysis\nuv run ruff check .                      # \u2705 0 errors\nuv run ruff format . --check             # \u2705 No drift\nuv run mypy .                            # \u2705 0 type errors\nuv run bandit -r .                       # \u2705 0 high severity\n\n# Testing\nuv run pytest --cov=src --cov-report=html\n# \u2705 287 passed, 0 failed\n# \u2705 Coverage: 87%\n</code></pre></p> <p>AI generates checklist: <pre><code># Verification Checklist\n\n## Static Analysis &amp; Security\n| Check | Result | Evidence |\n|-------|--------|----------|\n| Linting | \u2705 PASS | 0 errors |\n| Type checking | \u2705 PASS | 0 type errors |\n| Security | \u2705 PASS | 0 high severity |\n\n## Testing &amp; Coverage\n| Check | Result | Evidence |\n|-------|--------|----------|\n| Tests | \u2705 PASS | 287 passed |\n| Coverage | \u2705 87% | htmlcov/index.html |\n\n**Status**: \u2705 ALL CHECKS PASSED\n</code></pre></p>"},{"location":"guides/ai-code-generation-master-workflow/#stage-6-qa-report-handoff_1","title":"Stage 6: QA Report &amp; Handoff","text":"<p>AI reads: <code>qa-report-template.md</code></p> <p>AI generates: <pre><code># QA Report: P2P Lending Platform\n\n**Status**: \u2705 READY FOR DEPLOYMENT\n\n## Executive Summary\nDelivered production-ready P2P lending platform with:\n- 5 microservices (API, Bot, Worker, PostgreSQL, MongoDB)\n- 24 API endpoints with OpenAPI documentation\n- 287 tests with 87% coverage\n- GDPR &amp; FCA compliance verified\n\n## Deliverables\n- \u2705 Source code (GitHub)\n- \u2705 Docker Compose configuration\n- \u2705 API documentation (Swagger UI)\n- \u2705 Test coverage reports\n- \u2705 Deployment guide\n\n## Deployment Instructions\n```bash\n# 1. Configure production environment\ncp .env.example .env\n# Edit .env with production values\n\n# 2. Deploy stack\ndocker-compose -f docker-compose.prod.yml up -d\n\n# 3. Run migrations\ndocker-compose exec template_data_postgres_api alembic upgrade head\n\n# 4. Verify health\ncurl https://api.p2p-lending.com/health\n</code></pre></p> <p>Recommendation: APPROVED for production deployment <pre><code>**User reviews** \u2192 \u2705 Approved \u2192 **HANDOFF COMPLETE**\n\n---\n\n## Part 5: Common Issues &amp; Recovery\n\n### Issue 1: User prompt incomplete\n\n**Symptom**: Missing functional requirements or business context\n\n**Detection**: Stage 1 (Prompt Validation)\n\n**Recovery**:\n1. Identify missing fields using `prompt-validation-guide.md` checklist\n2. Use clarification templates from `prompt-templates.md`\n3. Wait for user response\n4. Re-validate prompt\n5. Proceed to Stage 2 only when complete\n\n**Prevention**: Always run Stage 1 validation before any work.\n\n---\n\n### Issue 2: Architecture conflict detected\n\n**Symptom**: User requirements contradict Improved Hybrid constraints\n\n**Example**: User wants business service to directly write to PostgreSQL\n\n**Detection**: Stage 2 (Requirements Intake)\n\n**Recovery**:\n1. Explain architectural constraint:\n   ```\n   \u26a0\ufe0f Architecture Conflict Detected\n\n   Your requirement: \"FastAPI service writes directly to PostgreSQL\"\n   Framework constraint: Business services MUST use HTTP-only data access\n\n   Reason: Improved Hybrid Approach enforces centralized data services\n   for consistency, maintainability, and performance.\n\n   Solution: FastAPI service will call PostgreSQL data service via HTTP.\n   ```\n2. Update requirements to align with architecture\n3. Get user approval\n4. Proceed with corrected approach\n\n**Prevention**: Read `architecture-guide.md` during Stage 2.\n\n---\n\n### Issue 3: Test failures during verification\n\n**Symptom**: pytest fails or coverage below threshold\n\n**Detection**: Stage 5 (Verification)\n\n**Recovery**:\n1. Read test failure logs\n2. Identify root cause:\n   - Broken test? \u2192 Fix test\n   - Broken code? \u2192 Fix code (Stage 4)\n   - Missing test? \u2192 Add test\n3. Re-run verification\n4. Repeat until all tests pass\n\n**Prevention**: Run tests continuously during Stage 4 (after each phase).\n\n---\n\n### Issue 4: Type checking errors\n\n**Symptom**: `mypy` reports type errors\n\n**Detection**: Stage 5 (Verification)\n\n**Recovery**:\n1. Read `atomic/testing/quality-assurance/type-checking.md`\n2. Fix type annotations:\n   - Add missing type hints\n   - Fix incorrect types\n   - Use `from __future__ import annotations` for forward refs\n3. Re-run `uv run mypy .`\n4. Repeat until 0 errors\n\n**Common fixes**:\n```python\n# Before (error)\ndef process_payment(amount):\n    ...\n\n# After (fixed)\nfrom decimal import Decimal\n\ndef process_payment(amount: Decimal) -&gt; bool:\n    ...\n</code></pre></p>"},{"location":"guides/ai-code-generation-master-workflow/#issue-5-service-not-healthy-in-docker","title":"Issue 5: Service not healthy in Docker","text":"<p>Symptom: <code>docker-compose ps</code> shows service as unhealthy</p> <p>Detection: Stage 4.1 (Infrastructure)</p> <p>Recovery: 1. Check logs: <code>docker-compose logs &lt;service&gt;</code> 2. Consult <code>troubleshooting.md</code> for symptoms 3. Common causes:    - Database connection failed \u2192 check .env credentials    - Port conflict \u2192 change port mapping    - Missing dependency \u2192 rebuild image 4. Fix issue 5. Restart: <code>docker-compose up -d &lt;service&gt;</code> 6. Verify: <code>curl http://localhost:&lt;port&gt;/health</code></p> <p>Prevention: Always test infrastructure before moving to next phase.</p>"},{"location":"guides/ai-code-generation-master-workflow/#issue-6-broken-links-in-generated-documentation","title":"Issue 6: Broken links in generated documentation","text":"<p>Symptom: Links in README.md point to non-existent files</p> <p>Detection: Manual review or link validator</p> <p>Recovery: 1. Run <code>scripts/validate_docs.py</code> (if available) 2. Fix broken links:    - Update paths    - Remove dead links    - Use relative paths 3. Re-validate 4. Commit fixes</p> <p>Prevention: Use <code>LINKS_REFERENCE.md</code> for canonical link paths.</p>"},{"location":"guides/ai-code-generation-master-workflow/#maintenance","title":"Maintenance","text":""},{"location":"guides/ai-code-generation-master-workflow/#updating-this-document","title":"Updating This Document","text":"<p>When framework documentation changes:</p> <ol> <li>Navigation Matrix: Update document paths if files are renamed/moved</li> <li>Reading Order: Update if new mandatory documents are added</li> <li>Example Walkthrough: Update code examples if patterns change</li> <li>Common Issues: Add new issues as they are discovered</li> </ol>"},{"location":"guides/ai-code-generation-master-workflow/#cross-references","title":"Cross-References","text":"<p>Keep aligned with: - <code>agent-context-summary.md</code> (critical rules) - <code>INDEX.md</code> (full documentation map) - <code>LINKS_REFERENCE.md</code> (canonical link table) - All atomic documentation (patterns source)</p>"},{"location":"guides/ai-code-generation-master-workflow/#change-log","title":"Change Log","text":"<ul> <li>2025-10-01: Initial creation (unified AGENT_WORKFLOW + INTERACTIVE_AI_WORKFLOW)</li> </ul>"},{"location":"guides/ai-code-generation-master-workflow/#quick-reference-card","title":"Quick Reference Card","text":"<p>For AI agents: Bookmark this section for fast lookup.</p> Question Answer Where do I start? Read AGENTS.md \u2192 agent-context-summary.md \u2192 this document What's the high-level process? 7 stages: Init \u2192 Validation \u2192 Intake \u2192 Planning \u2192 Generation \u2192 Verification \u2192 Handoff What do I read at each stage? See Part 3: Navigation Matrix How do I validate prompts? <code>prompt-validation-guide.md</code> + <code>prompt-templates.md</code> How do I structure requirements? Fill <code>requirements-intake-template.md</code> How do I plan implementation? Fill <code>implementation-plan-template.md</code> How do I generate code? Read atomic docs per Navigation Matrix, follow DDD/Hexagonal patterns How do I verify quality? Execute <code>agent-verification-checklist.md</code> How do I hand off? Complete <code>qa-report-template.md</code> What if I'm stuck? Consult Part 5: Common Issues <p>END OF DOCUMENT</p>"},{"location":"guides/architecture-guide/","title":"Architecture Guide","text":"<p>CANONICAL ARCHITECTURE REFERENCE: This document is the single source of truth for all architectural decisions, patterns, and constraints. All implementation must follow these guidelines.</p>"},{"location":"guides/architecture-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Improved Hybrid Approach Overview</li> <li>Core Principles and Constraints</li> <li>Service Types and Separation</li> <li>Data Access Architecture</li> <li>Inter-Service Communication</li> <li>Event-Driven Architecture</li> <li>DDD/Hexagonal Architecture</li> <li>Quality Standards</li> <li>Implementation Guidelines</li> </ul>"},{"location":"guides/architecture-guide/#improved-hybrid-approach-overview","title":"Improved Hybrid Approach Overview","text":"<p>The Improved Hybrid Approach is the foundational architecture pattern for this microservices platform. It combines the best aspects of microservices architecture with centralized data access to achieve optimal performance, maintainability, and scalability.</p>"},{"location":"guides/architecture-guide/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Centralized Data Services: Two dedicated services handle ALL database operations</li> <li>Business Logic Separation: Business services contain ONLY business logic</li> <li>HTTP-Only Data Access: No direct database connections in business services</li> <li>Event-Driven Communication: RabbitMQ for inter-service messaging</li> <li>Service Type Isolation: Each service type runs in separate processes</li> </ul>"},{"location":"guides/architecture-guide/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>graph TB\n    subgraph \"External Access\"\n        CLIENT[External Clients]\n        NGINX[Nginx API Gateway :80/:443]\n    end\n\n    subgraph \"Business Services\"\n        API[FastAPI Service :8000]\n        BOT[Aiogram Bot]\n        WORKER[AsyncIO Workers]\n    end\n\n    subgraph \"Data Services\"\n        PG[template_data_postgres_api :8001]\n        MONGO[template_data_mongo_api :8002]\n    end\n\n    subgraph \"Infrastructure\"\n        POSTGRES[(PostgreSQL)]\n        MONGODB[(MongoDB)]\n        REDIS[(Redis)]\n        RABBIT[RabbitMQ]\n    end\n\n    CLIENT --&gt;|HTTPS| NGINX\n    NGINX --&gt;|Reverse Proxy| API\n    NGINX --&gt;|Reverse Proxy| BOT\n\n    API --&gt;|HTTP only| PG\n    API --&gt;|HTTP only| MONGO\n    BOT --&gt;|HTTP only| PG\n    BOT --&gt;|HTTP only| MONGO\n    WORKER --&gt;|HTTP only| PG\n    WORKER --&gt;|HTTP only| MONGO\n\n    PG --&gt; POSTGRES\n    MONGO --&gt; MONGODB\n\n    API -.-&gt;|Events| RABBIT\n    BOT -.-&gt;|Events| RABBIT\n    WORKER -.-&gt;|Events| RABBIT\n\n    style CLIENT fill:#e0e7ff,stroke:#4338ca,stroke-width:2px,color:#1e3a8a\n    style NGINX fill:#fef3c7,stroke:#d97706,stroke-width:3px,color:#92400e\n    style API fill:#93c5fd,stroke:#1e40af,stroke-width:3px,color:#1e3a8a\n    style BOT fill:#93c5fd,stroke:#1e40af,stroke-width:3px,color:#1e3a8a\n    style WORKER fill:#93c5fd,stroke:#1e40af,stroke-width:3px,color:#1e3a8a\n    style PG fill:#c4b5fd,stroke:#6d28d9,stroke-width:3px,color:#5b21b6\n    style MONGO fill:#c4b5fd,stroke:#6d28d9,stroke-width:3px,color:#5b21b6\n    style POSTGRES fill:#dbeafe,stroke:#1e40af,stroke-width:2px,color:#1e3a8a\n    style MONGODB fill:#dbeafe,stroke:#1e40af,stroke-width:2px,color:#1e3a8a\n    style REDIS fill:#fecaca,stroke:#b91c1c,stroke-width:2px,color:#991b1b\n    style RABBIT fill:#fed7aa,stroke:#c2410c,stroke-width:2px,color:#9a3412</code></pre>"},{"location":"guides/architecture-guide/#core-principles-and-constraints","title":"Core Principles and Constraints","text":""},{"location":"guides/architecture-guide/#mandatory-architectural-constraints","title":"MANDATORY Architectural Constraints","text":"<p>These constraints are NON-NEGOTIABLE and must be followed in all implementations:</p>"},{"location":"guides/architecture-guide/#1-data-access-architecture-improved-hybrid-approach","title":"1. Data Access Architecture (Improved Hybrid Approach)","text":"<ul> <li>MANDATORY: Centralized Data Services - Two dedicated data services handle ALL database operations:</li> <li><code>template_data_postgres_api</code> (Port: 8001) - PostgreSQL data access service</li> <li><code>template_data_mongo_api</code> (Port: 8002) - MongoDB data access service</li> <li>MANDATORY: Business Logic Separation - Business services (<code>template_business_api</code>, <code>template_business_bot</code>, <code>template_business_worker</code>) contain ONLY business logic</li> <li>MANDATORY: HTTP-Only Data Access - Business services access data EXCLUSIVELY via HTTP APIs to data services</li> <li>PROHIBITED: Direct database connections in business services</li> </ul>"},{"location":"guides/architecture-guide/#2-service-type-separation-critical-for-event-loop-management","title":"2. Service Type Separation (Critical for Event Loop Management)","text":"<ul> <li>MANDATORY: Event Loop Isolation - Each service type MUST run in separate processes/containers</li> <li>Service Types:</li> <li>HTTP API Services: FastAPI + Uvicorn (separate process)</li> <li>Telegram Bot Services: Aiogram (separate process)</li> <li>Background Workers: AsyncIO workers (separate process)</li> <li>PROHIBITED: Running multiple event loop managers (FastAPI + Aiogram) in same process</li> <li>MANDATORY: Communication - Use RabbitMQ for inter-service communication</li> </ul>"},{"location":"guides/architecture-guide/#3-api-gateway-production-requirement","title":"3. API Gateway (Production Requirement)","text":"<ul> <li>MANDATORY: Nginx as API Gateway for production deployments</li> <li>Responsibilities:</li> <li>TLS/SSL termination (HTTPS)</li> <li>Reverse proxy and load balancing</li> <li>Rate limiting and DDoS protection</li> <li>CORS and security headers</li> <li>Request routing and URL rewriting</li> <li>Configuration: See Nginx Setup and Load Balancing</li> <li>Development: Optional for local development (can access services directly)</li> <li>Production: MANDATORY for all production environments</li> </ul>"},{"location":"guides/architecture-guide/#4-technology-stack-requirements","title":"4. Technology Stack Requirements","text":"<ul> <li>MANDATORY: Python Version - 3.12+ MANDATORY for all services (unified runtime)</li> <li>MANDATORY: Base Image - <code>python:3.12-slim</code> for all Docker containers</li> <li>MANDATORY: Async Libraries - Use only async-compatible libraries (asyncpg, aio-pika, redis.asyncio)</li> <li>MANDATORY: Database Strategy - Dual database approach (PostgreSQL + MongoDB)</li> <li>MANDATORY: API Gateway - Nginx 1.25+ for production deployments</li> </ul> <p>COMPLETE TECHNOLOGY SPECIFICATIONS: For detailed versions, configurations, and compatibility information, see the Technical Specifications.</p>"},{"location":"guides/architecture-guide/#5-naming-conventions-enforced-project-wide","title":"5. Naming Conventions (Enforced Project-Wide)","text":"<ul> <li>MANDATORY: Underscore-Only Policy - Use snake_case for ALL identifiers</li> <li>PROHIBITED: Hyphens in any user-controlled names (files, variables, functions, databases, APIs)</li> <li>MANDATORY: Consistent naming across all layers (code, database, API, Docker, etc.)</li> </ul> <p>COMPLETE NAMING RULES: See the Naming Conventions for comprehensive naming standards.</p>"},{"location":"guides/architecture-guide/#service-types-and-separation","title":"Service Types and Separation","text":""},{"location":"guides/architecture-guide/#critical-event-loop-management","title":"Critical Event Loop Management","text":"<p>Why Separation is Critical: Different frameworks manage event loops differently. Running FastAPI and Aiogram in the same process creates conflicting event loop claims, leading to runtime errors and unstable behavior.</p>"},{"location":"guides/architecture-guide/#service-types-and-technologies","title":"Service Types and Technologies","text":""},{"location":"guides/architecture-guide/#http-api-services","title":"HTTP API Services","text":"<ul> <li>Technology: FastAPI + Uvicorn</li> <li>Event Loop: Managed by FastAPI/Uvicorn</li> <li>Integration: Redis and RabbitMQ via dependency injection</li> <li>Process: Separate container/process</li> <li>Guide: See FastAPI Rules</li> </ul>"},{"location":"guides/architecture-guide/#telegram-bot-services","title":"Telegram Bot Services","text":"<ul> <li>Technology: Aiogram</li> <li>Event Loop: Managed by Aiogram via <code>asyncio.run(dp.start_polling(bot))</code></li> <li>Integration: Redis and RabbitMQ via dependency injection in Dispatcher</li> <li>Process: Separate container/process</li> <li>Guide: See Aiogram Rules</li> </ul>"},{"location":"guides/architecture-guide/#background-worker-services","title":"Background Worker Services","text":"<ul> <li>Technology: AsyncIO + aio-pika + redis.asyncio</li> <li>Event Loop: <code>asyncio.run(main())</code> in separate process</li> <li>Integration: Direct use of async libraries</li> <li>Process: Separate container/process</li> <li>Guide: See AsyncIO Rules</li> </ul>"},{"location":"guides/architecture-guide/#inter-service-communication-patterns","title":"Inter-Service Communication Patterns","text":"<ul> <li>Synchronous: HTTP API between services (FastAPI \u2194 FastAPI)</li> <li>Asynchronous: RabbitMQ events between all service types</li> <li>Caching: Redis for all service types (idempotency, cache, sessions)</li> <li>Tracing: Request ID and OpenTelemetry trace propagation</li> </ul> <p>DETAILED SEPARATION PRINCIPLES: For comprehensive service separation rationale, patterns, and anti-patterns, see Service Separation Principles.</p>"},{"location":"guides/architecture-guide/#data-access-architecture","title":"Data Access Architecture","text":""},{"location":"guides/architecture-guide/#centralized-data-services-pattern","title":"Centralized Data Services Pattern","text":"<p>The Improved Hybrid Approach uses dedicated data services to centralize all database operations while maintaining service autonomy for business logic.</p>"},{"location":"guides/architecture-guide/#data-service-responsibilities","title":"Data Service Responsibilities","text":"<ul> <li>PostgreSQL Data Service (<code>template_data_postgres_api</code>):</li> <li>Handles all relational data operations</li> <li>Users, products, orders, payments</li> <li>ACID transactions and complex queries</li> <li> <p>Port: 8001 (external), Port: 8000 (internal)</p> </li> <li> <p>MongoDB Data Service (<code>template_data_mongo_api</code>):</p> </li> <li>Handles all document and analytics data</li> <li>User behavior, application logs, analytics events</li> <li>Aggregation pipelines and real-time analytics</li> <li>Port: 8002 (external), Port: 8000 (internal)</li> </ul>"},{"location":"guides/architecture-guide/#business-service-integration","title":"Business Service Integration","text":"<ul> <li>HTTP-Only Access: Business services communicate with data services via HTTP APIs</li> <li>No Direct Database Connections: Business services never connect directly to databases</li> <li>Request Context: All requests include request_id and user_id for tracing</li> <li>Error Handling: Proper HTTP status code handling and retry logic</li> </ul> <p>WHY THIS MATTERS: The separation of business and data services is a core architectural principle. For the complete rationale, patterns, and common pitfalls, see Service Separation Principles.</p>"},{"location":"guides/architecture-guide/#data-access-patterns","title":"Data Access Patterns","text":"<pre><code># CORRECT: HTTP-based data access in business service\nasync def get_user_profile(user_id: str, request_id: str) -&gt; UserProfile:\n    # Get user data via PostgreSQL service\n    user_data = await postgres_client.get_user(user_id, request_id)\n\n    # Get analytics data via MongoDB service\n    analytics_data = await mongo_client.get_user_analytics(user_id, request_id)\n\n    # Business logic: combine and transform data\n    return UserProfile.combine(user_data, analytics_data)\n\n# WRONG: Direct database access in business service\nasync def get_user_profile(user_id: str) -&gt; UserProfile:\n    # PROHIBITED: Direct database connection\n    user = await db.execute(select(User).where(User.id == user_id))\n    return UserProfile.from_orm(user)\n</code></pre> <p>DETAILED DATA ACCESS RULES: See the Data Access Rules for comprehensive data access patterns.</p>"},{"location":"guides/architecture-guide/#inter-service-communication","title":"Inter-Service Communication","text":""},{"location":"guides/architecture-guide/#communication-types","title":"Communication Types","text":""},{"location":"guides/architecture-guide/#1-synchronous-communication-http","title":"1. Synchronous Communication (HTTP)","text":"<ul> <li>Use Case: Direct data access and immediate responses</li> <li>Pattern: Business services \u2192 Data services</li> <li>Protocol: HTTP/HTTPS with JSON payloads</li> <li>Error Handling: HTTP status codes, timeouts, retries</li> </ul>"},{"location":"guides/architecture-guide/#2-asynchronous-communication-events","title":"2. Asynchronous Communication (Events)","text":"<ul> <li>Use Case: Cross-service notifications and event-driven workflows</li> <li>Pattern: All services \u2192 RabbitMQ \u2192 All services</li> <li>Protocol: AMQP with JSON payloads</li> <li>Reliability: Persistent queues, acknowledgments, dead letter queues</li> </ul>"},{"location":"guides/architecture-guide/#communication-patterns","title":"Communication Patterns","text":"<pre><code># HTTP Communication Example\nasync def create_user(user_data: UserCreate, request_id: str) -&gt; UserResponse:\n    # Create user via HTTP call to PostgreSQL service\n    user = await postgres_client.create_user(user_data.dict(), request_id)\n\n    # Publish event for other services\n    await publish_event(\"user.created\", {\n        \"user_id\": user[\"id\"],\n        \"email\": user[\"email\"],\n        \"timestamp\": datetime.utcnow().isoformat()\n    })\n\n    return UserResponse(**user)\n\n# Event Handling Example\nasync def handle_user_created_event(event_data: dict) -&gt; None:\n    user_id = event_data[\"user_id\"]\n\n    # Business logic: initialize user analytics\n    await analytics_service.initialize_user_metrics(user_id)\n\n    # Business logic: send welcome email\n    await notification_service.send_welcome_email(event_data[\"email\"])\n</code></pre> <p>DETAILED COMMUNICATION RULES: See the RabbitMQ Rules for comprehensive messaging patterns.</p>"},{"location":"guides/architecture-guide/#event-driven-architecture","title":"Event-Driven Architecture","text":""},{"location":"guides/architecture-guide/#event-patterns","title":"Event Patterns","text":""},{"location":"guides/architecture-guide/#event-types","title":"Event Types","text":"<ul> <li>Entity Events: <code>user.created</code>, <code>order.completed</code>, <code>payment.processed</code></li> <li>Process Events: <code>workflow.started</code>, <code>batch.completed</code>, <code>notification.sent</code></li> <li>System Events: <code>service.started</code>, <code>health.degraded</code>, <code>metrics.collected</code></li> </ul>"},{"location":"guides/architecture-guide/#event-structure","title":"Event Structure","text":"<pre><code>{\n  \"event_type\": \"user.created\",\n  \"event_id\": \"uuid-v6\",\n  \"timestamp\": \"2025-01-15T10:30:00Z\",\n  \"service\": \"template_business_api\",\n  \"request_id\": \"req-uuid\",\n  \"user_id\": \"user-uuid\",\n  \"data\": {\n    \"user_id\": \"user-uuid\",\n    \"email\": \"user@example.com\",\n    \"registration_source\": \"web\"\n  }\n}\n</code></pre>"},{"location":"guides/architecture-guide/#event-processing-patterns","title":"Event Processing Patterns","text":"<ul> <li>Fire-and-Forget: Non-critical notifications</li> <li>At-Least-Once: Critical business events with idempotency</li> <li>Saga Pattern: Complex workflows spanning multiple services</li> <li>Event Sourcing: Audit trails and state reconstruction</li> </ul>"},{"location":"guides/architecture-guide/#dddhexagonal-architecture","title":"DDD/Hexagonal Architecture","text":""},{"location":"guides/architecture-guide/#domain-driven-design-layers","title":"Domain-Driven Design Layers","text":""},{"location":"guides/architecture-guide/#1-domain-layer-core","title":"1. Domain Layer (Core)","text":"<ul> <li>Business Entities: User, Product, Order, Task</li> <li>Value Objects: Email, Money, Address</li> <li>Domain Services: Business rules and calculations</li> <li>Domain Events: Business-significant occurrences</li> <li>No Dependencies: Pure business logic, no infrastructure</li> </ul>"},{"location":"guides/architecture-guide/#2-application-layer-use-cases","title":"2. Application Layer (Use Cases)","text":"<ul> <li>Application Services: Orchestrate business workflows</li> <li>Use Cases: Specific business scenarios</li> <li>Command/Query Handlers: CQRS patterns</li> <li>Event Handlers: React to domain events</li> <li>Minimal Dependencies: Only domain layer</li> </ul>"},{"location":"guides/architecture-guide/#3-infrastructure-layer-external-concerns","title":"3. Infrastructure Layer (External Concerns)","text":"<ul> <li>Repositories: Data access implementations</li> <li>HTTP Clients: External service communication</li> <li>Message Publishers: Event publishing</li> <li>Configuration: Settings and environment variables</li> <li>Framework Integration: FastAPI, Aiogram adapters</li> </ul>"},{"location":"guides/architecture-guide/#4-interface-layer-presentation","title":"4. Interface Layer (Presentation)","text":"<ul> <li>Controllers: HTTP request handling</li> <li>Routers: API endpoint definitions</li> <li>Bot Handlers: Telegram command handling</li> <li>Middleware: Cross-cutting concerns</li> <li>DTO Mappers: Request/response transformation</li> </ul>"},{"location":"guides/architecture-guide/#hexagonal-architecture-benefits","title":"Hexagonal Architecture Benefits","text":"<ul> <li>Testability: Easy to test business logic in isolation</li> <li>Flexibility: Easy to swap infrastructure components</li> <li>Maintainability: Clear separation of concerns</li> <li>Scalability: Independent scaling of different layers</li> </ul>"},{"location":"guides/architecture-guide/#quality-standards","title":"Quality Standards","text":""},{"location":"guides/architecture-guide/#code-quality-requirements","title":"Code Quality Requirements","text":""},{"location":"guides/architecture-guide/#1-type-annotations-mandatory","title":"1. Type Annotations (MANDATORY)","text":"<ul> <li>Full typing required: All functions must have complete type hints</li> <li>Enforcement: mypy&gt;=1.8.0 with strict settings</li> <li>No <code>Any</code> types: Use specific types or Union types</li> <li>Return types: All functions must specify return types</li> </ul>"},{"location":"guides/architecture-guide/#2-test-coverage-mandatory","title":"2. Test Coverage (MANDATORY)","text":"<ul> <li>Critical Paths: 100% coverage for business logic</li> <li>Integration Tests: Real database testing via testcontainers</li> <li>Unit Tests: Mock external dependencies</li> <li>End-to-End Tests: Complete user workflows</li> </ul>"},{"location":"guides/architecture-guide/#3-code-quality-tools-mandatory","title":"3. Code Quality Tools (MANDATORY)","text":"<ul> <li>Linting: Ruff (PEP8 compliance)</li> <li>Type Checking: Mypy (strict mode)</li> <li>Security: Bandit (static analysis)</li> <li>Formatting: Ruff format (consistent style)</li> </ul>"},{"location":"guides/architecture-guide/#4-documentation-required","title":"4. Documentation (REQUIRED)","text":"<ul> <li>Comprehensive docstrings: All public methods</li> <li>API documentation: OpenAPI/Swagger</li> <li>Architecture decisions: Documented rationale</li> <li>Examples: Working code samples</li> </ul>"},{"location":"guides/architecture-guide/#performance-standards","title":"Performance Standards","text":"<ul> <li>Response Times: &lt; 200ms for simple operations, &lt; 1s for complex</li> <li>Database Queries: Optimized with proper indexes</li> <li>Connection Pooling: Configured for all external services</li> <li>Caching: Redis for frequently accessed data</li> <li>Resource Limits: Memory and CPU constraints in production</li> </ul>"},{"location":"guides/architecture-guide/#implementation-guidelines","title":"Implementation Guidelines","text":""},{"location":"guides/architecture-guide/#service-development-checklist","title":"Service Development Checklist","text":""},{"location":"guides/architecture-guide/#for-fastapi-services","title":"For FastAPI Services","text":"<ul> <li> Implement health check endpoint (<code>/health</code>)</li> <li> Use dependency injection for data clients</li> <li> Implement proper error handling and HTTP status codes</li> <li> Add OpenAPI documentation with examples</li> <li> Configure CORS, rate limiting, and security middleware</li> <li> Implement request/response logging with correlation IDs</li> </ul>"},{"location":"guides/architecture-guide/#for-aiogram-services","title":"For Aiogram Services","text":"<ul> <li> Implement graceful startup and shutdown</li> <li> Use dependency injection in dispatcher</li> <li> Handle all bot update types (messages, callbacks, etc.)</li> <li> Implement user session management</li> <li> Add comprehensive error handling</li> <li> Configure webhook mode for production</li> </ul>"},{"location":"guides/architecture-guide/#for-asyncio-workers","title":"For AsyncIO Workers","text":"<ul> <li> Implement proper signal handling for graceful shutdown</li> <li> Use connection pooling for external services</li> <li> Implement retry logic with exponential backoff</li> <li> Add comprehensive logging with context</li> <li> Monitor queue backlogs and processing times</li> <li> Implement health checks for worker processes</li> </ul>"},{"location":"guides/architecture-guide/#for-data-services","title":"For Data Services","text":"<ul> <li> Implement repository pattern for data access</li> <li> Use proper transaction management</li> <li> Add comprehensive validation with Pydantic</li> <li> Implement connection pooling and health checks</li> <li> Add database migration support (Alembic)</li> <li> Configure proper indexing for performance</li> </ul>"},{"location":"guides/architecture-guide/#security-requirements","title":"Security Requirements","text":"<ul> <li>Authentication: OAuth2/JWT for API endpoints</li> <li>Authorization: Role-based access control</li> <li>Input Validation: Pydantic schemas for all inputs</li> <li>SQL Injection Prevention: Parameterized queries only</li> <li>Rate Limiting: Per-user and per-endpoint limits</li> <li>HTTPS: Required for all production communication</li> <li>Secrets Management: Environment variables only, no hardcoded secrets</li> </ul>"},{"location":"guides/architecture-guide/#related-documentation","title":"Related Documentation","text":""},{"location":"guides/architecture-guide/#implementation-resources","title":"Implementation Resources","text":"<ul> <li>Development Commands: Development Commands</li> <li>Technology Specifications: Technical Specifications</li> <li>Troubleshooting: Troubleshooting</li> </ul>"},{"location":"guides/architecture-guide/#implementation-rules","title":"Implementation Rules","text":"<ul> <li>IDE Rules &amp; Patterns: IDE Rules &amp; Patterns (15 rule files for architecture, services, etc.)</li> <li>FastAPI Rules: FastAPI Rules</li> <li>Aiogram Rules: Aiogram Rules</li> <li>AsyncIO Rules: AsyncIO Rules</li> <li>Data Access Rules: Data Access Rules</li> <li>Testing Standards: Testing Standards</li> </ul>"},{"location":"guides/architecture-guide/#project-organization","title":"Project Organization","text":"<ul> <li>Main Guide: Main Entry Point</li> <li>Use Case Implementation: Use Case Implementation</li> </ul>"},{"location":"guides/architecture-guide/#architectural-decision-records","title":"Architectural Decision Records","text":""},{"location":"guides/architecture-guide/#adr-001-improved-hybrid-approach","title":"ADR-001: Improved Hybrid Approach","text":"<p>Decision: Adopt centralized data services with HTTP-only business service access Rationale: Simplifies data access patterns while maintaining service autonomy Status: Accepted</p>"},{"location":"guides/architecture-guide/#adr-002-service-type-separation","title":"ADR-002: Service Type Separation","text":"<p>Decision: Run each service type (FastAPI, Aiogram, AsyncIO) in separate processes Rationale: Prevents event loop conflicts and improves system stability Status: Accepted</p>"},{"location":"guides/architecture-guide/#adr-003-dual-database-strategy","title":"ADR-003: Dual Database Strategy","text":"<p>Decision: Use PostgreSQL for relational data and MongoDB for analytics Rationale: Optimizes for different data patterns and query requirements Status: Accepted</p>"},{"location":"guides/architecture-guide/#adr-004-http-only-data-access","title":"ADR-004: HTTP-Only Data Access","text":"<p>Decision: Prohibit direct database connections in business services Rationale: Centralizes data expertise and simplifies service development Status: Accepted</p> <p>COMPLIANCE REQUIRED: All implementations must comply with this architecture guide. Violations will result in system instability and maintainability issues. When in doubt, refer to the implementation rules in Main Project Guide.</p>"},{"location":"guides/development-commands/","title":"Development Commands Reference","text":"<p>CANONICAL COMMAND REFERENCE: This document is the single source of truth for all development commands. All other documentation should reference this file instead of duplicating commands.</p>"},{"location":"guides/development-commands/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Docker Compose Operations</li> <li>Observability Operations</li> <li>Data Service Operations</li> <li>Production Deployment</li> <li>Package Management (UV)</li> <li>Code Quality Commands</li> <li>Testing Commands</li> <li>Configuration and Validation</li> <li>Development Workflow</li> <li>Troubleshooting Commands</li> </ul>"},{"location":"guides/development-commands/#docker-compose-operations","title":"Docker Compose Operations","text":""},{"location":"guides/development-commands/#basic-operations","title":"Basic Operations","text":"<pre><code># Start entire stack\ndocker-compose up\n\n# Start in detached mode\ndocker-compose up -d\n\n# Stop and remove containers\ndocker-compose down\n\n# Stop and remove volumes (Data loss)\ndocker-compose down -v\n</code></pre>"},{"location":"guides/development-commands/#build-operations","title":"Build Operations","text":"<pre><code># Build all services\ndocker-compose build\n\n# Build specific service\ndocker-compose build &lt;service_name&gt;\n\n# Force rebuild without cache\ndocker-compose build --no-cache\n\n# Build and start\ndocker-compose up --build\n</code></pre>"},{"location":"guides/development-commands/#service-management","title":"Service Management","text":"<pre><code># Follow logs for specific service\ndocker-compose logs -f &lt;service_name&gt;\n\n# Enter service container\ndocker-compose exec &lt;service_name&gt; bash\n\n# Restart specific service\ndocker-compose restart &lt;service_name&gt;\n\n# Scale specific service\ndocker-compose up --scale &lt;service_name&gt;=3\n\n# Check service status\ndocker-compose ps\n</code></pre>"},{"location":"guides/development-commands/#observability-operations","title":"Observability Operations","text":""},{"location":"guides/development-commands/#start-monitoring-stack","title":"Start Monitoring Stack","text":"<pre><code># Start with all monitoring services\ndocker-compose --profile observability up -d\n\n# Start only specific monitoring services\ndocker-compose up prometheus grafana jaeger elasticsearch logstash kibana filebeat -d\n</code></pre>"},{"location":"guides/development-commands/#access-monitoring-dashboards","title":"Access Monitoring Dashboards","text":"<ul> <li>Grafana: http://localhost:3000 (admin/admin)</li> <li>Jaeger: http://localhost:16686</li> <li>Kibana: http://localhost:5601</li> <li>Prometheus: http://localhost:9090</li> <li>RabbitMQ Management: http://localhost:15672 (admin/admin)</li> </ul>"},{"location":"guides/development-commands/#monitoring-commands","title":"Monitoring Commands","text":"<pre><code># Follow ELK logs\ndocker-compose logs -f elasticsearch logstash kibana\n\n# Check Prometheus targets\ncurl http://localhost:9090/api/v1/targets\n\n# Check Grafana health\ncurl http://localhost:3000/api/health\n\n# Check RabbitMQ queues\ndocker-compose exec rabbitmq rabbitmqctl list_queues\n</code></pre>"},{"location":"guides/development-commands/#data-service-operations","title":"Data Service Operations","text":""},{"location":"guides/development-commands/#service-urls-and-health-checks","title":"Service URLs and Health Checks","text":"<p>COMPLETE SERVICE ARCHITECTURE: For detailed service ports, communication patterns, and architecture, see the Architecture Guide.</p> <pre><code># External Access (from host machine)\ncurl http://localhost:8001/health    # PostgreSQL Data Service\ncurl http://localhost:8002/health    # MongoDB Data Service\ncurl http://localhost:8000/health    # Business API Service\n\n# API Documentation\nopen http://localhost:8001/docs      # PostgreSQL Data Service API\nopen http://localhost:8002/docs      # MongoDB Data Service API\nopen http://localhost:8000/docs      # Business API Service API\n</code></pre>"},{"location":"guides/development-commands/#inter-service-communication-inside-docker-network","title":"Inter-Service Communication (inside Docker network)","text":"<ul> <li>PostgreSQL Data Service: <code>http://template_data_postgres_api:8000</code></li> <li>MongoDB Data Service: <code>http://template_data_mongo_api:8000</code></li> <li>Business API Service: <code>http://template_business_api:8000</code></li> </ul> <p>Port Mapping Strategy: All services run on port 8000 inside containers. Docker Compose maps them to different host ports (8000, 8001, 8002) to avoid conflicts.</p>"},{"location":"guides/development-commands/#database-connectivity-checks","title":"Database Connectivity Checks","text":"<pre><code># PostgreSQL connectivity\ndocker-compose exec postgres pg_isready -U postgres\ndocker-compose exec postgres psql -U postgres -d microservices_db\n\n# MongoDB connectivity\ndocker-compose exec mongodb mongosh --eval \"db.adminCommand('ping')\"\n\n# Redis connectivity\ndocker-compose exec redis redis-cli ping\n</code></pre>"},{"location":"guides/development-commands/#production-deployment","title":"Production Deployment","text":""},{"location":"guides/development-commands/#production-commands","title":"Production Commands","text":"<pre><code># Deploy with production config\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n\n# Scale services for production\ndocker-compose up --scale template_business_api=3 --scale template_business_worker=2 -d\n\n# Production build with optimizations\ndocker-compose -f docker-compose.prod.yml build --no-cache\n</code></pre>"},{"location":"guides/development-commands/#health-checks-in-production","title":"Health Checks in Production","text":"<pre><code># Check all service health\n./scripts/health-check.sh\n\n# Validate configuration consistency\n./scripts/validate-config.sh\n</code></pre>"},{"location":"guides/development-commands/#package-management-uv","title":"Package Management (UV)","text":""},{"location":"guides/development-commands/#dependency-management","title":"Dependency Management","text":"<pre><code># Add new dependencies\nuv add &lt;package&gt;\n\n# Add development dependencies\nuv add --dev &lt;package&gt;\n\n# Update lock file\nuv lock\n\n# Install dependencies from lock file\nuv sync\n\n# Install with dev dependencies\nuv sync --dev\n\n# Run application\nuv run python main.py\n</code></pre>"},{"location":"guides/development-commands/#code-quality-commands","title":"Code Quality Commands","text":""},{"location":"guides/development-commands/#linting-and-formatting","title":"Linting and Formatting","text":"<pre><code># Run linter (follows PEP8 compliance)\nuv run ruff check .\n\n# Auto-fix linting issues\nuv run ruff check . --fix\n\n# Format code\nuv run ruff format .\n\n# Check formatting without applying\nuv run ruff format . --check\n</code></pre>"},{"location":"guides/development-commands/#type-checking-and-security","title":"Type Checking and Security","text":"<pre><code># Type checking (requires mypy&gt;=1.8.0)\nuv run mypy .\n\n# Security analysis\nuv run bandit -r .\n\n# Run all quality checks\nuv run ruff check . &amp;&amp; uv run ruff format . --check &amp;&amp; uv run mypy . &amp;&amp; uv run bandit -r .\n</code></pre>"},{"location":"guides/development-commands/#testing-commands","title":"Testing Commands","text":""},{"location":"guides/development-commands/#test-execution","title":"Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=src --cov-report=html --cov-report=xml\n\n# Run specific test categories\nuv run pytest tests/unit/              # Unit tests only\nuv run pytest tests/integration/       # Integration tests only\nuv run pytest tests/ -k \"test_api\"     # Filter by test name\n\n# Run tests with verbose output\nuv run pytest -v\n\n# Run tests in parallel (with pytest-xdist)\nuv run pytest -n auto\n</code></pre>"},{"location":"guides/development-commands/#coverage-analysis","title":"Coverage Analysis","text":"<pre><code># Generate HTML coverage report\nuv run pytest --cov=src --cov-report=html\nopen htmlcov/index.html\n\n# Coverage with missing lines\nuv run pytest --cov=src --cov-report=term-missing\n\n# Set coverage threshold\nuv run pytest --cov=src --cov-fail-under=80\n</code></pre> <p>Target: 100% test coverage for critical paths</p>"},{"location":"guides/development-commands/#configuration-and-validation","title":"Configuration and Validation","text":""},{"location":"guides/development-commands/#environment-setup","title":"Environment Setup","text":"<pre><code># Copy environment template\ncp .env.example .env\n\n# Validate Docker Compose configuration\ndocker-compose config\n\n# Validate environment variables\ndocker-compose config --quiet &amp;&amp; echo \"Configuration valid\"\n</code></pre>"},{"location":"guides/development-commands/#service-health-and-connectivity-checks","title":"Service Health and Connectivity Checks","text":"<pre><code># Check all service health\ncurl http://localhost:8000/health  # Business API\ncurl http://localhost:8001/health  # PostgreSQL Data Service\ncurl http://localhost:8002/health  # MongoDB Data Service\n\n# Database connectivity checks\ndocker-compose exec postgres pg_isready -U postgres\ndocker-compose exec mongodb mongosh --eval \"db.adminCommand('ping')\"\ndocker-compose exec redis redis-cli ping\n</code></pre>"},{"location":"guides/development-commands/#development-workflow","title":"Development Workflow","text":""},{"location":"guides/development-commands/#quick-start","title":"Quick Start","text":"<pre><code># 1. Setup environment\ncp .env.example .env\n# Edit .env with your settings\n\n# 2. Start development stack\ndocker-compose up -d\n\n# 3. Install dependencies\nuv sync --dev\n\n# 4. Run quality checks\nuv run ruff check . &amp;&amp; uv run mypy . &amp;&amp; uv run pytest\n\n# 5. View logs\ndocker-compose logs -f\n</code></pre>"},{"location":"guides/development-commands/#common-development-tasks","title":"Common Development Tasks","text":"<pre><code># Start only infrastructure (for local development)\ndocker-compose up postgres mongodb redis rabbitmq -d\n\n# Rebuild after dependency changes\ndocker-compose down &amp;&amp; docker-compose up --build -d\n\n# Reset everything (Data loss)\ndocker-compose down -v &amp;&amp; docker-compose up --build -d\n\n# Debug specific service\ndocker-compose logs -f &lt;service_name&gt;\ndocker-compose exec &lt;service_name&gt; bash\n</code></pre>"},{"location":"guides/development-commands/#troubleshooting-commands","title":"Troubleshooting Commands","text":""},{"location":"guides/development-commands/#service-diagnostics","title":"Service Diagnostics","text":"<pre><code># Check services status and logs\ndocker-compose ps\ndocker-compose logs -f [service_name]\n\n# Test connectivity\ncurl http://localhost:8000/health  # API service\ncurl http://localhost:8001/health  # PostgreSQL data service\ncurl http://localhost:8002/health  # MongoDB data service\n</code></pre>"},{"location":"guides/development-commands/#infrastructure-diagnostics","title":"Infrastructure Diagnostics","text":"<pre><code># Check Docker system status\ndocker system df\ndocker system prune -a  # Clean up unused resources\n\n# Check network connectivity\ndocker network ls\ndocker network inspect try_microservices_default\n\n# Check port usage\nsudo netstat -tulpn | grep :5432\n</code></pre>"},{"location":"guides/development-commands/#database-diagnostics","title":"Database Diagnostics","text":"<pre><code># PostgreSQL diagnostics\ndocker-compose exec postgres pg_isready -U postgres\ndocker-compose logs postgres\n\n# MongoDB diagnostics\ndocker-compose exec mongodb mongosh --eval \"db.adminCommand('ping')\"\ndocker-compose logs mongodb\n\n# Redis diagnostics\ndocker-compose exec redis redis-cli -a redis123 ping\ndocker-compose exec redis redis-cli -a redis123 info memory\n</code></pre>"},{"location":"guides/development-commands/#service-communication-diagnostics","title":"Service Communication Diagnostics","text":"<pre><code># RabbitMQ diagnostics\ndocker-compose logs rabbitmq\nopen http://localhost:15672  # Management UI\n\n# Check message queues\ndocker-compose exec rabbitmq rabbitmqctl list_queues\n\n# Test HTTP communication between services\ndocker-compose exec template_business_api curl http://template_data_postgres_api:8000/health\n</code></pre>"},{"location":"guides/development-commands/#performance-diagnostics","title":"Performance Diagnostics","text":"<pre><code># Monitor resource usage\ndocker stats\n\n# Check logs for performance issues\ndocker-compose logs -f --timestamps\n\n# Database query performance\ndocker-compose exec postgres psql -U postgres -c \"SELECT * FROM pg_stat_activity;\"\n</code></pre>"},{"location":"guides/development-commands/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Details: Architecture Guide</li> <li>Technology Specifications: Technical Specifications</li> <li>Troubleshooting Guide: Troubleshooting Guide</li> <li>Main Development Guide: Main Entry Point</li> </ul>"},{"location":"guides/development-commands/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"guides/development-commands/#service-recovery","title":"Service Recovery","text":"<pre><code># Emergency restart all services\ndocker-compose down &amp;&amp; docker-compose up -d\n\n# Reset with data loss (last resort)\ndocker-compose down -v\ndocker system prune -a\ndocker-compose up --build -d\n</code></pre>"},{"location":"guides/development-commands/#data-recovery","title":"Data Recovery","text":"<pre><code># PostgreSQL backup\ndocker-compose exec postgres pg_dump -U postgres microservices_db &gt; backup.sql\n\n# MongoDB backup\ndocker-compose exec mongodb mongodump --db microservices_analytics_db --out /backup/\n\n# Redis backup\ndocker-compose exec redis redis-cli -a redis123 BGSAVE\n</code></pre> <p>Documentation Hierarchy: For complete project guidance, see Main Entry Point. For architectural details, see Architecture Guide. For technology specifications, see Technical Specifications.</p>"},{"location":"guides/development-commands/#verification-and-linting","title":"Verification and Linting","text":"<p>This section contains the canonical set of commands for verifying code quality, style, and conventions. These should be run before committing code.</p>"},{"location":"guides/development-commands/#full-verification-suite","title":"Full Verification Suite","text":"<pre><code># Run all checks: lint, format, types, security, tests, and naming\nuv run ruff check .\nuv run ruff format . --check\nuv run mypy .\nuv run bandit -r .\nuv run pytest\nfind . -name \"*-*\" -type f ! -name \"docker-compose*\" ! -name \".dockerignore\" ! -path \"./.github/*\" ! -name \".gitignore\" ! -name \".pre-commit-config.yaml\"\n</code></pre>"},{"location":"guides/development-commands/#individual-checks","title":"Individual Checks","text":"Command Purpose <code>uv run ruff check .</code> Lint code for style and errors <code>uv run ruff format . --check</code> Check code formatting <code>uv run mypy .</code> Static type checking <code>uv run bandit -r .</code> Security vulnerability scanning <code>uv run pytest</code> Run all unit and integration tests <code>find . -name \"*-*\"</code> Check for prohibited hyphens in filenames (see note) <p>Note on <code>find</code> command: The full command to check for prohibited hyphens in filenames, excluding justified exceptions, is: <code>find . -name \"*-*\" -type f ! -name \"docker-compose*\" ! -name \".dockerignore\" ! -path \"./.github/*\" ! -name \".gitignore\" ! -name \".pre-commit-config.yaml\"</code> This command should return an empty result.</p>"},{"location":"guides/dry-kiss-yagni-principles/","title":"DRY, KISS, YAGNI Principles","text":"<p>Purpose: Educational guide linking software engineering principles to framework architecture</p> <p>Audience: AI code generation agents, developers, architects</p> <p>Last Updated: 2025-01-07</p>"},{"location":"guides/dry-kiss-yagni-principles/#table-of-contents","title":"Table of Contents","text":"<ol> <li>DRY (Don't Repeat Yourself)</li> <li>KISS (Keep It Simple, Stupid)</li> <li>YAGNI (You Aren't Gonna Need It)</li> <li>How Framework Enforces Principles</li> <li>Automated Detection Tools</li> <li>Related Documents</li> </ol>"},{"location":"guides/dry-kiss-yagni-principles/#1-dry-dont-repeat-yourself","title":"1. DRY (Don't Repeat Yourself)","text":""},{"location":"guides/dry-kiss-yagni-principles/#definition","title":"Definition","text":"<p>Every piece of knowledge must have a single, unambiguous representation in the system.</p> <p>The DRY principle states that duplication of code, logic, or data structures leads to maintenance nightmares. When the same knowledge exists in multiple places, changes must be synchronized across all copies, creating risk of inconsistency.</p>"},{"location":"guides/dry-kiss-yagni-principles/#how-framework-enforces-dry","title":"How Framework Enforces DRY","text":""},{"location":"guides/dry-kiss-yagni-principles/#architectural-pattern-http-only-data-access","title":"Architectural Pattern: HTTP-Only Data Access","text":"<p>The framework enforces DRY by requiring all business services to access data via HTTP, creating a single source of truth for database operations.</p> <p>\u2705 CORRECT - Single Source of Truth:</p> <pre><code># Business Service: auth_api/src/services/user_service.py\nclass UserService:\n    def __init__(self, data_client: DataClient):\n        self._data_client = data_client\n\n    async def get_user(self, user_id: int) -&gt; User:\n        # HTTP call to data service (single source of truth)\n        response = await self._data_client.get(f\"/users/{user_id}\")\n        return User(**response.json())\n\n# Data Service: data_postgres_api/src/repositories/user_repository.py\nclass UserRepository:\n    def __init__(self, db: Session):\n        self._db = db\n\n    async def get_by_id(self, user_id: int) -&gt; UserModel:\n        # Only place with direct database access\n        return self._db.query(UserModel).filter(UserModel.id == user_id).first()\n</code></pre> <p>\u274c WRONG - Duplicated Database Logic:</p> <pre><code># Business Service 1: auth_api/src/services/user_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # Direct database access - VIOLATES ARCHITECTURE\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n\n# Business Service 2: profile_api/src/services/profile_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # DUPLICATED: Same query in different service\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n\n# Business Service 3: payment_api/src/services/payment_service.py\nasync def get_user(self, user_id: int) -&gt; User:\n    # DUPLICATED AGAIN: Now bug fixes require changing 3 places\n    user = self._db.query(UserModel).filter(UserModel.id == user_id).first()\n    return User.from_orm(user)\n</code></pre> <p>Why This Matters:</p> <ul> <li>\u2705 Single source of truth for database operations</li> <li>\u2705 Bug fix in <code>UserRepository.get_by_id</code> automatically fixes all consumers</li> <li>\u2705 No possibility of inconsistent query logic across services</li> <li>\u2705 Easier connection pool management (one pool, not N pools)</li> <li>\u2705 Clear separation of concerns (data layer vs. business logic)</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#shared-utilities-pattern","title":"Shared Utilities Pattern","text":"<p>The framework provides <code>shared/utils/</code> for commonly duplicated code:</p> <p>\u2705 CORRECT - Use Shared Utilities:</p> <pre><code># shared/utils/validators.py\ndef is_valid_email(email: str) -&gt; bool:\n    \"\"\"Validate email address format.\"\"\"\n    if not email or len(email) &gt; 254:\n        return False\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\n# services/auth_api/src/api/v1/users.py\nfrom shared.utils.validators import is_valid_email\n\n@router.post(\"/users\")\nasync def create_user(data: UserCreate):\n    if not is_valid_email(data.email):\n        raise ValidationError(\"Invalid email\")\n    # ... continue\n</code></pre> <p>\u274c WRONG - Duplicated Validation:</p> <pre><code># services/auth_api/src/api/v1/users.py\n@router.post(\"/users\")\nasync def create_user(data: UserCreate):\n    # Duplicated validation logic\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    # ...\n\n# services/profile_api/src/api/v1/profiles.py\n@router.put(\"/profiles\")\nasync def update_profile(data: ProfileUpdate):\n    # DUPLICATED: Same email validation\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    # ...\n\n# services/notification_api/src/api/v1/subscriptions.py\n@router.post(\"/subscriptions\")\nasync def subscribe(data: SubscriptionCreate):\n    # DUPLICATED AGAIN: Third copy of same validation\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', data.email):\n        raise HTTPException(400, \"Invalid email\")\n    # ...\n</code></pre> <p>Impact of Violation:</p> <ul> <li>\u274c Bug in email regex requires fixing 3+ files</li> <li>\u274c Developer updates 2 files, forgets third \u2192 inconsistent behavior</li> <li>\u274c Must test same logic in 3+ test files</li> <li>\u274c ~500 lines of duplicated code per 5-service project</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#rule-of-three","title":"Rule of Three","text":"<p>Extract shared code to <code>shared/utils/</code> when:</p> <ol> <li>Same logic appears in 2+ places (Rule of Three)</li> <li>Logic is pure (no business context, no external dependencies)</li> <li>Logic is stable (won't change per service)</li> </ol> <p>Examples of what goes in shared/utils/:</p> <ul> <li>\u2705 Validators (email, phone, UUID, URL)</li> <li>\u2705 Logging configuration</li> <li>\u2705 Pagination helpers (offset, cursor)</li> <li>\u2705 Exception base classes</li> <li>\u2705 Request ID management</li> </ul> <p>Examples of what stays in services:</p> <ul> <li>\u274c Business logic (user registration flow)</li> <li>\u274c Domain-specific validation (e.g., \"premium users can have 10 profiles\")</li> <li>\u274c Service-specific configuration</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#automated-detection","title":"Automated Detection","text":"<p>Check code duplication percentage:</p> <pre><code># Install jscpd\nnpm install -g jscpd\n\n# Scan for duplicates (fail if &gt;10%)\njscpd src/ --threshold 10 --exitCode 1\n\n# Detailed HTML report\njscpd src/ --format html --output ./jscpd-report\nopen jscpd-report/jscpd-report.html\n</code></pre> <p>Find similar files:</p> <pre><code># Using cloc\ncloc --by-file --csv src/ | awk -F',' '$5 &gt; 80 {print $2, $5\"%\"}'\n# Output shows files with &gt;80% similarity\n</code></pre> <p>Find duplicated functions:</p> <pre><code># Using PMD CPD\npmd cpd --minimum-tokens 50 --files src/ --language python\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#2-kiss-keep-it-simple-stupid","title":"2. KISS (Keep It Simple, Stupid)","text":""},{"location":"guides/dry-kiss-yagni-principles/#definition_1","title":"Definition","text":"<p>Most systems work best if they are kept simple rather than made complicated.</p> <p>The KISS principle advocates for simplicity in design and implementation. Complex solutions are harder to understand, maintain, test, and debug. Simple solutions are easier to reason about and less prone to bugs.</p>"},{"location":"guides/dry-kiss-yagni-principles/#how-framework-enforces-kiss","title":"How Framework Enforces KISS","text":""},{"location":"guides/dry-kiss-yagni-principles/#maturity-levels-incremental-complexity","title":"Maturity Levels - Incremental Complexity","text":"<p>The framework enforces KISS through 4 maturity levels that add complexity only when needed:</p> <p>Level 1 (PoC): Minimal infrastructure - FastAPI app with basic routes - No logging, no health checks, no middleware - ~50 lines of code, 2-minute setup</p> <p>Level 2 (Development): Essential development tools - + Request ID tracking - + Swagger documentation - + Health checks - + Basic tests</p> <p>Level 3 (Pre-Production): Production readiness - + HTTPS/TLS - + Nginx load balancer - + Prometheus metrics - + Structured logging</p> <p>Level 4 (Production): Enterprise scale - + ELK stack (centralized logs) - + Jaeger distributed tracing - + Multi-environment CI/CD - + Auto-scaling</p> <p>\u2705 CORRECT - Start Simple, Upgrade When Needed:</p> <pre><code>Scenario: New project, 1 developer, 0 users\n\nDecision: Start at Level 1 \u2705\n- 50 lines of code\n- 2-minute generation time\n- Easy to understand and modify\n\nAfter 2 weeks: Team grows to 4, need debugging tools\nDecision: Upgrade to Level 2 \u2705\n- Add request ID tracking for debugging\n- Add Swagger for team coordination\n</code></pre> <p>\u274c WRONG - Premature Complexity:</p> <pre><code>Scenario: New project, 1 developer, 0 users\n\nDecision: Start at Level 4 \u274c\n- 2000+ lines of generated code\n- Kubernetes, service mesh, distributed tracing\n- 30-minute generation time\n- Overwhelming for solo developer\n- 95% of infrastructure unused\n\nResult:\n- Slow iteration (complex setup)\n- Cognitive overload (too many moving parts)\n- Time wasted on configuration instead of features\n</code></pre> <p>Why Maturity Levels Enforce KISS:</p> <ul> <li>\u2705 Start simple, add complexity incrementally</li> <li>\u2705 Only add infrastructure when evidence shows need</li> <li>\u2705 Avoid premature optimization</li> <li>\u2705 Reduce cognitive load for developers</li> <li>\u2705 Faster time to market</li> </ul> <p>See: Maturity Levels Documentation</p>"},{"location":"guides/dry-kiss-yagni-principles/#cyclomatic-complexity-limits","title":"Cyclomatic Complexity Limits","text":"<p>The framework enforces KISS by limiting function complexity:</p> <p>Rule: McCabe cyclomatic complexity &lt; 10 for all functions</p> <p>\u2705 CORRECT - Simple Function:</p> <pre><code>async def get_user(self, user_id: int) -&gt; User:\n    \"\"\"Get user by ID.\n\n    Complexity: 2 (1 base + 1 if statement)\n    \"\"\"\n    user = await self._repository.get_by_id(user_id)\n\n    if not user:\n        raise NotFoundError(f\"User {user_id} not found\")\n\n    return user\n</code></pre> <p>\u274c WRONG - Complex Function:</p> <pre><code>async def process_payment(self, order_id: int, payment_data: dict) -&gt; Payment:\n    \"\"\"Process payment with multiple conditional paths.\n\n    Complexity: 15 (TOO HIGH - VIOLATES KISS)\n    \"\"\"\n    order = await self._get_order(order_id)\n\n    # Nested conditionals increase complexity\n    if order.status == \"pending\":\n        if payment_data[\"method\"] == \"credit_card\":\n            if payment_data[\"amount\"] &gt; 1000:\n                if not payment_data.get(\"cvv\"):\n                    raise ValidationError(\"CVV required for large amounts\")\n                result = await self._charge_card(payment_data)\n            else:\n                result = await self._charge_card(payment_data)\n        elif payment_data[\"method\"] == \"paypal\":\n            if payment_data[\"amount\"] &gt; 500:\n                result = await self._charge_paypal_express(payment_data)\n            else:\n                result = await self._charge_paypal(payment_data)\n        elif payment_data[\"method\"] == \"bank_transfer\":\n            if self._is_business_customer(order.customer_id):\n                result = await self._initiate_wire_transfer(payment_data)\n            else:\n                raise ValidationError(\"Bank transfer only for business customers\")\n        else:\n            raise ValidationError(f\"Unsupported payment method: {payment_data['method']}\")\n    else:\n        raise ValidationError(f\"Order {order_id} is not pending\")\n\n    return result\n</code></pre> <p>Refactoring Strategy - Extract Methods:</p> <pre><code>async def process_payment(self, order_id: int, payment_data: dict) -&gt; Payment:\n    \"\"\"Process payment (refactored for simplicity).\n\n    Complexity: 3 (simple and readable)\n    \"\"\"\n    order = await self._validate_order(order_id)\n    payment_handler = self._get_payment_handler(payment_data[\"method\"])\n    result = await payment_handler.charge(payment_data, order)\n    return result\n\n# Extracted methods (each with complexity &lt; 10)\nasync def _validate_order(self, order_id: int) -&gt; Order:\n    \"\"\"Validate order is ready for payment.\"\"\"\n    order = await self._get_order(order_id)\n    if order.status != \"pending\":\n        raise ValidationError(f\"Order {order_id} is not pending\")\n    return order\n\ndef _get_payment_handler(self, method: str) -&gt; PaymentHandler:\n    \"\"\"Get payment handler for method (Strategy Pattern).\"\"\"\n    handlers = {\n        \"credit_card\": CreditCardHandler(self._payment_gateway),\n        \"paypal\": PayPalHandler(self._paypal_client),\n        \"bank_transfer\": BankTransferHandler(self._bank_api),\n    }\n\n    if method not in handlers:\n        raise ValidationError(f\"Unsupported payment method: {method}\")\n\n    return handlers[method]\n</code></pre> <p>Benefits of Refactoring:</p> <ul> <li>\u2705 Complexity reduced from 15 to 3</li> <li>\u2705 Each method has single responsibility</li> <li>\u2705 Easy to test (test each handler independently)</li> <li>\u2705 Easy to add new payment methods (extend handlers dict)</li> <li>\u2705 Readable and maintainable</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#automated-detection_1","title":"Automated Detection","text":"<p>Check cyclomatic complexity:</p> <pre><code># Install radon\npip install radon\n\n# Check complexity (fail if any function has complexity &gt;= 10)\nradon cc src/ --min B --total-average --show-complexity\n\n# Output example:\n# src/services/payment_service.py\n#     M 156:4 PaymentService.process_payment - B (6)  \u2705 PASS\n#     M 180:4 PaymentService._validate_order - A (2)  \u2705 PASS\n</code></pre> <p>Check maintainability index:</p> <pre><code># MI (Maintainability Index) considers complexity, LOC, comments\nradon mi src/ --min B --show\n\n# Grading scale:\n# A: 20-100 (excellent)\n# B: 10-19 (good)\n# C: 0-9 (needs refactoring)\n</code></pre> <p>Check file sizes:</p> <pre><code># Files &gt;500 lines violate KISS\nfind src/ -name \"*.py\" -type f -exec wc -l {} \\; | awk '$1 &gt; 500 {print $2, \"(\"$1\" lines)\"}'\n\n# Example output:\n# src/services/god_object_service.py (842 lines)  \u274c VIOLATES KISS\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#3-yagni-you-arent-gonna-need-it","title":"3. YAGNI (You Aren't Gonna Need It)","text":""},{"location":"guides/dry-kiss-yagni-principles/#definition_2","title":"Definition","text":"<p>Don't add functionality until it is necessary.</p> <p>The YAGNI principle states that developers should not add features, infrastructure, or abstraction layers based on speculation about future needs. Only implement what is required for current requirements.</p>"},{"location":"guides/dry-kiss-yagni-principles/#how-framework-enforces-yagni","title":"How Framework Enforces YAGNI","text":""},{"location":"guides/dry-kiss-yagni-principles/#evidence-driven-maturity-upgrades","title":"Evidence-Driven Maturity Upgrades","text":"<p>The framework enforces YAGNI by requiring evidence before upgrading complexity:</p> <p>\u2705 CORRECT - Evidence-Based Upgrade:</p> <pre><code>Current State: Level 2 app, 50 beta users, 2 weeks in production\n\nEvidence for Level 3 upgrade:\n1. \u2705 Launching to production next week (HTTPS required)\n2. \u2705 CTO requires 99% uptime SLA (Prometheus monitoring needed)\n3. \u2705 Security audit mandated TLS encryption\n4. \u2705 Traffic projection: 500 req/sec (Nginx load balancing needed)\n\nDecision: Upgrade to Level 3 \u2705\nJustification: All infrastructure has concrete business need\n</code></pre> <p>\u274c WRONG - Speculative Upgrade:</p> <pre><code>Current State: Level 1 PoC, 0 users, solo developer\n\nReasoning: \"We MIGHT need monitoring later\"\nDecision: Generate Level 4 with full observability stack \u274c\n\nResult:\n- 30-minute generation time\n- Prometheus, Grafana, ELK, Jaeger configured\n- 95% of infrastructure completely unused\n- Time wasted: 4 hours configuring unused systems\n- Complexity: Overwhelming for solo developer\n\nCorrect Decision: Stay at Level 1, upgrade when evidence shows need \u2705\n</code></pre> <p>When to Upgrade Maturity Levels:</p> <p>See: Maturity Level Upgrade Triggers</p> <p>Key evidence types: - Team size: 1 developer \u2192 no coordination tools needed - User count: 0 users \u2192 no monitoring needed - Deployment status: Not in production \u2192 no HTTPS needed - Compliance: No audit \u2192 no ELK needed</p>"},{"location":"guides/dry-kiss-yagni-principles/#feature-necessity-validation","title":"Feature Necessity Validation","text":"<p>The framework enforces YAGNI through Stage 1: Feature Prioritization in the AI workflow:</p> <p>\u2705 CORRECT - Challenge Unnecessary Features:</p> <pre><code>User Request: \"Build authentication service with:\n- Email/password login\n- OAuth (Google, Facebook, GitHub, Apple, Twitter, LinkedIn)\n- 2FA (SMS, TOTP, email, biometric)\n- Password reset\n- Account recovery via security questions\n- Magic link login\n- Passkey support\n- Session management\n- Remember me\n- CAPTCHA\n- Rate limiting\n- Account lockout after failed attempts\"\n\nAI Agent (Stage 1 - Feature Necessity Challenge):\n\"I see 15 features requested. Let's prioritize using MoSCoW method:\n\nMUST HAVE (MVP):\n- Email/password login\n- Password reset\n- Session management\n\nSHOULD HAVE (Phase 2):\n- OAuth (Google only for MVP)\n- 2FA (TOTP only for MVP)\n- Rate limiting\n\nCOULD HAVE (Phase 3):\n- OAuth (additional providers)\n- Magic link login\n- Remember me\n\nWON'T HAVE (YAGNI - no evidence of need):\n- Passkey support (bleeding edge, low adoption)\n- Biometric 2FA (requires mobile app)\n- Security questions (outdated, insecure)\n\nRecommendation: Start with 3 MUST HAVE features, add others when evidence shows need.\"\n</code></pre> <p>\u274c WRONG - Implement Everything Upfront:</p> <pre><code>Developer: \"Implements all 15 features in MVP\"\n\nResult:\n- Development time: 6 weeks instead of 1 week\n- Testing complexity: 3x more test cases\n- Bugs: Security question feature has vulnerability (wasted time)\n- Usage stats after 3 months:\n  - Passkey: 0 users (wasted 40 hours)\n  - LinkedIn OAuth: 2 users (wasted 20 hours)\n  - Biometric 2FA: 0 users (requires mobile app that doesn't exist)\n\nTotal wasted effort: ~120 hours on unused features \u274c\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#dependency-minimalism","title":"Dependency Minimalism","text":"<p>The framework enforces YAGNI through dependency count limits:</p> <p>Rule: - Level 1-2: Max 30 dependencies - Level 3-4: Max 50 dependencies</p> <p>\u2705 CORRECT - Minimal Dependencies:</p> <pre><code># requirements.txt (Level 2 project - 12 dependencies)\nfastapi==0.115.0\nuvicorn==0.31.0\npydantic==2.9.2\nhttpx==0.27.2\npython-multipart==0.0.12\npython-jose[cryptography]==3.3.0\n\n# Development\npytest==8.3.3\npytest-asyncio==0.24.0\npytest-cov==5.0.0\nhttpx==0.27.2\nruff==0.6.9\nmypy==1.11.2\n</code></pre> <p>\u274c WRONG - Dependency Bloat:</p> <pre><code># requirements.txt (Level 1 PoC - 45 dependencies! YAGNI VIOLATION)\nfastapi==0.115.0\nuvicorn==0.31.0\npydantic==2.9.2\n\n# \"We MIGHT need these later\" \u274c\ncelery==5.4.0           # No background tasks in PoC\nredis==5.1.1            # No caching requirement\nprometheus-client==0.21.0  # No monitoring in PoC\nopentelemetry-api==1.27.0  # No tracing in PoC\nsentry-sdk==2.15.0      # No error tracking in PoC\nelasticsearch==8.15.1   # No search feature in PoC\npillow==10.4.0          # No image processing in requirements\npandas==2.2.3           # No data analysis in requirements\nnumpy==2.1.2            # No numerical computation in requirements\n\n# ... 36 more unused dependencies\n\nProblems:\n- Installation time: 5 minutes instead of 30 seconds\n- Docker image size: 2GB instead of 200MB\n- Security: 45 packages = 45 potential vulnerabilities\n- Maintenance: Must update 45 packages\n- Confusion: Developers don't know which are actually used\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#automated-detection_2","title":"Automated Detection","text":"<p>Check dependency count:</p> <pre><code># Count non-comment, non-empty lines\ngrep -v '^#' requirements.txt | grep -v '^$' | wc -l\n\n# Expected output:\n# Level 1-2: &lt;30 \u2705\n# Level 3-4: &lt;50 \u2705\n</code></pre> <p>Find unused dependencies:</p> <pre><code># Install pip-check\npip install pip-check\n\n# Check for unused dependencies\npip-check --verbose\n\n# Remove unused dependencies\npip install pip-autoremove\npip-autoremove &lt;package-name&gt; -y\n</code></pre> <p>Check for overengineered abstractions:</p> <pre><code># Find abstract base classes (potential over-abstraction)\ngrep -r \"from abc import ABC\" src/\n\n# Find classes with only one implementation (YAGNI violation)\n# If AbstractPaymentProvider has only CreditCardProvider \u2192 unnecessary abstraction\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#4-how-framework-enforces-principles","title":"4. How Framework Enforces Principles","text":""},{"location":"guides/dry-kiss-yagni-principles/#architectural-enforcement","title":"Architectural Enforcement","text":"Principle Architectural Mechanism Enforcement Method DRY HTTP-only data access Business services MUST call data service via HTTP (no direct DB access) DRY Shared utilities Reusable validators, logger, pagination in <code>shared/utils/</code> KISS Maturity levels Start simple (Level 1), add complexity incrementally based on evidence KISS Complexity limits McCabe complexity &lt;10, file size &lt;500 lines YAGNI Evidence-based upgrades Require metrics (team size, user count, deployment status) before upgrading YAGNI Feature prioritization Stage 1 workflow challenges unnecessary features"},{"location":"guides/dry-kiss-yagni-principles/#single-event-loop-ownership","title":"Single Event Loop Ownership","text":"<p>The framework enforces KISS by preventing async/await conflicts:</p> <p>Rule: Each service owns ONE event loop</p> <p>\u2705 CORRECT:</p> <pre><code># Business Service: Uses HTTP clients (not direct async database)\nasync def get_user_profile(user_id: int) -&gt; Profile:\n    # HTTP call (no event loop conflict)\n    user_data = await data_client.get(f\"/users/{user_id}\")\n    return Profile(**user_data)\n</code></pre> <p>\u274c WRONG (Old Hybrid Approach):</p> <pre><code># Business Service: Direct database access creates event loop conflicts\nasync def get_user_profile(user_id: int) -&gt; Profile:\n    # Service has Telegram Bot event loop\n    # Database access tries to create second event loop\n    # Result: RuntimeError: Event loop is already running\n    user = await db.query(User).filter(User.id == user_id).first()  \u274c\n</code></pre> <p>See: Improved Hybrid Approach</p>"},{"location":"guides/dry-kiss-yagni-principles/#template-completeness","title":"Template Completeness","text":"<p>The framework enforces DRY through complete templates:</p> Template Component Status DRY Enforcement <code>shared/utils/logger.py</code> \u2705 100% Eliminates logging setup duplication <code>shared/utils/validators.py</code> \u2705 100% Eliminates validation duplication <code>shared/utils/pagination.py</code> \u2705 100% Eliminates pagination logic duplication <code>template_data_postgres_api/</code> \u2705 100% Single source of truth for PostgreSQL access <code>template_business_api/</code> \u2705 100% HTTP client patterns, middleware"},{"location":"guides/dry-kiss-yagni-principles/#5-automated-detection-tools","title":"5. Automated Detection Tools","text":""},{"location":"guides/dry-kiss-yagni-principles/#ci-pipeline-quality-gates","title":"CI Pipeline Quality Gates","text":"<p>The framework enforces all three principles through automated CI checks:</p>"},{"location":"guides/dry-kiss-yagni-principles/#dry-enforcement","title":"DRY Enforcement","text":"<pre><code># .github/workflows/ci.yml\ncheck-duplication:\n  runs-on: ubuntu-latest\n  steps:\n    - name: Check code duplication\n      run: |\n        npm install -g jscpd\n        jscpd src/ --threshold 10 --exitCode 1 || {\n          echo \"\u274c DRY VIOLATION: Code duplication &gt;10%\"\n          echo \"Extract shared code to shared/utils/\"\n          exit 1\n        }\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#kiss-enforcement","title":"KISS Enforcement","text":"<pre><code>check-complexity:\n  runs-on: ubuntu-latest\n  steps:\n    - name: Check cyclomatic complexity\n      run: |\n        pip install radon\n        radon cc src/ --min B || {\n          echo \"\u274c KISS VIOLATION: Function complexity &gt;= 10\"\n          echo \"Refactor complex functions into smaller ones\"\n          exit 1\n        }\n\n    - name: Check file sizes\n      run: |\n        large_files=$(find src/ -name \"*.py\" -exec wc -l {} \\; | awk '$1&gt;500')\n        if [ -n \"$large_files\" ]; then\n          echo \"\u274c KISS VIOLATION: Files &gt;500 lines\"\n          echo \"$large_files\"\n          exit 1\n        fi\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#yagni-enforcement","title":"YAGNI Enforcement","text":"<pre><code>check-dependencies:\n  runs-on: ubuntu-latest\n  steps:\n    - name: Check dependency count\n      run: |\n        dep_count=$(grep -v '^#' requirements.txt | grep -v '^$' | wc -l)\n        threshold=30  # Level 1-2 threshold\n\n        if [ $dep_count -gt $threshold ]; then\n          echo \"\u274c YAGNI VIOLATION: Too many dependencies ($dep_count &gt;$threshold)\"\n          echo \"Remove unused dependencies or justify each one\"\n          exit 1\n        fi\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#local-development-tools","title":"Local Development Tools","text":"<p>Pre-commit checks:</p> <pre><code># Install tools\nnpm install -g jscpd\npip install radon pip-check\n\n# Create pre-commit script\ncat &gt; .git/hooks/pre-commit &lt;&lt; 'EOF'\n#!/bin/bash\n\necho \"Running quality gates...\"\n\n# DRY check\njscpd src/ --threshold 10 || exit 1\n\n# KISS checks\nradon cc src/ --min B || exit 1\nradon mi src/ --min B || exit 1\n\n# YAGNI check\ndep_count=$(grep -v '^#' requirements.txt | grep -v '^$' | wc -l)\nif [ $dep_count -gt 30 ]; then\n  echo \"\u274c Too many dependencies: $dep_count\"\n  exit 1\nfi\n\necho \"\u2705 All quality gates passed\"\nEOF\n\nchmod +x .git/hooks/pre-commit\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#monitoring-commands","title":"Monitoring Commands","text":"<p>DRY Monitoring:</p> <pre><code># Code duplication report\njscpd src/ --reporters \"console,html\" --output ./report\nopen report/jscpd-report.html\n\n# Find similar files\ncloc --by-file --csv src/ | awk -F',' '$5 &gt; 80 {print $2, \"(\"$5\"%)\"}'\n\n# Find duplicated imports (symptom of duplication)\ngrep -r \"^from\\|^import\" src/ | sort | uniq -c | sort -rn | head -20\n</code></pre> <p>KISS Monitoring:</p> <pre><code># Complexity metrics\nradon cc src/ --show-complexity --total-average\nradon mi src/ --show\n\n# Largest files (potential god objects)\nfind src/ -name \"*.py\" -exec wc -l {} \\; | sort -rn | head -10\n\n# Most complex functions\nradon cc src/ --json | jq '.[] | .[] | select(.complexity &gt; 5) | {name, complexity}'\n</code></pre> <p>YAGNI Monitoring:</p> <pre><code># Dependency analysis\npip list --format=freeze | wc -l  # Total installed\ngrep -v '^#' requirements.txt | grep -v '^$' | wc -l  # Required\n\n# Find unused dependencies\npip install pipreqs\npipreqs . --print  # Shows actually imported packages\ndiff requirements.txt requirements_actual.txt  # Compare\n\n# Vulnerability scan (more deps = more risk)\npip install safety\nsafety check\n</code></pre>"},{"location":"guides/dry-kiss-yagni-principles/#6-related-documents","title":"6. Related Documents","text":""},{"location":"guides/dry-kiss-yagni-principles/#architecture-documentation","title":"Architecture Documentation","text":"<ul> <li>Improved Hybrid Approach - How HTTP-only pattern enforces DRY</li> <li>Architecture Overview - Overall system design</li> <li>Maturity Levels - Incremental complexity (KISS + YAGNI)</li> <li>Quality Standards - Code quality requirements</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#anti-patterns","title":"Anti-Patterns","text":"<ul> <li>Copy-Paste Programming - DRY violations</li> <li>God Object - KISS violations</li> <li>Speculative Generality - YAGNI violations</li> <li>Premature Infrastructure - KISS + YAGNI violations</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#implementation-guides","title":"Implementation Guides","text":"<ul> <li>Shared Utilities README - Reusable components (DRY)</li> <li>HTTP Client Patterns - HTTP-only data access (DRY)</li> <li>AI Code Generation Workflow - Feature prioritization (YAGNI)</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Code Review Checklist - Includes DRY/KISS/YAGNI checks</li> <li>Automated Quality Gates - CI enforcement</li> <li>Testing Strategy - How to test simple code</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#quick-reference-card","title":"Quick Reference Card","text":""},{"location":"guides/dry-kiss-yagni-principles/#dry-checklist","title":"DRY Checklist","text":"<ul> <li> No duplicated database queries across services (use data service via HTTP)</li> <li> No duplicated validators (use <code>shared/utils/validators.py</code>)</li> <li> No duplicated logging setup (use <code>shared/utils/logger.py</code>)</li> <li> No duplicated pagination logic (use <code>shared/utils/pagination.py</code>)</li> <li> Code duplication &lt;10% (verified by <code>jscpd</code>)</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#kiss-checklist","title":"KISS Checklist","text":"<ul> <li> All functions have McCabe complexity &lt;10 (verified by <code>radon cc</code>)</li> <li> All files &lt;500 lines (verified by <code>find</code> + <code>wc</code>)</li> <li> Maturity level matches project phase (PoC \u2192 Level 1, Production \u2192 Level 3-4)</li> <li> No premature optimization or over-engineering</li> <li> Clear, readable code with minimal nesting</li> </ul>"},{"location":"guides/dry-kiss-yagni-principles/#yagni-checklist","title":"YAGNI Checklist","text":"<ul> <li> All features have documented business justification</li> <li> Maturity level upgrade based on evidence (team size, users, deployment status)</li> <li> Dependency count appropriate for maturity level (&lt;30 for Level 1-2)</li> <li> No unused dependencies (verified by <code>pip-check</code>)</li> <li> No speculative abstractions (no interfaces with single implementation)</li> </ul> <p>Document Version: 1.0 Last Updated: 2025-01-07 Status: \u2705 Complete Reviewed By: Framework Maintainers</p>"},{"location":"guides/implementation-plan-template/","title":"Implementation Plan Template","text":"<p>Instructions: Populate this template after completing the Requirements Intake. Use it to obtain approval before writing code.</p>"},{"location":"guides/implementation-plan-template/#plan-metadata","title":"Plan Metadata","text":"<ul> <li>Request ID:</li> <li>Plan Version:</li> <li>Date:</li> <li>Prepared By (Agent):</li> <li>Reviewed / Approved By:</li> </ul>"},{"location":"guides/implementation-plan-template/#summary","title":"Summary","text":"<ul> <li>Problem &amp; objective recap (link to <code>docs/guides/requirements-intake-template.md</code> artefact):</li> <li>High-level solution concept:</li> <li>Maturity Level: [1-PoC / 2-Development / 3-Pre-Production / 4-Production]</li> <li>Optional Modules: [List selected modules: Workers, Bot, MongoDB, etc.]</li> <li>Estimated Generation Time: [Based on level and modules]</li> <li>Key assumptions:</li> </ul>"},{"location":"guides/implementation-plan-template/#maturity-level-features","title":"Maturity Level Features","text":""},{"location":"guides/implementation-plan-template/#included-at-selected-level","title":"\u2705 Included at Selected Level","text":"Category Feature Justification Example Structured logging Level \u2265 2 requirement Example Nginx API Gateway Level \u2265 3 requirement Example OAuth/JWT Level 4 requirement <p>Reference: See <code>docs/reference/maturity-levels.md</code> for complete feature matrix.</p>"},{"location":"guides/implementation-plan-template/#skipped-features-available-at-higher-levels","title":"\u274c Skipped Features (Available at Higher Levels)","text":"Feature Available At Level Upgrade Impact Example ELK Stack Level 4 Example CI/CD Pipelines Level 4"},{"location":"guides/implementation-plan-template/#architecture-impact","title":"Architecture Impact","text":"Area Description Relevant Rules / Docs Services <code>docs/atomic/services/</code>, <code>docs/guides/architecture-guide.md</code> Data access <code>docs/atomic/architecture/data-access-architecture.md</code>, <code>docs/atomic/infrastructure/</code> Observability <code>docs/atomic/observability/</code> Security / compliance <code>docs/atomic/testing/</code>, policy docs"},{"location":"guides/implementation-plan-template/#requirements-traceability-matrix","title":"Requirements Traceability Matrix","text":"<p>PURPOSE: Explicit mapping between user requirements (from Requirements Intake) and implementation tasks. Ensures 100% coverage by systematically tracking every Req ID through the implementation lifecycle.</p> <p>INSTRUCTIONS: 1. Extract ALL Req IDs (FR-, UI-, NF-*) from completed Requirements Intake document 2. For EACH Req ID, identify which Phase(s) and Task(s) will implement it 3. Fill Evidence column during Stage 4 (Code Generation) with exact file paths 4. Update Status as implementation progresses (Pending \u2192 In Progress \u2192 \u2705 Done)</p> Req ID Feature/Element Mapped to Phase Mapped to Tasks Evidence (when implemented) Status FR-001 (example: User registration) Phase 3 Task 3.1: Domain entityTask 3.2: API endpoint (fill during Stage 4: <code>services/api/src/api/v1/users.py:20</code>) Pending FR-002 (example: Loan creation) Phase 3 Task 3.3: Loan entityTask 3.4: Validation logic (fill during Stage 4) Pending UI-001 (example: Registration form) Phase 5 Task 5.3: Registration handler with FSM (fill during Stage 4: <code>services/bot/src/handlers/register.py:15</code>) Pending <p>Requirements Coverage Plan: - Total Requirements: [X] (from Requirements Intake \u00a7 Requirements Summary) - Distributed across: [Y] phases - Average: [Z] requirements per phase</p> <p>VERIFICATION: In Stage 5, AI will verify ALL Req IDs have Status \"\u2705 Done\" + Evidence before proceeding to Stage 6. Coverage must be 100% OR descoped requirements must have stakeholder approval documented in QA Report.</p> <p>REFERENCE: See <code>docs/guides/requirements-traceability-guide.md</code> for complete Req ID lifecycle and coverage calculation methodology.</p>"},{"location":"guides/implementation-plan-template/#work-plan","title":"Work Plan","text":"Stage Purpose Key Tasks Tooling / Owners Definition of Done References 1 2"},{"location":"guides/implementation-plan-template/#risks-mitigations","title":"Risks &amp; Mitigations","text":"Risk Impact Likelihood Mitigation Strategy Owner"},{"location":"guides/implementation-plan-template/#verification-strategy","title":"Verification Strategy","text":"<ul> <li>Linting &amp; formatting commands (<code>docs/guides/development-commands.md</code>):</li> <li>Type checking &amp; security tools:</li> <li>Test suites and coverage targets (<code>docs/atomic/testing/</code>):</li> <li>Observability validation (if applicable):</li> </ul>"},{"location":"guides/implementation-plan-template/#deliverables-acceptance","title":"Deliverables &amp; Acceptance","text":"<ul> <li>Expected artefacts (<code>docs/reference/deliverables-catalog.md</code>):</li> <li>Acceptance criteria alignment:</li> <li>Additional documentation requirements (ADR, diagrams, etc.):</li> </ul>"},{"location":"guides/implementation-plan-template/#dependencies-schedule","title":"Dependencies &amp; Schedule","text":"<ul> <li>External dependencies / handoffs:</li> <li>Milestones with target dates:</li> </ul>"},{"location":"guides/implementation-plan-template/#sign-off","title":"Sign-Off","text":"<ul> <li>Agent signature &amp; date:</li> <li>Reviewer signature &amp; date:</li> <li>Requester confirmation:</li> </ul>"},{"location":"guides/implementation-plan-template/#references","title":"References","text":"<ul> <li>Requirements Intake document:</li> <li>Relevant ADRs or historical decisions:</li> </ul>"},{"location":"guides/migration-guide-phase1/","title":"Migration Guide: Phase 1 - DRY/KISS/YAGNI Enforcement","text":"<p>Target Audience: Existing projects using the AI Generator for Async Microservices framework Phase: Phase 1 (DRY/KISS/YAGNI Principles Enforcement) Last Updated: 2025-11-07</p>"},{"location":"guides/migration-guide-phase1/#overview","title":"Overview","text":"<p>This guide helps you migrate existing microservices projects to adopt Phase 1 improvements:</p> <ol> <li>Shared Utilities - Eliminate code duplication</li> <li>PostgreSQL Data Service Template - Standardize data access patterns</li> <li>Automated Quality Gates - Enforce quality standards in CI</li> </ol> <p>Estimated Migration Time: 4-8 hours for a typical 5-service project</p>"},{"location":"guides/migration-guide-phase1/#prerequisites","title":"Prerequisites","text":"<p>Before starting migration:</p> <ul> <li> Existing project uses framework version 0.1.0 or later</li> <li> Git working directory is clean (commit or stash changes)</li> <li> All tests passing in current state</li> <li> CI/CD pipeline functional</li> <li> Backup or branch created (<code>git checkout -b migrate-phase1</code>)</li> </ul>"},{"location":"guides/migration-guide-phase1/#phase-1-migrate-to-shared-utilities","title":"Phase 1: Migrate to Shared Utilities","text":"<p>Goal: Replace duplicated code with shared utilities</p>"},{"location":"guides/migration-guide-phase1/#step-11-copy-shared-utilities","title":"Step 1.1: Copy Shared Utilities","text":"<pre><code># From framework root\ncp -r templates/shared/utils/ your_project/shared/\n\n# Verify files copied\nls -la your_project/shared/utils/\n# Expected: __init__.py, logger.py, validators.py, exceptions.py,\n#           pagination.py, request_id.py, README.md\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-12-migrate-logging","title":"Step 1.2: Migrate Logging","text":"<p>Before: Duplicated logging setup in each service</p> <pre><code># services/user_api/src/core/logging_config.py (BEFORE)\nimport logging\nimport sys\nfrom pythonjsonlogger import jsonlogger\n\ndef setup_logging(level: str = \"INFO\") -&gt; None:\n    handler = logging.StreamHandler(sys.stdout)\n    formatter = jsonlogger.JsonFormatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n    )\n    handler.setFormatter(formatter)\n    logging.root.addHandler(handler)\n    logging.root.setLevel(level)\n</code></pre> <p>After: Use shared logger</p> <pre><code># services/user_api/src/core/logging_config.py (AFTER)\nfrom shared.utils.logger import create_logger\n\n# Create service-specific logger\nlogger = create_logger(\"user_api\", level=\"INFO\", include_request_id=True)\n\n# In your application code\nfrom shared.utils.logger import create_logger\n\nlogger = create_logger(__name__)\nlogger.info(\"User created\", extra={\"user_id\": user.id, \"email\": user.email})\n</code></pre> <p>Files to migrate: - <code>services/*/src/core/logging_config.py</code> \u2192 Use <code>shared.utils.logger</code> - <code>services/*/src/main.py</code> \u2192 Import from shared logger</p>"},{"location":"guides/migration-guide-phase1/#step-13-migrate-validators","title":"Step 1.3: Migrate Validators","text":"<p>Before: Duplicated validation in multiple services</p> <pre><code># services/user_api/src/utils/validators.py (BEFORE - DELETE THIS)\nimport re\n\ndef is_valid_email(email: str) -&gt; bool:\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\n# services/profile_api/src/utils/validators.py (BEFORE - DELETE THIS)\n# ^^^ SAME CODE DUPLICATED ^^^\n</code></pre> <p>After: Use shared validators</p> <pre><code># services/user_api/src/api/v1/users.py (AFTER)\nfrom shared.utils.validators import is_valid_email, is_valid_phone\nfrom shared.utils.exceptions import ValidationError\n\n@router.post(\"/users\")\nasync def create_user(data: UserCreate):\n    if not is_valid_email(data.email):\n        raise ValidationError(\"Invalid email format\")\n\n    if data.phone and not is_valid_phone(data.phone):\n        raise ValidationError(\"Invalid phone format\")\n\n    # ... create user\n</code></pre> <p>Files to migrate: - <code>services/*/src/utils/validators.py</code> \u2192 DELETE and use <code>shared.utils.validators</code> - All imports \u2192 Change to <code>from shared.utils.validators import ...</code></p>"},{"location":"guides/migration-guide-phase1/#step-14-migrate-exception-handling","title":"Step 1.4: Migrate Exception Handling","text":"<p>Before: Inconsistent exception handling</p> <pre><code># services/user_api/src/exceptions.py (BEFORE)\nclass UserNotFound(Exception):\n    pass\n\n# services/payment_api/src/exceptions.py (BEFORE)\nclass PaymentNotFound(Exception):\n    pass\n</code></pre> <p>After: Use shared exception hierarchy</p> <pre><code># services/user_api/src/exceptions.py (AFTER)\nfrom shared.utils.exceptions import NotFoundError\n\nclass UserNotFound(NotFoundError):\n    \"\"\"User not found (404).\"\"\"\n\n    def __init__(self, user_id: int):\n        super().__init__(\n            message=f\"User {user_id} not found\",\n            error_code=\"USER_NOT_FOUND\",\n            details={\"user_id\": user_id}\n        )\n</code></pre> <p>Benefits: - Automatic HTTP status code mapping (404, 422, 401, etc.) - Consistent error response format - Built-in error details support</p>"},{"location":"guides/migration-guide-phase1/#step-15-migrate-pagination","title":"Step 1.5: Migrate Pagination","text":"<p>Before: Custom pagination in each service</p> <pre><code># services/user_api/src/api/v1/users.py (BEFORE)\n@router.get(\"/users\")\nasync def list_users(skip: int = 0, limit: int = 50):\n    users = await user_service.get_users(skip=skip, limit=limit)\n    total = await user_service.count_users()\n    return {\n        \"items\": users,\n        \"total\": total,\n        \"skip\": skip,\n        \"limit\": limit\n    }\n</code></pre> <p>After: Use shared pagination</p> <pre><code># services/user_api/src/api/v1/users.py (AFTER)\nfrom shared.utils.pagination import (\n    OffsetPaginationParams,\n    OffsetPaginatedResponse,\n    paginate_query\n)\n\n@router.get(\"/users\", response_model=OffsetPaginatedResponse[UserOut])\nasync def list_users(\n    pagination: OffsetPaginationParams = Depends()\n):\n    users, total = await user_service.get_users(\n        skip=pagination.skip,\n        limit=pagination.limit\n    )\n    return OffsetPaginatedResponse(\n        items=users,\n        total=total,\n        skip=pagination.skip,\n        limit=pagination.limit\n    )\n</code></pre> <p>Benefits: - Type-safe pagination with Pydantic models - Consistent pagination across all services - Supports both offset and cursor pagination</p>"},{"location":"guides/migration-guide-phase1/#step-16-add-request-id-tracking","title":"Step 1.6: Add Request ID Tracking","text":"<p>New feature: Correlation IDs for distributed tracing</p> <pre><code># services/user_api/src/core/middleware.py (NEW)\nfrom fastapi import Request\nfrom shared.utils.request_id import generate_request_id, set_request_id\n\nasync def request_id_middleware(request: Request, call_next):\n    # Get request ID from header or generate new one\n    request_id = request.headers.get(\"X-Request-ID\", generate_request_id())\n    set_request_id(request_id)\n\n    response = await call_next(request)\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n\n# In main.py\nfrom src.core.middleware import request_id_middleware\n\napp.middleware(\"http\")(request_id_middleware)\n</code></pre> <p>Usage in logging:</p> <pre><code>from shared.utils.logger import create_logger\nfrom shared.utils.request_id import get_request_id\n\nlogger = create_logger(__name__, include_request_id=True)\n\n# Request ID automatically included in logs\nlogger.info(\"Processing payment\")\n# Output: {\"timestamp\": \"...\", \"request_id\": \"abc-123\", \"message\": \"Processing payment\"}\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-17-verify-migration","title":"Step 1.7: Verify Migration","text":"<pre><code># 1. Check imports\ngrep -r \"from shared.utils\" services/*/src/ | wc -l\n# Should show multiple imports\n\n# 2. Remove old duplicate files\nfind services/ -name \"validators.py\" -path \"*/utils/*\" -delete\nfind services/ -name \"logging_config.py\" -path \"*/core/*\" -delete\n\n# 3. Run tests\npytest services/*/tests/ -v\n\n# 4. Run quality gates (see Phase 3)\njscpd services/ shared/ --threshold 10\n</code></pre>"},{"location":"guides/migration-guide-phase1/#phase-2-adopt-postgresql-data-service-pattern","title":"Phase 2: Adopt PostgreSQL Data Service Pattern","text":"<p>Goal: Standardize PostgreSQL data access using the template</p>"},{"location":"guides/migration-guide-phase1/#step-21-identify-data-services","title":"Step 2.1: Identify Data Services","text":"<pre><code># List services with direct database access\ngrep -r \"create_engine\\|AsyncEngine\" services/*/src/ -l\n\n# These services should be converted to data service pattern\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-22-create-new-data-service-from-template","title":"Step 2.2: Create New Data Service from Template","text":"<pre><code># Copy PostgreSQL data service template\ncp -r templates/services/template_data_postgres_api/ services/data_postgres_api/\n\n# Rename placeholders (if using sed)\ncd services/data_postgres_api/\nfind . -type f -exec sed -i 's/{{PROJECT_NAME}}/your_project/g' {} +\nfind . -type f -exec sed -i 's/{{SERVICE_NAME}}/data_postgres_api/g' {} +\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-23-migrate-database-models","title":"Step 2.3: Migrate Database Models","text":"<p>Before: Models in business services</p> <pre><code># services/user_api/src/models/user.py (BEFORE - MOVE TO DATA SERVICE)\nfrom sqlalchemy import Column, Integer, String\nfrom src.core.database import Base\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True)\n    email = Column(String(255), unique=True, nullable=False)\n    name = Column(String(100), nullable=False)\n</code></pre> <p>After: Models in data service</p> <pre><code># services/data_postgres_api/src/models/user.py (AFTER)\nfrom sqlalchemy import Column, Integer, String\nfrom src.models.base import Base, TimestampMixin, SoftDeleteMixin\n\nclass User(Base, TimestampMixin, SoftDeleteMixin):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    email = Column(String(255), unique=True, nullable=False, index=True)\n    name = Column(String(100), nullable=False)\n\n    # TimestampMixin adds: created_at, updated_at\n    # SoftDeleteMixin adds: deleted_at, soft_delete(), restore()\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-24-create-repository","title":"Step 2.4: Create Repository","text":"<pre><code># services/data_postgres_api/src/repositories/user_repository.py (NEW)\nfrom typing import Optional\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.repositories.base_repository import BaseRepository\nfrom src.models.user import User\n\nclass UserRepository(BaseRepository[User]):\n    \"\"\"User repository with CRUD operations.\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        super().__init__(User, session)\n\n    async def get_by_email(self, email: str) -&gt; Optional[User]:\n        \"\"\"Get user by email (custom query).\"\"\"\n        from sqlalchemy import select\n\n        stmt = select(self.model).where(self.model.email == email)\n        result = await self.session.execute(stmt)\n        return result.scalar_one_or_none()\n</code></pre> <p>Benefits: - All CRUD operations inherited from BaseRepository - Only implement custom queries (get_by_email) - Type-safe with Generic[User]</p>"},{"location":"guides/migration-guide-phase1/#step-25-create-api-endpoints","title":"Step 2.5: Create API Endpoints","text":"<pre><code># services/data_postgres_api/src/api/v1/users.py (NEW)\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom src.repositories.user_repository import UserRepository\nfrom src.schemas.user import UserOut, UserCreate\nfrom src.core.database import get_session\n\nrouter = APIRouter(prefix=\"/users\", tags=[\"users\"])\n\n@router.get(\"/{user_id}\", response_model=UserOut)\nasync def get_user(\n    user_id: int,\n    session = Depends(get_session)\n):\n    repo = UserRepository(session)\n    user = await repo.get_by_id(user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@router.post(\"\", response_model=UserOut, status_code=201)\nasync def create_user(\n    data: UserCreate,\n    session = Depends(get_session)\n):\n    repo = UserRepository(session)\n    user = await repo.create(**data.model_dump())\n    return user\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-26-update-business-services-to-use-http","title":"Step 2.6: Update Business Services to Use HTTP","text":"<p>Before: Business service with direct DB access</p> <pre><code># services/user_api/src/services/user_service.py (BEFORE - REMOVE DB ACCESS)\nclass UserService:\n    def __init__(self, db: Session):\n        self._db = db\n\n    async def get_user(self, user_id: int) -&gt; User:\n        return self._db.query(UserModel).filter(UserModel.id == user_id).first()\n</code></pre> <p>After: Business service with HTTP access</p> <pre><code># services/user_api/src/services/user_service.py (AFTER - HTTP ONLY)\nimport httpx\nfrom src.core.config import settings\n\nclass UserService:\n    def __init__(self):\n        self._data_api_url = settings.DATA_API_URL\n\n    async def get_user(self, user_id: int) -&gt; User:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                f\"{self._data_api_url}/users/{user_id}\",\n                timeout=30.0\n            )\n            response.raise_for_status()\n            return User(**response.json())\n</code></pre> <p>Benefits: - Single source of truth for data access - No duplicated database queries - Data service handles connection pooling, transactions - Business services focus on business logic only</p>"},{"location":"guides/migration-guide-phase1/#step-27-run-migrations","title":"Step 2.7: Run Migrations","text":"<pre><code># In data service directory\ncd services/data_postgres_api/\n\n# Generate initial migration\nalembic revision --autogenerate -m \"Initial schema\"\n\n# Review migration file\ncat alembic/versions/*_initial_schema.py\n\n# Apply migration\nalembic upgrade head\n\n# Verify\nalembic current\n</code></pre>"},{"location":"guides/migration-guide-phase1/#phase-3-add-automated-quality-gates","title":"Phase 3: Add Automated Quality Gates","text":"<p>Goal: Enforce quality standards in CI pipeline</p>"},{"location":"guides/migration-guide-phase1/#step-31-install-quality-tools","title":"Step 3.1: Install Quality Tools","text":"<pre><code># Install jscpd (code duplication detector)\nnpm install -g jscpd\n\n# Install radon (complexity analyzer)\npip install radon\n\n# Verify installation\njscpd --version\nradon --version\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-32-copy-ci-workflow","title":"Step 3.2: Copy CI Workflow","text":"<pre><code># Copy quality gates workflow\ncp templates/ci-cd/.github/workflows/ci.yml .github/workflows/\n\n# Review the new quality gate jobs\ngrep -A5 \"check-duplication\\|check-complexity\\|check-dependencies\" .github/workflows/ci.yml\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-33-run-quality-gates-locally","title":"Step 3.3: Run Quality Gates Locally","text":"<p>Test before pushing:</p> <pre><code># 1. DRY check (code duplication)\njscpd services/ shared/ --threshold 10 --format \"python\" --reporters \"console\"\n\n# 2. KISS checks\n# 2a. Cyclomatic complexity\nradon cc services/ shared/ --min B --total-average --show-complexity\n\n# 2b. Maintainability index\nradon mi services/ shared/ --min B --show\n\n# 2c. File sizes\nfind services/ shared/ -name \"*.py\" -type f -exec wc -l {} \\; | awk '$1 &gt; 500'\n\n# 3. YAGNI check (dependencies)\nfor dir in services/*/; do\n  echo \"$(basename $dir): $(grep -cve '^#' -e '^$' $dir/requirements.txt 2&gt;/dev/null || echo 0) deps\"\ndone\n</code></pre>"},{"location":"guides/migration-guide-phase1/#step-34-fix-violations","title":"Step 3.4: Fix Violations","text":"<p>If quality gates fail, see remediation guide: - Automated Quality Gates Documentation</p> <p>Common fixes:</p> <ol> <li>Code duplication &gt;10%</li> <li>Extract to <code>shared/utils/</code></li> <li>Create base classes</li> <li> <p>Use composition</p> </li> <li> <p>Complexity &gt;10</p> </li> <li>Extract methods</li> <li>Use early returns</li> <li> <p>Apply strategy pattern</p> </li> <li> <p>Too many dependencies</p> </li> <li>Remove dev deps from production requirements.txt</li> <li>Use stdlib alternatives</li> <li>Remove unused dependencies</li> </ol>"},{"location":"guides/migration-guide-phase1/#step-35-commit-and-push","title":"Step 3.5: Commit and Push","text":"<pre><code># Stage all changes\ngit add .github/workflows/ci.yml shared/utils/ services/\n\n# Commit\ngit commit -m \"feat: Migrate to Phase 1 (DRY/KISS/YAGNI enforcement)\n\n- Add shared utilities (logger, validators, exceptions, pagination)\n- Migrate to PostgreSQL data service pattern\n- Add automated quality gates in CI\n\nQuality Metrics:\n- Code duplication: &lt;10%\n- Cyclomatic complexity: &lt;10\n- All files &lt;500 lines\n- Dependencies within limits\n\n\ud83e\udd16 Migrated using Phase 1 migration guide\"\n\n# Push and watch CI\ngit push origin migrate-phase1\n</code></pre>"},{"location":"guides/migration-guide-phase1/#verification-checklist","title":"Verification Checklist","text":"<p>After migration, verify:</p>"},{"location":"guides/migration-guide-phase1/#shared-utilities","title":"Shared Utilities","text":"<ul> <li> All services import from <code>shared.utils.*</code></li> <li> Old duplicate files deleted</li> <li> Request IDs propagate across services</li> <li> Logging produces structured JSON</li> <li> Validators used consistently</li> </ul>"},{"location":"guides/migration-guide-phase1/#data-service-pattern","title":"Data Service Pattern","text":"<ul> <li> Data service has all database models</li> <li> Business services use HTTP only (no direct DB)</li> <li> Alembic migrations working</li> <li> Health checks responding (<code>/health</code>, <code>/health/ready</code>)</li> <li> BaseRepository used for CRUD operations</li> </ul>"},{"location":"guides/migration-guide-phase1/#quality-gates","title":"Quality Gates","text":"<ul> <li> CI workflow includes quality gate jobs</li> <li> Code duplication &lt;10%</li> <li> Complexity &lt;10 (McCabe)</li> <li> File sizes &lt;500 lines</li> <li> Dependencies within limits (30/50)</li> <li> All tests passing</li> </ul>"},{"location":"guides/migration-guide-phase1/#rollback-plan","title":"Rollback Plan","text":"<p>If migration causes issues:</p> <pre><code># 1. Rollback git changes\ngit reset --hard origin/main  # or origin/master\n\n# 2. Remove shared utilities\nrm -rf shared/utils/\n\n# 3. Restore old CI workflow\ngit checkout origin/main -- .github/workflows/ci.yml\n\n# 4. Restart services\ndocker-compose restart\n</code></pre>"},{"location":"guides/migration-guide-phase1/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/migration-guide-phase1/#issue-import-errors-after-migration","title":"Issue: Import errors after migration","text":"<p>Symptom: <pre><code>ImportError: No module named 'shared.utils'\n</code></pre></p> <p>Solution: <pre><code># Ensure shared/ is in PYTHONPATH\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n\n# Or in Dockerfile\nENV PYTHONPATH=/app\n</code></pre></p>"},{"location":"guides/migration-guide-phase1/#issue-quality-gates-failing-in-ci","title":"Issue: Quality gates failing in CI","text":"<p>Symptom: <pre><code>\u274c DRY VIOLATION: Code duplication exceeds 10% threshold\n</code></pre></p> <p>Solution: - See automated-quality-gates.md for detailed remediation - Run checks locally first: <code>jscpd services/ shared/ --threshold 10</code> - Fix violations before pushing</p>"},{"location":"guides/migration-guide-phase1/#issue-business-services-cant-connect-to-data-service","title":"Issue: Business services can't connect to data service","text":"<p>Symptom: <pre><code>httpx.ConnectError: Connection refused\n</code></pre></p> <p>Solution: <pre><code># 1. Verify data service is running\ndocker-compose ps data_postgres_api\n\n# 2. Check DATA_API_URL in business service .env\necho $DATA_API_URL  # Should be http://data_postgres_api:8000\n\n# 3. Test connectivity\ncurl http://data_postgres_api:8000/health\n</code></pre></p>"},{"location":"guides/migration-guide-phase1/#issue-alembic-migrations-fail","title":"Issue: Alembic migrations fail","text":"<p>Symptom: <pre><code>alembic.util.exc.CommandError: Can't locate revision identified by 'xyz'\n</code></pre></p> <p>Solution: <pre><code># 1. Check migration history\nalembic history\n\n# 2. Stamp current database version\nalembic stamp head\n\n# 3. Generate new migration\nalembic revision --autogenerate -m \"Fix migration\"\n</code></pre></p>"},{"location":"guides/migration-guide-phase1/#support","title":"Support","text":"<ul> <li>Documentation: docs/INDEX.md</li> <li>Quality Gates: docs/quality/automated-quality-gates.md</li> <li>Shared Utils: templates/shared/utils/README.md</li> <li>Data Service: templates/services/template_data_postgres_api/README.md</li> <li>Issues: https://github.com/anthropics/claude-code/issues</li> </ul>"},{"location":"guides/migration-guide-phase1/#next-steps","title":"Next Steps","text":"<p>After completing Phase 1 migration:</p> <ol> <li>Monitor Quality Metrics</li> <li>Track duplication trends</li> <li>Monitor complexity growth</li> <li> <p>Review dependency changes</p> </li> <li> <p>Consider Phase 2 (when available)</p> </li> <li>Complete business API template</li> <li>Add anti-patterns documentation</li> <li> <p>Maturity level upgrade triggers</p> </li> <li> <p>Share Feedback</p> </li> <li>Report migration issues</li> <li>Suggest improvements</li> <li>Share success stories</li> </ol> <p>Migration Guide Version: 1.0 Last Updated: 2025-11-07 Status: Active</p>"},{"location":"guides/prompt-validation-guide/","title":"Prompt Validation Guide","text":"<p>Purpose: Ensure every user prompt entering the agent workflow contains the minimum context required to follow the microservices framework rules and produce production-ready deliverables.</p>"},{"location":"guides/prompt-validation-guide/#when-to-run-this-checklist","title":"When to Run This Checklist","text":"<p>Run prompt validation immediately after receiving a new user request and before starting the Requirements Intake step (Stage 2 in <code>ai-code-generation-master-workflow.md</code>). If any mandatory field is missing, pause all further actions and ask the requester for clarification using the prompt augmentation templates.</p>"},{"location":"guides/prompt-validation-guide/#critical-input-checklist","title":"Critical Input Checklist","text":"Field Why It Matters Primary References Business Context Anchors the solution in a clear problem statement, target users, and success metrics. <code>README.md</code>, <code>docs/reference/tech_stack.md</code>, <code>docs/reference/agent-context-summary.md</code> Target Maturity Level Determines infrastructure complexity, observability, security, and generation time. Prevents over-engineering for MVPs and ensures production readiness for enterprise deployments. <code>docs/reference/maturity-levels.md</code>, <code>docs/reference/conditional-stage-rules.md</code> Functional Requirements Defines the capabilities the generated services must expose. <code>docs/guides/use-case-implementation-guide.md</code>, <code>docs/reference/project-structure.md</code> Optional Modules Identifies additional services beyond core (Workers, Bot, MongoDB, Redis, etc.). Available at any maturity level. <code>docs/reference/maturity-levels.md</code> (modules section) Non-Functional Constraints Ensures compliance with architecture, performance, and security requirements. <code>docs/guides/architecture-guide.md</code>, <code>docs/atomic/architecture/</code>, <code>docs/atomic/observability/</code> Dependencies &amp; Integrations Identifies external systems, queues, or data flows that must be modeled. <code>docs/atomic/infrastructure/</code>, <code>docs/atomic/services/</code>, <code>docs/reference/deliverables-catalog.md</code> Scope Boundaries Prevents unplanned features from entering the delivery plan. <code>docs/guides/implementation-plan-template.md</code> Expected Deliverables Aligns produced artefacts with framework expectations. <code>docs/reference/deliverables-catalog.md</code>, <code>docs/reference/architecture-decision-log-template.md</code> Acceptance Criteria Adds measurable success checks that feed the verification stage. <code>docs/quality/agent-verification-checklist.md</code>, <code>docs/atomic/testing/</code> Open Questions &amp; Risks Triggers early clarification to avoid rework. <code>docs/reference/troubleshooting.md</code>, <code>docs/reference/prompt-templates.md</code>"},{"location":"guides/prompt-validation-guide/#validation-procedure","title":"Validation Procedure","text":"<ol> <li>Collect Prompt</li> <li>Store the raw user prompt in the working notes.</li> <li>Confirm the prompt language and conventions comply with <code>docs/STYLE_GUIDE.md</code> if it will be referenced in documentation.</li> <li>Inspect Each Field</li> <li>For every row in the checklist above, verify the prompt contains explicit information.</li> <li>If a field is partially filled, treat it as missing.</li> <li>Request Clarifications When Needed</li> <li>Use the relevant prompt augmentation snippet from <code>docs/reference/prompt-templates.md</code>.</li> <li>Clearly state which field is missing and why it is required.</li> <li>Do not continue until the requester provides the missing context.</li> <li>Record Validation Outcome</li> <li>When all mandatory fields are satisfied, capture a short confirmation note to include in the Requirements Intake artefact.</li> <li>If the requester cancels or cannot supply the data, terminate the workflow and log the reason.</li> </ol>"},{"location":"guides/prompt-validation-guide/#decision-matrix","title":"Decision Matrix","text":"Missing Information Required Action Blocker? Business context or overall goal Ask the requester to restate the problem, target users, and success metrics. Yes Target maturity level Ask: \"Choose maturity level: 1=PoC (~5 min), 2=Development (~10 min), 3=Pre-Production (~15 min), 4=Production (~30 min)\". See <code>prompt-templates.md</code> for full prompt. Yes Optional modules If not mentioned, ask explicitly: \"Do you need any optional modules (Workers, Bot, MongoDB, RabbitMQ, Redis) or just core (FastAPI + PostgreSQL)?\" MUST be explicitly stated (default: \"none\" if user confirms core-only). No (defaults to \"none\" if user confirms, but must ask) Functional requirements Request a prioritized feature list or user stories. Yes Architecture and quality constraints Ask for performance/security expectations or confirm adherence to framework defaults. Yes Dependencies or integrations Clarify external systems, message queues, and data sources. Yes Scope boundaries Request explicit exclusions to avoid over-delivery. Yes Deliverables or acceptance criteria Confirm which artefacts and checks are expected (tests, coverage, reports). Yes Open questions/risks Capture known unknowns; recommend a follow-up session if unresolved. No, but must be tracked"},{"location":"guides/prompt-validation-guide/#retry-policy-for-unresponsive-users","title":"Retry Policy for Unresponsive Users","text":"<p>Purpose: Define how AI handles cases where users don't provide required clarifications, preventing indefinite workflow suspension.</p>"},{"location":"guides/prompt-validation-guide/#retry-sequence","title":"Retry Sequence","text":"<p>When AI requests clarification for missing mandatory fields:</p> <ol> <li>First Attempt (immediate)</li> <li>Send clarification request using templates from <code>prompt-templates.md</code></li> <li>Clearly list all missing fields</li> <li>Provide examples for each field</li> <li> <p>Set expectations: \"Please provide this information to proceed with Stage 2\"</p> </li> <li> <p>Wait Period</p> </li> <li>Monitor for user response</li> <li> <p>If no valid response received, proceed to second attempt</p> </li> <li> <p>Second Attempt (after first timeout)</p> </li> <li>Resend clarification with simplified format</li> <li>Highlight most critical missing fields (e.g., Maturity Level, Business Context)</li> <li>Offer options/defaults where applicable:      <pre><code>Quick Decision Guide:\n\u2022 Maturity Level: Choose 1 (PoC) if unsure - can upgrade later\n\u2022 Optional Modules: Choose \"none\" if uncertain - can add later\n</code></pre></li> <li> <p>Final warning: \"Without this information, workflow cannot proceed\"</p> </li> <li> <p>Third Attempt Decision</p> </li> <li>If still no valid response after second attempt:<ul> <li>TERMINATE workflow gracefully</li> <li>Log termination reason: \"Workflow terminated: User did not provide required information after 2 clarification attempts\"</li> <li>Send termination summary to user:    <pre><code>## \u26a0\ufe0f Workflow Terminated\n\n**Reason**: Missing mandatory information after multiple clarification requests\n\n**Missing Fields**:\n\u2022 Target Maturity Level (1-4)\n\u2022 Business Context (problem, users, metrics)\n[... list all still-missing fields ...]\n\n**Next Steps**:\nTo restart the workflow, please provide a complete prompt including all mandatory fields.\nSee docs/guides/prompt-validation-guide.md for requirements.\n</code></pre></li> </ul> </li> </ol>"},{"location":"guides/prompt-validation-guide/#handling-ambiguous-responses","title":"Handling Ambiguous Responses","text":"<p>If user provides partial or ambiguous information:</p> Scenario AI Action Example User says \"I don't know\" for non-critical field Use framework default, document assumption in Requirements Intake User: \"I don't know auth method\"AI: \"Defaulting to JWT (framework standard), can change later\" User says \"I don't know\" for critical field (Maturity Level, Business Context) Cannot proceed \u2192 retry with more guidance User: \"I don't know which level\"AI: \"Cannot proceed without level. For quick prototype, choose Level 1 (PoC). For production, choose Level 4.\" User provides invalid value Reject, ask for correction with valid options User: \"Maturity Level = 7\"AI: \"Invalid level. Valid options: 1, 2, 3, or 4\""},{"location":"guides/prompt-validation-guide/#do-not-assume-defaults-for-critical-fields","title":"DO NOT Assume Defaults for Critical Fields","text":"<p>NEVER auto-select these without explicit user confirmation: - \u274c Target Maturity Level (1-4) - \u274c Business Context - \u274c Functional Requirements</p> <p>MAY auto-select these with user notification: - \u2705 Optional Modules (default: \"none\" if user confirms core-only is sufficient) - \u2705 Authentication method (default: JWT if user approves) - \u2705 Coverage threshold (use level-appropriate default from <code>maturity-levels.md</code>)</p>"},{"location":"guides/prompt-validation-guide/#timeout-configuration","title":"Timeout Configuration","text":"Attempt Wait Time Notes After 1<sup>st</sup> request Implementation-dependent In interactive CLI: wait for user inputIn async environments: configurable timeout After 2<sup>nd</sup> request Implementation-dependent Shorter than first timeoutSignal urgency to user <p>Note: Exact timeout values are implementation-specific (CLI vs web UI vs API). The principle is: 2 clarification attempts maximum, then terminate gracefully.</p>"},{"location":"guides/prompt-validation-guide/#integration-with-agent-workflow","title":"Integration With Agent Workflow","text":"<ul> <li>This guide is executed at Stage 1 in <code>docs/guides/ai-code-generation-master-workflow.md</code>.</li> <li>Only after successful validation should the agent proceed to Stage 2 (Requirements Intake) and populate <code>docs/guides/requirements-intake-template.md</code>.</li> <li>The validated prompt becomes part of the project artefacts referenced in <code>docs/reference/deliverables-catalog.md</code>.</li> </ul>"},{"location":"guides/prompt-validation-guide/#maintenance","title":"Maintenance","text":"<ul> <li>Update this checklist whenever new artefacts are added or requirements change.</li> <li>Ensure references stay aligned with <code>docs/INDEX.md</code> and <code>docs/reference/agent-context-summary.md</code>.</li> <li>Follow <code>docs/STYLE_GUIDE.md</code> when editing this guide.</li> </ul>"},{"location":"guides/requirements-intake-template/","title":"Requirements Intake Template","text":"<p>Instructions: Copy this template when documenting user requirements. Provide explicit answers for each section. Reference <code>docs/guides/prompt-validation-guide.md</code> for mandatory content.</p>"},{"location":"guides/requirements-intake-template/#request-metadata","title":"Request Metadata","text":"<ul> <li>Request ID:</li> <li>Requester / Stakeholders:</li> <li>Date:</li> <li>Communication Channel:</li> </ul>"},{"location":"guides/requirements-intake-template/#target-configuration","title":"Target Configuration","text":"<ul> <li>Maturity Level: [1-PoC / 2-Development / 3-Pre-Production / 4-Production]</li> <li>Optional Modules: [None / Workers / Bot / MongoDB / RabbitMQ / Redis / File Storage / Real-Time]</li> <li>Estimated Generation Time: [~5 min / ~10 min / ~15 min / ~30 min based on level]</li> <li>Reference: See <code>docs/reference/maturity-levels.md</code> for level details</li> </ul>"},{"location":"guides/requirements-intake-template/#business-context-objectives","title":"Business Context &amp; Objectives","text":"<ul> <li>Problem statement:</li> <li>Target users / personas:</li> <li>Success metrics / KPIs:</li> <li>Strategic alignment notes (see <code>README.md</code> for framework positioning):</li> </ul>"},{"location":"guides/requirements-intake-template/#functional-requirements","title":"Functional Requirements","text":"Req ID Feature / Capability Priority (Must / Should / Could) Description Acceptance Criteria Implementation Status FR-001 (example) Must (example) (example) Pending <p>NOTE: Assign unique Req ID (FR-001, FR-002, ...) to EVERY functional requirement for traceability. See <code>docs/guides/requirements-traceability-guide.md</code> for Req ID lifecycle.</p>"},{"location":"guides/requirements-intake-template/#uiux-requirements-for-ui-heavy-projects","title":"UI/UX Requirements (for UI-heavy projects)","text":"<p>WHEN TO USE: For projects with detailed UI/UX specifications (Telegram bots, web frontends, mobile apps). Skip this section if project has minimal UI (API-only services).</p> Req ID UI Element / Screen Priority (Must / Should / Could) Description Acceptance Criteria Implementation Status UI-001 (example: Login screen) Must (example: Email/password with \"Forgot?\" link) (example: Redirect to /dashboard on success) Pending <p>NOTE: Assign unique Req ID (UI-001, UI-002, ...) to EVERY UI element, screen, modal, button, or form. Critical for ensuring 100% UI coverage in large UX/UI prompts.</p>"},{"location":"guides/requirements-intake-template/#non-functional-requirements-measurable-constraints","title":"Non-Functional Requirements (measurable constraints)","text":"<p>WHEN TO USE: For performance, security, compliance, or availability requirements that can be objectively measured and verified.</p> Req ID Constraint Type Target / SLA Description Acceptance Criteria Implementation Status NF-001 (example: Performance) (example: &lt; 200ms p95) (example: API latency) (example: Load test confirms &lt; 200ms) Pending <p>NOTE: Assign Req ID (NF-001, NF-002, ...) only to measurable constraints that can be verified (e.g., latency &lt; 200ms, uptime &gt; 99.9%). Skip subjective constraints.</p>"},{"location":"guides/requirements-intake-template/#requirements-summary","title":"Requirements Summary","text":"<p>PURPOSE: Track total requirement count for coverage calculation in Stage 5 (Verification) and Stage 6 (QA Report).</p> <ul> <li>Total Functional (FR-*): [count]</li> <li>Total UI/UX (UI-*): [count or \"N/A\" if API-only]</li> <li>Total Non-Functional (NF-*): [count or \"0\" if none]</li> <li>Grand Total: [sum]</li> </ul> <p>TRACEABILITY: See <code>docs/guides/requirements-traceability-guide.md</code> for Req ID lifecycle through all workflow stages. Coverage verification mandatory in Stage 5.</p>"},{"location":"guides/requirements-intake-template/#non-functional-constraints-general","title":"Non-Functional Constraints (general)","text":"<ul> <li>Performance / SLA expectations:</li> <li>Security / compliance requirements:</li> <li>Reliability &amp; availability targets:</li> <li>Architecture alignment confirmation (Improved Hybrid Approach, HTTP-only data access, service separation; see <code>docs/guides/architecture-guide.md</code> and <code>docs/atomic/architecture/</code>):</li> <li>Observability expectations (logging, metrics, tracing; see <code>docs/atomic/observability/</code>):</li> </ul>"},{"location":"guides/requirements-intake-template/#dependencies-integrations","title":"Dependencies &amp; Integrations","text":"External System / Service Interaction Pattern Protocol / API Notes"},{"location":"guides/requirements-intake-template/#data-storage-considerations","title":"Data &amp; Storage Considerations","text":"<ul> <li>Primary data sources:</li> <li>Expected data volume / growth:</li> <li>Data retention or compliance rules:</li> <li>Mapping to data services (<code>docs/reference/project-structure.md</code>, <code>docs/atomic/infrastructure/</code>):</li> </ul>"},{"location":"guides/requirements-intake-template/#scope-boundaries","title":"Scope Boundaries","text":"<ul> <li>In scope:</li> <li>Out of scope:</li> </ul>"},{"location":"guides/requirements-intake-template/#expected-deliverables","title":"Expected Deliverables","text":"<ul> <li>Code / services:</li> <li>Configuration / infrastructure artefacts:</li> <li>Documentation (ADR, QA report, others per <code>docs/reference/deliverables-catalog.md</code>):</li> </ul>"},{"location":"guides/requirements-intake-template/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Functional validation steps:</li> <li>Quality gates (linting, typing, security, tests, coverage per <code>docs/quality/agent-verification-checklist.md</code>):</li> <li>Deployment / release expectations:</li> </ul>"},{"location":"guides/requirements-intake-template/#risks-open-questions","title":"Risks &amp; Open Questions","text":"Item Description Owner Resolution Path"},{"location":"guides/requirements-intake-template/#next-steps","title":"Next Steps","text":"<ul> <li>Agreed decisions:</li> <li>Pending clarifications:</li> <li>Target date for implementation plan review:</li> </ul>"},{"location":"guides/requirements-intake-template/#references","title":"References","text":"<ul> <li>Link to original prompt:</li> <li>Related documents / tickets:</li> </ul>"},{"location":"guides/requirements-traceability-guide/","title":"Requirements Traceability Guide","text":"<p>PURPOSE: Establish a systematic approach to track every requirement from initial user prompt through implementation to final delivery, guaranteeing 100% coverage without exceptions. Critical for large, detailed UX/UI prompts with 50+ requirements.</p>"},{"location":"guides/requirements-traceability-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>What is Requirements Traceability?</li> <li>Why RTM is Critical</li> <li>Req ID Format Standards</li> <li>Lifecycle Through Workflow</li> <li>Coverage Calculation</li> <li>Implementation Guide</li> <li>Complete Example</li> <li>Common Pitfalls</li> </ul>"},{"location":"guides/requirements-traceability-guide/#what-is-requirements-traceability","title":"What is Requirements Traceability?","text":"<p>Requirements Traceability Matrix (RTM) is a document that maps each user requirement to its implementation in code, tests, and deliverables. It ensures bidirectional traceability:</p> <ul> <li>Forward: Requirement \u2192 Design \u2192 Implementation \u2192 Testing \u2192 Delivery</li> <li>Backward: Code \u2192 Test \u2192 Requirement (proving every line serves a purpose)</li> </ul>"},{"location":"guides/requirements-traceability-guide/#key-benefits","title":"Key Benefits","text":"<ol> <li>100% Coverage Guarantee: No requirement left unimplemented</li> <li>Auditability: Stakeholders can verify every requirement was addressed</li> <li>Change Impact Analysis: Identify which code to modify when requirements change</li> <li>Quality Gate: Block delivery if coverage &lt; 100% (unless explicitly approved)</li> <li>UX/UI Completeness: Essential for UI-heavy projects with 50+ UI elements</li> </ol>"},{"location":"guides/requirements-traceability-guide/#why-rtm-is-critical","title":"Why RTM is Critical","text":""},{"location":"guides/requirements-traceability-guide/#problem-without-rtm","title":"Problem Without RTM","text":"<p>When AI generates code from a large user prompt: - \u274c Memory limits: AI may forget requirements from early in prompt - \u274c Implicit tracking: No systematic verification of completeness - \u274c Easy to miss: One missing button, modal, or error message = incomplete product - \u274c No evidence: Cannot prove to stakeholders that everything was built</p>"},{"location":"guides/requirements-traceability-guide/#solution-with-rtm","title":"Solution With RTM","text":"<ul> <li>\u2705 Explicit tracking: Every requirement gets unique Req ID (FR-001, UI-001)</li> <li>\u2705 Systematic verification: Stage 5 checks 100% coverage before delivery</li> <li>\u2705 Evidence-based: QA Report shows exact code location for each requirement</li> <li>\u2705 Stakeholder confidence: Coverage matrix proves completeness</li> </ul>"},{"location":"guides/requirements-traceability-guide/#critical-for-large-prompts","title":"Critical for Large Prompts","text":"<p>Example: UX/UI prompt with 50 requirements - 20 UI screens (Login, Dashboard, Profile, Settings, etc.) - 30 UI elements (buttons, forms, modals, dropdowns, etc.) - 15 user flows (registration \u2192 verification \u2192 onboarding) - 25 validation rules (email format, password strength, etc.) - 30 error messages (field empty, wrong format, etc.)</p> <p>Without RTM: High risk of missing 5-10% of requirements With RTM: 100% coverage guaranteed by systematic Stage 5 verification</p>"},{"location":"guides/requirements-traceability-guide/#req-id-format-standards","title":"Req ID Format Standards","text":""},{"location":"guides/requirements-traceability-guide/#id-structure","title":"ID Structure","text":"<pre><code>[PREFIX]-[NUMBER]\n\nPREFIX:\n- FR = Functional Requirement\n- UI = UI/UX Requirement\n- NF = Non-Functional Requirement\n\nNUMBER: 001, 002, 003, ... (zero-padded, 3 digits)\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#examples","title":"Examples","text":"Req ID Type Description FR-001 Functional User registration with email/password FR-002 Functional Loan creation with validation rules UI-001 UI/UX Registration form (email, password, confirm fields) UI-002 UI/UX Login screen with \"Forgot password?\" link UI-003 UI/UX Dashboard showing active loans + stats NF-001 Non-Functional API latency &lt; 200ms p95 NF-002 Non-Functional 99.9% uptime SLA"},{"location":"guides/requirements-traceability-guide/#numbering-rules","title":"Numbering Rules","text":"<ol> <li>Sequential: Assign IDs in order as requirements are documented (FR-001, FR-002, FR-003)</li> <li>Immutable: Once assigned, Req ID never changes (even if requirement is descoped)</li> <li>No reuse: Never reuse Req ID from deleted requirement</li> <li>Separate sequences: FR, UI, NF have independent numbering (FR-001 \u2260 UI-001)</li> </ol>"},{"location":"guides/requirements-traceability-guide/#when-to-assign-ids","title":"When to Assign IDs","text":"<p>Stage 2: Requirements Intake (MANDATORY) - As AI documents requirements in <code>requirements-intake-template.md</code> - EVERY requirement in Functional Requirements table gets Req ID - EVERY UI element/screen gets Req ID (for UI-heavy projects) - EVERY measurable non-functional constraint gets Req ID</p>"},{"location":"guides/requirements-traceability-guide/#lifecycle-through-workflow","title":"Lifecycle Through Workflow","text":""},{"location":"guides/requirements-traceability-guide/#stage-0-ai-initialization","title":"Stage 0: AI Initialization","text":"<ul> <li>RTM Status: Not yet created</li> <li>AI Action: Read this guide to understand RTM concept</li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-1-prompt-validation","title":"Stage 1: Prompt Validation","text":"<ul> <li>RTM Status: Not yet created</li> <li>AI Action: Ensure prompt contains detailed requirements (foundation for RTM)</li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-2-requirements-intake","title":"Stage 2: Requirements Intake","text":"<ul> <li>RTM Status: \u2705 CREATED</li> <li>AI Action:</li> <li>Extract all requirements from user prompt</li> <li>Assign unique Req ID to each requirement (FR-, UI-, NF-*)</li> <li>Document in <code>requirements-intake-template.md</code> with columns:<ul> <li>Req ID</li> <li>Feature/Capability</li> <li>Priority (Must/Should/Could)</li> <li>Description</li> <li>Acceptance Criteria</li> <li>Implementation Status = Pending</li> </ul> </li> <li>Count total requirements for coverage tracking</li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-3-architecture-mapping-planning","title":"Stage 3: Architecture Mapping &amp; Planning","text":"<ul> <li>RTM Status: \u2705 MAPPED TO TASKS</li> <li>AI Action:</li> <li>Create Requirements Traceability Matrix in <code>implementation-plan-template.md</code></li> <li>Map EVERY Req ID \u2192 Phase \u2192 Specific Tasks</li> <li>Example:      <pre><code>FR-001 (User registration) \u2192 Phase 3 \u2192 Task 3.1, 3.2\nUI-001 (Registration form) \u2192 Phase 5 \u2192 Task 5.3\n</code></pre></li> <li>Verify all Req IDs from Stage 2 appear in mapping (no orphaned requirements)</li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-4-code-generation","title":"Stage 4: Code Generation","text":"<ul> <li>RTM Status: \u2705 IMPLEMENTATION IN PROGRESS</li> <li>AI Action:</li> <li>As each requirement is implemented, update RTM:<ul> <li>Change Status from \"Pending\" \u2192 \"In Progress\" \u2192 \"\u2705 Done\"</li> <li>Add Evidence (code file location: <code>services/api/src/api/v1/users.py:20</code>)</li> </ul> </li> <li>Add comments in code linking back to Req ID:      <pre><code># Implements: FR-001 (User registration)\n@router.post(\"/users\", status_code=201)\nasync def create_user(...):\n</code></pre></li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-5-quality-verification","title":"Stage 5: Quality Verification","text":"<ul> <li>RTM Status: \u2705 COVERAGE VERIFIED</li> <li>AI Action:</li> <li>Run Requirements Coverage Verification check (NEW in <code>agent-verification-checklist.md</code>)</li> <li>For EACH Req ID in Stage 2:<ul> <li>Verify Status = \"\u2705 Done\" in RTM</li> <li>Verify Evidence (code location) exists</li> <li>Verify tests exist for requirement</li> </ul> </li> <li>Calculate coverage: <code>implemented / total * 100%</code></li> <li>GATE: If coverage &lt; 100% \u2192 BLOCK Stage 6 (unless stakeholder approves descope)</li> </ul>"},{"location":"guides/requirements-traceability-guide/#stage-6-qa-report-handoff","title":"Stage 6: QA Report &amp; Handoff","text":"<ul> <li>RTM Status: \u2705 DOCUMENTED IN QA REPORT</li> <li>AI Action:</li> <li>Generate Requirements Coverage Matrix in <code>qa-report-template.md</code></li> <li>Include full table with ALL Req IDs:<ul> <li>Status (\u2705 Done / \u26a0\ufe0f Descoped / \u274c Missing)</li> <li>Evidence (code + tests)</li> <li>Notes</li> </ul> </li> <li>Include Overall Coverage Summary:      <pre><code>Total Requirements: 50\nImplemented: 50 (100%)\nDescoped: 0\nOutstanding: 0\nStatus: \u2705 100% COVERAGE ACHIEVED\n</code></pre></li> </ul>"},{"location":"guides/requirements-traceability-guide/#coverage-calculation","title":"Coverage Calculation","text":""},{"location":"guides/requirements-traceability-guide/#formula","title":"Formula","text":"<pre><code>Coverage (%) = (Implemented Requirements / Total Requirements) \u00d7 100%\n\nWhere:\n- Implemented = Req IDs with Status \"\u2705 Done\" AND Evidence exists\n- Total = All Req IDs assigned in Stage 2 (FR-* + UI-* + NF-*)\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#coverage-thresholds","title":"Coverage Thresholds","text":"Coverage Status Action 100% \u2705 PASS Proceed to Stage 6 (QA Report) 95-99% \u26a0\ufe0f WARNING Review missing requirements, consider descope with stakeholder approval &lt; 95% \u274c FAIL BLOCK Stage 6, implement missing requirements OR get explicit descope approval"},{"location":"guides/requirements-traceability-guide/#descope-process","title":"Descope Process","text":"<p>If stakeholder approves descoping requirements: 1. Update Req ID Status: \"Pending\" \u2192 \"\u26a0\ufe0f Descoped (Approved by [Name] on [Date])\" 2. Document reason in QA Report \u00a7 Defects &amp; Risks 3. Recalculate coverage excluding descoped:    <pre><code>Adjusted Coverage = Implemented / (Total - Descoped) \u00d7 100%\n</code></pre> 4. Adjusted coverage MUST be 100% to proceed</p>"},{"location":"guides/requirements-traceability-guide/#implementation-guide","title":"Implementation Guide","text":""},{"location":"guides/requirements-traceability-guide/#for-ai-agents","title":"For AI Agents","text":""},{"location":"guides/requirements-traceability-guide/#step-1-stage-2-create-rtm-foundation","title":"Step 1: Stage 2 - Create RTM Foundation","text":"<p>When filling <code>requirements-intake-template.md</code>:</p> <pre><code>## Functional Requirements\n| **Req ID** | Feature / Capability | Priority | Description | Acceptance Criteria | **Implementation Status** |\n|------------|---------------------|----------|-------------|---------------------|--------------------------|\n| FR-001 | User registration | Must | Email/password signup | POST /users endpoint works, email verification sent | **Pending** |\n| FR-002 | Loan creation | Must | Borrower creates loan request | POST /loans validates amount/duration, stores in DB | **Pending** |\n| FR-003 | Payment automation | Must | Monthly payments via Stripe | Worker processes payments, updates loan status | **Pending** |\n\n## UI/UX Requirements (for UI-heavy projects)\n| **Req ID** | UI Element / Screen | Priority | Description | Acceptance Criteria | **Implementation Status** |\n|------------|-------------------|----------|-------------|---------------------|--------------------------|\n| UI-001 | Registration form | Must | Email, password, confirm password fields | Form validation works, error messages shown | **Pending** |\n| UI-002 | Login screen | Must | Email/password with \"Forgot password?\" link | Redirect to /dashboard on success | **Pending** |\n| UI-003 | Dashboard | Must | Show active loans + statistics | Data loads from API, responsive layout | **Pending** |\n\n## Requirements Summary\n- **Total Functional (FR-*):** 3\n- **Total UI/UX (UI-*):** 3\n- **Total Non-Functional (NF-*):** 0\n- **Grand Total:** 6\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#step-2-stage-3-map-requirements-to-tasks","title":"Step 2: Stage 3 - Map Requirements to Tasks","text":"<p>In <code>implementation-plan-template.md</code>:</p> <pre><code>## Requirements Traceability Matrix\n\n| Req ID | Feature/Element | Mapped to Phase | Mapped to Tasks | Evidence (when implemented) | Status |\n|--------|----------------|-----------------|-----------------|----------------------------|--------|\n| FR-001 | User registration | Phase 3 | Task 3.1: Domain entity, Task 3.2: API endpoint | TBD | Pending |\n| FR-002 | Loan creation | Phase 3 | Task 3.3: Loan entity, Task 3.4: Validation logic | TBD | Pending |\n| FR-003 | Payment automation | Phase 4 | Task 4.1: Payment worker, Task 4.2: Stripe integration | TBD | Pending |\n| UI-001 | Registration form | Phase 5 | Task 5.3: Registration handler with FSM | TBD | Pending |\n| UI-002 | Login screen | Phase 5 | Task 5.4: Auth handler | TBD | Pending |\n| UI-003 | Dashboard | Phase 5 | Task 5.5: Dashboard handler with API calls | TBD | Pending |\n\n**Requirements Coverage Plan:**\n- Total Requirements: 6\n- Distributed across 3 phases (Phase 3, 4, 5)\n- Average 2 requirements per phase\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#step-3-stage-4-update-rtm-during-implementation","title":"Step 3: Stage 4 - Update RTM During Implementation","text":"<p>As you implement each task, update the RTM Evidence column:</p> <pre><code>| Req ID | Evidence (when implemented) | Status |\n|--------|----------------------------|--------|\n| FR-001 | `services/api/src/api/v1/users.py:20` | \u2705 Done |\n| FR-002 | `services/api/src/api/v1/loans.py:15` | \u2705 Done |\n| UI-001 | `services/bot/src/handlers/register.py:15` | In Progress |\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#step-4-stage-5-verify-coverage","title":"Step 4: Stage 5 - Verify Coverage","text":"<p>Run Requirements Coverage Verification:</p> <pre><code># 1. Extract all Req IDs from Requirements Intake\ngrep \"FR-\\|UI-\\|NF-\" docs/artifacts/requirements-intake.md\n\n# 2. For each Req ID, verify implementation exists\n# (Manual or automated check)\n\n# 3. Calculate coverage\nTotal: 6\nImplemented: 6\nCoverage: 100%\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#step-5-stage-6-document-in-qa-report","title":"Step 5: Stage 6 - Document in QA Report","text":"<p>Include full Coverage Matrix:</p> <pre><code>## Requirements Coverage Matrix\n\n### Functional Requirements (FR-*)\n| Req ID | Feature | Status | Evidence (Code Location) | Tests | Notes |\n|--------|---------|--------|--------------------------|-------|-------|\n| FR-001 | User registration | \u2705 Done | `services/api/src/api/v1/users.py:20` | \u2705 5 tests | Fully implemented |\n| FR-002 | Loan creation | \u2705 Done | `services/api/src/api/v1/loans.py:15` | \u2705 8 tests | Complete with validations |\n| FR-003 | Payment automation | \u2705 Done | `services/worker/src/workers/payment.py:30` | \u2705 6 tests | Worker operational |\n\n**Functional Coverage:** 3/3 requirements (100%)\n\n### Overall Coverage Summary\n- **Total Requirements:** 6 (3 functional + 3 UI + 0 non-functional)\n- **Implemented:** 6 (100%)\n- **Descoped:** 0\n- **Outstanding:** 0\n\n**Status:** \u2705 **ALL REQUIREMENTS COVERED**\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#complete-example-p2p-lending","title":"Complete Example: P2P Lending","text":""},{"location":"guides/requirements-traceability-guide/#user-prompt-simplified","title":"User Prompt (Simplified)","text":"<pre><code>Build a P2P lending platform with:\n1. User registration with KYC verification\n2. Loan marketplace (browse/search loans)\n3. Automated monthly payments via Stripe\n4. Credit scoring algorithm\n5. Telegram bot for notifications\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#stage-2-requirements-intake-excerpt","title":"Stage 2: Requirements Intake (Excerpt)","text":"<pre><code>## Functional Requirements\n| Req ID | Feature | Priority | Description | Acceptance Criteria | Status |\n|--------|---------|----------|-------------|---------------------|--------|\n| FR-001 | User registration | Must | Email/password + KYC | POST /users, Onfido integration | Pending |\n| FR-002 | Loan marketplace | Must | Browse/filter loans | GET /loans with pagination | Pending |\n| FR-003 | Automated payments | Must | Monthly via Stripe | Worker + webhook handler | Pending |\n| FR-004 | Credit scoring | Must | 3-factor algorithm | Score calculation in worker | Pending |\n\n## UI/UX Requirements\n| Req ID | Element | Priority | Description | Acceptance Criteria | Status |\n|--------|---------|----------|-------------|---------------------|--------|\n| UI-001 | Registration form | Must | Email, password, confirm | Validation + error messages | Pending |\n| UI-002 | Login screen | Must | Email/password + \"Forgot?\" | Redirect to dashboard | Pending |\n| UI-003 | Loan list | Must | Cards with amount/rate/term | Clickable to view details | Pending |\n| UI-004 | Notification setup | Must | Enable/disable Telegram | Toggle in settings | Pending |\n\n**Total:** 8 requirements (4 FR + 4 UI)\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#stage-3-requirements-traceability-matrix","title":"Stage 3: Requirements Traceability Matrix","text":"<pre><code>| Req ID | Feature | Phase | Tasks | Evidence | Status |\n|--------|---------|-------|-------|----------|--------|\n| FR-001 | User registration | Phase 3 | 3.1, 3.2 | TBD | Pending |\n| FR-002 | Loan marketplace | Phase 3 | 3.3, 3.4 | TBD | Pending |\n| FR-003 | Automated payments | Phase 4 | 4.1, 4.2 | TBD | Pending |\n| FR-004 | Credit scoring | Phase 4 | 4.3 | TBD | Pending |\n| UI-001 | Registration form | Phase 5 | 5.1 | TBD | Pending |\n| UI-002 | Login screen | Phase 5 | 5.2 | TBD | Pending |\n| UI-003 | Loan list | Phase 5 | 5.3 | TBD | Pending |\n| UI-004 | Notification setup | Phase 5 | 5.4 | TBD | Pending |\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#stage-5-coverage-verification","title":"Stage 5: Coverage Verification","text":"<pre><code>Total Requirements: 8\nImplemented: 8\nCoverage: 8/8 = 100% \u2705\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#stage-6-qa-report-excerpt","title":"Stage 6: QA Report (Excerpt)","text":"<pre><code>## Requirements Coverage Matrix\n\n### Functional Requirements (4 total)\n| Req ID | Feature | Status | Evidence | Tests |\n|--------|---------|--------|----------|-------|\n| FR-001 | User registration | \u2705 Done | `api/v1/users.py:20` | \u2705 5 tests |\n| FR-002 | Loan marketplace | \u2705 Done | `api/v1/loans.py:15` | \u2705 8 tests |\n| FR-003 | Automated payments | \u2705 Done | `worker/payment.py:30` | \u2705 6 tests |\n| FR-004 | Credit scoring | \u2705 Done | `worker/credit_score.py:45` | \u2705 4 tests |\n\n**Functional Coverage:** 4/4 (100%)\n\n### UI/UX Requirements (4 total)\n| Req ID | Element | Status | Evidence | Tests |\n|--------|---------|--------|----------|-------|\n| UI-001 | Registration form | \u2705 Done | `bot/handlers/register.py:15` | \u2705 e2e |\n| UI-002 | Login screen | \u2705 Done | `bot/handlers/auth.py:30` | \u2705 e2e |\n| UI-003 | Loan list | \u2705 Done | `bot/handlers/loans.py:40` | \u2705 e2e |\n| UI-004 | Notification setup | \u2705 Done | `bot/handlers/settings.py:25` | \u2705 e2e |\n\n**UI/UX Coverage:** 4/4 (100%)\n\n### Overall Coverage\n- **Total:** 8 requirements\n- **Implemented:** 8 (100%)\n- **Status:** \u2705 ALL REQUIREMENTS COVERED\n</code></pre>"},{"location":"guides/requirements-traceability-guide/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"guides/requirements-traceability-guide/#pitfall-1-forgetting-to-assign-req-ids-in-stage-2","title":"\u274c Pitfall 1: Forgetting to Assign Req IDs in Stage 2","text":"<p>Problem: Requirements documented without Req IDs <pre><code>| Feature | Description |\n|---------|-------------|\n| User registration | Email/password signup |\n</code></pre></p> <p>Solution: ALWAYS include Req ID column <pre><code>| **Req ID** | Feature | Description |\n|------------|---------|-------------|\n| FR-001 | User registration | Email/password signup |\n</code></pre></p>"},{"location":"guides/requirements-traceability-guide/#pitfall-2-partial-requirements-mapping-in-stage-3","title":"\u274c Pitfall 2: Partial Requirements Mapping in Stage 3","text":"<p>Problem: Some Req IDs missing from RTM <pre><code>RTM shows FR-001, FR-002, but FR-003 is missing\n</code></pre></p> <p>Solution: Verify ALL Req IDs from Stage 2 appear in RTM - Use checklist: grep all Req IDs from Requirements Intake - Ensure each Req ID has Phase + Tasks mapping</p>"},{"location":"guides/requirements-traceability-guide/#pitfall-3-no-evidence-links-in-stage-4","title":"\u274c Pitfall 3: No Evidence Links in Stage 4","text":"<p>Problem: RTM says \"Done\" but no code location <pre><code>| Req ID | Status | Evidence |\n|--------|--------|----------|\n| FR-001 | Done | ??? |\n</code></pre></p> <p>Solution: ALWAYS include file path + line number <pre><code>| Req ID | Status | Evidence |\n|--------|--------|----------|\n| FR-001 | \u2705 Done | `services/api/src/api/v1/users.py:20` |\n</code></pre></p>"},{"location":"guides/requirements-traceability-guide/#pitfall-4-skipping-coverage-verification-in-stage-5","title":"\u274c Pitfall 4: Skipping Coverage Verification in Stage 5","text":"<p>Problem: Proceeding to Stage 6 without verifying 100% coverage</p> <p>Solution: MANDATORY check in <code>agent-verification-checklist.md</code> - Extract all Req IDs from Stage 2 - Verify each has Status \"\u2705 Done\" + Evidence - Calculate coverage (must be 100% or descope approved)</p>"},{"location":"guides/requirements-traceability-guide/#pitfall-5-missing-coverage-matrix-in-qa-report","title":"\u274c Pitfall 5: Missing Coverage Matrix in QA Report","text":"<p>Problem: QA Report lacks RTM table</p> <p>Solution: Use <code>qa-report-template.md</code> Requirements Coverage Matrix section - Include full table with ALL Req IDs - Show Overall Coverage Summary - Provide evidence links</p>"},{"location":"guides/requirements-traceability-guide/#integration-points","title":"Integration Points","text":""},{"location":"guides/requirements-traceability-guide/#with-other-framework-documents","title":"With Other Framework Documents","text":"Document How RTM Integrates <code>prompt-validation-guide.md</code> Stage 1 ensures prompt has detailed requirements (foundation for RTM) <code>requirements-intake-template.md</code> Stage 2 creates RTM with Req IDs <code>implementation-plan-template.md</code> Stage 3 maps Req IDs to tasks <code>agent-verification-checklist.md</code> Stage 5 verifies 100% coverage <code>qa-report-template.md</code> Stage 6 documents final coverage <code>ai-code-generation-master-workflow.md</code> All stages reference RTM lifecycle"},{"location":"guides/requirements-traceability-guide/#with-maturity-levels","title":"With Maturity Levels","text":"<p>RTM is MANDATORY for ALL maturity levels (Level 1-4): - Level 1 (PoC): Fewer requirements, but 100% coverage of selected requirements - Level 4 (Production): More requirements, but same 100% coverage rule</p> <p>Key Principle: Maturity Level = Scope Selector (how many requirements), NOT coverage target</p>"},{"location":"guides/requirements-traceability-guide/#maintenance","title":"Maintenance","text":"<ul> <li>Update examples when workflow changes</li> <li>Keep Req ID format consistent with new requirement types</li> <li>Align with <code>STYLE_GUIDE.md</code> for formatting</li> <li>Cross-reference with <code>ai-code-generation-master-workflow.md</code> for lifecycle accuracy</li> </ul>"},{"location":"guides/requirements-traceability-guide/#quick-reference-card","title":"Quick Reference Card","text":"Question Answer When to create RTM? Stage 2 (Requirements Intake) Req ID format? FR-001, UI-001, NF-001 (PREFIX-NUMBER) When to map requirements? Stage 3 (Planning) When to verify coverage? Stage 5 (Verification) Required coverage? 100% (or descope with approval) Where to document final RTM? Stage 6 (QA Report \u00a7 Requirements Coverage Matrix) How to handle missing requirements? BLOCK Stage 6, implement OR get descope approval <p>NAVIGATION: This guide is referenced by Requirements Intake Template, Implementation Plan Template, Agent Verification Checklist, and QA Report Template.</p>"},{"location":"guides/semantic-shortening-guide/","title":"Semantic Shortening Guide","text":"<p>Purpose: Complete guide for creating concise, meaningful service names using 3-part formula that maintains readability without cryptic abbreviations.</p>"},{"location":"guides/semantic-shortening-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>The 3-Part Formula</li> <li>Philosophy: Why Semantic Shortening?</li> <li>Decision Tree</li> <li>Examples by Context</li> <li>When to Use 4-Part (Exceptions)</li> <li>Common Mistakes</li> <li>Validation Checklist</li> <li>Migration from 4-Part</li> </ul>"},{"location":"guides/semantic-shortening-guide/#overview","title":"Overview","text":"<p>Semantic shortening eliminates redundant function words from service names while preserving clarity through context + domain combination.</p>"},{"location":"guides/semantic-shortening-guide/#key-benefits","title":"Key Benefits","text":"Metric Before (4-part) After (3-part) Improvement Average length 38 chars 24 chars 37% shorter K8s compatibility 70% fit (&lt;30 chars) 95% fit +25% improvement Readability Good Excellent Self-documenting Onboarding time Medium Fast No registry lookup needed Maintenance High (registry sync) Low No abbreviation dictionary"},{"location":"guides/semantic-shortening-guide/#the-3-part-formula","title":"The 3-Part Formula","text":""},{"location":"guides/semantic-shortening-guide/#default-pattern","title":"Default Pattern","text":"<pre><code>{context}_{domain}_{type}\n</code></pre> <ul> <li>{context}: Business area (finance, healthcare, construction...)</li> <li>{domain}: Subdomain within context (lending, telemedicine, house...)</li> <li>{type}: Technical service type (api, worker, bot...)</li> </ul>"},{"location":"guides/semantic-shortening-guide/#examples","title":"Examples","text":"<pre><code># 3-part examples (function implied):\nfinance_lending_api              # lending \u2192 matching/approval\nhealthcare_telemedicine_api      # telemedicine \u2192 consultation\nconstruction_house_bot           # house + bot \u2192 management\nlogistics_delivery_api           # delivery \u2192 tracking/routing\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#extended-pattern-4-part","title":"Extended Pattern (4-part)","text":"<pre><code>{context}_{domain}_{function}_{type}\n</code></pre> <p>Use only when domain alone is ambiguous:</p> <pre><code># 4-part examples (function NOT implied):\nlogistics_fleet_tracking_api        # fleet = tracking? management? maintenance?\nanalytics_reporting_api             # analytics = reporting? querying? processing?\ncommunication_notification_worker   # communication = notifications? email? SMS?\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#philosophy-why-semantic-shortening","title":"Philosophy: Why Semantic Shortening?","text":""},{"location":"guides/semantic-shortening-guide/#the-problem-with-4-part-names","title":"The Problem with 4-Part Names","text":"<p>Over-specification leads to verbose names:</p> <pre><code># 4-part formula (redundant):\nfinance_lending_matching_api                # \"matching\" redundant (lending = matching)\nfinance_payment_processing_worker           # \"processing\" redundant (worker = processing)\nhealthcare_telemedicine_consultation_api    # \"consultation\" redundant (telemedicine = consultation)\n\n# Character counts:\n# - finance_lending_matching_api: 28 chars\n# - finance_payment_processing_worker: 33 chars\n# - healthcare_telemedicine_consultation_api: 42 chars\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#the-solution-implied-functions","title":"The Solution: Implied Functions","text":"<p>Context + domain combination already communicates function:</p> <pre><code># 3-part formula (semantic):\nfinance_lending_api           # 19 chars (-9 chars, -32%)\nfinance_payment_worker        # 22 chars (-11 chars, -33%)\nhealthcare_telemedicine_api   # 27 chars (-15 chars, -36%)\n</code></pre> <p>Why this works: - <code>lending</code> in finance context \u2192 P2P matching is the only function - <code>payment</code> + <code>worker</code> type \u2192 processing is obvious - <code>telemedicine</code> in healthcare \u2192 consultation is the service</p>"},{"location":"guides/semantic-shortening-guide/#decision-tree","title":"Decision Tree","text":""},{"location":"guides/semantic-shortening-guide/#step-1-identify-context-domain","title":"Step 1: Identify Context &amp; Domain","text":"<pre><code>Example:\n- Context: finance\n- Domain: lending\n- Type: api\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#step-2-test-for-implicit-function","title":"Step 2: Test for Implicit Function","text":"<p>Question: Does \"{context}{domain}\" clearly communicate what the service does?</p> <pre><code>Test name: finance_lending_api\n\nAsk team: \"What does finance_lending_api do?\"\nExpected answer: \"P2P lending matching/approval platform\"\n\nIf 90%+ of team gives correct answer \u2192 Use 3-part \u2705\nIf answers vary widely \u2192 Use 4-part with explicit function \u274c\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#step-3-check-for-ambiguity","title":"Step 3: Check for Ambiguity","text":"<p>Question: Could this domain have multiple functions?</p> <pre><code># Example: logistics_fleet_api\n\nPossible interpretations:\n1. Fleet tracking (GPS monitoring)\n2. Fleet management (vehicles, drivers)\n3. Fleet maintenance (repairs, inspections)\n\nResult: AMBIGUOUS \u2192 Use 4-part\nCorrect name: logistics_fleet_tracking_api\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#decision-algorithm-code","title":"Decision Algorithm (Code)","text":"<pre><code>def choose_service_name_pattern(context: str, domain: str, type: str) -&gt; str:\n    \"\"\"\n    Determine whether to use 3-part or 4-part service name.\n\n    Returns:\n        \"3-part\" if domain implies function\n        \"4-part\" if explicit function needed\n    \"\"\"\n    # Step 1: Check if domain has single obvious function\n    implied_functions = get_implied_functions(context, domain)\n\n    if len(implied_functions) == 1:\n        return \"3-part\"  # Domain clearly implies ONE function\n\n    # Step 2: Check if type clarifies function\n    if type == \"worker\" and \"processing\" in implied_functions:\n        return \"3-part\"  # worker type implies processing\n\n    # Step 3: Check if combination is unambiguous\n    if is_combination_clear(context, domain, type):\n        return \"3-part\"\n\n    # Default: use explicit function\n    return \"4-part\"\n\n\n# Example usage:\nchoose_service_name_pattern(\"finance\", \"lending\", \"api\")\n# Returns: \"3-part\" \u2192 finance_lending_api\n\nchoose_service_name_pattern(\"logistics\", \"fleet\", \"api\")\n# Returns: \"4-part\" \u2192 logistics_fleet_{function}_api\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#examples-by-context","title":"Examples by Context","text":""},{"location":"guides/semantic-shortening-guide/#finance-context-95-use-3-part","title":"Finance Context (95% use 3-part)","text":"Domain Implied Function 3-Part Name Why 3-Part? <code>lending</code> matching, approval <code>finance_lending_api</code> Lending always means P2P matching <code>payment</code> processing <code>finance_payment_api</code> Payment systems process transactions <code>crypto</code> portfolio mgmt <code>finance_crypto_api</code> Crypto services manage portfolios <code>billing</code> invoicing, cycles <code>finance_billing_api</code> Billing generates invoices <code>trading</code> algo trading <code>finance_trading_api</code> Trading executes orders <p>Exception (4-part needed): <pre><code>finance_crypto_trading_api      # Crypto could be trading or portfolio management\nfinance_payment_validation_api  # Payment could be processing or validation\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#healthcare-context-80-use-3-part","title":"Healthcare Context (80% use 3-part)","text":"Domain Implied Function 3-Part Name Why 3-Part? <code>telemedicine</code> consultation <code>healthcare_telemedicine_api</code> Telemedicine means online consultation <code>appointment</code> booking <code>healthcare_appointment_api</code> Appointments are booked/scheduled <code>pharmacy</code> medication mgmt <code>healthcare_pharmacy_api</code> Pharmacy manages medications <code>mental_health</code> therapy <code>healthcare_mental_health_api</code> Mental health provides therapy <p>Exception (4-part needed): <pre><code>healthcare_appointment_reminder_worker  # Appointments could be booking or reminders\nhealthcare_pharmacy_inventory_api       # Pharmacy could be inventory or prescriptions\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#construction-context-90-use-3-part","title":"Construction Context (90% use 3-part)","text":"Domain Implied Function 3-Part Name Why 3-Part? <code>house</code> project mgmt <code>construction_house_bot</code> House projects need management <code>material</code> calc, inventory <code>construction_material_api</code> Materials are calculated/tracked <code>renovation</code> planning <code>construction_renovation_api</code> Renovations are planned/tracked <code>commercial</code> project mgmt <code>construction_commercial_api</code> Commercial projects managed"},{"location":"guides/semantic-shortening-guide/#logistics-context-50-use-4-part","title":"Logistics Context (50% use 4-part)","text":"<p>\u26a0\ufe0f Logistics requires explicit functions \u2014 domains are highly ambiguous.</p> Domain Multiple Functions 4-Part Name (Required) Why 4-Part? <code>fleet</code> tracking, management, maintenance <code>logistics_fleet_tracking_api</code> Fleet has 3+ functions <code>delivery</code> routing, tracking <code>logistics_delivery_tracking_api</code> Delivery could route or track <code>warehouse</code> inventory, fulfillment <code>logistics_warehouse_inventory_api</code> Warehouse has multiple ops <p>Rare 3-part cases: <pre><code>logistics_shipping_api   # Shipping is clearly booking/scheduling shipments\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#analytics-context-60-use-4-part","title":"Analytics Context (60% use 4-part)","text":"Domain Multiple Functions Name Pattern <code>reporting</code> generation <code>analytics_reporting_api</code> 3-part (specific) <code>data</code> aggregation, transformation <code>analytics_data_aggregation_worker</code> 4-part (ambiguous) <code>dashboard</code> visualization <code>analytics_dashboard_api</code> 3-part (specific) <code>metrics</code> collection, calculation <code>analytics_metrics_collection_worker</code> 4-part (ambiguous)"},{"location":"guides/semantic-shortening-guide/#when-to-use-4-part-exceptions","title":"When to Use 4-Part (Exceptions)","text":""},{"location":"guides/semantic-shortening-guide/#rule-1-domain-has-multiple-common-functions","title":"Rule 1: Domain Has Multiple Common Functions","text":"<pre><code># \u274c BAD (ambiguous):\nlogistics_fleet_api\n\n# \u2705 GOOD (explicit):\nlogistics_fleet_tracking_api      # vs management, maintenance\nlogistics_fleet_management_api    # vs tracking, maintenance\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#rule-2-context-is-generic","title":"Rule 2: Context is Generic","text":"<pre><code># \u274c BAD (too generic):\ncommunication_email_api\n\n# \u2705 GOOD (specific function):\ncommunication_email_notification_worker   # vs campaign, validation\ncommunication_email_campaign_api          # vs notification, validation\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#rule-3-type-doesnt-clarify-function","title":"Rule 3: Type Doesn't Clarify Function","text":"<pre><code># \u2705 OK (type clarifies):\nfinance_payment_worker    # worker \u2192 processing implied\n\n# \u274c BAD (type doesn't clarify):\nfinance_payment_api       # API could be processing, validation, history\n\n# \u2705 GOOD (explicit):\nfinance_payment_processing_api\nfinance_payment_validation_api\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#common-mistakes","title":"Common Mistakes","text":""},{"location":"guides/semantic-shortening-guide/#mistake-1-over-shortening-under-specification","title":"Mistake #1: Over-Shortening (Under-Specification)","text":"<p>\u274c WRONG: <pre><code>logistics_fleet_api         # Ambiguous - what does it do?\nanalytics_data_api          # Too generic\ncommunication_bot           # Which communication channel?\n</code></pre></p> <p>\u2705 CORRECT: <pre><code>logistics_fleet_tracking_api        # Explicit function\nanalytics_data_aggregation_worker   # Specific operation\ncommunication_telegram_bot          # Specific channel\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#mistake-2-over-specification-redundancy","title":"Mistake #2: Over-Specification (Redundancy)","text":"<p>\u274c WRONG: <pre><code>finance_lending_matching_api                # \"matching\" redundant\nfinance_payment_processing_worker           # \"processing\" redundant\nhealthcare_telemedicine_consultation_api    # \"consultation\" redundant\n</code></pre></p> <p>\u2705 CORRECT: <pre><code>finance_lending_api           # matching implied\nfinance_payment_worker        # processing implied\nhealthcare_telemedicine_api   # consultation implied\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#mistake-3-inconsistent-patterns-within-context","title":"Mistake #3: Inconsistent Patterns Within Context","text":"<p>\u274c WRONG: <pre><code># Mixing 3-part and 4-part without reason:\nfinance_lending_api                    # 3-part\nfinance_crypto_portfolio_api           # 4-part (unnecessary)\nfinance_billing_invoicing_generation_api  # 4-part (over-specified)\n</code></pre></p> <p>\u2705 CORRECT: <pre><code># Consistent 3-part (all have clear functions):\nfinance_lending_api     # matching implied\nfinance_crypto_api      # portfolio implied\nfinance_billing_api     # invoicing implied\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#mistake-4-using-abbreviations-instead-of-semantic-shortening","title":"Mistake #4: Using Abbreviations Instead of Semantic Shortening","text":"<p>\u274c WRONG: <pre><code>fin_lend_api           # Cryptic abbreviations\nhealth_telem_api       # Hard to read\nconstr_house_bot       # Onboarding nightmare\n</code></pre></p> <p>\u2705 CORRECT: <pre><code>finance_lending_api              # Full words, semantic shortening\nhealthcare_telemedicine_api      # Clear and professional\nconstruction_house_bot           # Self-documenting\n</code></pre></p>"},{"location":"guides/semantic-shortening-guide/#validation-checklist","title":"Validation Checklist","text":""},{"location":"guides/semantic-shortening-guide/#before-naming-a-new-service","title":"Before Naming a New Service","text":"<ul> <li> Step 1: Identified context, domain, and type clearly</li> <li> Step 2: Asked 3+ team members: \"What does <code>{context}_{domain}_{type}</code> do?\"</li> <li> Step 3: 90%+ of answers were consistent \u2192 use 3-part</li> <li> Step 4: If answers varied \u2192 add explicit function (4-part)</li> <li> Step 5: Checked name length &lt; 30 chars (95% compatibility)</li> <li> Step 6: Verified no ambiguity with existing services in same context</li> <li> Step 7: Tested in Kubernetes DNS format (<code>name.replace('_', '-')</code>)</li> </ul>"},{"location":"guides/semantic-shortening-guide/#quality-gates","title":"Quality Gates","text":"<p>Must pass ALL checks:</p> <ol> <li>Clarity Test: Can a new developer understand service purpose from name alone?</li> <li>Uniqueness Test: No other service in same context has similar name?</li> <li>Length Test: Name \u2264 30 chars (Kubernetes compatibility)?</li> <li>Consistency Test: Follows same pattern as other services in context?</li> <li>No Abbreviations Test: All words are full words (no <code>fin</code>, <code>telem</code>, <code>mgmt</code>)?</li> </ol>"},{"location":"guides/semantic-shortening-guide/#migration-from-4-part","title":"Migration from 4-Part","text":""},{"location":"guides/semantic-shortening-guide/#when-to-migrate","title":"When to Migrate","text":"<p>Migrate when: - \u2705 Service name &gt; 30 chars - \u2705 Function word is clearly redundant - \u2705 Team consensus that 3-part is clear - \u2705 Service is under active development (low risk)</p> <p>DON'T migrate when: - \u274c Service is in production with external integrations - \u274c Function word adds meaningful clarity - \u274c Team is uncertain about 3-part clarity - \u274c Migration requires &gt;1 hour of work</p>"},{"location":"guides/semantic-shortening-guide/#migration-steps","title":"Migration Steps","text":""},{"location":"guides/semantic-shortening-guide/#step-1-identify-candidates","title":"Step 1: Identify Candidates","text":"<pre><code># Find all services with &gt;30 char names:\nfind services/ -type d -name \"*_*_*_*\" | \\\n  awk -F'/' '{print length($NF), $NF}' | \\\n  awk '$1 &gt; 30' | \\\n  sort -rn\n\n# Example output:\n# 42 healthcare_telemedicine_consultation_api\n# 38 finance_payment_processing_worker\n# 36 construction_material_calculation_api\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#step-2-apply-decision-tree","title":"Step 2: Apply Decision Tree","text":"<pre><code># For each candidate:\ndef should_migrate(service_name: str) -&gt; bool:\n    context, domain, function, type_ = service_name.split('_')\n\n    # Test if function is redundant:\n    if is_function_implied(context, domain, type_):\n        return True\n\n    # Test if domain is ambiguous without function:\n    if is_domain_ambiguous(context, domain):\n        return False\n\n    return True\n\n# Examples:\nshould_migrate(\"healthcare_telemedicine_consultation_api\")  # True\nshould_migrate(\"logistics_fleet_tracking_api\")              # False (ambiguous)\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#step-3-refactor-service","title":"Step 3: Refactor Service","text":"<pre><code># Old structure:\nservices/\n  finance_payment_processing_worker/\n    src/\n      finance_payment_processing_worker/\n        __init__.py\n        main.py\n\n# New structure (refactored):\nservices/\n  finance_payment_worker/\n    src/\n      finance_payment_worker/\n        __init__.py\n        main.py\n</code></pre> <p>Refactoring checklist: - [ ] Rename service folder - [ ] Rename Python package - [ ] Update <code>pyproject.toml</code> / <code>setup.py</code> - [ ] Update Docker Compose service name - [ ] Update Kubernetes manifests - [ ] Update CI/CD pipelines - [ ] Update documentation references - [ ] Update inter-service communication configs</p>"},{"location":"guides/semantic-shortening-guide/#step-4-automated-refactoring-script","title":"Step 4: Automated Refactoring Script","text":"<pre><code>#!/bin/bash\n# migrate_service.sh\n\nOLD_NAME=\"$1\"  # e.g., finance_payment_processing_worker\nNEW_NAME=\"$2\"  # e.g., finance_payment_worker\n\n# Validate inputs\nif [ -z \"$OLD_NAME\" ] || [ -z \"$NEW_NAME\" ]; then\n    echo \"Usage: ./migrate_service.sh &lt;old_name&gt; &lt;new_name&gt;\"\n    exit 1\nfi\n\n# 1. Rename service directory\nmv \"services/$OLD_NAME\" \"services/$NEW_NAME\"\n\n# 2. Rename Python package\nmv \"services/$NEW_NAME/src/$OLD_NAME\" \"services/$NEW_NAME/src/$NEW_NAME\"\n\n# 3. Update imports across entire project\nfind services/ -type f -name \"*.py\" -exec sed -i \\\n    \"s/from $OLD_NAME/from $NEW_NAME/g\" {} +\nfind services/ -type f -name \"*.py\" -exec sed -i \\\n    \"s/import $OLD_NAME/import $NEW_NAME/g\" {} +\n\n# 4. Update Docker Compose\nsed -i \"s/$OLD_NAME/$NEW_NAME/g\" docker-compose.yml\n\n# 5. Update Kubernetes manifests\nfind kubernetes/ -type f -name \"*.yaml\" -exec sed -i \\\n    \"s/${OLD_NAME//_/-}/${NEW_NAME//_/-}/g\" {} +\n\n# 6. Update pyproject.toml\nsed -i \"s/name = \\\"$OLD_NAME\\\"/name = \\\"$NEW_NAME\\\"/g\" \\\n    \"services/$NEW_NAME/pyproject.toml\"\n\necho \"\u2705 Migration complete: $OLD_NAME \u2192 $NEW_NAME\"\necho \"\u26a0\ufe0f  Manual steps required:\"\necho \"  1. Review all changes with git diff\"\necho \"  2. Update CI/CD pipeline configs\"\necho \"  3. Update documentation\"\necho \"  4. Test locally with docker-compose up\"\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#step-5-rollback-plan","title":"Step 5: Rollback Plan","text":"<pre><code>#!/bin/bash\n# rollback_migration.sh\n\n# If migration fails, rollback using git:\ngit checkout services/$OLD_NAME\ngit checkout docker-compose.yml\ngit checkout kubernetes/\n\n# Restore original service\nmv \"services/$NEW_NAME\" \"services/$OLD_NAME\"\nmv \"services/$OLD_NAME/src/$NEW_NAME\" \"services/$OLD_NAME/src/$OLD_NAME\"\n\necho \"\u2705 Rollback complete\"\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#summary","title":"Summary","text":""},{"location":"guides/semantic-shortening-guide/#quick-reference-card","title":"Quick Reference Card","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          SEMANTIC SHORTENING QUICK REFERENCE                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502  DEFAULT: {context}_{domain}_{type}  (3-part)               \u2502\n\u2502                                                             \u2502\n\u2502  \u2705 Use 3-part when:                                        \u2502\n\u2502     \u2022 Domain clearly implies ONE function                   \u2502\n\u2502     \u2022 Team understands service from name alone              \u2502\n\u2502     \u2022 Type clarifies function (worker \u2192 processing)         \u2502\n\u2502                                                             \u2502\n\u2502  \u274c Use 4-part when:                                        \u2502\n\u2502     \u2022 Domain has MULTIPLE possible functions                \u2502\n\u2502     \u2022 Context is generic/ambiguous                          \u2502\n\u2502     \u2022 Explicit function adds critical clarity               \u2502\n\u2502                                                             \u2502\n\u2502  \ud83d\udccf Target: 20-27 chars (95% K8s compatible)                \u2502\n\u2502                                                             \u2502\n\u2502  \ud83d\udeab NEVER use cryptic abbreviations (fin, telem, mgmt)      \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/semantic-shortening-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Naming Conventions \u2014 Complete naming standards</li> <li>Service Catalog \u2014 Current service inventory</li> <li>Architecture Guide \u2014 Service design principles</li> <li>Migration Steps \u2014 See Section 5 above for step-by-step migration from 4-part</li> </ul> <p>Last Updated: 2025-01-02 Maintainer: System Architect Status: Active Version: 1.0</p>"},{"location":"guides/shared-components/","title":"Guide to Shared Components","text":""},{"location":"guides/shared-components/#introduction","title":"Introduction","text":"<p>In a microservice architecture, it is crucial to have a single source of truth for code and data contracts that are used by multiple services. This prevents code duplication, reduces errors, and simplifies system maintenance. In our project, the <code>src/shared/</code> directory serves this purpose.</p> <p>This document describes the types of shared components, the rules for their use, and how to integrate them into services.</p>"},{"location":"guides/shared-components/#structure-of-the-srcshared-directory","title":"Structure of the <code>src/shared/</code> Directory","text":"<p>According to the Project Structure, the shared directory contains the following components:</p> <ul> <li><code>dtos/</code>: A package for shared Data Transfer Objects (DTOs), grouped by domain area (e.g., <code>user_dtos.py</code>, <code>product_dtos.py</code>).</li> <li><code>events/</code>: A package for event schemas, also grouped by domain (e.g., <code>user_events.py</code>).</li> <li><code>utils/</code>: A package for common utility functions, grouped by category (e.g., <code>cache.py</code>, <code>formatters.py</code>).</li> </ul>"},{"location":"guides/shared-components/#types-of-shared-components","title":"Types of Shared Components","text":""},{"location":"guides/shared-components/#1-dtos-and-event-schemas-dtos-and-events","title":"1. DTOs and Event Schemas (<code>dtos/</code> and <code>events/</code>)","text":"<p>These are the most important shared components, as they define the data contracts between services.</p> <ul> <li>Technology: All DTOs and event schemas must be implemented using <code>pydantic.BaseModel</code>.</li> <li>Purpose:<ul> <li>Ensuring Consistency: All services \"speak\" the same language, using identical data structures.</li> <li>Validation: Pydantic automatically validates data upon creation or receipt, which increases system reliability.</li> <li>Self-documentation: The code for Pydantic models serves as excellent documentation for the data contracts.</li> </ul> </li> <li>Naming Rules:<ul> <li>The naming of these models MUST strictly follow the rules outlined in the Naming Conventions document.</li> <li>The key principle is naming by purpose:<ul> <li><code>...Base</code>: for base models.</li> <li><code>...Create</code>: for creating entities.</li> <li><code>...Update</code>: for partial updates.</li> <li><code>...Public</code>: for public API responses.</li> <li><code>...Payload</code>: for messages in a message broker.</li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/shared-components/#2-common-utilities-utils","title":"2. Common Utilities (<code>utils/</code>)","text":"<p>This package is intended for small, reusable helper functions that can be used in any service. Functions should be grouped by category into separate files.</p> <ul> <li> <p>Key Requirement: Functions in the <code>utils/</code> package must be pure and stateless. This means they must not depend on external state and must not access databases, the network, or the file system.</p> </li> <li> <p>Example structure of the <code>utils/</code> package:</p> <ul> <li><code>utils/cache.py</code>: Utilities for working with the cache.</li> <li><code>utils/formatters.py</code>: Functions for data formatting.</li> <li><code>utils/validators.py</code>: Common, reusable validators.</li> </ul> </li> <li> <p>What should NOT be in <code>utils/</code>:</p> <ul> <li>Business logic specific to a single service.</li> <li>Functions that import anything from a specific service (e.g., from <code>template_business_api</code>).</li> <li>Any code that performs I/O operations.</li> </ul> </li> </ul>"},{"location":"guides/shared-components/#usage-and-import-in-services","title":"Usage and Import in Services","text":"<p>Shared components should be imported into services using absolute paths from the <code>src/</code> root.</p> <p>Rule #1: Shared components are never redefined locally.</p> <p>If a service needs an extended or modified version of a shared component, it must create a new, internal class that inherits from or transforms the shared component, but it must not modify the shared component itself.</p>"},{"location":"guides/shared-components/#example-of-import-and-usage","title":"Example of Import and Usage","text":"<p>Suppose <code>template_business_worker</code> needs to process a user and use a shared utility for it.</p> <p><code>src/shared/dtos/user_dtos.py</code> <pre><code>from pydantic import BaseModel\nimport uuid\nfrom datetime import datetime\n\nclass UserPublic(BaseModel):\n    id: int\n    email: str\n</code></pre></p> <p><code>src/shared/utils/generators.py</code> <pre><code>import uuid\n\ndef generate_processing_id(user_id: int, task_name: str) -&gt; str:\n    return f\"{task_name}_{user_id}_{uuid.uuid4()}\"\n</code></pre></p> <p><code>src/template_business_worker/tasks.py</code> <pre><code># Import shared components from packages\nfrom shared.dtos.user_dtos import UserPublic\nfrom shared.utils.generators import generate_processing_id\n\ndef process_user_task(user: UserPublic):\n    # Use the shared components\n    processing_id = generate_processing_id(user.id, \"send_email\")\n\n    print(f\"Starting task {processing_id} for user {user.email}\")\n    # ... rest of the logic\n</code></pre> This approach ensures a clean, predictable, and easily maintainable codebase.</p>"},{"location":"guides/template-naming-guide/","title":"Template Service Naming Guide","text":"<p>Status: \u2705 Active Reference Last Updated: 2025-10-02 Related: Naming Conventions | Semantic Shortening Guide</p>"},{"location":"guides/template-naming-guide/#why-template-names-use-template_-context","title":"Why Template Names Use <code>template_</code> Context","text":"<p>Framework templates use the <code>template_</code> context prefix to clearly indicate these are placeholder names that should be replaced with your actual business context and domain when generating a real application.</p> <p>Design Philosophy: - <code>template_</code> makes it obvious these are not production service names - Follows the mandatory <code>{context}_{domain}_{type}</code> naming pattern (line 39, naming-conventions.md) - Provides clear migration path for AI agents and developers - Prevents confusion about whether templates are real business services</p>"},{"location":"guides/template-naming-guide/#template-service-names","title":"Template Service Names","text":"Template Name Purpose Components Replace With <code>template_business_api</code> FastAPI REST API for business logic context=template, domain=business, type=api <code>{yourcontext}_{yourdomain}_api</code> <code>template_business_bot</code> Aiogram Telegram bot for business logic context=template, domain=business, type=bot <code>{yourcontext}_{yourdomain}_bot</code> <code>template_business_worker</code> AsyncIO background worker context=template, domain=business, type=worker <code>{yourcontext}_{yourdomain}_worker</code> <code>template_data_postgres_api</code> PostgreSQL HTTP data access service context=template, domain=data_postgres, type=api <code>{yourcontext}_data_postgres_api</code> <code>template_data_mongo_api</code> MongoDB HTTP data access service context=template, domain=data_mongo, type=api <code>{yourcontext}_data_mongo_api</code> <p>Note: Data services typically keep the <code>data_</code> prefix in the domain since they're infrastructure services providing HTTP-only data access per the framework's architecture.</p>"},{"location":"guides/template-naming-guide/#understanding-the-naming-pattern","title":"Understanding the Naming Pattern","text":""},{"location":"guides/template-naming-guide/#the-3-part-formula","title":"The 3-Part Formula","text":"<pre><code>{context}_{domain}_{type}\n   \u2193        \u2193       \u2193\ntemplate_business_api\n</code></pre> <ul> <li>context: Business area (finance, healthcare, logistics, etc.)</li> <li>domain: Subdomain within context (lending, telemedicine, fleet, etc.)</li> <li>type: Technical service type (api, worker, bot, gateway, etc.)</li> </ul>"},{"location":"guides/template-naming-guide/#why-template-and-business","title":"Why \"template\" and \"business\"?","text":"<p><code>template</code> (context): - Clearly signals \"this is a placeholder\" - Not a real business domain - Easy to search-and-replace</p> <p><code>business</code> (domain): - Generic placeholder for \"your business logic\" - Distinguishes from infrastructure services (<code>data_postgres</code>, <code>data_mongo</code>) - Covers API, bot, and worker services that implement business rules</p>"},{"location":"guides/template-naming-guide/#renaming-process","title":"Renaming Process","text":""},{"location":"guides/template-naming-guide/#step-1-choose-your-context-and-domain","title":"Step 1: Choose Your Context and Domain","text":"<p>Identify your business context and specific domain:</p> <p>Examples: - P2P Lending: context=<code>finance</code>, domain=<code>lending</code> \u2192 <code>finance_lending_api</code> - Telemedicine: context=<code>healthcare</code>, domain=<code>telemedicine</code> \u2192 <code>healthcare_telemedicine_api</code> - Construction Management: context=<code>construction</code>, domain=<code>house</code> \u2192 <code>construction_house_bot</code> - Fleet Tracking: context=<code>logistics</code>, domain=<code>fleet_tracking</code> \u2192 <code>logistics_fleet_tracking_api</code></p> <p>Decision Guide: - DEFAULT (80-90%): Use 3-part naming when domain clearly implies function - EXCEPTION (10-20%): Use 4-part <code>{context}_{domain}_{function}_{type}</code> ONLY when domain is ambiguous - BURDEN OF PROOF: Always start with 3-part, justify 4-part with one of 10 reasons - See Service Naming Checklist for quick decision - See 10 Serious Reasons for 4-Part Naming for complete list of 10 reasons - See Semantic Shortening Guide for detailed decision tree</p>"},{"location":"guides/template-naming-guide/#step-2-global-search-and-replace","title":"Step 2: Global Search-and-Replace","text":"<p>Method A: Using find and sed (Bash)</p> <pre><code># Replace template_business_api with your actual service name\ncd your-project-root\n\nfind . -type f \\( -name \"*.yml\" -o -name \"*.yaml\" -o -name \"*.py\" -o -name \"*.conf\" -o -name \"*.md\" \\) \\\n  -not -path \"./.git/*\" \\\n  -exec sed -i 's/template_business_api/finance_lending_api/g' {} \\;\n\n# Repeat for other services:\n# template_business_bot \u2192 finance_lending_bot\n# template_business_worker \u2192 finance_lending_worker\n# template_data_postgres_api \u2192 finance_data_postgres_api\n# template_data_mongo_api \u2192 finance_data_mongo_api\n</code></pre> <p>Method B: Using IDE Global Replace</p> <ol> <li>Open your IDE's \"Find and Replace\" dialog (usually Ctrl+Shift+H)</li> <li>Enable \"Regular Expression\" mode</li> <li>Search for: <code>\\btemplate_business_api\\b</code></li> <li>Replace with: <code>finance_lending_api</code></li> <li>Review matches before replacing</li> <li>Repeat for each template service name</li> </ol>"},{"location":"guides/template-naming-guide/#step-3-rename-directories","title":"Step 3: Rename Directories","text":"<pre><code># Rename service directories\nmv services/template_business_api services/finance_lending_api\nmv services/template_business_bot services/finance_lending_bot\nmv services/template_business_worker services/finance_lending_worker\n\n# Data services usually stay in separate directories or may not exist yet\n# mv services/template_data_postgres_api services/finance_data_postgres_api (if it exists)\n</code></pre>"},{"location":"guides/template-naming-guide/#step-4-update-build-contexts","title":"Step 4: Update Build Contexts","text":"<p>After renaming directories, verify Docker Compose build contexts:</p> <pre><code># docker-compose.yml\nservices:\n  finance_lending_api:\n    build:\n      context: ./services/finance_lending_api  # \u2705 Updated path\n      dockerfile: Dockerfile\n</code></pre>"},{"location":"guides/template-naming-guide/#step-5-update-import-paths-python","title":"Step 5: Update Import Paths (Python)","text":"<p>If you have any cross-service imports (rare in microservices), update them:</p> <pre><code># Before\nfrom services.template_business_api.config import settings\n\n# After\nfrom services.finance_lending_api.config import settings\n</code></pre> <p>Note: Following the framework's HTTP-only data access architecture, you should NOT have direct imports between business services and data services.</p>"},{"location":"guides/template-naming-guide/#validation-checklist","title":"Validation Checklist","text":"<p>After renaming, verify all changes:</p>"},{"location":"guides/template-naming-guide/#service-names","title":"Service Names","text":"<ul> <li> All service names follow <code>{context}_{domain}_{type}</code> pattern</li> <li> No remaining <code>template_</code> prefixes (except in documentation examples)</li> <li> Docker Compose service names updated</li> <li> Kubernetes manifests updated (if using Kubernetes)</li> <li> Nginx upstream names updated</li> <li> Directory names match service names</li> </ul>"},{"location":"guides/template-naming-guide/#configuration-files","title":"Configuration Files","text":"<ul> <li> Environment variables reference correct service names</li> <li> Docker Compose service references updated (depends_on, etc.)</li> <li> Nginx proxy_pass directives updated</li> <li> Volume names updated (logs, data, etc.)</li> <li> CI/CD workflow service matrices updated</li> </ul>"},{"location":"guides/template-naming-guide/#code-imports","title":"Code &amp; Imports","text":"<ul> <li> No Python imports reference old service names</li> <li> Configuration defaults updated (service URLs)</li> <li> README and documentation updated</li> <li> Comments and docstrings reference correct names</li> </ul>"},{"location":"guides/template-naming-guide/#testing","title":"Testing","text":"<ul> <li> Run <code>docker-compose config</code> to validate YAML syntax</li> <li> Test service startup: <code>docker-compose up -d</code></li> <li> Verify service-to-service communication</li> <li> Check logs for connection errors</li> </ul>"},{"location":"guides/template-naming-guide/#common-renaming-examples","title":"Common Renaming Examples","text":""},{"location":"guides/template-naming-guide/#example-1-p2p-lending-platform","title":"Example 1: P2P Lending Platform","text":"<p>Original templates: <pre><code>template_business_api\ntemplate_business_worker\ntemplate_data_postgres_api\n</code></pre></p> <p>Renamed for finance domain: <pre><code>finance_lending_api         # P2P loan matching/approval API\nfinance_lending_worker      # Background loan processing worker\nfinance_data_postgres_api   # PostgreSQL data access service\n</code></pre></p> <p>Files to update: - <code>docker-compose.yml</code>: service definitions, depends_on, URLs - <code>nginx/conf.d/upstream.conf</code>: upstream blocks - <code>nginx/conf.d/api-gateway.conf</code>: proxy_pass directives - Directory rename: <code>services/template_business_api/</code> \u2192 <code>services/finance_lending_api/</code></p>"},{"location":"guides/template-naming-guide/#example-2-healthcare-telemedicine","title":"Example 2: Healthcare Telemedicine","text":"<p>Original templates: <pre><code>template_business_api\ntemplate_business_bot\ntemplate_data_postgres_api\n</code></pre></p> <p>Renamed for healthcare domain: <pre><code>healthcare_telemedicine_api      # Telemedicine consultation API\nhealthcare_appointment_bot       # Telegram bot for booking (different domain!)\nhealthcare_data_postgres_api     # PostgreSQL data access service\n</code></pre></p> <p>Note: The bot has a different domain (<code>appointment</code> vs <code>telemedicine</code>) because it serves appointment booking, not consultations. This is correct - services within the same context can have different domains.</p>"},{"location":"guides/template-naming-guide/#example-3-e-commerce-marketplace","title":"Example 3: E-commerce Marketplace","text":"<p>Original templates: <pre><code>template_business_api\ntemplate_business_worker\ntemplate_data_mongo_api\n</code></pre></p> <p>Renamed for ecommerce domain: <pre><code>ecommerce_marketplace_api      # Marketplace listings API\necommerce_order_worker         # Order processing worker (different domain!)\necommerce_data_mongo_api       # MongoDB data access service\n</code></pre></p> <p>Note: Worker has <code>order</code> domain instead of <code>marketplace</code> because it specifically processes orders, not general marketplace operations.</p>"},{"location":"guides/template-naming-guide/#example-4-logistics-fleet-tracking-4-part-naming","title":"Example 4: Logistics Fleet Tracking (4-Part Naming)","text":"<p>Original template: <pre><code>template_business_api\n</code></pre></p> <p>Renamed with 4-part pattern (domain <code>fleet</code> is ambiguous): <pre><code>logistics_fleet_tracking_api   # 4-part: function \"tracking\" clarifies intent\n</code></pre></p> <p>Why 4-part?: \"fleet\" alone could mean tracking, management, maintenance, or scheduling. Adding \"tracking\" clarifies the specific function.</p>"},{"location":"guides/template-naming-guide/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":""},{"location":"guides/template-naming-guide/#dont-keep-template_-prefix-in-production","title":"\u274c DON'T: Keep template_ prefix in production","text":"<pre><code># BAD - Still using template prefix\nservices:\n  template_business_api:  # \u274c Looks like you forgot to rename\n</code></pre>"},{"location":"guides/template-naming-guide/#dont-mix-old-and-new-names","title":"\u274c DON'T: Mix old and new names","text":"<pre><code># BAD - Inconsistent naming\nservices:\n  finance_lending_api:\n    environment:\n      - POSTGRES_SERVICE_URL=http://template_data_postgres_api:8000  # \u274c Still template\n</code></pre>"},{"location":"guides/template-naming-guide/#dont-use-generic-names","title":"\u274c DON'T: Use generic names","text":"<pre><code># BAD - Too generic, missing context\nservices:\n  api_service:           # \u274c What context? What domain?\n  business_api:          # \u274c Missing context\n  my_api:                # \u274c Not descriptive\n</code></pre>"},{"location":"guides/template-naming-guide/#dont-abbreviate-context-or-domain","title":"\u274c DON'T: Abbreviate context or domain","text":"<pre><code># BAD - Unnecessary abbreviations\nservices:\n  fin_lend_api:          # \u274c Use full words: finance_lending_api\n  hc_telemed_api:        # \u274c Use full words: healthcare_telemedicine_api\n</code></pre>"},{"location":"guides/template-naming-guide/#dont-add-version-numbers-to-service-names","title":"\u274c DON'T: Add version numbers to service names","text":"<pre><code># BAD - Version in service name\nservices:\n  finance_lending_api_v2:  # \u274c Versions belong in API paths, not service names\n</code></pre> <p>Correct approach: Keep service name stable, version in API path: - Service: <code>finance_lending_api</code> - API path: <code>/api/v2/loans</code></p>"},{"location":"guides/template-naming-guide/#migration-from-old-naming-patterns","title":"Migration from Old Naming Patterns","text":""},{"location":"guides/template-naming-guide/#if-you-have-existing-services-with-non-compliant-names","title":"If you have existing services with non-compliant names:","text":"<p>Before (generic 2-part names): <pre><code>lending_api          # Missing context\npayment_service      # Missing context, wrong suffix\nuser_management      # Missing type\n</code></pre></p> <p>After (compliant 3-part names): <pre><code>finance_lending_api         # Added context\nfinance_payment_api         # Added context, fixed suffix\nuser_auth_api              # Added type (context=user, domain=auth)\n</code></pre></p> <p>Migration strategy: 1. Create Context Registry first 2. Map old names to new <code>{context}_{domain}_{type}</code> pattern 3. Plan service-by-service migration (avoid renaming all at once) 4. Update one service, test, then proceed to next 5. Maintain backward compatibility during transition (DNS aliases, etc.)</p>"},{"location":"guides/template-naming-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/template-naming-guide/#problem-service-wont-start-after-renaming","title":"Problem: Service won't start after renaming","text":"<p>Symptoms: <pre><code>Error: Cannot connect to host template_business_api\nConnection refused: template_data_postgres_api:8000\n</code></pre></p> <p>Solutions: 1. Check Docker Compose service definitions match new names 2. Verify environment variables reference new service names 3. Check Nginx upstream server addresses 4. Ensure all depends_on references are updated 5. Clear old containers: <code>docker-compose down &amp;&amp; docker-compose up -d</code></p>"},{"location":"guides/template-naming-guide/#problem-import-errors-in-python-code","title":"Problem: Import errors in Python code","text":"<p>Symptoms: <pre><code>ModuleNotFoundError: No module named 'services.template_business_api'\n</code></pre></p> <p>Solutions: 1. Update all Python import statements 2. Check if using absolute vs relative imports 3. Verify PYTHONPATH includes renamed directories 4. Rebuild Docker images: <code>docker-compose build --no-cache</code></p>"},{"location":"guides/template-naming-guide/#problem-nginx-502-bad-gateway","title":"Problem: Nginx 502 Bad Gateway","text":"<p>Symptoms: Nginx returns 502 when accessing API</p> <p>Solutions: 1. Check Nginx upstream blocks use new service names 2. Verify proxy_pass directives reference correct upstream names 3. Ensure backend services are running: <code>docker-compose ps</code> 4. Check Nginx logs: <code>docker-compose logs nginx</code> 5. Restart Nginx: <code>docker-compose restart nginx</code></p>"},{"location":"guides/template-naming-guide/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"guides/template-naming-guide/#verify-no-template_-references-remain","title":"Verify no template_ references remain","text":"<pre><code># Search for remaining template_ prefixes\ngrep -r \"template_\" --include=\"*.yml\" --include=\"*.py\" --include=\"*.conf\" \\\n  --exclude-dir=\".git\" --exclude=\"template-naming-guide.md\"\n</code></pre>"},{"location":"guides/template-naming-guide/#validate-docker-compose-syntax","title":"Validate Docker Compose syntax","text":"<pre><code>docker-compose -f docker-compose.yml config\n</code></pre>"},{"location":"guides/template-naming-guide/#test-renamed-services","title":"Test renamed services","text":"<pre><code># Start services\ndocker-compose up -d\n\n# Check health\ndocker-compose ps\n\n# View logs\ndocker-compose logs -f finance_lending_api\n\n# Test API endpoint\ncurl http://localhost/api/v1/health\n</code></pre>"},{"location":"guides/template-naming-guide/#rollback-if-needed","title":"Rollback if needed","text":"<pre><code># If using git\ngit diff                    # Review changes\ngit checkout .              # Discard all changes\ngit clean -fd               # Remove new files\n\n# Or restore from backup branch\ngit checkout backup/before-rename-20251002\n</code></pre>"},{"location":"guides/template-naming-guide/#see-also","title":"See Also","text":"<ul> <li>Naming Conventions - Complete naming rules reference</li> <li>Semantic Shortening Guide - Decision tree for 3-part vs 4-part naming</li> <li>Context Registry - Prevent context name conflicts</li> <li>Project Structure - Canonical repository layout</li> <li>Architecture Guide - HTTP-only data access patterns</li> </ul>"},{"location":"guides/template-naming-guide/#examples-in-the-wild","title":"Examples in the Wild","text":"<p>Real-world service naming examples (following the framework):</p> <pre><code># Finance domain\nfinance_lending_api          # P2P loan matching\nfinance_crypto_api           # Cryptocurrency portfolio\nfinance_payment_worker       # Payment processing\nfinance_data_postgres_api    # PostgreSQL data access\n\n# Healthcare domain\nhealthcare_telemedicine_api      # Online consultations\nhealthcare_appointment_api       # Doctor booking\nhealthcare_pharmacy_bot          # Telegram medication bot\nhealthcare_data_postgres_api     # PostgreSQL data access\n\n# Logistics domain\nlogistics_fleet_tracking_api         # 4-part (domain ambiguous)\nlogistics_delivery_routing_worker    # 4-part (domain ambiguous)\nlogistics_data_mongo_api             # MongoDB data access\n\n# E-commerce domain\necommerce_marketplace_api    # Product listings\necommerce_checkout_api       # Payment checkout\necommerce_order_worker       # Order fulfillment\necommerce_data_postgres_api  # PostgreSQL data access\n</code></pre> <p>Document Version: 1.0 Last Updated: 2025-10-02 Maintained By: Framework Core Team</p>"},{"location":"guides/use-case-implementation-guide/","title":"AI-Powered Project Generation Guide","text":"<p>This guide provides comprehensive instructions for creating complete, production-ready microservices applications using the AI agents framework. All implementations follow the standardized project structure and architectural patterns documented in Main Entry Point.</p> <p>NEW APPROACH: This guide covers the AI-first project generation workflow where users create new repositories and AI generates complete applications with proper structure.</p>"},{"location":"guides/use-case-implementation-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>AI-First Development Workflow</li> <li>Generated Project Structure</li> <li>AI Generation Process</li> <li>Implementation Guidelines</li> <li>Quality Standards</li> <li>Deployment and Production</li> <li>Common Patterns</li> <li>Validation Checklist</li> </ul>"},{"location":"guides/use-case-implementation-guide/#mandatory-architecture-constraints","title":"MANDATORY ARCHITECTURE CONSTRAINTS","text":"<p>Before generating any application, AI agents MUST comply with these non-negotiable constraints:</p> <p>MANDATORY COMPLIANCE: All constraints are defined in the canonical architecture documentation. This section provides implementation-specific guidance.</p>"},{"location":"guides/use-case-implementation-guide/#1-architecture-compliance-mandatory","title":"1. Architecture Compliance (MANDATORY)","text":"<ul> <li>Foundation: Follow the Improved Hybrid Approach architecture</li> <li>Data Access: HTTP-only communication with data services</li> <li>Service Separation: Each service type in separate containers</li> <li>Project Structure: All source code in <code>src/</code> folder, Dockerfiles in service folders</li> </ul>"},{"location":"guides/use-case-implementation-guide/#2-development-standards","title":"2. Development Standards","text":"<ul> <li>Commands: Use canonical development commands</li> <li>Technology: Follow complete technology specifications</li> <li>Architecture: Follow comprehensive architecture guide</li> <li>Naming: Follow Naming Conventions</li> <li>Patterns: See Documentation Index for service-specific implementation patterns</li> </ul> <p>Violation of these constraints will result in non-functional applications. This guide provides compliant generation patterns.</p>"},{"location":"guides/use-case-implementation-guide/#ai-first-development-workflow","title":"AI-First Development Workflow","text":""},{"location":"guides/use-case-implementation-guide/#step-1-user-creates-new-repository","title":"Step 1: User Creates New Repository","text":"<pre><code># User creates new repository for their project\nmkdir my_awesome_project\ncd my_awesome_project\ngit init\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#step-2-ai-reads-documentation-project","title":"Step 2: AI Reads Documentation Project","text":"<p>AI agents access this documentation project to understand: - Architectural patterns and constraints - Service templates and implementation rules - Quality standards and testing patterns - Deployment and configuration patterns</p>"},{"location":"guides/use-case-implementation-guide/#step-3-ai-generates-complete-application","title":"Step 3: AI Generates Complete Application","text":"<p>Using the documented automation workflow, AI generates: - Complete project structure with <code>src/</code> folder organization - All microservices with proper separation - Docker Compose configuration in root - Environment configuration and documentation - Testing infrastructure and examples</p>"},{"location":"guides/use-case-implementation-guide/#step-4-deploy-and-iterate","title":"Step 4: Deploy and Iterate","text":"<pre><code># Generated by AI, executed by user\ncp .env.example .env\n# Edit .env with your configuration\ndocker-compose up -d\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#generated-project-structure","title":"Generated Project Structure","text":"<p>AI agents generate projects following this standardized structure:</p> <p>AUTHORITATIVE PROJECT STRUCTURE: See ../reference/project-structure.md for the complete, detailed project structure guide with explanations and setup instructions.</p>"},{"location":"guides/use-case-implementation-guide/#key-structure-principles","title":"Key Structure Principles","text":"<ol> <li>Root-Level Configuration: Docker Compose, environment, and project configs in root</li> <li>Source Code Organization: All code in <code>src/</code> with clear separation</li> <li>Service-Specific Dockerfiles: Each service has its own Dockerfile in its folder</li> <li>Shared Components: Common code in <code>shared/</code> at root level</li> <li>Comprehensive Testing: Unit and integration tests with proper fixtures</li> </ol>"},{"location":"guides/use-case-implementation-guide/#ai-generation-process","title":"AI Generation Process","text":""},{"location":"guides/use-case-implementation-guide/#phase-1-business-validation","title":"Phase 1: Business Validation","text":"<p>AI applies the business validation workflow described in this guide to: 1. Feasibility Check: Validate if business idea fits the architecture 2. Domain Classification: Identify business patterns and optimal allocation 3. Constraint Validation: Ensure architectural compliance</p>"},{"location":"guides/use-case-implementation-guide/#phase-2-service-mapping","title":"Phase 2: Service Mapping","text":"<p>AI performs structured service mapping to: 1. Service Allocation: Map business functions to specific services 2. Data Flow Design: Define PostgreSQL vs MongoDB usage 3. Integration Patterns: Specify service communication</p>"},{"location":"guides/use-case-implementation-guide/#phase-3-code-generation","title":"Phase 3: Code Generation","text":"<p>AI leverages the standardized code generation patterns to: 1. Template Selection: Choose appropriate service templates 2. Variable Substitution: Fill templates with business-specific data 3. Code Assembly: Generate complete implementations</p>"},{"location":"guides/use-case-implementation-guide/#phase-4-quality-validation","title":"Phase 4: Quality Validation","text":"<p>AI executes the quality validation checklist to: 1. Architecture Compliance: Verify HTTP-only data access, service separation 2. Code Quality: Check type hints, error handling, naming conventions 3. Integration Testing: Ensure service communication works</p>"},{"location":"guides/use-case-implementation-guide/#phase-5-deployment-generation","title":"Phase 5: Deployment Generation","text":"<p>AI prepares deployment assets to: 1. Docker Compose: Generate complete infrastructure configuration 2. Environment Setup: Create secure configuration templates 3. Deployment Scripts: Generate automation and health checks</p>"},{"location":"guides/use-case-implementation-guide/#implementation-guidelines","title":"Implementation Guidelines","text":""},{"location":"guides/use-case-implementation-guide/#service-implementation-standards","title":"Service Implementation Standards","text":""},{"location":"guides/use-case-implementation-guide/#1-fastapi-services-servicestemplate_business_api","title":"1. FastAPI Services (<code>services/template_business_api/</code>)","text":"<pre><code># Generated main.py structure\n\"\"\"\nAPI Service - FastAPI Business Logic Implementation\nGenerated for: {{business_domain}}\n\"\"\"\n\nimport asyncio\nimport logging\nfrom contextlib import asynccontextmanager\n\nimport httpx\nfrom fastapi import FastAPI, HTTPException\nimport structlog\n\n# Service-specific imports from shared/\nfrom shared.dtos import {{model_imports}}\nfrom ...config.settings import Settings\n\n# HTTP-only data access via data services\nclass DataServiceClient:\n    def __init__(self):\n        self.postgres_url = \"http://template_data_postgres_api:8000\"\n        self.mongo_url = \"http://template_data_mongo_api:8000\"\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#2-aiogram-bot-services-servicestemplate_business_bot","title":"2. Aiogram Bot Services (<code>services/template_business_bot/</code>)","text":"<pre><code># Generated main.py structure\n\"\"\"\nBot Service - Aiogram Telegram Bot Implementation\nGenerated for: {{business_domain}}\n\"\"\"\n\nimport asyncio\nimport logging\n\nfrom aiogram import Bot, Dispatcher\nfrom aiogram.types import Message\nimport structlog\n\n# HTTP-only communication with API service\nclass BotService:\n    def __init__(self):\n        self.api_url = \"http://template_business_api:8000\"\n        # No direct database access\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#3-worker-services-servicestemplate_business_worker","title":"3. Worker Services (<code>services/template_business_worker/</code>)","text":"<pre><code># Generated main.py structure\n\"\"\"\nWorker Service - AsyncIO Background Workers\nGenerated for: {{business_domain}}\n\"\"\"\n\nimport asyncio\nimport logging\n\nimport aio_pika\nimport structlog\n\n# Event-driven processing with HTTP data access\nclass WorkerService:\n    def __init__(self):\n        self.postgres_url = \"http://template_data_postgres_api:8000\"\n        self.mongo_url = \"http://template_data_mongo_api:8000\"\n        # Event handling via RabbitMQ\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#docker-configuration-standards","title":"Docker Configuration Standards","text":""},{"location":"guides/use-case-implementation-guide/#1-service-dockerfiles-servicesdockerfile","title":"1. Service Dockerfiles (<code>services/*/Dockerfile</code>)","text":"<pre><code>FROM python:3.12-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy service-specific requirements\nCOPY services/{{service_name}}/requirements.txt ./\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy shared modules\nCOPY shared/ ./shared/\n\n# Copy service code\nCOPY services/{{service_name}}/ ./\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\nCMD [\"python\", \"main.py\"]\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#2-root-docker-compose-docker-composeyml","title":"2. Root Docker Compose (<code>docker-compose.yml</code>)","text":"<pre><code># Generated by AI in project root\nversion: '3.8'\n\nservices:\n  # Infrastructure Services\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_DB: {{project_name}}_db\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres123\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    networks:\n      - app_network\n\n  # Data Services\n  template_data_postgres_api:\n    build:\n      context: \".\"\n      dockerfile: \"./services/template_data_postgres_api/Dockerfile\"\n    environment:\n      DATABASE_URL: postgresql://postgres:postgres123@postgres:5432/{{project_name}}_db\n    ports:\n      - \"8001:8000\"\n    depends_on:\n      - postgres\n    networks:\n      - app_network\n\n  # Business Services\n  template_business_api:\n    build:\n      context: \".\"\n      dockerfile: \"./services/template_business_api/Dockerfile\"\n    environment:\n      POSTGRES_SERVICE_URL: http://template_data_postgres_api:8000\n      MONGO_SERVICE_URL: http://template_data_mongo_api:8000\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      - template_data_postgres_api\n      - template_data_mongo_api\n    networks:\n      - app_network\n\nnetworks:\n  app_network:\n    driver: bridge\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#quality-standards","title":"Quality Standards","text":""},{"location":"guides/use-case-implementation-guide/#code-quality-requirements","title":"Code Quality Requirements","text":"<ol> <li>Type Annotations: 100% type coverage for all functions</li> <li>Error Handling: Comprehensive error handling with structured logging</li> <li>HTTP-Only Data Access: No direct database imports in business services</li> <li>Service Separation: Each service type in separate containers</li> <li>Security: OAuth2/JWT, input validation, no hardcoded secrets</li> </ol>"},{"location":"guides/use-case-implementation-guide/#testing-requirements","title":"Testing Requirements","text":"<ol> <li>Unit Tests: 100% coverage for critical business logic paths</li> <li>Integration Tests: Real service communication via testcontainers</li> <li>End-to-End Tests: Complete workflows across services</li> <li>Performance Tests: Load testing for expected traffic</li> </ol>"},{"location":"guides/use-case-implementation-guide/#documentation-requirements","title":"Documentation Requirements","text":"<ol> <li>Project README: Clear setup and usage instructions</li> <li>API Documentation: OpenAPI/Swagger for all endpoints</li> <li>Architecture Overview: Service communication and data flow</li> <li>Deployment Guide: Production deployment instructions</li> </ol>"},{"location":"guides/use-case-implementation-guide/#deployment-and-production","title":"Deployment and Production","text":""},{"location":"guides/use-case-implementation-guide/#pre-deployment-checklist","title":"Pre-Deployment Checklist","text":"<ul> <li> All tests pass with required coverage</li> <li> Docker images build successfully</li> <li> Environment variables documented and validated</li> <li> Health checks implemented and working</li> <li> Security scan passes (bandit, safety)</li> <li> Load testing completed</li> <li> Documentation complete and accurate</li> </ul>"},{"location":"guides/use-case-implementation-guide/#production-environment","title":"Production Environment","text":"<ul> <li> SSL/TLS certificates configured</li> <li> Secrets management implemented</li> <li> Database backups automated</li> <li> Log aggregation configured</li> <li> Monitoring dashboards created</li> <li> Alerting rules defined</li> <li> Disaster recovery plan documented</li> </ul>"},{"location":"guides/use-case-implementation-guide/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/use-case-implementation-guide/#example-business-domain-mappings","title":"Example Business Domain Mappings","text":""},{"location":"guides/use-case-implementation-guide/#e-commerce-application","title":"E-commerce Application","text":"<pre><code>postgresql_entities: [\"users\", \"products\", \"orders\", \"payments\"]\nmongodb_collections: [\"product_reviews\", \"user_behavior\", \"analytics\"]\napi_endpoints: [\"GET /products\", \"POST /orders\", \"GET /users/{id}\"]\nbot_commands: [\"/products\", \"/order_status\", \"/support\"]\nworker_tasks: [\"process_payments\", \"send_notifications\", \"generate_reports\"]\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#project-management-tool","title":"Project Management Tool","text":"<pre><code>postgresql_entities: [\"users\", \"projects\", \"tasks\", \"time_entries\"]\nmongodb_collections: [\"activity_logs\", \"file_attachments\", \"analytics\"]\napi_endpoints: [\"GET /projects\", \"POST /tasks\", \"PUT /tasks/{id}\"]\nbot_commands: [\"/create_task\", \"/my_tasks\", \"/deadlines\"]\nworker_tasks: [\"send_reminders\", \"generate_reports\", \"backup_data\"]\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#data-service-communication-patterns","title":"Data Service Communication Patterns","text":"<pre><code># HTTP-only communication example\nclass BusinessService:\n    async def get_user_data(self, user_id: str) -&gt; UserData:\n        \"\"\"Get user data via PostgreSQL service\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                f\"{self.postgres_url}/api/v1/users/{user_id}\"\n            )\n            response.raise_for_status()\n            return UserData(**response.json())\n\n    async def track_analytics(self, event_data: EventData) -&gt; None:\n        \"\"\"Track analytics via MongoDB service\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self.mongo_url}/api/v1/events\",\n                json=event_data.dict()\n            )\n            response.raise_for_status()\n</code></pre>"},{"location":"guides/use-case-implementation-guide/#validation-checklist","title":"Validation Checklist","text":""},{"location":"guides/use-case-implementation-guide/#project-structure-validation","title":"Project Structure Validation","text":"<ul> <li> All required directories exist in <code>src/</code> structure</li> <li> Dockerfiles present in each service folder</li> <li> Docker Compose in project root</li> <li> Environment configuration files present</li> <li> Shared components properly organized</li> </ul>"},{"location":"guides/use-case-implementation-guide/#service-implementation-validation","title":"Service Implementation Validation","text":"<ul> <li> Health check endpoints implemented</li> <li> HTTP-only data access pattern followed</li> <li> No direct database connections in business services</li> <li> Proper async/await usage</li> <li> Structured logging configured</li> </ul>"},{"location":"guides/use-case-implementation-guide/#architecture-compliance-validation","title":"Architecture Compliance Validation","text":"<ul> <li> Service type separation enforced</li> <li> Data services accessible via HTTP on ports 8001, 8002</li> <li> RabbitMQ event communication working</li> <li> Redis caching functional</li> <li> Naming conventions followed (underscore_only)</li> </ul>"},{"location":"guides/use-case-implementation-guide/#quality-validation","title":"Quality Validation","text":"<ul> <li> Type annotations on all functions</li> <li> Error handling comprehensive</li> <li> Security measures implemented</li> <li> Performance requirements met</li> <li> Code quality tools configured and passing</li> </ul>"},{"location":"guides/use-case-implementation-guide/#conclusion","title":"Conclusion","text":"<p>The AI-first project generation workflow enables rapid creation of production-ready microservices applications. Key success factors:</p> <ol> <li>Automation Workflow Utilization: Follow the complete validation, mapping, generation, and deployment workflow outlined in this guide</li> <li>Structure Compliance: Follow the standardized <code>src/</code> folder organization with root-level configuration</li> <li>Architecture Adherence: HTTP-only data access, service separation, event-driven communication</li> <li>Quality Focus: Comprehensive testing, security, monitoring, and documentation</li> </ol> <p>Estimated Generation Time: 5-15 minutes for complete application generation vs 2-4 days for manual implementation.</p> <p>Next Steps: 1. Create new repository for your project 2. Use AI agents with this documentation project as context 3. Generate complete application following this guide 4. Deploy using generated Docker Compose configuration 5. Customize and extend for your specific business needs</p> <p>Ready to generate your first AI-powered microservices application? Create a new repository and start collaborating with AI using this knowledge base!</p>"},{"location":"quality/agent-verification-checklist/","title":"Agent Verification Checklist","text":"<p>Purpose: Enforce mandatory quality gates before delivering artefacts. Complete this checklist at the end of the execution phase.</p>"},{"location":"quality/agent-verification-checklist/#usage-instructions","title":"Usage Instructions","text":"<ul> <li>Run these checks in the order listed.</li> <li>Capture command outputs or links to reports in the Evidence column.</li> <li>If a check fails, resolve the issue or document the blocker before proceeding.</li> <li>Refer back to <code>docs/guides/development-commands.md</code> for detailed command descriptions.</li> </ul>"},{"location":"quality/agent-verification-checklist/#pre-flight-environment-checks","title":"Pre-Flight Environment Checks","text":"Check Command / Action Expected Result Evidence Status Python version <code>python --version</code> &gt;= 3.12 UV installed <code>uv --version</code> Command succeeds Environment configured <code>cp .env.example .env</code> (if not yet copied) <code>.env</code> present"},{"location":"quality/agent-verification-checklist/#static-analysis-security","title":"Static Analysis &amp; Security","text":"Check Command Expected Result Evidence Status Linting <code>uv run ruff check .</code> No errors reported Formatting <code>uv run ruff format . --check</code> No format drift Type checking <code>uv run mypy .</code> No type errors Security scan <code>uv run bandit -r .</code> No high severity findings"},{"location":"quality/agent-verification-checklist/#testing-coverage","title":"Testing &amp; Coverage","text":"Check Command Expected Result Evidence Status Full test suite <code>uv run pytest</code> or plan-specific command Tests pass Coverage threshold <code>uv run pytest --cov=src --cov-report=html --cov-report=xml</code> Coverage meets level-specific threshold:\u2022 Level 1: \u2265 60%\u2022 Level 2: \u2265 75%\u2022 Level 3: \u2265 80%\u2022 Level 4: \u2265 85%Reference: See <code>docs/reference/maturity-levels.md</code> (SSOT) Coverage artefacts Inspect <code>htmlcov/</code>, <code>coverage.xml</code> Reports generated <p>Note: Coverage thresholds are defined in <code>docs/reference/maturity-levels.md</code> (Single Source of Truth). If thresholds change, update only maturity-levels.md; this document references it.</p>"},{"location":"quality/agent-verification-checklist/#requirements-coverage-verification","title":"Requirements Coverage Verification","text":"<p>PURPOSE: Verify ALL requirements from Requirements Intake are implemented without exceptions. This is the PRIMARY quality gate ensuring user prompt completeness.</p> <p>CRITICAL: This check is MANDATORY for ALL maturity levels (1-4). Without 100% requirements coverage (or explicit descope approval), workflow CANNOT proceed to Stage 6 (QA Report &amp; Handoff).</p> Check Action Expected Result Evidence Status Requirements traceability Step 1: Open Requirements Intake document (from Stage 2)Step 2: Extract all Req IDs (FR-, UI-, NF-) \u2014 count total**Step 3*: Open Implementation Plan RTM (from Stage 3)Step 4: For EACH Req ID, verify:\u2022 Status = \"\u2705 Done\"\u2022 Evidence (code file path) exists\u2022 Code actually implements the requirementStep 5: Calculate coverage = implemented / total \u00d7 100% 100% coverage: ALL requirements (FR-, UI-, NF-) marked \"\u2705 Done\" with valid Evidence in Implementation Plan RTM**OR*Descoped requirements have stakeholder approval documented (see Failure Handling below) Requirements Coverage Matrix in QA ReportEvidence examples:\u2022 <code>services/api/src/api/v1/users.py:20</code>\u2022 <code>services/bot/src/handlers/register.py:15</code>\u2022 Test results confirming functionality UX/UI element coverage For UI-heavy projects only (Telegram bots, web UIs):Step 1: Extract all UI-* Req IDs from Requirements IntakeStep 2: For EACH UI element:\u2022 Verify handler/view code exists\u2022 Verify FSM states complete (for bots)\u2022 Verify error messages implemented\u2022 Verify e2e tests exist ALL UI elements from prompt implemented:\u2022 All screens/modals present\u2022 All buttons/forms functional\u2022 All error messages displayed\u2022 No placeholder text (\"Coming soon\", \"TODO\") Screenshots (optional)E2e test resultsManual verification checklist Feature completeness Step 1: grep for incomplete markers:<code>grep -r \"TODO\\|FIXME\\|XXX\\|PLACEHOLDER\" services/</code>Step 2: Verify each feature 100% complete:\u2022 All handlers have FSM states (bots)\u2022 All endpoints have business logic (APIs)\u2022 No partial implementationsStep 3: Verify tests exist for each feature Zero incomplete markersEvery feature 100% functional:\u2022 All handlers have complete FSM flows\u2022 All endpoints have full business logic\u2022 All database operations have error handling\u2022 All external API calls have retry logic Code review resultsgrep output showing 0 matchesTest coverage report"},{"location":"quality/agent-verification-checklist/#requirements-coverage-thresholds","title":"Requirements Coverage Thresholds","text":"Coverage % Status Action Required 100% \u2705 PASS Proceed to Release Gate checks 95-99% \u26a0\ufe0f WARNING Review missing requirements:\u2022 Can they be implemented quickly?\u2022 Should they be descoped with approval?\u2022 Document decision in QA Report &lt; 95% \u274c FAIL BLOCK Stage 6 (QA Report)MUST:\u2022 Implement missing requirements, OR\u2022 Get explicit stakeholder descope approval\u2022 Document in QA Report \u00a7 Defects &amp; Risks"},{"location":"quality/agent-verification-checklist/#descope-process-if-coverage-100","title":"Descope Process (if coverage &lt; 100%)","text":"<p>If stakeholder approves descoping requirements:</p> <ol> <li> <p>Update Implementation Plan RTM:    <pre><code>| Req ID | Status |\n|--------|--------|\n| FR-015 | \u26a0\ufe0f **Descoped** (Approved by [Name] on [Date]) |\n</code></pre></p> </li> <li> <p>Document in QA Report \u00a7 Defects &amp; Risks:    <pre><code>## Descoped Requirements\n| Req ID | Feature | Reason | Approved By | Date |\n|--------|---------|--------|-------------|------|\n| FR-015 | Advanced search filters | Low priority for MVP, defer to v2 | John Doe (Product Owner) | 2025-10-30 |\n</code></pre></p> </li> <li> <p>Recalculate coverage (excluding descoped):    <pre><code>Adjusted Coverage = Implemented / (Total - Descoped) \u00d7 100%\n</code></pre></p> </li> <li> <p>Adjusted coverage MUST be 100% to proceed</p> </li> </ol>"},{"location":"quality/agent-verification-checklist/#failure-handling-for-requirements-coverage","title":"Failure Handling for Requirements Coverage","text":"<p>If coverage verification fails:</p> <p>Attempt 1 (immediate): - Identify which Req IDs are missing (Status \u2260 \"\u2705 Done\") - Check if they were accidentally marked wrong status - Fix status if code exists but not marked</p> <p>Attempt 2 (if still failing): - Review missing requirements with stakeholder - Decide: implement now OR descope with approval - If descope: follow Descope Process above - If implement: return to Stage 4, implement, then re-verify</p> <p>Attempt 3 (escalation): - If still &lt; 100% and no descope approval:   - HALT workflow   - Generate escalation report (see agent-verification-checklist.md \u00a7 Escalation Output Template)   - Await user decision: implement OR approve descope OR cancel workflow</p> <p>Hard Limit: Maximum 3 attempts. After 3<sup>rd</sup> failure \u2192 FORCE ESCALATION to user.</p>"},{"location":"quality/agent-verification-checklist/#artefact-validation","title":"Artefact Validation","text":"Check Action Expected Result Evidence Status Project structure compliance Review against <code>docs/reference/project-structure.md</code> (\u00a7Creating the Project Structure)Verify ALL directories created before file generation \u2022 All <code>services/*/src/*</code> directories exist\u2022 DDD layers present (<code>domain/</code>, <code>application/</code>, <code>infrastructure/</code>)\u2022 <code>shared/</code> directory exists with subdirectories\u2022 <code>tests/</code> subdirectories present (<code>unit/</code>, <code>integration/</code>)\u2022 Conditional directories created per maturity level Shared components usage Confirm adherence to <code>docs/guides/shared_components.md</code> No duplication or rule violations Naming conventions Spot-check against <code>docs/atomic/architecture/naming/README.md</code> No prohibited names Documentation updates Ensure relevant docs updated (plans, ADRs, etc.) Artefacts listed in <code>docs/reference/deliverables-catalog.md</code>"},{"location":"quality/agent-verification-checklist/#release-gate","title":"Release Gate","text":"Check Action Expected Result Evidence Status QA report Draft using <code>docs/quality/qa-report-template.md</code> Report ready for sign-off Deliverables summary Update per <code>docs/reference/deliverables-catalog.md</code> Complete deliverable list Outstanding issues Record unresolved risks or follow-ups Stakeholder notified"},{"location":"quality/agent-verification-checklist/#failure-handling-retry-policy","title":"Failure Handling &amp; Retry Policy","text":"<p>Purpose: Define systematic approach to handling check failures, preventing infinite retry loops while ensuring quality gates are met.</p>"},{"location":"quality/agent-verification-checklist/#retry-procedure","title":"Retry Procedure","text":"<p>When any check fails, follow this structured retry process:</p>"},{"location":"quality/agent-verification-checklist/#step-1-initial-failure-analysis","title":"Step 1: Initial Failure Analysis","text":"<ol> <li>Capture Failure Details</li> <li>Record exact error message</li> <li>Identify which check failed (linting, type checking, tests, etc.)</li> <li> <p>Save relevant logs/output</p> </li> <li> <p>Attempt Fix #1 (Immediate)</p> </li> <li>Analyze error output</li> <li>Apply most likely fix based on error message</li> <li>Document what was changed</li> <li>Re-run the failed check only</li> </ol> <p>Example:    <pre><code>Failed Check: mypy type checking\nError: \"services/api/use_cases/loan.py:45: error: Argument 1 has incompatible type\"\n\nFix Applied: Add type annotation to function parameter\nResult: Re-run `uv run mypy .`\n</code></pre></p>"},{"location":"quality/agent-verification-checklist/#step-2-troubleshooting-consultation-if-attempt-1-fails","title":"Step 2: Troubleshooting Consultation (if Attempt #1 fails)","text":"<ol> <li>Attempt Fix #2 (Guided)</li> <li>Consult <code>docs/reference/troubleshooting.md</code> for symptom</li> <li>Read relevant atomic documentation (e.g., <code>docs/atomic/testing/unit-testing/pytest-setup.md</code>)</li> <li>Apply recommended fix from documentation</li> <li>Document fix attempt</li> <li>Re-run check</li> </ol> <p>Example:    <pre><code>Failed Check: pytest tests\nError: \"FAILED tests/test_loan.py::test_create_loan - AssertionError\"\n\nTroubleshooting: Checked troubleshooting.md \u2192 \"Mock HTTP client not configured\"\nFix Applied: Added pytest fixture for PostgresHTTPClient mock\nResult: Re-run `uv run pytest tests/test_loan.py`\n</code></pre></p>"},{"location":"quality/agent-verification-checklist/#step-3-alternative-approach-if-attempt-2-fails","title":"Step 3: Alternative Approach (if Attempt #2 fails)","text":"<ol> <li>Attempt Fix #3 (Creative)</li> <li>Try alternative solution (e.g., different implementation approach)</li> <li>Verify fix doesn't break other checks</li> <li>Document rationale for alternative approach</li> <li>Re-run all checks (not just failed one)</li> </ol> <p>Example:    <pre><code>Failed Check: coverage threshold (78% &lt; 80% required for Level 3)\n\nAttempts:\n1. Added more unit tests \u2192 79% (still insufficient)\n2. Added integration tests \u2192 79.5% (still insufficient)\n3. Identified untested error paths, added error case tests \u2192 82% \u2705\n\nResult: Coverage threshold met\n</code></pre></p>"},{"location":"quality/agent-verification-checklist/#step-4-escalation-if-attempt-3-fails","title":"Step 4: Escalation (if Attempt #3 fails)","text":"<ol> <li>Max Retries Reached (3 attempts per check)</li> <li>STOP automated retry attempts</li> <li> <p>Document failure in QA report with full diagnostic information:      <pre><code>## \u26a0\ufe0f Quality Gate Failure\n\n**Failed Check**: [Check name]\n**Status**: Unresolved after 3 fix attempts\n\n**Error Details**:\n</code></pre>      [Full error message and logs]      <pre><code>**Attempted Fixes**:\n1. [Attempt 1 description] \u2192 Result: [outcome]\n2. [Attempt 2 description] \u2192 Result: [outcome]\n3. [Attempt 3 description] \u2192 Result: [outcome]\n\n**Diagnostic Information**:\n\u2022 Environment: Python 3.12.1, UV 0.1.5\n\u2022 Affected files: [list]\n\u2022 Related checks: [any other failing checks]\n\n**Suggested Next Steps**:\n\u2022 [AI's analysis of root cause]\n\u2022 [Recommended actions for human developer]\n\u2022 [Alternative approaches to consider]\n\n**User Decision Required**:\nCannot proceed to Stage 6 (QA Report &amp; Handoff) without resolving this issue\nor obtaining explicit stakeholder sign-off on this deviation.\n</code></pre></p> </li> <li> <p>Notify user with actionable diagnostic info</p> </li> <li>WAIT for user guidance (one of):<ul> <li>User fixes issue manually \u2192 AI re-runs verification</li> <li>User approves deviation \u2192 AI documents exception in QA report \u2192 proceed to Stage 6</li> <li>User cancels workflow \u2192 AI terminates gracefully</li> </ul> </li> </ol>"},{"location":"quality/agent-verification-checklist/#retry-limits-by-check-type","title":"Retry Limits by Check Type","text":"Check Type Max Retries Escalation Trigger Linting (Ruff) 3 Code style issues persist after automated fixes Formatting (Ruff) 2 Format conflicts (rare, should auto-fix) Type Checking (Mypy) 3 Type inference issues, complex generics Security Scan (Bandit) 3 High severity findings remain after mitigation attempts Unit Tests 3 Test logic errors, environment issues Integration Tests 3 Testcontainer setup issues, flaky tests Coverage Threshold 3 Cannot reach required % after adding tests Artifact Validation 2 Structural issues, missing files"},{"location":"quality/agent-verification-checklist/#special-cases","title":"Special Cases","text":""},{"location":"quality/agent-verification-checklist/#flaky-tests","title":"Flaky Tests","text":"<p>If a test passes on retry without code changes: - Mark as flaky in QA report - Document intermittent failure for investigation - DO NOT count toward retry limit (not a real failure) - Suggest adding retry logic or test stability improvements</p>"},{"location":"quality/agent-verification-checklist/#environment-issues","title":"Environment Issues","text":"<p>If failure is due to environment (e.g., Docker not running, missing dependencies): - Provide clear diagnostic: \"Docker daemon not running. Start with: <code>sudo systemctl start docker</code>\" - DO NOT count toward retry limit - Wait for user to fix environment - Re-run check once environment is ready</p>"},{"location":"quality/agent-verification-checklist/#blocker-bugs-in-dependencies","title":"Blocker Bugs in Dependencies","text":"<p>If failure is due to bug in external library: - Document the external bug (version, issue tracker link if available) - Suggest workaround or version downgrade - Escalate immediately (no retries, external issue) - User decides: wait for fix, use workaround, or accept deviation</p>"},{"location":"quality/agent-verification-checklist/#preventing-infinite-loops","title":"Preventing Infinite Loops","text":"<p>Hard Limits: - Maximum 3 retry attempts per individual check - Maximum 10 total fix attempts across all checks in Stage 5 - If 10<sup>th</sup> fix attempt reached \u2192 FORCE ESCALATION to user</p> <p>Example Scenario: <pre><code>Check Results:\n\u2022 Ruff: PASS\n\u2022 Mypy: FAIL (attempted 3 fixes, still failing)\n\u2022 Pytest: FAIL (attempted 3 fixes, still failing)\n\u2022 Bandit: PASS\n\u2022 Coverage: FAIL (attempted 2 fixes, still failing)\n\nTotal fix attempts: 3 + 3 + 2 = 8\nAction: Continue with remaining checks, but escalate if total reaches 10\n</code></pre></p>"},{"location":"quality/agent-verification-checklist/#successful-resolution-criteria","title":"Successful Resolution Criteria","text":"<p>Stage 5 verification is considered COMPLETE when: - \u2705 ALL checks pass (preferred outcome) - \u2705 OR User explicitly approves deviations for failed checks (documented exception) - \u2705 Coverage meets level-specific threshold (60%/75%/80%/85% per <code>docs/reference/maturity-levels.md</code>)</p>"},{"location":"quality/agent-verification-checklist/#escalation-output-template","title":"Escalation Output Template","text":"<p>When escalating to user, provide structured output:</p> <p><pre><code>## \ud83d\udd34 Stage 5 Verification: Manual Intervention Required\n\n**Summary**: X out of Y checks failed after exhausting automated retry attempts.\n\n**Failed Checks** (details below):\n1. [Check name] - [brief error description]\n2. [Check name] - [brief error description]\n\n---\n\n### Failed Check #1: [Check Name]\n\n**Status**: \u274c Failed after 3 fix attempts\n**Impact**: [Blocker/Warning/Minor]\n\n**Error Message**:\n</code></pre> [Exact error output] <pre><code>**Fix Attempts**:\n| Attempt | Action Taken | Outcome | Logs |\n|---------|-------------|---------|------|\n| 1 | [Description] | Still failing | [Link/snippet] |\n| 2 | [Description] | Still failing | [Link/snippet] |\n| 3 | [Description] | Still failing | [Link/snippet] |\n\n**Root Cause Analysis**:\n[AI's analysis of why this is failing]\n\n**Recommended Actions** (choose one):\n- [ ] Option A: [Suggested fix with steps]\n- [ ] Option B: [Alternative approach]\n- [ ] Option C: Approve deviation (proceed with known issue)\n\n**Next Steps**:\nPlease choose an action above, or provide alternative guidance.\n\n---\n\n[Repeat for each failed check]\n\n---\n\n**Workflow Status**: \u23f8\ufe0f PAUSED at Stage 5 (Verification)\n**Next Stage**: Cannot proceed to Stage 6 until checks pass or deviations approved\n</code></pre></p>"},{"location":"quality/agent-verification-checklist/#integration-with-workflow","title":"Integration with Workflow","text":"<ul> <li>This retry policy applies only to Stage 5 (Quality Verification)</li> <li>After 3 failed attempts or user escalation \u2192 workflow PAUSES</li> <li>User decision required to proceed or terminate</li> <li>If user approves deviations \u2192 document in QA report \u2192 proceed to Stage 6</li> <li>If user provides fix \u2192 re-run Stage 5 from beginning</li> </ul>"},{"location":"quality/agent-verification-checklist/#original-failure-handling-notes","title":"Original Failure Handling Notes","text":"<ul> <li>If any check fails, consult <code>docs/reference/troubleshooting.md</code> and rerun the step.</li> <li>Document persistent issues in the QA report and notify stakeholders.</li> <li>Do not proceed to release without explicit sign-off on known deviations.</li> </ul>"},{"location":"quality/agent-verification-checklist/#maintenance","title":"Maintenance","text":"<ul> <li>Align commands with <code>docs/guides/development-commands.md</code> if they change.</li> <li>Keep coverage targets synchronized with <code>docs/atomic/testing/</code>.</li> <li>Update link references in <code>docs/reference/agent-context-summary.md</code> and <code>docs/INDEX.md</code> when modifying this checklist.</li> </ul>"},{"location":"quality/automated-quality-gates/","title":"Automated Quality Gates","text":"<p>Purpose: Enforce DRY, KISS, and YAGNI principles through automated CI checks</p> <p>Last Updated: 2025-01-07</p>"},{"location":"quality/automated-quality-gates/#overview","title":"Overview","text":"<p>The CI pipeline includes automated quality gates that enforce software engineering principles. These checks run on every push and pull request, ensuring code quality and consistency across the framework.</p>"},{"location":"quality/automated-quality-gates/#quality-gate-jobs","title":"Quality Gate Jobs","text":""},{"location":"quality/automated-quality-gates/#1-check-duplication-dry-enforcement","title":"1. check-duplication (DRY Enforcement)","text":"<p>Tool: jscpd (JavaScript Copy/Paste Detector) Threshold: 10% duplication max Fails if: Code duplication exceeds threshold</p>"},{"location":"quality/automated-quality-gates/#what-it-checks","title":"What it checks","text":"<ul> <li>Duplicated code blocks across files</li> <li>Copy-paste patterns</li> <li>Similar code structures</li> </ul>"},{"location":"quality/automated-quality-gates/#how-to-fix-violations","title":"How to fix violations","text":"<pre><code># Generate duplication report locally\nnpm install -g jscpd\njscpd services/ shared/ --reporters \"console,html\" --output \"./report\"\nopen report/jscpd-report.html\n</code></pre> <p>Common fixes:</p> <ol> <li> <p>Extract to shared/utils/ <pre><code># Before: Duplicated in 3 files\nif not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', email):\n    raise ValidationError(\"Invalid email\")\n\n# After: Use shared validator\nfrom shared.utils.validators import is_valid_email\nif not is_valid_email(email):\n    raise ValidationError(\"Invalid email\")\n</code></pre></p> </li> <li> <p>Create base classes <pre><code># Before: Same CRUD methods in 5 repositories\nclass UserRepository:\n    async def get_by_id(self, id: int): ...\n    async def create(self, **kwargs): ...\n\n# After: Inherit from BaseRepository\nclass UserRepository(BaseRepository[User]):\n    # Only add model-specific methods\n    async def get_by_email(self, email: str): ...\n</code></pre></p> </li> <li> <p>Use composition over duplication <pre><code># Before: Same HTTP client setup in every service\nclient = httpx.AsyncClient(timeout=30, ...)\n\n# After: Use shared client factory\nfrom shared.utils.http_client import create_client\nclient = create_client(timeout=30)\n</code></pre></p> </li> </ol>"},{"location":"quality/automated-quality-gates/#2-check-complexity-kiss-enforcement","title":"2. check-complexity (KISS Enforcement)","text":"<p>Tool: radon Thresholds: - McCabe complexity &lt; 10 per function - Maintainability Index &gt;= 20 (Grade B) - File size &lt; 500 lines</p> <p>Fails if: Any function/file exceeds thresholds</p>"},{"location":"quality/automated-quality-gates/#what-it-checks_1","title":"What it checks","text":"<p>Cyclomatic Complexity - Number of independent code paths: <pre><code># Complexity = 1 (simple)\ndef get_user(user_id: int) -&gt; User:\n    return repository.get(user_id)\n\n# Complexity = 5 (moderate)\ndef validate_user(user: User) -&gt; bool:\n    if not user.email:  # +1\n        return False\n    if not user.name:  # +1\n        return False\n    if user.age &lt; 0:  # +1\n        return False\n    if user.age &gt; 150:  # +1\n        return False\n    return True\n\n# Complexity = 15 (too high! \u274c)\ndef process_payment(order, payment_data):\n    if order.status == \"pending\":  # +1\n        if payment_data[\"method\"] == \"card\":  # +1\n            if payment_data[\"amount\"] &gt; 1000:  # +1\n                if not payment_data.get(\"cvv\"):  # +1\n                    # ... 11 more nested conditions\n</code></pre></p> <p>Maintainability Index - Composite metric (0-100): - A (20-100): Excellent - B (10-19): Good - C (0-9): Needs refactoring</p> <p>File Size - Lines of code per file</p>"},{"location":"quality/automated-quality-gates/#how-to-fix-violations_1","title":"How to fix violations","text":"<pre><code># Check complexity locally\npip install radon\nradon cc services/ shared/ --show-complexity\nradon mi services/ shared/ --show\n\n# Find large files\nfind services/ shared/ -name \"*.py\" -exec wc -l {} \\; | sort -rn | head -10\n\n# Most complex functions\nradon cc services/ shared/ --json | jq '.[] | .[] | select(.complexity &gt; 5) | {name, complexity}'\n</code></pre> <p>Common fixes:</p> <ol> <li> <p>Extract methods (Replace Temp with Query) <pre><code># Before: Complex function (McCabe = 15)\ndef process_order(order_id):\n    order = get_order(order_id)\n    if order.status == \"pending\":\n        if order.items:\n            total = 0\n            for item in order.items:\n                if item.price &gt; 0:\n                    total += item.price * item.quantity\n            if total &gt; order.discount:\n                final_total = total - order.discount\n            else:\n                final_total = 0\n            if final_total &gt; 0:\n                charge_payment(order.payment_method, final_total)\n        # ... more nested logic\n\n# After: Extracted methods (McCabe = 3)\ndef process_order(order_id):\n    order = get_order(order_id)\n    if not can_process_order(order):\n        return\n    total = calculate_order_total(order)\n    charge_payment(order.payment_method, total)\n\ndef can_process_order(order):\n    return order.status == \"pending\" and order.items\n\ndef calculate_order_total(order):\n    subtotal = sum(item.price * item.quantity for item in order.items)\n    return max(subtotal - order.discount, 0)\n</code></pre></p> </li> <li> <p>Use early returns (Guard Clauses) <pre><code># Before: Nested conditions (McCabe = 8)\ndef validate_user(user):\n    if user:\n        if user.email:\n            if user.name:\n                if user.age &gt;= 0:\n                    if user.age &lt;= 150:\n                        return True\n    return False\n\n# After: Early returns (McCabe = 4)\ndef validate_user(user):\n    if not user:\n        return False\n    if not user.email:\n        return False\n    if not user.name:\n        return False\n    if user.age &lt; 0 or user.age &gt; 150:\n        return False\n    return True\n</code></pre></p> </li> <li> <p>Apply strategy pattern <pre><code># Before: Large switch/case (McCabe = 12)\ndef process_payment(method, data):\n    if method == \"card\":\n        if data[\"type\"] == \"visa\":\n            # ... visa logic\n        elif data[\"type\"] == \"mastercard\":\n            # ... mastercard logic\n    elif method == \"paypal\":\n        # ... paypal logic\n    elif method == \"bank\":\n        # ... bank logic\n    # ... 8 more payment methods\n\n# After: Strategy pattern (McCabe = 2)\ndef process_payment(method, data):\n    handler = get_payment_handler(method)\n    return handler.charge(data)\n\nclass VisaHandler:\n    def charge(self, data): ...\n\nclass PayPalHandler:\n    def charge(self, data): ...\n</code></pre></p> </li> <li> <p>Split large classes <pre><code># Before: God class (842 lines)\nclass UserService:\n    # 50+ methods mixing concerns\n\n# After: Split by responsibility\nclass UserAuthService:  # 150 lines\n    # Only authentication methods\n\nclass UserProfileService:  # 200 lines\n    # Only profile management\n\nclass UserNotificationService:  # 180 lines\n    # Only notifications\n</code></pre></p> </li> </ol>"},{"location":"quality/automated-quality-gates/#3-check-dependencies-yagni-enforcement","title":"3. check-dependencies (YAGNI Enforcement)","text":"<p>Tool: grep + pip-check Thresholds: - Level 1-2 (Data services): max 30 dependencies - Level 3-4 (Business services): max 50 dependencies</p> <p>Fails if: Dependency count exceeds threshold</p>"},{"location":"quality/automated-quality-gates/#what-it-checks_2","title":"What it checks","text":"<ul> <li>Total number of dependencies per service</li> <li>Potentially unused dependencies (informational)</li> </ul>"},{"location":"quality/automated-quality-gates/#how-to-fix-violations_2","title":"How to fix violations","text":"<pre><code># Check dependencies locally\nwc -l &lt; requirements.txt\n\n# Find unused dependencies\npip install pip-check\npip-check --verbose\n\n# Remove unused dependency\npip install pip-autoremove\npip-autoremove &lt;package-name&gt; -y\n</code></pre> <p>Common fixes:</p> <ol> <li> <p>Remove dev dependencies from production <pre><code># Before: requirements.txt (45 dependencies)\nfastapi==0.115.0\npytest==8.3.3          # \u274c Should be in requirements-dev.txt\nmypy==1.11.2           # \u274c Should be in requirements-dev.txt\nblack==24.10.0         # \u274c Should be in requirements-dev.txt\n...\n\n# After: requirements.txt (15 dependencies)\nfastapi==0.115.0\nuvicorn==0.31.0\nsqlalchemy==2.0.35\n...\n\n# requirements-dev.txt\npytest==8.3.3\nmypy==1.11.2\nblack==24.10.0\n</code></pre></p> </li> <li> <p>Use stdlib alternatives <pre><code># Before: Install requests (heavy dependency)\nimport requests\nresponse = requests.get(url)\n\n# After: Use stdlib urllib (no dependency)\nfrom urllib.request import urlopen\nresponse = urlopen(url)\n\n# Or: Use httpx (already required by framework)\nimport httpx\nresponse = await httpx.get(url)\n</code></pre></p> </li> <li> <p>Remove dependencies from earlier iterations <pre><code># Before: Leftover from prototype\npandas==2.2.3          # \u274c Used in prototype, not production\nnumpy==2.1.2           # \u274c Used in prototype, not production\npillow==10.4.0         # \u274c Image processing not needed\ncelery==5.4.0          # \u274c Replaced with AsyncIO workers\n</code></pre></p> </li> </ol>"},{"location":"quality/automated-quality-gates/#running-checks-locally","title":"Running Checks Locally","text":"<p>Before pushing, run all checks locally to catch issues early:</p> <pre><code># Install tools\nnpm install -g jscpd\npip install radon pip-check\n\n# DRY check\njscpd services/ shared/ --threshold 10\n\n# KISS checks\nradon cc services/ shared/ --min B\nradon mi services/ shared/ --min B\nfind services/ shared/ -name \"*.py\" -exec wc -l {} \\; | awk '$1&gt;500 {print $0}'\n\n# YAGNI check\nfor dir in services/*/; do\n  echo \"$(basename $dir): $(grep -v '^#' $dir/requirements.txt | grep -v '^$' | wc -l) dependencies\"\ndone\n</code></pre> <p>Makefile shortcuts (if available):</p> <pre><code>make quality-check      # Run all quality gates\nmake check-duplication  # DRY only\nmake check-complexity   # KISS only\nmake check-dependencies # YAGNI only\n</code></pre>"},{"location":"quality/automated-quality-gates/#ci-badge","title":"CI Badge","text":"<p>Add to README.md to show quality gate status:</p> <pre><code>![Quality Gates](https://github.com/your-org/your-repo/actions/workflows/ci.yml/badge.svg)\n</code></pre>"},{"location":"quality/automated-quality-gates/#quality-gate-results","title":"Quality Gate Results","text":""},{"location":"quality/automated-quality-gates/#success","title":"Success \u2705","text":"<p>All checks pass:</p> <pre><code>\u2705 All CI checks passed successfully!\n\n\ud83d\udccb Quality Gates Summary:\n   \u2705 Linting &amp; Type Checking\n   \u2705 Unit Tests\n   \u2705 Integration Tests\n   \u2705 Docker Build\n   \u2705 DRY Check (Code Duplication &lt;10%)\n   \u2705 KISS Check (Complexity, Maintainability, File Size)\n   \u2705 YAGNI Check (Dependency Count)\n   \u2705 Security Scanning\n\n\ud83c\udf89 Ready for deployment!\n</code></pre>"},{"location":"quality/automated-quality-gates/#failure","title":"Failure \u274c","text":"<p>Example violation:</p> <pre><code>\u274c DRY VIOLATION: Code duplication exceeds 10% threshold\n\n\ud83d\udcca Duplicated code violates the DRY (Don't Repeat Yourself) principle.\n\n\ud83d\udca1 Consider extracting shared code to:\n   \u2022 shared/utils/ for reusable utilities\n   \u2022 Base classes for common patterns\n   \u2022 Helper functions in appropriate modules\n\n\ud83d\udcd6 Learn more: docs/guides/dry-kiss-yagni-principles.md#dry\n\ud83d\udcc1 Detailed report: jscpd-report/jscpd-report.html\n</code></pre>"},{"location":"quality/automated-quality-gates/#thresholds-summary","title":"Thresholds Summary","text":"Check Threshold Rationale Code Duplication &lt;10% Industry standard for maintainable code Cyclomatic Complexity &lt;10 (McCabe) Recommended max for testable functions Maintainability Index &gt;=20 (Grade B) Good maintainability baseline File Size &lt;500 lines Single Responsibility Principle Dependencies (Data) &lt;30 Minimal attack surface Dependencies (Business) &lt;50 Allow integrations but limit bloat"},{"location":"quality/automated-quality-gates/#customizing-thresholds","title":"Customizing Thresholds","text":"<p>To adjust thresholds for your project:</p> <ol> <li> <p>Fork CI workflow <pre><code>cp templates/ci-cd/.github/workflows/ci.yml .github/workflows/\n</code></pre></p> </li> <li> <p>Edit thresholds <pre><code># DRY threshold\njscpd services/ shared/ --threshold 15  # Increase to 15%\n\n# KISS threshold\nradon cc services/ --min C  # Allow grade C (complexity 10-20)\n\n# YAGNI threshold\nthreshold=50  # Increase dependency limit\n</code></pre></p> </li> <li> <p>Document justification <pre><code># CUSTOMIZATION.md\n## Quality Gate Thresholds\n\nModified thresholds:\n- Code duplication: 15% (legacy codebase, reducing gradually)\n- Complexity: Grade C allowed (complex domain logic)\n- Dependencies: 50 for data services (requires ML libraries)\n</code></pre></p> </li> </ol>"},{"location":"quality/automated-quality-gates/#related-documentation","title":"Related Documentation","text":"<ul> <li>DRY/KISS/YAGNI Principles - Comprehensive principle guide</li> <li>Code Review Checklist - Manual checks</li> <li>Testing Strategy - How to test quality improvements</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-01-07 Status: \u2705 Active in CI Pipeline</p>"},{"location":"quality/qa-report-template/","title":"QA Report Template","text":"<p>Instructions: Complete this report after running the verification checklist. Provide links to evidence wherever possible.</p>"},{"location":"quality/qa-report-template/#report-metadata","title":"Report Metadata","text":"<ul> <li>Project / Service:</li> <li>Request ID:</li> <li>Report Version:</li> <li>Date:</li> <li>Prepared By (Agent):</li> <li>Reviewed By:</li> </ul>"},{"location":"quality/qa-report-template/#executive-summary","title":"Executive Summary","text":"<ul> <li>Overall status (Ready / Blocked):</li> <li>Key accomplishments:</li> <li>Outstanding issues:</li> <li>Recommendation:</li> </ul>"},{"location":"quality/qa-report-template/#verification-checklist-summary","title":"Verification Checklist Summary","text":"Check Category Status Evidence Link Notes Environment Static analysis Testing &amp; coverage Requirements coverage [\u2705 100% / \u26a0\ufe0f Partial / \u274c Incomplete] RTM below [Coverage %] Artefact validation Release gate <p>Reference: Completed <code>docs/quality/agent-verification-checklist.md</code>.</p>"},{"location":"quality/qa-report-template/#requirements-coverage-matrix","title":"Requirements Coverage Matrix","text":"<p>PURPOSE: Evidence that ALL requirements from original user prompt were implemented. This is the PRIMARY deliverable proving completeness.</p> <p>INSTRUCTIONS: Extract Req IDs from Requirements Intake (Stage 2) and Implementation Plan RTM (Stage 3), verify implementation, and document evidence below.</p>"},{"location":"quality/qa-report-template/#functional-requirements-fr-","title":"Functional Requirements (FR-*)","text":"Req ID Feature Status Evidence (Code Location) Tests Notes FR-001 (example: User registration) \u2705 Done <code>services/api/src/api/v1/users.py:20</code> \u2705 5 unit tests\u2705 2 integration tests Fully implemented with email verification FR-002 (example: Loan creation) \u2705 Done <code>services/api/src/api/v1/loans.py:15</code> \u2705 8 unit tests\u2705 3 integration tests Complete with validation rules FR-003 (example: Payment automation) \u2705 Done <code>services/worker/src/workers/payment.py:30</code> \u2705 6 unit tests\u2705 2 e2e tests Worker operational with Stripe integration <p>Functional Coverage: [X]/[X] requirements ([100]%)</p>"},{"location":"quality/qa-report-template/#uiux-requirements-ui-for-ui-heavy-projects-only","title":"UI/UX Requirements (UI-) \u2014 *For UI-heavy projects only","text":"<p>NOTE: This section applies ONLY to projects with detailed UI/UX requirements (Telegram bots, web frontends, mobile apps). Skip if project is API-only.</p> Req ID UI Element/Screen Status Evidence (Code + Screenshot) Tests Notes UI-001 (example: Registration form) \u2705 Done Code: <code>services/bot/src/handlers/register.py:15</code>Screenshot: <code>screenshots/register.png</code> \u2705 e2e test\u2705 FSM states verified All fields present: email, password, confirm UI-002 (example: Login screen) \u2705 Done Code: <code>services/bot/src/handlers/auth.py:30</code>Screenshot: <code>screenshots/login.png</code> \u2705 e2e test \"Forgot password\" link functional UI-003 (example: Dashboard) \u2705 Done Code: <code>services/bot/src/handlers/dashboard.py:40</code>Screenshot: <code>screenshots/dashboard.png</code> \u2705 e2e test Stats displayed correctly, responsive <p>UI/UX Coverage: [Y]/[Y] requirements ([100]%)</p>"},{"location":"quality/qa-report-template/#non-functional-requirements-nf-for-measurable-constraints-only","title":"Non-Functional Requirements (NF-) \u2014 *For measurable constraints only","text":"<p>NOTE: This section applies ONLY to projects with measurable non-functional constraints (performance SLAs, uptime targets, etc.). Skip if no NF requirements in Requirements Intake.</p> Req ID Constraint Target / SLA Status Evidence Verification Method Notes NF-001 (example: API latency) &lt; 200ms p95 \u2705 Met Load test results: p95 = 145ms Apache Bench / k6 load testing Performance acceptable NF-002 (example: Uptime) 99.9% \u2705 Met Healthcheck + monitoring config Prometheus + alerting rules HA configured (Level 4 only) NF-003 (example: Test coverage) \u2265 80% (Level 3) \u2705 Met Coverage report: 82% pytest --cov Threshold met <p>Non-Functional Coverage: [Z]/[Z] requirements ([100]%)</p>"},{"location":"quality/qa-report-template/#overall-coverage-summary","title":"Overall Coverage Summary","text":"<p>CRITICAL METRICS: These numbers determine whether project can proceed to deployment or requires additional work.</p> <ul> <li>Total Requirements: [X+Y+Z] = [sum] requirements</li> <li>Functional (FR-*): [X]</li> <li>UI/UX (UI-): [Y] *(or N/A if API-only)</li> <li> <p>Non-Functional (NF-): [Z] *(or 0 if none)</p> </li> <li> <p>Implemented: [count] requirements ([percentage]%)</p> </li> <li>Descoped: [count] requirements (with stakeholder approval \u2014 see \u00a7 Defects &amp; Risks)</li> <li>Outstanding: [count] requirements (BLOCKER if &gt; 0 without approval)</li> </ul> <p>Coverage Status: - \u2705 100% COVERAGE ACHIEVED \u2014 All requirements implemented, ready for deployment - \u26a0\ufe0f PARTIAL COVERAGE ([percentage]%) \u2014 Requires stakeholder approval (see Descoped Requirements below) - \u274c INCOMPLETE ([percentage]%) \u2014 Cannot proceed to deployment until missing requirements implemented</p>"},{"location":"quality/qa-report-template/#descoped-requirements-if-any","title":"Descoped Requirements (if any)","text":"<p>NOTE: Fill this section ONLY if coverage &lt; 100% and stakeholder approved descoping certain requirements.</p> Req ID Feature/Element Reason for Descope Approved By Approval Date Planned for Version FR-015 (example: Advanced search filters) Low priority for MVP, defer to v2 John Doe (Product Owner) 2025-10-30 v2.0 (Q2 2026) UI-007 (example: Dark mode theme) Nice-to-have, not critical for launch Jane Smith (Stakeholder) 2025-10-30 v1.1 (Q4 2025) <p>Adjusted Coverage (excluding descoped): [implemented] / ([total] - [descoped]) \u00d7 100% = 100%</p>"},{"location":"quality/qa-report-template/#coverage-verification-evidence","title":"Coverage Verification Evidence","text":"<ul> <li>Requirements Intake Document: [link to artifacts/requirements-intake.md]</li> <li>Implementation Plan RTM: [link to artifacts/implementation-plan.md \u00a7 Requirements Traceability Matrix]</li> <li>Verification Checklist: [link to artifacts/verification-checklist.md \u00a7 Requirements Coverage Verification]</li> </ul> <p>REFERENCE: See <code>docs/guides/requirements-traceability-guide.md</code> for RTM methodology and coverage calculation formula.</p>"},{"location":"quality/qa-report-template/#test-coverage-details","title":"Test &amp; Coverage Details","text":"<ul> <li>Test command(s) executed:</li> <li>Coverage percentage (compare with <code>docs/atomic/testing/</code>):</li> <li>Location of reports (<code>htmlcov/</code>, <code>coverage.xml</code>, CI artifacts):</li> </ul>"},{"location":"quality/qa-report-template/#defects-risks","title":"Defects &amp; Risks","text":"ID Description Severity Status Owner Mitigation / Next Steps"},{"location":"quality/qa-report-template/#deliverables-summary","title":"Deliverables Summary","text":"<ul> <li>Updated deliverables list reference (<code>docs/reference/deliverables-catalog.md</code>):</li> <li>ADRs created or updated (<code>docs/reference/architecture-decision-log-template.md</code>):</li> <li>Documentation updates (requirements, plans, guides):</li> </ul>"},{"location":"quality/qa-report-template/#sign-off","title":"Sign-Off","text":"<ul> <li>Agent signature &amp; date:</li> <li>Reviewer signature &amp; date:</li> <li>Requester acknowledgement:</li> </ul>"},{"location":"quality/qa-report-template/#references","title":"References","text":"<ul> <li>Requirements Intake document:</li> <li>Implementation Plan:</li> <li>Verification Checklist artefact:</li> <li>Additional notes:</li> </ul>"},{"location":"reference/agent-context-summary/","title":"Agent Context Summary","text":"<p>Purpose: Provide AI agents with a fast, authoritative orientation to this microservices framework. Use this file before scanning the rest of the documentation tree.</p>"},{"location":"reference/agent-context-summary/#core-orientation","title":"Core Orientation","text":"<ul> <li>Framework Model: Framework-as-submodule (<code>README.md</code>). Application code lives outside <code>.ai-framework/</code>; the framework supplies patterns, infrastructure, and rules.</li> <li>Architecture Paradigm: Improved Hybrid Approach with HTTP-only data access, dedicated data services, Nginx API Gateway, and event-driven coordination (<code>docs/guides/architecture-guide.md</code>).</li> <li>Primary Entry Point: <code>AGENTS.md</code> (or <code>AGENTS.md</code> symlink) explains how AI agents should traverse documentation and obey mandatory constraints. This follows the industry-standard filename adopted by GitHub Copilot, Cursor, and other AI coding agents.</li> </ul>"},{"location":"reference/agent-context-summary/#mandatory-references","title":"Mandatory References","text":"Need Primary Sources Full documentation map <code>docs/LINKS_REFERENCE.md</code>, <code>docs/INDEX.md</code> Maturity level selection <code>docs/reference/maturity-levels.md</code>, <code>docs/reference/conditional-stage-rules.md</code> Architecture constraints <code>docs/guides/architecture-guide.md</code>, <code>docs/atomic/architecture/improved-hybrid-overview.md</code>, <code>docs/atomic/architecture/data-access-architecture.md</code>, <code>docs/atomic/architecture/naming/README.md</code> Service implementation patterns <code>docs/atomic/services/fastapi/</code>, <code>docs/atomic/services/aiogram/</code>, <code>docs/atomic/services/asyncio-workers/</code>, <code>docs/atomic/services/data-services/</code> Infrastructure integration rules <code>docs/atomic/integrations/redis/</code>, <code>docs/atomic/integrations/rabbitmq/</code>, <code>docs/atomic/integrations/http-communication/</code> Database patterns <code>docs/atomic/databases/postgresql/</code>, <code>docs/atomic/databases/postgresql-advanced/</code>, <code>docs/atomic/infrastructure/databases/</code> Observability <code>docs/atomic/observability/</code> (logging, metrics, tracing, error tracking, ELK stack) Quality and testing <code>docs/atomic/testing/</code>, <code>docs/guides/development-commands.md</code>"},{"location":"reference/agent-context-summary/#agent-focused-documents","title":"Agent-Focused Documents","text":"Purpose Document Complete workflow process <code>docs/guides/ai-code-generation-master-workflow.md</code> Stage-by-stage navigation <code>docs/reference/ai-navigation-matrix.md</code> Prompt validation <code>docs/guides/prompt-validation-guide.md</code> Prompt augmentation snippets <code>docs/reference/prompt-templates.md</code> Requirements capture <code>docs/guides/requirements-intake-template.md</code> Requirements traceability <code>docs/guides/requirements-traceability-guide.md</code> \u2014 100% coverage methodology Delivery planning <code>docs/guides/implementation-plan-template.md</code> Tooling catalog <code>docs/reference/agent-toolbox.md</code> Deliverables inventory <code>docs/reference/deliverables-catalog.md</code> Verification checklist <code>docs/quality/agent-verification-checklist.md</code> QA reporting <code>docs/quality/qa-report-template.md</code> Architecture decisions <code>docs/reference/architecture-decision-log-template.md</code> Failure &amp; recovery handling <code>docs/reference/failure-scenarios.md</code>"},{"location":"reference/agent-context-summary/#critical-rules-snapshot","title":"Critical Rules Snapshot","text":"<ol> <li>Requirements Coverage: 100% requirement coverage MANDATORY \u2014 ALL requirements from Stage 2 must be implemented by Stage 5 (or explicitly descoped with approval). Use Req ID tracking (FR-, UI-, NF-*) throughout workflow (<code>docs/guides/requirements-traceability-guide.md</code>).</li> <li>Service Separation: FastAPI, Aiogram, and AsyncIO workers run in separate processes/containers (<code>docs/atomic/architecture/service-separation-principles.md</code>).</li> <li>Data Access: Business services must call data services over HTTP; direct database access is prohibited (<code>docs/atomic/architecture/data-access-architecture.md</code>).</li> <li>API Gateway: Nginx is MANDATORY for production deployments (TLS, load balancing, rate limiting) (<code>docs/atomic/infrastructure/api-gateway/</code>).</li> <li>Eventing: RabbitMQ is the mandatory broker for asynchronous communication (<code>docs/atomic/integrations/rabbitmq/</code>).</li> <li>Naming: DEFAULT TO 3-PART naming (<code>{context}_{domain}_{type}</code>). Use 4-part ONLY when domain is ambiguous (burden of proof required). See <code>docs/atomic/architecture/naming/naming-4part-reasons.md</code> for 10 serious reasons. Use <code>docs/checklists/service-naming-checklist.md</code> for quick decision.</li> <li>Quality Gates: Ruff, mypy, bandit, pytest, and test coverage thresholds are non-negotiable (<code>docs/guides/development-commands.md</code>).</li> </ol>"},{"location":"reference/agent-context-summary/#workflow-overview","title":"Workflow Overview","text":"<p>Complete 7-stage process: See <code>docs/guides/ai-code-generation-master-workflow.md</code></p> <p>Quick summary: 1. Stage 0: Initialization \u2192 Load framework context (AGENTS.md, this file, Master Workflow) 2. Stage 1: Prompt Validation \u2192 <code>docs/guides/prompt-validation-guide.md</code> \u2014 SELECT MATURITY LEVEL (1-4) 3. Stage 2: Requirements Intake \u2192 populate <code>docs/guides/requirements-intake-template.md</code> \u2014 ASSIGN REQ IDs (FR-, UI-, NF-*) 4. Stage 3: Implementation Planning \u2192 use <code>docs/guides/implementation-plan-template.md</code> \u2014 CREATE RTM (map Req IDs \u2192 tasks) 5. Stage 4: Code Generation \u2192 CONDITIONAL based on maturity level per <code>docs/reference/conditional-stage-rules.md</code> 6. Stage 5: Verification \u2192 <code>docs/quality/agent-verification-checklist.md</code> \u2014 VERIFY 100% REQUIREMENTS COVERAGE (PRIMARY GATE) 7. Stage 6: Reporting &amp; Handoff \u2192 <code>docs/quality/qa-report-template.md</code> with Requirements Coverage Matrix, update <code>docs/reference/deliverables-catalog.md</code></p> <p>Navigation: Use <code>docs/reference/ai-navigation-matrix.md</code> for exact document mapping at each stage.</p> <p>Maturity Levels: 4 levels from PoC (~5 min) to Production (~30 min). See <code>docs/reference/maturity-levels.md</code> for details.</p>"},{"location":"reference/agent-context-summary/#maintenance","title":"Maintenance","text":"<ul> <li>Update this summary whenever new mandatory documents are introduced.</li> <li>Keep the links aligned with <code>docs/INDEX.md</code> and <code>docs/LINKS_REFERENCE.md</code>.</li> <li>Follow <code>docs/STYLE_GUIDE.md</code> for formatting updates.</li> </ul>"},{"location":"reference/agent-toolbox/","title":"Agent Toolbox","text":"<p>Purpose: Provide a machine-friendly catalog of commands and scripts referenced throughout the framework. Every entry points back to the canonical source in <code>docs/guides/development-commands.md</code> or related references.</p>"},{"location":"reference/agent-toolbox/#usage-guidelines","title":"Usage Guidelines","text":"<ol> <li>Treat this file as a lookup table when selecting commands inside the workflow.</li> <li>Do not invent new commands\u2014always reuse the canonical form from <code>docs/guides/development-commands.md</code>.</li> <li>Verify prerequisites (environment variables, running containers) before executing a command.</li> <li>When adding new tools, update <code>docs/INDEX.md</code> and cross-reference the source documentation.</li> </ol>"},{"location":"reference/agent-toolbox/#environment-setup","title":"Environment &amp; Setup","text":"Tool / Command Parameters Preconditions Expected Output When to Use References <code>uv sync --dev</code> none Python &gt;=3.12, <code>pyproject.toml</code> present Dependencies installed with dev extras Prepare local environment <code>docs/guides/development-commands.md</code> (\"Package Management\") <code>cp .env.example .env</code> none <code>.env.example</code> available Local <code>.env</code> file created Initialize environment variables <code>docs/guides/development-commands.md</code> (\"Configuration and Validation\")"},{"location":"reference/agent-toolbox/#docker-services","title":"Docker &amp; Services","text":"Tool / Command Parameters Preconditions Expected Output When to Use References <code>docker-compose up -d</code> optional service list Docker daemon running Services started in background Start full stack for development <code>docs/guides/development-commands.md</code> (\"Docker Compose Operations\") <code>docker-compose logs -f &lt;service&gt;</code> <code>&lt;service&gt;</code> Service already running Streaming logs for service Investigate service behaviour <code>docs/guides/development-commands.md</code> (\"Docker Compose Operations\") <code>docker-compose exec &lt;service&gt; bash</code> <code>&lt;service&gt;</code> Container running Shell inside service container Run service-level diagnostics <code>docs/guides/development-commands.md</code> (\"Docker Compose Operations\") <code>docker-compose --profile observability up -d</code> none Monitoring profile defined Observability stack running Enable monitoring suite <code>docs/guides/development-commands.md</code> (\"Observability Operations\")"},{"location":"reference/agent-toolbox/#diagnostics-health-checks","title":"Diagnostics &amp; Health Checks","text":"Tool / Command Parameters Preconditions Expected Output When to Use References <code>curl http://localhost:8000/health</code> none API service exposed HTTP 200 with health payload Confirm business API availability <code>docs/guides/development-commands.md</code> (\"Configuration and Validation\") <code>docker-compose exec postgres pg_isready -U postgres</code> none Postgres container running Readiness confirmation Check PostgreSQL health <code>docs/guides/development-commands.md</code> (\"Data Service Operations\") <code>docker-compose exec rabbitmq rabbitmqctl list_queues</code> none RabbitMQ running Queue listing Inspect broker state <code>docs/guides/development-commands.md</code> (\"Observability Operations\") <code>docker stats</code> none Containers running Live resource metrics Monitor performance issues <code>docs/guides/development-commands.md</code> (\"Troubleshooting Commands\")"},{"location":"reference/agent-toolbox/#quality-testing","title":"Quality &amp; Testing","text":"Tool / Command Parameters Preconditions Expected Output When to Use References <code>uv run ruff check .</code> <code>--fix</code> (optional) Dependencies installed Lint report, optional fixes applied Enforce style before commit <code>docs/guides/development-commands.md</code> (\"Code Quality Commands\") <code>uv run ruff format . --check</code> none Dependencies installed Formatting check status Verify formatting without changes <code>docs/guides/development-commands.md</code> (\"Code Quality Commands\") <code>uv run mypy .</code> none Dependencies installed Type-check report Ensure static typing compliance <code>docs/guides/development-commands.md</code> (\"Code Quality Commands\") <code>uv run bandit -r .</code> none Dependencies installed Security scan report Detect common security issues <code>docs/guides/development-commands.md</code> (\"Code Quality Commands\") <code>uv run pytest --cov=src --cov-report=html --cov-report=xml</code> optional <code>-k</code>, <code>-n</code> Test suite available Test results + coverage artefacts Run tests with coverage before delivery <code>docs/guides/development-commands.md</code> (\"Testing Commands\")"},{"location":"reference/agent-toolbox/#release-recovery","title":"Release &amp; Recovery","text":"Tool / Command Parameters Preconditions Expected Output When to Use References <code>docker-compose down &amp;&amp; docker-compose up -d</code> none Stack running Services restarted Emergency restart of all services <code>docs/guides/development-commands.md</code> (\"Emergency Procedures\") <code>docker-compose down -v</code> none Awareness of data loss Services stopped, volumes removed Full reset with volume cleanup <code>docs/guides/development-commands.md</code> (\"Emergency Procedures\") <code>docker-compose exec postgres pg_dump -U postgres microservices_db &gt; backup.sql</code> destination path Postgres running SQL dump file Create database backup <code>docs/guides/development-commands.md</code> (\"Emergency Procedures\")"},{"location":"reference/agent-toolbox/#troubleshooting-notes","title":"Troubleshooting Notes","text":"<ul> <li>For detailed remediation steps, always consult <code>docs/reference/troubleshooting.md</code>.</li> <li>Observability dashboards (Grafana, Jaeger, Kibana, Prometheus) are documented in <code>docs/guides/development-commands.md#observability-operations</code>.</li> </ul>"},{"location":"reference/agent-toolbox/#maintenance","title":"Maintenance","text":"<ul> <li>Align updates with <code>docs/guides/development-commands.md</code> whenever commands change.</li> <li>Follow formatting rules from <code>docs/STYLE_GUIDE.md</code>.</li> <li>Update <code>docs/INDEX.md</code> and <code>docs/reference/agent-context-summary.md</code> after modifying this toolbox.</li> </ul>"},{"location":"reference/ai-navigation-matrix/","title":"AI Navigation Matrix","text":"<p>PURPOSE: Quick-lookup table showing exactly which documents AI should read at each workflow stage and what outputs are expected.</p>"},{"location":"reference/ai-navigation-matrix/#how-to-use-this-matrix","title":"How to Use This Matrix","text":"<ol> <li>Find your current stage (0-6) in the leftmost column</li> <li>Read the \"Documents to Read\" column - these are MANDATORY reading for that stage</li> <li>Generate outputs listed in \"AI Generates\" column</li> <li>Use tools from \"Templates/Tools\" column</li> <li>Verify success using \"Success Criteria\" column</li> </ol>"},{"location":"reference/ai-navigation-matrix/#complete-navigation-matrix","title":"Complete Navigation Matrix","text":"<p>NEW: Each sub-stage now includes \"Required At Level\" to support adaptive generation based on maturity level selection. See <code>docs/reference/maturity-levels.md</code> for level definitions.</p> Stage Phase Required At Level Documents to Read AI Generates Success Criteria 0 Initialization ALL \u2022 <code>AGENTS.md</code>\u2022 <code>docs/reference/agent-context-summary.md</code>\u2022 <code>docs/guides/ai-code-generation-master-workflow.md</code>\u2022 <code>docs/reference/maturity-levels.md</code> Nothing (loading phase) AI has complete framework context 1 Prompt Validation ALL \u2022 <code>docs/guides/prompt-validation-guide.md</code>\u2022 <code>docs/reference/prompt-templates.md</code>\u2022 <code>docs/reference/maturity-levels.md</code> (for level selection) \u2022 Validation confirmation\u2022 Selected maturity level (1-4)\u2022 Selected optional modules All mandatory fields present:\u2705 Business context\u2705 Target maturity level\u2705 Functional requirements\u2705 Dependencies 2 Requirements Clarification &amp; Intake ALL \u2022 <code>docs/guides/requirements-intake-template.md</code>\u2022 <code>docs/guides/requirements-traceability-guide.md</code> (for Req ID format)\u2022 <code>docs/guides/architecture-guide.md</code>\u2022 <code>docs/reference/tech_stack.md</code>\u2022 <code>docs/atomic/architecture/improved-hybrid-overview.md</code> \u2022 Completed Requirements Intake\u2022 ALL requirements assigned Req IDs (FR-, UI-, NF-*)\u2022 Requirements Summary (total count)\u2022 Maturity level confirmed\u2022 Architecture compatibility analysis \u2022 Requirements approved\u2022 Req IDs assigned to ALL requirements\u2022 Maturity level documented\u2022 Architecture aligned 3 Architecture Mapping &amp; Planning ALL \u2022 <code>docs/guides/implementation-plan-template.md</code>\u2022 <code>docs/guides/requirements-traceability-guide.md</code> (for RTM creation)\u2022 <code>docs/reference/conditional-stage-rules.md</code>\u2022 <code>docs/checklists/service-naming-checklist.md</code>\u2022 <code>docs/atomic/architecture/naming/README.md</code> (Section 2.3)\u2022 <code>docs/atomic/services/**/*</code> (based on level + modules)\u2022 <code>docs/atomic/integrations/**/*</code> (if needed) \u2022 Implementation Plan with:\u00a0\u00a0\u2022 Requirements Traceability Matrix (ALL Req IDs mapped to tasks)\u00a0\u00a0\u2022 Included features list\u00a0\u00a0\u2022 Skipped features list\u00a0\u00a0\u2022 Conditional sub-stages\u2022 Service names (DEFAULT TO 3-PART) \u2022 Plan approved\u2022 RTM complete (all Req IDs mapped)\u2022 Features clearly marked\u2022 Sub-stages identified\u2022 Naming follows conventions 4.1 Infrastructure (Basic) ALL \u2022 <code>docs/reference/project-structure.md</code> (\u00a7Creating the Project Structure)\u2022 <code>docs/atomic/architecture/project-structure-patterns.md</code>\u2022 <code>docs/atomic/infrastructure/containerization/docker-compose-setup.md</code>\u2022 <code>docs/atomic/infrastructure/containerization/dockerfile-patterns.md</code> \u2022 Complete directory structure (per project-structure.md)\u2022 <code>docker-compose.yml</code>\u2022 <code>.env.example</code>\u2022 <code>Makefile</code> \u2022 All directories created and verified\u2022 Docker services healthy 4.1b + Dev Overrides \u2265 Level 2 \u2022 <code>docs/atomic/infrastructure/configuration/settings-patterns.md</code> \u2022 <code>docker-compose.dev.yml</code>\u2022 Docker healthchecks \u2022 Dev environment working 4.1c + Nginx + SSL + Metrics \u2265 Level 3 \u2022 <code>docs/atomic/infrastructure/api-gateway/nginx-setup.md</code>\u2022 <code>docs/atomic/infrastructure/api-gateway/ssl-configuration.md</code>\u2022 <code>docs/atomic/observability/metrics/prometheus-setup.md</code> \u2022 Nginx config\u2022 SSL setup\u2022 Prometheus + Grafana\u2022 <code>docker-compose.prod.yml</code> \u2022 Nginx reverse proxy working\u2022 SSL functional\u2022 Metrics exposed 4.1d + ELK + Replication Level 4 only \u2022 <code>docs/atomic/observability/elk-stack/*</code>\u2022 <code>docs/atomic/infrastructure/databases/postgresql-replication.md</code> \u2022 ELK Stack config\u2022 DB replication\u2022 Backup scripts \u2022 Centralized logging\u2022 DB replication active 4.2 Data Layer (PostgreSQL) ALL \u2022 <code>docs/atomic/services/data-services/postgres-service-setup.md</code>\u2022 <code>docs/atomic/databases/postgresql/sqlalchemy-integration.md</code> \u2022 PostgreSQL service\u2022 Models, repositories\u2022 HTTP API\u2022 Migrations \u2022 Data service health checks pass\u2022 HTTP API functional 4.2b + MongoDB (optional) IF user requested \u2022 <code>docs/atomic/services/data-services/mongo-service-setup.md</code> \u2022 MongoDB service \u2022 MongoDB API functional 4.3 Business Logic (Core) ALL \u2022 <code>docs/atomic/services/fastapi/application-factory.md</code>\u2022 <code>docs/atomic/services/fastapi/routing-patterns.md</code>\u2022 <code>docs/atomic/services/fastapi/dependency-injection.md</code>\u2022 <code>docs/atomic/services/fastapi/schema-validation.md</code>\u2022 <code>docs/atomic/services/fastapi/error-handling.md</code>\u2022 <code>docs/atomic/architecture/ddd-hexagonal-principles.md</code>\u2022 <code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code> Domain Layer:\u2022 Entities, Value objectsApplication Layer:\u2022 Use cases, DTOsInfrastructure Layer:\u2022 HTTP clients (to data services)API Layer:\u2022 FastAPI routers\u2022 Request/response schemas \u2022 API endpoints functional\u2022 HTTP-only data access verified 4.3b + Structured Logging \u2265 Level 2 \u2022 <code>docs/atomic/observability/logging/structured-logging.md</code>\u2022 <code>docs/atomic/observability/logging/log-correlation.md</code> \u2022 Logger setup\u2022 Request ID propagation\u2022 Error logging \u2022 Logs are structured JSON\u2022 Correlation IDs present 4.3c + Prometheus Metrics \u2265 Level 3 \u2022 <code>docs/atomic/observability/metrics/prometheus-setup.md</code>\u2022 <code>docs/atomic/observability/metrics/custom-metrics.md</code> \u2022 Metrics endpoints\u2022 Custom business metrics \u2022 <code>/metrics</code> endpoint works\u2022 Grafana dashboards 4.3d + OAuth/JWT + Tracing Level 4 only \u2022 <code>docs/atomic/services/fastapi/oauth-jwt.md</code> (TODO: not yet created)\u2022 <code>docs/atomic/observability/tracing/jaeger-configuration.md</code> \u2022 OAuth 2.0 / JWT auth\u2022 RBAC middleware\u2022 Distributed tracing \u2022 Auth functional\u2022 Traces visible in Jaeger 4.4 Background Workers (optional) IF user requested \u2022 <code>docs/atomic/services/asyncio-workers/basic-setup.md</code>\u2022 <code>docs/atomic/services/asyncio-workers/main-function-patterns.md</code>\u2022 <code>docs/atomic/services/asyncio-workers/signal-handling.md</code>\u2022 <code>docs/atomic/integrations/rabbitmq/message-consuming.md</code> \u2022 Worker implementations\u2022 RabbitMQ consumers\u2022 Main entrypoint with signal handling \u2022 Workers start successfully\u2022 Event consumption working 4.4b + Structured Logging (Workers) \u2265 Level 2 AND Workers requested \u2022 <code>docs/atomic/observability/logging/structured-logging.md</code> (adapted for workers) \u2022 Worker logger setup \u2022 Worker logs structured 4.5 Telegram Bot (optional) IF user requested \u2022 <code>docs/atomic/services/aiogram/basic-setup.md</code>\u2022 <code>docs/atomic/services/aiogram/bot-initialization.md</code>\u2022 <code>docs/atomic/services/aiogram/handler-patterns.md</code>\u2022 <code>docs/atomic/integrations/rabbitmq/aiogram-integration.md</code> \u2022 Bot handlers (commands, messages)\u2022 RabbitMQ event listeners\u2022 Main entrypoint \u2022 Bot responds to commands\u2022 Event-based notifications working 4.5b + Structured Logging (Bot) \u2265 Level 2 AND Bot requested \u2022 <code>docs/atomic/observability/logging/structured-logging.md</code> (adapted for bots) \u2022 Bot logger setup \u2022 Bot logs structured 4.6 Testing (Basic) ALL \u2022 <code>docs/atomic/testing/unit-testing/pytest-setup.md</code>\u2022 <code>docs/atomic/testing/unit-testing/fixture-patterns.md</code>\u2022 <code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> \u2022 <code>pytest.ini</code>\u2022 <code>conftest.py</code>\u2022 Unit tests (core layers)\u2022 Service tests \u2022 All tests pass\u2022 Coverage \u2265 60% (Level 1) 4.6b + Integration Tests \u2265 Level 2 \u2022 <code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code>\u2022 <code>docs/atomic/testing/unit-testing/mocking-strategies.md</code> \u2022 Integration tests (with testcontainers)\u2022 Enhanced mocking \u2022 Coverage \u2265 75% 4.6c + E2E Tests \u2265 Level 3 \u2022 <code>docs/atomic/testing/end-to-end-testing/e2e-test-setup.md</code> \u2022 End-to-end API tests \u2022 Coverage \u2265 80% 4.6d + Security Tests Level 4 only \u2022 <code>docs/atomic/testing/quality-assurance/linting-standards.md</code> (includes Bandit)\u2022 <code>docs/atomic/testing/end-to-end-testing/performance-testing.md</code> \u2022 Security test suite\u2022 Bandit config \u2022 Coverage \u2265 85%\u2022 Security tests pass 5 Quality Verification ALL (criteria vary by level) \u2022 <code>docs/quality/agent-verification-checklist.md</code>\u2022 <code>docs/guides/requirements-traceability-guide.md</code> (for coverage verification)\u2022 <code>docs/reference/agent-toolbox.md</code>\u2022 <code>docs/reference/maturity-levels.md</code> (for coverage targets)\u2022 <code>docs/reference/troubleshooting.md</code> (if issues) \u2022 Completed verification checklist\u2022 Requirements Coverage Matrix (100% or approved descope)\u2022 Coverage reports (HTML + XML)\u2022 Evidence logs/screenshots ALL checks must pass:\u2705 Requirements coverage: 100% (PRIMARY GATE)\u2705 Linting (Ruff): 0 errors\u2705 Formatting: No drift\u2705 Type checking (Mypy): 0 errors\u2705 Security (Bandit): 0 high severity\u2705 Tests: All pass\u2705 Test coverage: Level-dependent (60%/75%/80%/85%)\u2705 Project structure: Compliant\u2705 Naming: Follows conventions 6 QA Report &amp; Handoff ALL \u2022 <code>docs/quality/qa-report-template.md</code>\u2022 <code>docs/guides/requirements-traceability-guide.md</code> (for final coverage matrix)\u2022 <code>docs/reference/deliverables-catalog.md</code> \u2022 Final QA Report with:\u00a0\u00a0\u2022 Requirements Coverage Matrix (complete)\u00a0\u00a0\u2022 Overall Coverage Summary\u2022 Deliverables summary\u2022 Deployment guide\u2022 Updated DELIVERABLES_CATALOG \u2022 QA report approved by stakeholder\u2022 100% requirements coverage documented\u2022 All deliverables documented\u2022 Deployment instructions verified\u2022 Sign-off obtained"},{"location":"reference/ai-navigation-matrix/#stage-transition-rules","title":"Stage Transition Rules","text":"<p>NEW: Transition rules now account for conditional sub-stages. AI must check maturity level and optional modules before proceeding.</p>"},{"location":"reference/ai-navigation-matrix/#when-to-proceed-to-next-stage","title":"When to Proceed to Next Stage","text":"From Stage To Stage Transition Criteria 0 \u2192 1 Initialization \u2192 Validation AI has loaded all framework context 1 \u2192 2 Validation \u2192 Intake All mandatory prompt fields present, maturity level selected 2 \u2192 3 Intake \u2192 Planning Requirements document approved by user 3 \u2192 4.1 Planning \u2192 Generation Implementation plan approved by user 4.1 \u2192 4.1b Infrastructure (Basic) \u2192 Dev Overrides IF maturity level \u2265 2 AND 4.1 complete 4.1b \u2192 4.1c Dev Overrides \u2192 Nginx+SSL IF maturity level \u2265 3 AND 4.1b complete 4.1c \u2192 4.1d Nginx+SSL \u2192 ELK+Replication IF maturity level = 4 AND 4.1c complete 4.1x \u2192 4.2 Infrastructure \u2192 Data All applicable infrastructure sub-stages complete 4.2 \u2192 4.2b PostgreSQL \u2192 MongoDB IF user requested MongoDB AND 4.2 complete 4.2x \u2192 4.3 Data \u2192 Business Logic All applicable data sub-stages complete 4.3 \u2192 4.3b Core Business \u2192 Logging IF maturity level \u2265 2 AND 4.3 complete 4.3b \u2192 4.3c Logging \u2192 Metrics IF maturity level \u2265 3 AND 4.3b complete 4.3c \u2192 4.3d Metrics \u2192 Auth+Tracing IF maturity level = 4 AND 4.3c complete 4.3x \u2192 4.4 Business \u2192 Workers IF user requested Workers OR proceed to 4.5 4.4 \u2192 4.4b Workers Core \u2192 Workers Logging IF maturity level \u2265 2 AND 4.4 complete 4.4x \u2192 4.5 Workers \u2192 Bot IF user requested Bot OR proceed to 4.6 4.5 \u2192 4.5b Bot Core \u2192 Bot Logging IF maturity level \u2265 2 AND 4.5 complete 4.5x \u2192 4.6 Bot \u2192 Testing All applicable service sub-stages complete 4.6 \u2192 4.6b Basic Tests \u2192 Integration Tests IF maturity level \u2265 2 AND 4.6 complete 4.6b \u2192 4.6c Integration \u2192 E2E Tests IF maturity level \u2265 3 AND 4.6b complete 4.6c \u2192 4.6d E2E \u2192 Security Tests IF maturity level = 4 AND 4.6c complete 4.6x \u2192 5 Testing \u2192 Verification All applicable test sub-stages complete 5 \u2192 6 Verification \u2192 Handoff All quality checks pass (level-specific criteria) 6 \u2192 END Handoff \u2192 Complete Stakeholder sign-off obtained"},{"location":"reference/ai-navigation-matrix/#when-to-go-back","title":"When to Go Back","text":"Failure Point Go Back To Reason Stage 2 Stage 1 Architecture conflict detected \u2192 need clarification Stage 3 Stage 2 Requirements incomplete/unclear Stage 4 Stage 3 Plan needs adjustment (e.g., missing services) Stage 5 Stage 4 Tests fail, type errors, security issues Stage 6 Stage 5 Verification criteria not met"},{"location":"reference/ai-navigation-matrix/#sub-stage-execution-logic","title":"Sub-Stage Execution Logic","text":"<p>AI Decision Tree at Stage 4:</p> <pre><code>FOR each sub-stage in [4.1, 4.1b, 4.1c, 4.1d, 4.2, 4.2b, 4.3, 4.3b, 4.3c, 4.3d, 4.4, 4.4b, 4.5, 4.5b, 4.6, 4.6b, 4.6c, 4.6d]:\n  READ \"Required At Level\" column\n\n  IF \"Required At Level\" = \"ALL\":\n    EXECUTE sub-stage (mandatory for all levels)\n\n  ELSE IF \"Required At Level\" = \"\u2265 Level X\":\n    IF user's maturity level &gt;= X:\n      EXECUTE sub-stage\n    ELSE:\n      SKIP sub-stage\n\n  ELSE IF \"Required At Level\" = \"Level X only\":\n    IF user's maturity level == X:\n      EXECUTE sub-stage\n    ELSE:\n      SKIP sub-stage\n\n  ELSE IF \"Required At Level\" = \"IF user requested [module]\":\n    IF user selected [module] in optional modules:\n      EXECUTE sub-stage\n    ELSE:\n      SKIP sub-stage\n\n  ELSE IF \"Required At Level\" contains \"AND\":\n    PARSE compound condition (e.g., \"\u2265 Level 2 AND Workers requested\")\n    IF all conditions true:\n      EXECUTE sub-stage\n    ELSE:\n      SKIP sub-stage\n</code></pre>"},{"location":"reference/ai-navigation-matrix/#document-categories-reference","title":"Document Categories Reference","text":""},{"location":"reference/ai-navigation-matrix/#atomic-documents-by-domain","title":"Atomic Documents by Domain","text":"Domain Path Pattern When to Read Architecture <code>docs/atomic/architecture/*.md</code> Stage 2 (Requirements)Stage 3 (Planning) FastAPI Services <code>docs/atomic/services/fastapi/*.md</code> Stage 3 (Planning)Stage 4.3 (Business Logic) Aiogram Services <code>docs/atomic/services/aiogram/*.md</code> Stage 3 (Planning)Stage 4.5 (Bot) AsyncIO Workers <code>docs/atomic/services/asyncio-workers/*.md</code> Stage 3 (Planning)Stage 4.4 (Workers) Data Services <code>docs/atomic/services/data-services/*.md</code> Stage 3 (Planning)Stage 4.2 (Data Layer) Redis Integration <code>docs/atomic/integrations/redis/*.md</code> Stage 3 (if Redis needed)Stage 4 (during implementation) RabbitMQ Integration <code>docs/atomic/integrations/rabbitmq/*.md</code> Stage 3 (Planning)Stage 4.3, 4.4, 4.5 (eventing) HTTP Communication <code>docs/atomic/integrations/http-communication/*.md</code> Stage 4.3 (Business Logic) Infrastructure <code>docs/atomic/infrastructure/**/*.md</code> Stage 4.1 (Infrastructure) Observability <code>docs/atomic/observability/**/*.md</code> Stage 4 (all phases - logging, metrics) Testing <code>docs/atomic/testing/**/*.md</code> Stage 4.6 (Testing)Stage 5 (Verification)"},{"location":"reference/ai-navigation-matrix/#quick-lookup-i-need-to","title":"Quick Lookup: \"I Need To...\"","text":"Task Read These Documents Generate This Use This Tool Validate a user prompt <code>docs/guides/prompt-validation-guide.md</code> Validation note or clarification <code>docs/reference/prompt-templates.md</code> Understand architecture <code>docs/guides/architecture-guide.md</code><code>docs/atomic/architecture/improved-hybrid-overview.md</code> Nothing (learning) None Structure requirements <code>docs/guides/requirements-intake-template.md</code> Completed intake doc <code>docs/reference/prompt-templates.md</code> Plan implementation <code>docs/guides/implementation-plan-template.md</code><code>docs/guides/use-case-implementation-guide.md</code> Implementation plan <code>docs/reference/agent-toolbox.md</code> Setup Docker <code>docs/atomic/infrastructure/containerization/docker-compose-setup.md</code> docker-compose.yml <code>docs/reference/agent-toolbox.md</code> Create PostgreSQL service <code>docs/atomic/services/data-services/postgres-service-setup.md</code><code>docs/atomic/databases/postgresql/sqlalchemy-integration.md</code> Models, repositories, API <code>docs/reference/agent-toolbox.md</code> Create FastAPI endpoint <code>docs/atomic/services/fastapi/routing-patterns.md</code><code>docs/atomic/services/fastapi/dependency-injection.md</code> Router + use case <code>docs/reference/agent-toolbox.md</code> Call data service from business service <code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code> HTTP client code None Publish RabbitMQ event <code>docs/atomic/integrations/rabbitmq/message-publishing.md</code> Event publisher code None Consume RabbitMQ event <code>docs/atomic/integrations/rabbitmq/message-consuming.md</code> Consumer code None Create background worker <code>docs/atomic/services/asyncio-workers/main-function-patterns.md</code> Worker main.py <code>docs/reference/agent-toolbox.md</code> Create Telegram bot <code>docs/atomic/services/aiogram/bot-initialization.md</code><code>docs/atomic/services/aiogram/handler-patterns.md</code> Bot handlers <code>docs/reference/agent-toolbox.md</code> Write tests <code>docs/atomic/testing/unit-testing/pytest-setup.md</code><code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> Test files <code>docs/reference/agent-toolbox.md</code> Run quality checks <code>docs/quality/agent-verification-checklist.md</code> Checklist results <code>docs/reference/agent-toolbox.md</code> Create QA report <code>docs/quality/qa-report-template.md</code> QA report None Troubleshoot issues <code>docs/reference/troubleshooting.md</code> Nothing (diagnosis) <code>docs/reference/agent-toolbox.md</code>"},{"location":"reference/ai-navigation-matrix/#reading-optimization-tips","title":"Reading Optimization Tips","text":""},{"location":"reference/ai-navigation-matrix/#do-not-read-everything-upfront","title":"Do NOT Read Everything Upfront","text":"<p>\u274c Anti-pattern: AI reads all 157 atomic documents at start \u2705 Correct approach: AI reads documents on-demand based on current stage</p>"},{"location":"reference/ai-navigation-matrix/#example-p2p-lending-platform","title":"Example: P2P Lending Platform","text":"<p>Stage 0-2 (Init, Validation, Intake): - Read: 5 documents (~500 lines) - Time: 2 minutes</p> <p>Stage 3 (Planning): - Read: 10 documents (~1500 lines) - only relevant services - Time: 5 minutes</p> <p>Stage 4.3 (Business Logic - FastAPI): - Read: 15 FastAPI atomic docs (~2000 lines) - Time: 7 minutes</p> <p>Total reading: ~30 documents out of 157 (82% saved!)</p>"},{"location":"reference/ai-navigation-matrix/#how-to-decide-what-to-read","title":"How to Decide What to Read","text":"<p>Use this decision tree:</p> <pre><code>\u250c\u2500 Does project need FastAPI service?\n\u2502  \u251c\u2500 YES \u2192 Read atomic/services/fastapi/* during Stage 4.3\n\u2502  \u2514\u2500 NO \u2192 Skip FastAPI docs entirely\n\u2502\n\u250c\u2500 Does project need Telegram bot?\n\u2502  \u251c\u2500 YES \u2192 Read atomic/services/aiogram/* during Stage 4.5\n\u2502  \u2514\u2500 NO \u2192 Skip Aiogram docs entirely\n\u2502\n\u250c\u2500 Does project use Redis?\n\u2502  \u251c\u2500 YES \u2192 Read atomic/integrations/redis/* during Stage 3-4\n\u2502  \u2514\u2500 NO \u2192 Skip Redis docs entirely\n\u2502\n... and so on for each technology\n</code></pre>"},{"location":"reference/ai-navigation-matrix/#reading-order-within-phase","title":"Reading Order Within Phase","text":"<p>When multiple atomic documents are listed for a single phase, read them in this recommended order:</p> <p>1. Architecture principles first (understand constraints before implementation)    - <code>docs/atomic/architecture/ddd-hexagonal-principles.md</code>    - <code>docs/atomic/architecture/service-separation-principles.md</code>    - <code>docs/atomic/architecture/data-access-architecture.md</code>    - <code>docs/atomic/architecture/naming-conventions.md</code></p> <p>2. Setup/scaffolding documents (project structure)    - <code>docs/atomic/services/fastapi/basic-setup.md</code>    - <code>docs/atomic/services/fastapi/application-factory.md</code>    - <code>docs/atomic/services/aiogram/bot-initialization.md</code>    - <code>docs/atomic/services/asyncio-workers/main-function-patterns.md</code></p> <p>3. Core implementation patterns (business logic)    - <code>docs/atomic/services/fastapi/routing-patterns.md</code>    - <code>docs/atomic/services/aiogram/handler-patterns.md</code>    - <code>docs/atomic/services/fastapi/dependency-injection.md</code>    - <code>docs/atomic/services/fastapi/schema-validation.md</code>    - <code>docs/atomic/services/data-services/repository-patterns.md</code></p> <p>4. Integration patterns (external communication)    - <code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code>    - <code>docs/atomic/integrations/rabbitmq/message-publishing.md</code>    - <code>docs/atomic/integrations/rabbitmq/message-consuming.md</code>    - <code>docs/atomic/integrations/redis/caching-patterns.md</code> (TODO: document not yet created)</p> <p>5. Advanced features (observability, security, error handling)    - <code>docs/atomic/services/aiogram/middleware-setup.md</code>    - <code>docs/atomic/services/fastapi/error-handling.md</code>    - <code>docs/atomic/observability/logging/structured-logging.md</code>    - <code>docs/atomic/observability/metrics/custom-metrics.md</code>    - <code>docs/atomic/services/fastapi/oauth-jwt.md</code> (TODO: document not yet created)</p> <p>Rationale: This order ensures AI understands: - Why before how (architecture \u2192 implementation) - Structure before details (setup \u2192 patterns) - Core before advanced (basic logic \u2192 integrations \u2192 observability)</p>"},{"location":"reference/ai-navigation-matrix/#maintenance","title":"Maintenance","text":""},{"location":"reference/ai-navigation-matrix/#updating-this-matrix","title":"Updating This Matrix","text":"<p>When framework documentation changes:</p> <ol> <li>New atomic documents added \u2192 Add row to \"Document Categories Reference\"</li> <li>Workflow stages change \u2192 Update main matrix rows</li> <li>Templates change \u2192 Update \"Templates/Tools\" column</li> <li>Success criteria change \u2192 Update \"Success Criteria\" column</li> </ol>"},{"location":"reference/ai-navigation-matrix/#cross-references","title":"Cross-References","text":"<p>Keep aligned with: - <code>docs/guides/ai-code-generation-master-workflow.md</code> (source of truth for process) - <code>docs/reference/agent-context-summary.md</code> (critical rules) - <code>INDEX.md</code> (full documentation map) - All atomic documentation (implementation rules)</p> <p>Last Updated: 2025-10-01</p>"},{"location":"reference/architecture-decision-log-template/","title":"Architecture Decision Log Template","text":"<p>Purpose: Standardize the way agents capture significant architecture decisions taken during planning or execution phases.</p>"},{"location":"reference/architecture-decision-log-template/#metadata","title":"Metadata","text":"<ul> <li>ADR ID: <code>ADR-YYYYMMDD-##</code></li> <li>Title: Concise decision statement</li> <li>Date: YYYY-MM-DD</li> <li>Authors: Names or agent identifiers</li> <li>Status: Proposed / Accepted / Deprecated / Superseded</li> </ul>"},{"location":"reference/architecture-decision-log-template/#context","title":"Context","text":"<ul> <li>Business drivers and functional requirements (link to <code>docs/guides/requirements-intake-template.md</code>).</li> <li>Non-functional constraints impacting the decision (refer to <code>docs/guides/architecture-guide.md</code> and <code>docs/atomic/architecture/</code>).</li> <li>Existing system assumptions or limitations.</li> </ul>"},{"location":"reference/architecture-decision-log-template/#decision","title":"Decision","text":"<ul> <li>Detailed description of the selected approach.</li> <li>How the decision aligns with the Improved Hybrid Approach and mandatory rules.</li> <li>References to any implementation plan stages (<code>docs/guides/implementation-plan-template.md</code>).</li> </ul>"},{"location":"reference/architecture-decision-log-template/#alternatives-considered","title":"Alternatives Considered","text":"Alternative Pros Cons Reason Rejected Example ... ... ..."},{"location":"reference/architecture-decision-log-template/#consequences","title":"Consequences","text":"<ul> <li>Positive impacts (e.g., scalability, maintainability).</li> <li>Negative trade-offs or mitigations required.</li> <li>Required updates to documentation or deliverables (e.g., <code>docs/reference/deliverables-catalog.md</code>).</li> </ul>"},{"location":"reference/architecture-decision-log-template/#follow-up-actions","title":"Follow-Up Actions","text":"<ul> <li>Tasks needed to implement or monitor the decision.</li> <li>Links to code changes, tickets, or implementation plan updates.</li> <li>Notes on future evaluation criteria.</li> </ul>"},{"location":"reference/architecture-decision-log-template/#references","title":"References","text":"<ul> <li><code>docs/guides/architecture-guide.md</code></li> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code></li> <li><code>docs/atomic/architecture/data-access-architecture.md</code></li> <li><code>docs/atomic/architecture/naming/README.md</code></li> <li><code>docs/guides/implementation-plan-template.md</code></li> </ul>"},{"location":"reference/architecture-decision-log-template/#maintenance","title":"Maintenance","text":"<ul> <li>Store ADRs in a dedicated directory (e.g., <code>artifacts/adr/</code>).</li> <li>Update status when decisions evolve or are superseded.</li> <li>Keep the index aligned with <code>docs/INDEX.md</code> and <code>docs/reference/agent-context-summary.md</code>.</li> </ul>"},{"location":"reference/conditional-stage-rules/","title":"Conditional Stage Rules","text":"<p>Purpose: Define which workflow stages and atomic documents AI must read/generate based on the selected Maturity Level. This document ensures AI generates only the appropriate complexity for each level, avoiding over-engineering while maintaining clear upgrade paths.</p>"},{"location":"reference/conditional-stage-rules/#overview","title":"Overview","text":"<p>The AI code generation workflow (Stages 0-6) remains the same across all Maturity Levels, but Stage 4 (Code Generation) becomes conditional based on the selected level. This document provides exact rules for what to include/skip at each level.</p>"},{"location":"reference/conditional-stage-rules/#core-principle","title":"Core Principle","text":"<pre><code>ALL Levels include:\n  \u251c\u2500 Stage 0: Initialization (MANDATORY)\n  \u251c\u2500 Stage 1: Prompt Validation (MANDATORY)\n  \u251c\u2500 Stage 2: Requirements Intake (MANDATORY)\n  \u251c\u2500 Stage 3: Implementation Planning (MANDATORY)\n  \u251c\u2500 Stage 4: Code Generation (CONDITIONAL \u2014 see below)\n  \u251c\u2500 Stage 5: Quality Verification (MANDATORY, criteria vary)\n  \u2514\u2500 Stage 6: QA Report &amp; Handoff (MANDATORY)\n\nThe ONLY difference between levels is Stage 4 sub-phases.\n</code></pre>"},{"location":"reference/conditional-stage-rules/#architecture-decision-records-adr-by-maturity-level","title":"Architecture Decision Records (ADR) by Maturity Level","text":"<p>Purpose: Define when AI should create ADR documents based on project maturity level and decision significance.</p>"},{"location":"reference/conditional-stage-rules/#adr-creation-policy","title":"ADR Creation Policy","text":"Maturity Level ADR Requirement When to Create Level 1-2 (PoC/Development) OPTIONAL Create ADR only for MAJOR architectural deviations:\u2022 Switching database paradigm (SQL \u2192 NoSQL)\u2022 Using different programming language\u2022 Replacing core framework component (e.g., FastAPI \u2192 Flask)\u2022 Deviating from Improved Hybrid ApproachSKIP for minor changes:\u2022 Configuration tweaks\u2022 Library version selection\u2022 Standard pattern variations Level 3-4 (Pre-Production/Production) MANDATORY Create ADR for ANY deviation from framework defaults:\u2022 Technology choice differs from <code>tech_stack.md</code>\u2022 Multiple implementation approaches exist\u2022 Custom integration pattern required\u2022 Security/compliance mandates specific approach\u2022 Performance optimization requires non-standard solutionREQUIRED for audit/compliance in regulated industries"},{"location":"reference/conditional-stage-rules/#adr-document-location","title":"ADR Document Location","text":"<ul> <li>Path: <code>docs/adr/XXX-brief-title.md</code> (where XXX = sequential number starting 001)</li> <li>Template: Use <code>docs/reference/architecture-decision-log-template.md</code></li> <li>Index: Update <code>docs/adr/README.md</code> with ADR list</li> </ul>"},{"location":"reference/conditional-stage-rules/#when-not-to-create-adr-any-level","title":"When NOT to Create ADR (Any Level)","text":"<ul> <li>Following framework defaults (e.g., PostgreSQL 16 as specified in <code>tech_stack.md</code>)</li> <li>Using standard patterns from atomic documentation (e.g., HTTP-only data access)</li> <li>Implementation details that don't affect architecture (e.g., variable naming)</li> <li>Trivial decisions easily reversible (e.g., log format JSON vs plaintext)</li> </ul>"},{"location":"reference/conditional-stage-rules/#examples","title":"Examples","text":"<p>Level 1 (PoC) \u2014 ADR Required: <pre><code>User: \"Use CockroachDB instead of PostgreSQL for geo-distribution\"\nAI: Major deviation from framework \u2192 Create ADR-001-use-cockroachdb.md\n</code></pre></p> <p>Level 1 (PoC) \u2014 ADR Not Required: <pre><code>User: \"Use Redis for session storage\"\nAI: Standard caching pattern, no ADR needed (documented in atomic/integrations/redis/)\n</code></pre></p> <p>Level 4 (Production) \u2014 ADR Required: <pre><code>User: \"Use GraphQL instead of REST for public API\"\nAI: Deviation from FastAPI REST default \u2192 Create ADR-003-graphql-api.md\n</code></pre></p>"},{"location":"reference/conditional-stage-rules/#stage-4-breakdown-by-maturity-level","title":"Stage 4 Breakdown by Maturity Level","text":""},{"location":"reference/conditional-stage-rules/#level-1-proof-of-concept-poc","title":"Level 1: Proof of Concept (PoC)","text":""},{"location":"reference/conditional-stage-rules/#sub-stages-to-execute","title":"Sub-Stages to Execute","text":"Sub-Stage Phase Action 4.1 Infrastructure EXECUTE (Basic) 4.2 Data Layer EXECUTE (PostgreSQL only) 4.3 Business Logic EXECUTE (Core only) 4.4 Background Workers CONDITIONAL (if user requested) 4.5 Telegram Bot CONDITIONAL (if user requested) 4.6 Testing EXECUTE (Complete unit tests, 60% threshold)"},{"location":"reference/conditional-stage-rules/#41-infrastructure-basic","title":"4.1: Infrastructure (Basic)","text":"<p>Documents to Read: - <code>docs/atomic/infrastructure/containerization/docker-compose-setup.md</code> - <code>docs/atomic/infrastructure/containerization/dockerfile-patterns.md</code> (single-stage only) - <code>docs/atomic/infrastructure/configuration/environment-variables.md</code></p> <p>Generate: - <code>docker-compose.yml</code> (dev only, no production config) - <code>.env.example</code> - <code>Makefile</code> (basic commands: up, down, logs) - Simple Dockerfiles (single-stage builds)</p> <p>Skip: - \u274c Nginx configuration - \u274c SSL/TLS setup - \u274c Multi-stage Docker builds - \u274c Production deployment configs - \u274c Health check probes</p>"},{"location":"reference/conditional-stage-rules/#42-data-layer-postgresql-only","title":"4.2: Data Layer (PostgreSQL only)","text":"<p>Documents to Read: - <code>docs/atomic/services/data-services/postgres-service-setup.md</code> - <code>docs/atomic/services/data-services/repository-patterns.md</code> - <code>docs/atomic/services/data-services/http-api-design.md</code> - <code>docs/atomic/databases/postgresql/sqlalchemy-integration.md</code></p> <p>Generate: - PostgreSQL data service (models, repositories, HTTP API) - Alembic migrations (basic)</p> <p>Skip: - \u274c MongoDB service - \u274c Database replication - \u274c Advanced PostgreSQL features (partitioning, etc.) - \u274c Connection pooling optimization</p>"},{"location":"reference/conditional-stage-rules/#43-business-logic-core-only","title":"4.3: Business Logic (Core only)","text":"<p>Documents to Read: - <code>docs/atomic/architecture/project-structure-patterns.md</code> (DDD/Hexagonal structure) - <code>docs/atomic/services/fastapi/application-factory.md</code> - <code>docs/atomic/services/fastapi/routing-patterns.md</code> - <code>docs/atomic/services/fastapi/dependency-injection.md</code> - <code>docs/atomic/services/fastapi/schema-validation.md</code> - <code>docs/atomic/integrations/http-communication/business-to-data-calls.md</code> - <code>docs/atomic/observability/logging/structured-logging.md</code></p> <p>Generate: - Full DDD/Hexagonal structure (<code>src/</code> with all layers: api, application, domain, infrastructure, schemas, core) - FastAPI service (routers, use cases, domain entities) - HTTP client to data service - Structured JSON logging (<code>src/core/logging.py</code> with python-json-logger) - Basic error handling</p> <p>Skip: - \u274c Request ID middleware (added in Level 2) - \u274c Health check endpoints (added in Level 2) - \u274c Prometheus metrics (added in Level 3) - \u274c Error tracking integration (Sentry - added in Level 2) - \u274c OpenAPI customization (use defaults)</p>"},{"location":"reference/conditional-stage-rules/#46-testing-basic","title":"4.6: Testing (Basic)","text":"<p>Documents to Read: - <code>docs/atomic/testing/unit-testing/pytest-setup.md</code> - <code>docs/atomic/testing/unit-testing/fixture-patterns.md</code></p> <p>Generate: - <code>pytest.ini</code> - Unit tests (core logic only)</p> <p>Skip: - \u274c Integration tests with testcontainers - \u274c Service tests (end-to-end) - \u274c Load tests - \u274c Security tests</p> <p>Quality Criteria (Stage 5): - Coverage \u2265 60% (complete code, lower threshold) - Ruff + Mypy pass - No Bandit requirement</p>"},{"location":"reference/conditional-stage-rules/#level-2-development-ready","title":"Level 2: Development Ready","text":""},{"location":"reference/conditional-stage-rules/#sub-stages-to-execute_1","title":"Sub-Stages to Execute","text":"Sub-Stage Phase Action 4.1 Infrastructure EXECUTE (+ Dev overrides) 4.2 Data Layer EXECUTE (PostgreSQL only) 4.3 Business Logic EXECUTE (+ Observability) 4.4 Background Workers CONDITIONAL (if user requested) 4.5 Telegram Bot CONDITIONAL (if user requested) 4.6 Testing EXECUTE (+ Integration tests)"},{"location":"reference/conditional-stage-rules/#41-infrastructure-dev-overrides","title":"4.1: Infrastructure (+ Dev Overrides)","text":"<p>Additional Documents: - <code>docs/atomic/infrastructure/configuration/settings-patterns.md</code></p> <p>Additional Generation: - <code>docker-compose.dev.yml</code> (dev overrides: hot reload, debug mode) - <code>docker-compose.test.yml</code> (test environment) - Docker health checks (basic)</p> <p>Still Skip: - \u274c Nginx - \u274c SSL - \u274c Production configs</p>"},{"location":"reference/conditional-stage-rules/#43-business-logic-observability","title":"4.3: Business Logic (+ Observability)","text":"<p>Additional Documents: - <code>docs/atomic/observability/logging/request-id-tracking.md</code> - <code>docs/atomic/observability/error-tracking/sentry-integration.md</code> - <code>docs/atomic/services/aiogram/middleware-setup.md</code> (adapt for FastAPI)</p> <p>Additional Generation: - Request ID middleware (<code>src/middleware/request_id.py</code>) - Update <code>src/core/logging.py</code> to include request IDs in JSON logs - Health check endpoints (<code>/health</code>, <code>/ready</code> in <code>src/api/v1/health_router.py</code>) - Error tracking integration (Sentry-ready, not deployed) - Custom OpenAPI metadata</p> <p>Note: Structured JSON logging already present from Level 1, only request ID tracking added.</p> <p>Still Skip: - \u274c Prometheus metrics - \u274c Distributed tracing - \u274c ELK stack</p>"},{"location":"reference/conditional-stage-rules/#46-testing-integration-tests","title":"4.6: Testing (+ Integration Tests)","text":"<p>Additional Documents: - <code>docs/atomic/testing/integration-testing/testcontainers-setup.md</code> - <code>docs/atomic/testing/integration-testing/database-testing.md</code></p> <p>Additional Generation: - Integration tests (with testcontainers) - <code>conftest.py</code> (shared fixtures)</p> <p>Quality Criteria (Stage 5): - Coverage \u2265 75% - Ruff + Mypy + Bandit pass</p>"},{"location":"reference/conditional-stage-rules/#level-3-pre-production","title":"Level 3: Pre-Production","text":""},{"location":"reference/conditional-stage-rules/#sub-stages-to-execute_2","title":"Sub-Stages to Execute","text":"Sub-Stage Phase Action 4.1 Infrastructure EXECUTE (+ Nginx + SSL + Metrics) 4.2 Data Layer EXECUTE (PostgreSQL only) 4.3 Business Logic EXECUTE (+ Metrics) 4.4 Background Workers CONDITIONAL (if user requested) 4.5 Telegram Bot CONDITIONAL (if user requested) 4.6 Testing EXECUTE (+ Service tests + Load tests)"},{"location":"reference/conditional-stage-rules/#41-infrastructure-nginx-ssl-metrics","title":"4.1: Infrastructure (+ Nginx + SSL + Metrics)","text":"<p>Additional Documents: - <code>docs/atomic/infrastructure/api-gateway/nginx-setup.md</code> - <code>docs/atomic/infrastructure/api-gateway/ssl-configuration.md</code> - <code>docs/atomic/infrastructure/api-gateway/load-balancing.md</code> - <code>docs/atomic/infrastructure/api-gateway/security-hardening.md</code> (basic) - <code>docs/atomic/infrastructure/containerization/multi-stage-builds.md</code> - <code>docs/atomic/observability/metrics/prometheus-setup.md</code> - <code>docs/atomic/observability/metrics/dashboards.md</code></p> <p>Additional Generation: - Nginx configuration (reverse proxy, rate limiting, CORS) - SSL/TLS setup (Let's Encrypt instructions) - Multi-stage Dockerfiles (optimized images) - <code>docker-compose.prod.yml</code> (production config) - Prometheus + Grafana stack - Basic dashboards (API overview) - Alerting rules (basic thresholds)</p> <p>Still Skip: - \u274c Jaeger tracing - \u274c ELK stack - \u274c Advanced security (OAuth, RBAC) - \u274c Database replication</p>"},{"location":"reference/conditional-stage-rules/#43-business-logic-metrics","title":"4.3: Business Logic (+ Metrics)","text":"<p>Additional Documents: - <code>docs/atomic/observability/metrics/service-metrics.md</code> - <code>docs/atomic/observability/metrics/custom-metrics.md</code></p> <p>Additional Generation: - Prometheus metrics endpoints - Custom metrics (request duration, error rates) - Metrics middleware</p> <p>Still Skip: - \u274c Distributed tracing - \u274c OAuth/JWT - \u274c RBAC - \u274c Circuit breakers</p>"},{"location":"reference/conditional-stage-rules/#46-testing-service-tests-load-tests","title":"4.6: Testing (+ Service Tests + Load Tests)","text":"<p>Additional Documents: - <code>docs/atomic/testing/service-testing/fastapi-testing-patterns.md</code> - <code>docs/atomic/testing/end-to-end-testing/user-journey-testing.md</code> - <code>docs/atomic/testing/end-to-end-testing/performance-testing.md</code></p> <p>Additional Generation: - Service tests (end-to-end) - Load test scripts (basic)</p> <p>Quality Criteria (Stage 5): - Coverage \u2265 80% - Ruff + Mypy + Bandit pass - Load test baseline established</p>"},{"location":"reference/conditional-stage-rules/#level-4-production","title":"Level 4: Production","text":""},{"location":"reference/conditional-stage-rules/#sub-stages-to-execute-all","title":"Sub-Stages to Execute (ALL)","text":"Sub-Stage Phase Action 4.1 Infrastructure EXECUTE (Full: Nginx + SSL + ELK + Jaeger + HA) 4.2 Data Layer EXECUTE (+ Replication) 4.3 Business Logic EXECUTE (Full: OAuth + RBAC + Tracing + Resilience) 4.4 Background Workers CONDITIONAL (if user requested) 4.5 Telegram Bot CONDITIONAL (if user requested) 4.6 Testing EXECUTE (Full: Security + E2E + Load) 4.7 CI/CD EXECUTE (NEW: Automated pipelines) 4.8 Documentation EXECUTE (NEW: ADRs + Runbooks)"},{"location":"reference/conditional-stage-rules/#41-infrastructure-full-stack","title":"4.1: Infrastructure (Full Stack)","text":"<p>Additional Documents: - <code>docs/atomic/observability/elk-stack/elasticsearch-setup.md</code> - <code>docs/atomic/observability/elk-stack/logstash-configuration.md</code> - <code>docs/atomic/observability/elk-stack/kibana-dashboards.md</code> - <code>docs/atomic/observability/tracing/jaeger-configuration.md</code> - <code>docs/atomic/infrastructure/databases/postgresql-replication.md</code> - <code>docs/atomic/infrastructure/deployment/production-deployment.md</code></p> <p>Additional Generation: - ELK Stack configuration - Jaeger distributed tracing - Database replication setup (master-slave) - Backup scripts (automated) - Disaster recovery documentation</p>"},{"location":"reference/conditional-stage-rules/#42-data-layer-replication","title":"4.2: Data Layer (+ Replication)","text":"<p>Additional Documents: - <code>docs/atomic/infrastructure/databases/postgresql-replication.md</code> (covers replication strategies) - <code>docs/atomic/file-storage/backup-strategies.md</code> (adapt for PostgreSQL backups)</p> <p>Additional Generation: - PostgreSQL replication config - Automated backup scripts - Point-in-time recovery setup</p>"},{"location":"reference/conditional-stage-rules/#43-business-logic-full-security-tracing","title":"4.3: Business Logic (Full Security + Tracing)","text":"<p>Additional Documents: - <code>docs/atomic/security/authentication-authorization-guide.md</code> - <code>docs/atomic/security/authorization-patterns.md</code> (RBAC) - <code>docs/atomic/security/session-management-patterns.md</code> - <code>docs/atomic/observability/tracing/jaeger-configuration.md</code> - <code>docs/atomic/services/fastapi/security-patterns.md</code> - <code>docs/atomic/integrations/cross-service/circuit-breaker-patterns.md</code> (TODO: document not yet created)</p> <p>Additional Generation: - OAuth 2.0 / JWT authentication - RBAC implementation (roles, permissions) - Session management (distributed) - Distributed tracing integration - Circuit breakers - Security headers middleware - Secrets management integration (Vault-ready) - Audit logging</p>"},{"location":"reference/conditional-stage-rules/#46-testing-full-suite","title":"4.6: Testing (Full Suite)","text":"<p>Additional Documents: - <code>docs/atomic/security/security-testing-guide.md</code> - All testing documents (comprehensive coverage)</p> <p>Additional Generation: - Security tests (OWASP) - Performance tests (comprehensive) - Chaos engineering tests (basic)</p> <p>Quality Criteria (Stage 5): - Coverage \u2265 85% - Ruff + Mypy + Bandit (strict) pass - Security scan (0 high severity) - Load tests pass (defined SLAs)</p>"},{"location":"reference/conditional-stage-rules/#47-cicd-new","title":"4.7: CI/CD (NEW)","text":"<p>Documents to Read: - <code>docs/atomic/infrastructure/deployment/ci-cd-patterns.md</code></p> <p>Generate: - <code>.github/workflows/ci.yml</code> (or <code>.gitlab-ci.yml</code>) - Automated testing pipeline - Security scanning pipeline - Deployment pipelines (staging + production) - Rollback procedures</p>"},{"location":"reference/conditional-stage-rules/#48-documentation-new","title":"4.8: Documentation (NEW)","text":"<p>Documents to Read: - <code>docs/reference/architecture-decision-log-template.md</code></p> <p>Generate: - ADRs (for major decisions made during generation) - Runbooks (incident response procedures) - Deployment guide (comprehensive) - Monitoring guide (alert responses)</p>"},{"location":"reference/conditional-stage-rules/#optional-modules-implementation","title":"Optional Modules Implementation","text":"<p>The following modules can be requested at any maturity level and are implemented as additional sub-stages during Stage 4. AI must check if user requested these modules during Stage 1 (Prompt Validation).</p>"},{"location":"reference/conditional-stage-rules/#4x-file-storage-module-conditional","title":"4.X: File Storage Module (CONDITIONAL)","text":"<p>When: If user requested File Storage (S3/MinIO, file uploads, media processing)</p> <p>Documents to Read: - <code>docs/atomic/file-storage/upload-patterns.md</code> - <code>docs/atomic/file-storage/cloud-integration.md</code> - <code>docs/atomic/file-storage/media-processing.md</code> (if media processing needed) - <code>docs/atomic/file-storage/cdn-integration.md</code> (if Level \u2265 3) - <code>docs/atomic/file-storage/backup-strategies.md</code> (if Level = 4)</p> <p>Generate: - File upload service (FastAPI endpoints for multipart upload) - Storage adapter layer (S3/MinIO/local filesystem abstraction) - File validation (size limits, MIME type checking, virus scanning) - File metadata storage (PostgreSQL schema for file records) - Pre-signed URLs (secure direct uploads)</p> <p>Additional for Level \u2265 2: - Structured logging for upload events - Health checks for storage connectivity</p> <p>Additional for Level \u2265 3: - CDN integration (CloudFront/CloudFlare) - Image optimization (thumbnail generation, compression)</p> <p>Additional for Level = 4: - Automated backup to secondary storage - Encryption at rest (AWS KMS, server-side encryption) - Access control (presigned URLs with expiration) - Audit logging (who uploaded/downloaded what)</p> <p>Testing: - Unit tests for storage adapter - Integration tests with testcontainers (MinIO) - Upload/download E2E tests</p> <p>Example Use Case: User wants to allow profile picture uploads, document attachments, or media gallery.</p>"},{"location":"reference/conditional-stage-rules/#4y-real-time-communication-module-conditional","title":"4.Y: Real-Time Communication Module (CONDITIONAL)","text":"<p>When: If user requested Real-Time features (WebSockets, Server-Sent Events, Push Notifications)</p> <p>Documents to Read: - <code>docs/atomic/real-time/websocket-patterns.md</code> - <code>docs/atomic/real-time/sse-implementation.md</code> - <code>docs/atomic/real-time/push-notifications.md</code> (if mobile push needed) - <code>docs/atomic/real-time/real-time-sync-patterns.md</code></p> <p>Generate: - WebSocket endpoints (FastAPI WebSocket routes) - Connection manager (track active connections, broadcast) - Event broadcaster (RabbitMQ \u2192 WebSocket bridge) - SSE endpoints (alternative to WebSockets for simpler cases) - Redis pub/sub integration (for scaling across multiple instances)</p> <p>Additional for Level \u2265 2: - Connection lifecycle logging (connect/disconnect events) - Heartbeat/ping-pong keep-alive</p> <p>Additional for Level \u2265 3: - Nginx WebSocket proxying configuration - Rate limiting (connections per IP) - Metrics (active connections, messages/sec)</p> <p>Additional for Level = 4: - JWT authentication for WebSocket connections - Message encryption (end-to-end) - Connection recovery patterns - Push notifications (FCM/APNs integration)</p> <p>Testing: - WebSocket connection tests - Message broadcast tests - Reconnection handling tests</p> <p>Example Use Case: User wants live chat, real-time notifications, collaborative editing, or live dashboards.</p>"},{"location":"reference/conditional-stage-rules/#4z-payment-gateway-integration-module-conditional","title":"4.Z: Payment Gateway Integration Module (CONDITIONAL)","text":"<p>When: If user requested Payment processing (Stripe, PayPal, cryptocurrency, invoicing)</p> <p>Documents to Read: - <code>docs/atomic/external-integrations/payment-gateways.md</code> - <code>docs/atomic/external-integrations/webhook-handling.md</code> - <code>docs/atomic/security/session-management-patterns.md</code> (for payment session security)</p> <p>Generate: - Payment service wrapper (Stripe/PayPal SDK integration) - Payment intent/session creation (FastAPI endpoints) - Webhook handlers (payment confirmation, refunds, disputes) - Payment state machine (pending \u2192 processing \u2192 completed/failed) - Idempotency keys (prevent duplicate charges) - Payment history storage (PostgreSQL schema: payments, transactions, refunds)</p> <p>Additional for Level \u2265 2: - Payment event logging (structured logs for auditing) - Webhook signature verification</p> <p>Additional for Level \u2265 3: - PCI-DSS compliance notes (no card data storage) - Rate limiting on payment endpoints - Fraud detection hooks (basic rules)</p> <p>Additional for Level = 4: - Full audit logging (all payment events, user actions) - Encryption for sensitive payment metadata - Multi-currency support - Reconciliation reports (automated daily) - Webhook retry logic with exponential backoff - Circuit breakers for payment gateway calls - Fallback to secondary gateway (if primary fails)</p> <p>Testing: - Payment flow tests (mock Stripe/PayPal) - Webhook verification tests - Idempotency tests (duplicate request handling) - Refund flow tests</p> <p>Example Use Case: User wants e-commerce checkout, subscription billing, marketplace payments, or donation processing.</p>"},{"location":"reference/conditional-stage-rules/#4a-communication-apis-module-conditional","title":"4.A: Communication APIs Module (CONDITIONAL)","text":"<p>When: If user requested Email/SMS/Voice communication (Twilio, SendGrid, AWS SES)</p> <p>Documents to Read: - <code>docs/atomic/external-integrations/communication-apis.md</code> - <code>docs/atomic/observability/logging/sensitive-data-handling.md</code> (for PII in logs)</p> <p>Generate: - Email service adapter (SendGrid/SES integration) - SMS service adapter (Twilio integration) - Template rendering (Jinja2 for email/SMS templates) - Message queue integration (RabbitMQ for async sending) - Delivery status tracking (webhooks from providers) - Storage (MongoDB for sent message history)</p> <p>Additional for Level \u2265 2: - Structured logging (omit sensitive data like phone numbers) - Retry logic for failed sends</p> <p>Additional for Level \u2265 3: - Rate limiting (prevent spam) - Metrics (emails sent, SMS delivered, failures)</p> <p>Additional for Level = 4: - User preferences (opt-out, frequency limits) - GDPR compliance (consent tracking, deletion) - Email verification (double opt-in) - Bounce/complaint handling - Cost tracking (per provider)</p> <p>Testing: - Mock email/SMS sending tests - Template rendering tests - Webhook handling tests (delivery status)</p> <p>Example Use Case: User wants password reset emails, order confirmations, 2FA SMS, or transactional notifications.</p>"},{"location":"reference/conditional-stage-rules/#module-dependency-graph-execution-order","title":"Module Dependency Graph &amp; Execution Order","text":"<p>Purpose: Define dependencies between optional modules and compute correct execution order to prevent broken integrations.</p>"},{"location":"reference/conditional-stage-rules/#module-dependencies","title":"Module Dependencies","text":"<p>Optional modules may depend on each other or on infrastructure components. AI must analyze requested modules and resolve dependencies before execution.</p>"},{"location":"reference/conditional-stage-rules/#dependency-matrix","title":"Dependency Matrix","text":"Module Depends On Rationale File Storage None Independent module, only needs FastAPI core Communication APIs \u2022 Workers (recommended)\u2022 RabbitMQ (if async sending) Email/SMS sending should be async to avoid blocking API requests Payment Gateway \u2022 Workers (required)\u2022 Communication APIs (recommended)\u2022 RabbitMQ Payment processing is async, email receipts improve UX Real-Time Communication \u2022 Workers (required)\u2022 Redis (required for scaling) WebSocket event broadcasting needs Workers, Redis for multi-instance Background Workers \u2022 RabbitMQ (required) Workers consume events from RabbitMQ queues Telegram Bot \u2022 RabbitMQ (recommended) Bot listens to events for notifications"},{"location":"reference/conditional-stage-rules/#dependency-graph-visualization","title":"Dependency Graph Visualization","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 CORE (Always Present)                                       \u2502\n\u2502 \u251c\u2500 Infrastructure (4.1)                                     \u2502\n\u2502 \u251c\u2500 Data Layer (4.2): PostgreSQL / MongoDB                  \u2502\n\u2502 \u2514\u2500 Business Logic (4.3): FastAPI                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                 \u2502                 \u2502                  \u2502\n    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 File   \u2502      \u2502 Workers  \u2502     \u2502 Telegram \u2502      \u2502  Redis   \u2502\n    \u2502Storage \u2502      \u2502   (4.4)  \u2502     \u2502Bot (4.5) \u2502      \u2502(infra 4.2)\u2502\n    \u2502 (4.X)  \u2502      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502        \u2502           \u2502                \u2502                 \u2502\n    \u2502(indep) \u2502           \u2502                \u2502                 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502                \u2502                 \u2502\n                         \u2502                \u2502                 \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n              \u2502          \u2502                                  \u2502\n              \u2502      \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n              \u2502      \u2502Communication \u2502                       \u2502\n              \u2502      \u2502   APIs (4.A) \u2502                       \u2502\n              \u2502      \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n              \u2502          \u2502                                  \u2502\n         \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2510\n         \u2502   Payment Gateway    \u2502      \u2502   Real-Time       \u2502\n         \u2502       (4.Z)          \u2502      \u2502 Communication(4.Y)\u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/conditional-stage-rules/#dependency-resolution-algorithm","title":"Dependency Resolution Algorithm","text":"<p>When user requests multiple modules, AI must:</p> <ol> <li> <p>Parse Requested Modules <pre><code>Example: User requests [\"Payment Gateway\", \"Real-Time Communication\", \"File Storage\"]\n</code></pre></p> </li> <li> <p>Build Dependency List <pre><code>Payment Gateway \u2192 requires Workers, Communication APIs\nReal-Time Communication \u2192 requires Workers, Redis\nFile Storage \u2192 no dependencies\n</code></pre></p> </li> <li> <p>Resolve Transitive Dependencies <pre><code>Communication APIs \u2192 requires Workers\nWorkers \u2192 requires RabbitMQ\n\nFinal dependency chain:\n- RabbitMQ (infrastructure)\n- Workers (consumes from RabbitMQ)\n- Communication APIs (uses Workers for async sending)\n- Payment Gateway (uses Workers + Communication APIs)\n- Real-Time Communication (uses Workers + Redis)\n- File Storage (independent)\n</code></pre></p> </li> <li> <p>Topological Sort (execution order)    <pre><code>Result:\n1. Infrastructure (Core) \u2192 includes Redis setup\n2. Data Layer (Core)\n3. Business Logic (Core)\n4. Workers (dependency for Payment, Real-Time, Communication)\n5. Communication APIs (dependency for Payment)\n6. File Storage (independent, can run anytime after Core)\n7. Payment Gateway (all dependencies met)\n8. Real-Time Communication (all dependencies met)\n9. Testing (all modules)\n</code></pre></p> </li> </ol>"},{"location":"reference/conditional-stage-rules/#automatic-dependency-injection","title":"Automatic Dependency Injection","text":"<p>If user requests a module that has dependencies, AI must automatically include the dependencies:</p> User Requests AI Auto-Includes User Notification \"Payment Gateway\" Workers, Communication APIs, RabbitMQ \u26a0\ufe0f \"Payment Gateway requires Workers and Communication APIs. Auto-including these modules.\" \"Real-Time Communication\" Workers, Redis, RabbitMQ \u26a0\ufe0f \"Real-Time Communication requires Workers and Redis. Auto-including these modules.\" \"Communication APIs\" Workers (recommended), RabbitMQ \u26a0\ufe0f \"Communication APIs work best with async Workers. Auto-including Workers module.\" <p>User Override: User can explicitly say \"no Workers\" \u2192 AI warns about synchronous limitations: <pre><code>\u26a0\ufe0f Warning: Communication APIs without Workers will send emails/SMS synchronously,\n   blocking API requests. This may cause timeouts for slow email providers.\n\n   Recommendation: Include Workers for production use.\n\n   Proceed without Workers? (yes/no)\n</code></pre></p>"},{"location":"reference/conditional-stage-rules/#execution-order-computed","title":"Execution Order (Computed)","text":"<p>AI follows this algorithm for Stage 4 execution:</p> <pre><code>def compute_execution_order(user_modules: list, maturity_level: int) -&gt; list:\n    \"\"\"\n    Compute correct execution order for Stage 4 sub-stages.\n\n    Returns ordered list of sub-stages to execute.\n    \"\"\"\n    # Core modules (always present)\n    stages = [\n        \"4.1: Infrastructure (Basic)\",\n        \"4.1b: Dev Overrides\" if maturity_level &gt;= 2 else None,\n        \"4.1c: Nginx + SSL + Metrics\" if maturity_level &gt;= 3 else None,\n        \"4.1d: ELK + Replication\" if maturity_level == 4 else None,\n        \"4.2: Data Layer (PostgreSQL)\",\n        \"4.2b: MongoDB\" if \"MongoDB\" in user_modules else None,\n        \"4.3: Business Logic (Core)\",\n        \"4.3b: Structured Logging\" if maturity_level &gt;= 2 else None,\n        \"4.3c: Prometheus Metrics\" if maturity_level &gt;= 3 else None,\n        \"4.3d: OAuth/JWT + Tracing\" if maturity_level == 4 else None,\n    ]\n\n    # Resolve dependencies\n    required_modules = set(user_modules)\n\n    if \"Payment Gateway\" in required_modules:\n        required_modules.add(\"Workers\")\n        required_modules.add(\"Communication APIs\")\n        required_modules.add(\"RabbitMQ\")\n\n    if \"Real-Time Communication\" in required_modules:\n        required_modules.add(\"Workers\")\n        required_modules.add(\"Redis\")\n        required_modules.add(\"RabbitMQ\")\n\n    if \"Communication APIs\" in required_modules:\n        required_modules.add(\"Workers\")  # Recommended\n        required_modules.add(\"RabbitMQ\")\n\n    if \"Workers\" in required_modules or \"Telegram Bot\" in required_modules:\n        required_modules.add(\"RabbitMQ\")\n\n    # Add optional modules in dependency order\n    if \"Workers\" in required_modules:\n        stages.append(\"4.4: Background Workers\")\n        if maturity_level &gt;= 2:\n            stages.append(\"4.4b: Worker Logging\")\n\n    if \"Telegram Bot\" in required_modules:\n        stages.append(\"4.5: Telegram Bot\")\n        if maturity_level &gt;= 2:\n            stages.append(\"4.5b: Bot Logging\")\n\n    # Independent modules (can run anytime after core)\n    if \"File Storage\" in required_modules:\n        stages.append(\"4.X: File Storage\")\n\n    # Dependent modules (after Workers)\n    if \"Communication APIs\" in required_modules:\n        stages.append(\"4.A: Communication APIs\")\n\n    if \"Payment Gateway\" in required_modules:\n        stages.append(\"4.Z: Payment Gateway Integration\")\n\n    if \"Real-Time Communication\" in required_modules:\n        stages.append(\"4.Y: Real-Time Communication\")\n\n    # Testing (always last in Stage 4)\n    stages.append(\"4.6: Testing (Basic)\")\n    if maturity_level &gt;= 2:\n        stages.append(\"4.6b: Integration Tests\")\n    if maturity_level &gt;= 3:\n        stages.append(\"4.6c: E2E Tests\")\n    if maturity_level == 4:\n        stages.append(\"4.6d: Security Tests\")\n\n    # Level 4 only\n    if maturity_level == 4:\n        stages.append(\"4.7: CI/CD\")\n        stages.append(\"4.8: Documentation\")\n\n    # Filter out None values\n    return [s for s in stages if s is not None]\n</code></pre>"},{"location":"reference/conditional-stage-rules/#example-execution-sequences","title":"Example Execution Sequences","text":""},{"location":"reference/conditional-stage-rules/#example-1-user-requests-payment-gateway-level-3","title":"Example 1: User Requests \"Payment Gateway\" (Level 3)","text":"<p>User Input: - Maturity Level: 3 (Pre-Production) - Optional Modules: Payment Gateway</p> <p>AI Dependency Resolution: <pre><code>Payment Gateway \u2192 requires Workers, Communication APIs\nCommunication APIs \u2192 requires Workers (already resolved)\nWorkers \u2192 requires RabbitMQ\n</code></pre></p> <p>Auto-Included Modules: Workers, Communication APIs, RabbitMQ</p> <p>User Notification: <pre><code>\u2139\ufe0f Dependency Resolution:\n   \u2022 You requested: Payment Gateway\n   \u2022 Auto-including: Workers, Communication APIs, RabbitMQ\n   \u2022 Reason: Payment processing requires async workers and email receipts\n   \u2022 Total modules: 4\n</code></pre></p> <p>Execution Order: <pre><code>\u2705 4.1: Infrastructure (+ Nginx, SSL, Metrics, RabbitMQ)\n\u2705 4.2: PostgreSQL\n\u2705 4.3: Business Logic (+ Logging, Metrics)\n\u2705 4.4: Background Workers (payment processor)\n\u2705 4.A: Communication APIs (email receipts)\n\u2705 4.Z: Payment Gateway Integration\n\u2705 4.6: Testing (unit, integration, e2e)\n</code></pre></p>"},{"location":"reference/conditional-stage-rules/#example-2-user-requests-real-time-file-storage-level-4","title":"Example 2: User Requests \"Real-Time + File Storage\" (Level 4)","text":"<p>User Input: - Maturity Level: 4 (Production) - Optional Modules: Real-Time Communication, File Storage</p> <p>AI Dependency Resolution: <pre><code>Real-Time Communication \u2192 requires Workers, Redis\nFile Storage \u2192 no dependencies\n</code></pre></p> <p>Auto-Included Modules: Workers, Redis, RabbitMQ</p> <p>Execution Order: <pre><code>\u2705 4.1: Infrastructure (+ Nginx, SSL, ELK, Replication, Redis)\n\u2705 4.2: PostgreSQL (with replication)\n\u2705 4.3: Business Logic (+ Logging, Metrics, OAuth, Tracing)\n\u2705 4.4: Background Workers (WebSocket event broadcasters)\n\u2705 4.X: File Storage (independent)\n\u2705 4.Y: Real-Time Communication (WebSockets + Redis pub/sub)\n\u2705 4.6: Testing (unit, integration, e2e, security)\n\u2705 4.7: CI/CD\n\u2705 4.8: Documentation (ADRs, Runbooks)\n</code></pre></p>"},{"location":"reference/conditional-stage-rules/#conflict-detection","title":"Conflict Detection","text":"<p>If user requests conflicting modules or configurations:</p> Conflict Detection AI Action \"No Workers\" but requests \"Payment Gateway\" Payment requires Workers ERROR: \"Payment Gateway requires Workers. Cannot proceed without Workers. Please either: (1) Include Workers, or (2) Remove Payment Gateway.\" \"No RabbitMQ\" but requests \"Workers\" Workers require RabbitMQ ERROR: \"Workers require RabbitMQ for event consumption. Auto-including RabbitMQ.\" Multiple payment gateways requested E.g., \"Stripe\" and \"PayPal\" OK: Generate adapters for both, document in ADR"},{"location":"reference/conditional-stage-rules/#benefits-of-dependency-resolution","title":"Benefits of Dependency Resolution","text":"<p>\u2705 Correctness: Modules always have their dependencies available \u2705 User Experience: AI explains what it's including and why \u2705 Flexibility: User can override if they understand implications \u2705 Scalability: Easy to add new modules with dependencies</p> <p>Previous Simple Ordering (Deprecated):</p> <p>The original simple ordering (4.1 \u2192 4.2 \u2192 4.3 \u2192 4.4 \u2192 4.5 \u2192 4.X \u2192 4.Y \u2192 4.Z \u2192 4.A \u2192 4.6) is replaced by the dependency resolution algorithm above. The new approach ensures correct ordering regardless of which modules user requests.</p>"},{"location":"reference/conditional-stage-rules/#decision-tree-for-ai","title":"Decision Tree for AI","text":"<pre><code>1. User selects Maturity Level \u2192 Store in Requirements Intake\n\n2. At Stage 3 (Planning):\n   - Read maturity-levels.md\n   - Read this document (conditional-stage-rules.md)\n   - Generate Implementation Plan with ONLY relevant phases\n\n3. At Stage 4 (Code Generation):\n   FOR each sub-stage (4.1, 4.2, 4.3, etc.):\n     IF sub-stage is MANDATORY for this level:\n       - Read documents listed for this level\n       - Generate artifacts listed for this level\n       - Run validation checks\n     ELSE IF sub-stage is CONDITIONAL:\n       IF user requested this module (e.g., Workers, Bot):\n         - Execute sub-stage\n       ELSE:\n         - Skip sub-stage, mark as \"Not Requested\"\n     ELSE:\n       - Skip sub-stage entirely\n\n4. At Stage 5 (Verification):\n   - Use quality criteria specific to this level\n   - Adjust coverage thresholds\n   - Run security scans only if Level \u2265 2\n\n5. At Stage 6 (QA Report):\n   - Document which level was generated\n   - List upgrade path to next level\n</code></pre>"},{"location":"reference/conditional-stage-rules/#stage-transition-rules-updated","title":"Stage Transition Rules (Updated)","text":""},{"location":"reference/conditional-stage-rules/#when-to-proceed-to-next-sub-stage","title":"When to Proceed to Next Sub-Stage","text":"From To Condition 4.1 \u2192 4.2 Infrastructure \u2192 Data Docker services healthy 4.2 \u2192 4.3 Data \u2192 Business Data service HTTP APIs functional 4.3 \u2192 4.4 Business \u2192 Workers API endpoints working OR Workers not needed (skip to 4.5) 4.4 \u2192 4.5 Workers \u2192 Bot Workers functional OR Bot not needed (skip to 4.6) 4.5 \u2192 4.6 Bot \u2192 Testing Bot functional OR Bot not needed 4.6 \u2192 4.7 Testing \u2192 CI/CD All tests pass AND Level = 4 OR Level &lt; 4 (skip to Stage 5) 4.7 \u2192 4.8 CI/CD \u2192 Documentation Pipelines configured AND Level = 4 OR skip to Stage 5 4.8 \u2192 5 Documentation \u2192 Verification ADRs + Runbooks created OR Level &lt; 4"},{"location":"reference/conditional-stage-rules/#examples-stage-4-execution-by-level","title":"Examples: Stage 4 Execution by Level","text":""},{"location":"reference/conditional-stage-rules/#example-1-level-1-poc-simple-rest-api","title":"Example 1: Level 1 (PoC) \u2014 Simple REST API","text":"<p>User Selection: - Maturity Level: 1 (PoC) - Optional Modules: None</p> <p>Stage 4 Execution: <pre><code>\u2705 4.1: Infrastructure (Basic)\n   - Generated: docker-compose.yml, .env, Makefile, simple Dockerfiles\n   - Skipped: Nginx, SSL, multi-stage builds\n\n\u2705 4.2: Data Layer (PostgreSQL)\n   - Generated: PostgreSQL service, models, repositories, API\n   - Skipped: MongoDB, replication\n\n\u2705 4.3: Business Logic (Core)\n   - Generated: FastAPI service, routers, domain logic, HTTP client\n   - Skipped: Structured logging, metrics, health checks\n\n\u23ed\ufe0f  4.4: SKIPPED (Workers not requested)\n\n\u23ed\ufe0f  4.5: SKIPPED (Bot not requested)\n\n\u2705 4.6: Testing (Basic)\n   - Generated: Unit tests\n   - Skipped: Integration tests, load tests\n\n\u2192 Proceed to Stage 5 (Verification with 60% coverage target)\n</code></pre></p> <p>Total Time: ~5 minutes</p>"},{"location":"reference/conditional-stage-rules/#example-2-level-3-pre-production-workers-rabbitmq","title":"Example 2: Level 3 (Pre-Production) + Workers + RabbitMQ","text":"<p>User Selection: - Maturity Level: 3 (Pre-Production) - Optional Modules: Background Workers, RabbitMQ</p> <p>Stage 4 Execution: <pre><code>\u2705 4.1: Infrastructure (Full for Level 3)\n   - Generated: docker-compose.yml, docker-compose.prod.yml, Nginx, SSL,\n                multi-stage Dockerfiles, Prometheus, Grafana\n   - Skipped: ELK, Jaeger, CI/CD\n\n\u2705 4.2: Data Layer (PostgreSQL)\n   - Generated: PostgreSQL service with optimization\n   - Skipped: Replication (Level 4 only)\n\n\u2705 4.3: Business Logic (+ Observability + Metrics)\n   - Generated: FastAPI, structured logging, health checks, Prometheus metrics,\n                RabbitMQ publisher\n   - Skipped: OAuth, RBAC, tracing, circuit breakers\n\n\u2705 4.4: Background Workers (User requested)\n   - Generated: AsyncIO workers, RabbitMQ consumers, task management\n   - Read: docs/atomic/services/asyncio-workers/*\n   - Read: docs/atomic/integrations/rabbitmq/*\n\n\u23ed\ufe0f  4.5: SKIPPED (Bot not requested)\n\n\u2705 4.6: Testing (+ Service tests + Load tests)\n   - Generated: Unit, integration, service, load tests\n   - Skipped: Security tests (Level 4 only)\n\n\u2192 Proceed to Stage 5 (Verification with 80% coverage target)\n</code></pre></p> <p>Total Time: ~17 minutes</p>"},{"location":"reference/conditional-stage-rules/#example-3-level-4-production-full-stack","title":"Example 3: Level 4 (Production) \u2014 Full Stack","text":"<p>User Selection: - Maturity Level: 4 (Production) - Optional Modules: All available</p> <p>Stage 4 Execution: <pre><code>\u2705 4.1: Infrastructure (Full Stack)\n   - Generated: Everything from Level 3 + ELK + Jaeger + DB replication + backups\n\n\u2705 4.2: Data Layer (+ Replication)\n   - Generated: PostgreSQL service with master-slave replication, automated backups\n\n\u2705 4.3: Business Logic (Full Security + Tracing)\n   - Generated: Everything from Level 3 + OAuth + RBAC + tracing + circuit breakers\n\n\u2705 4.4: Background Workers (if requested)\n   - Generated: Full workers with resilience patterns\n\n\u2705 4.5: Telegram Bot (if requested)\n   - Generated: Full bot with security\n\n\u2705 4.6: Testing (Full Suite)\n   - Generated: Unit + integration + service + security + load + chaos tests\n\n\u2705 4.7: CI/CD (NEW at Level 4)\n   - Generated: GitHub Actions workflows (CI + security + deploy)\n\n\u2705 4.8: Documentation (NEW at Level 4)\n   - Generated: ADRs + Runbooks + Deployment guides\n\n\u2192 Proceed to Stage 5 (Verification with 85% coverage target + strict security)\n</code></pre></p> <p>Total Time: ~32 minutes</p>"},{"location":"reference/conditional-stage-rules/#maintenance","title":"Maintenance","text":"<ul> <li>Update this document when new sub-stages are added to Stage 4.</li> <li>Keep synchronized with <code>maturity-levels.md</code> feature matrix.</li> <li>Ensure atomic documentation paths are accurate.</li> <li>Follow <code>STYLE_GUIDE.md</code> for formatting.</li> </ul>"},{"location":"reference/deliverables-catalog/","title":"Deliverables Catalog","text":"<p>Purpose: Define the standard artefacts produced during an agent-led delivery. Use this catalog to confirm expectations and storage locations.</p>"},{"location":"reference/deliverables-catalog/#core-deliverables","title":"Core Deliverables","text":"Deliverable Description Produced During Validation Method Storage / Path Source Template Prompt Validation Record Confirmation that all critical prompt fields are present. Prompt Validation Manual check per <code>docs/guides/prompt-validation-guide.md</code> Include in Requirements Intake notes <code>docs/guides/prompt-validation-guide.md</code> Requirements Intake Document Structured capture of business, functional, and non-functional inputs. Requirements Intake Review completeness vs. template Project docs (e.g., <code>artifacts/requirements/</code>) <code>docs/guides/requirements-intake-template.md</code> Implementation Plan Detailed plan with stages, DoD, and references. Planning Reviewer sign-off, alignment with architecture rules Project docs (e.g., <code>artifacts/plans/</code>) <code>docs/guides/implementation-plan-template.md</code> Architecture Decision Record (optional) Formalised decision for significant architectural choices. Planning / Execution Peer review, compliance with architecture guide Project docs (e.g., <code>artifacts/adr/</code>) <code>docs/reference/architecture-decision-log-template.md</code> Generated Code &amp; Config Service implementations, infrastructure, shared components. Implementation Testing &amp; verification gates Application repository (<code>src/</code>, configs) Framework rules Test Artefacts Unit/integration tests, coverage reports. Verification Thresholds in <code>docs/atomic/testing/</code> <code>htmlcov/</code>, <code>coverage.xml</code>, CI artefacts Testing standards Verification Checklist Result Completed checklist with statuses and evidence. Verification Sign-off via <code>docs/quality/agent-verification-checklist.md</code> <code>artifacts/reports/verification-checklist.md</code> <code>docs/quality/agent-verification-checklist.md</code> QA Report Final QA summary with defects and sign-off. Release Stakeholder approval <code>artifacts/reports/qa-report.md</code> <code>docs/quality/qa-report-template.md</code>"},{"location":"reference/deliverables-catalog/#optional-deliverables","title":"Optional Deliverables","text":"Deliverable When Needed Notes Change Log Entry When a release is prepared Follow the team's changelog policy when available Observability Dashboards Export When custom dashboards are created Document queries and panels Post-Incident Report When failures occur during delivery Base the write-up on <code>docs/reference/troubleshooting.md</code> guidance"},{"location":"reference/deliverables-catalog/#versioning-retention","title":"Versioning &amp; Retention","text":"<ul> <li>Align release notes and version bumps with the team's changelog policy when available.</li> <li>Store artefacts in the project repository or associated knowledge base with clear version tags.</li> <li>Retain verification reports and QA summaries for auditability per team policy.</li> </ul>"},{"location":"reference/deliverables-catalog/#maintenance","title":"Maintenance","text":"<ul> <li>Update entries whenever templates change or new artefacts are added.</li> <li>Cross-check with <code>docs/reference/agent-context-summary.md</code> and <code>docs/INDEX.md</code> after modifications.</li> <li>Use formatting rules from <code>docs/STYLE_GUIDE.md</code>.</li> </ul>"},{"location":"reference/failure-scenarios/","title":"Failure Scenarios &amp; Recovery Guide","text":"<p>Purpose: Provide AI agents with clear decision trees and recovery procedures for handling failures, blockers, and unexpected situations during the 7-stage code generation workflow.</p>"},{"location":"reference/failure-scenarios/#overview","title":"Overview","text":"<p>This document covers edge cases and failure scenarios that can occur at any stage of the workflow. For each scenario, AI must follow the specified recovery procedure and communicate clearly with the user.</p>"},{"location":"reference/failure-scenarios/#quick-navigation","title":"Quick Navigation","text":"Scenario Type When It Happens Jump To Validation failures Stage 1 Incomplete or Invalid Prompts Requirement conflicts Stage 2-3 Architecture Conflicts Test failures Stage 4-5 Test Failures During Generation Quality gate failures Stage 5 Quality Gate Failures User changes mind Any stage Mid-Workflow Requirement Changes External blockers Any stage External Dependency Failures Rollback requests Stage 3-6 Rollback to Previous Stage"},{"location":"reference/failure-scenarios/#core-principles","title":"Core Principles","text":"<ol> <li>Transparency: Always communicate failures clearly to the user</li> <li>No Silent Failures: Never skip checks or ignore errors</li> <li>User Decision: When uncertain, ask the user rather than making assumptions</li> <li>Document Recovery: Log all recovery actions for QA report</li> <li>Graceful Degradation: Offer alternatives when strict requirements can't be met</li> </ol>"},{"location":"reference/failure-scenarios/#scenario-1-incomplete-or-invalid-prompts","title":"Scenario 1: Incomplete or Invalid Prompts","text":"<p>Stage: 1 (Prompt Validation)</p> <p>Symptoms: - Missing mandatory fields (business context, maturity level, functional requirements) - Contradictory requirements - Vague or ambiguous descriptions</p>"},{"location":"reference/failure-scenarios/#recovery-procedure","title":"Recovery Procedure","text":"<pre><code>1. STOP immediately \u2014 do NOT proceed to Stage 2\n2. Identify ALL missing fields using prompt-validation-guide.md\n3. Use prompt-templates.md to formulate clarification questions\n4. Send clarification request to user with:\n   - List of missing fields\n   - Why each field is needed\n   - Expected format/examples\n5. WAIT for user response\n6. Re-validate prompt\n7. If still incomplete \u2192 repeat steps 2-6\n8. If complete \u2192 proceed to Stage 2\n</code></pre>"},{"location":"reference/failure-scenarios/#example","title":"Example","text":"<p>Bad Response \u274c:</p> <p>\"Proceeding with assumptions since business context is missing...\"</p> <p>Good Response \u2705:</p> <p>\"## \ud83d\udd0d Prompt Validation: Missing Information</p> <p>I cannot proceed without the following mandatory fields:</p> <p>Missing: 1. Target maturity level (1-4): This determines infrastructure complexity and generation time. 2. Expected user load: Need RPS, DAU to size infrastructure.</p> <p>Please provide these details to continue.\"</p>"},{"location":"reference/failure-scenarios/#references","title":"References","text":"<ul> <li><code>docs/guides/prompt-validation-guide.md</code></li> <li><code>docs/reference/prompt-templates.md</code></li> </ul>"},{"location":"reference/failure-scenarios/#scenario-2-architecture-conflicts","title":"Scenario 2: Architecture Conflicts","text":"<p>Stage: 2-3 (Requirements Intake / Planning)</p> <p>Symptoms: - User requests direct database access (violates HTTP-only rule) - User wants FastAPI + Aiogram in same process (violates service separation) - User wants features incompatible with Improved Hybrid Approach</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_1","title":"Recovery Procedure","text":"<pre><code>1. STOP immediately \u2014 do NOT generate conflicting architecture\n2. Identify the specific constraint violation\n3. Explain the architectural constraint to the user:\n   - What they requested\n   - Why it violates framework rules\n   - What the correct approach is\n4. Propose compliant alternative\n5. WAIT for user approval of alternative\n6. Update Requirements Intake document\n7. Proceed with compliant architecture\n</code></pre>"},{"location":"reference/failure-scenarios/#example_1","title":"Example","text":"<p>User Request (violates rules):</p> <p>\"FastAPI service should connect directly to PostgreSQL for better performance\"</p> <p>AI Response \u2705:</p> <p>\"## \u26a0\ufe0f Architecture Conflict Detected</p> <p>Your requirement: FastAPI service with direct PostgreSQL connection</p> <p>Framework constraint: Improved Hybrid Approach requires HTTP-only data access through dedicated data services.</p> <p>Why: - Centralized data access ensures consistency - Easier to scale data layer independently - Single source of truth for data operations</p> <p>Compliant solution: FastAPI service \u2192 HTTP calls \u2192 <code>template_data_postgres_api</code> (Port 8001) \u2192 PostgreSQL</p> <p>Performance impact is negligible (&lt;5ms overhead for internal HTTP calls).</p> <p>Do you approve this approach?\"</p>"},{"location":"reference/failure-scenarios/#references_1","title":"References","text":"<ul> <li><code>docs/guides/architecture-guide.md</code></li> <li><code>docs/atomic/architecture/improved-hybrid-overview.md</code></li> <li><code>docs/atomic/architecture/data-access-architecture.md</code></li> </ul>"},{"location":"reference/failure-scenarios/#scenario-3-test-failures-during-generation","title":"Scenario 3: Test Failures During Generation","text":"<p>Stage: 4 (Code Generation)</p> <p>Symptoms: - Unit tests fail after generating new code - Integration tests fail due to configuration issues - Type checking errors from Mypy - Linting errors from Ruff</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_2","title":"Recovery Procedure","text":"<pre><code>1. Capture the error output (full stack trace)\n2. Analyze the root cause:\n   - Code bug? \u2192 Fix the code\n   - Test bug? \u2192 Fix the test\n   - Configuration issue? \u2192 Fix config\n   - Missing dependency? \u2192 Add to requirements\n3. Apply fix\n4. Re-run the failing check\n5. If still failing \u2192 repeat steps 2-4 (max 3 attempts)\n6. If still failing after 3 attempts:\n   - Document the blocker\n   - Ask user for guidance\n   - Offer alternatives (skip feature, change approach)\n7. Once fixed \u2192 commit with clear message\n8. Continue to next sub-stage\n</code></pre>"},{"location":"reference/failure-scenarios/#example_2","title":"Example","text":"<p>Scenario: Test fails after generating payment integration</p> <p>AI Response \u2705:</p> <p>\"## \u26a0\ufe0f Test Failure: Payment Integration</p> <p>Failed test: <code>test_payment_creation_idempotency</code></p> <p>Error: <pre><code>AssertionError: Expected 1 payment, got 2 (idempotency key not working)\n</code></pre></p> <p>Root cause: Missing Redis connection in test fixtures.</p> <p>Fix applied: Added Redis testcontainer to <code>conftest.py</code></p> <p>Re-running test: \u2705 PASS</p> <p>Continuing to next sub-stage.\"</p>"},{"location":"reference/failure-scenarios/#references_2","title":"References","text":"<ul> <li><code>docs/reference/troubleshooting.md</code></li> <li><code>docs/atomic/testing/unit-testing/pytest-setup.md</code></li> </ul>"},{"location":"reference/failure-scenarios/#scenario-4-quality-gate-failures","title":"Scenario 4: Quality Gate Failures","text":"<p>Stage: 5 (Verification)</p> <p>Symptoms: - Coverage below threshold for maturity level - Security vulnerabilities found by Bandit - Type errors in critical paths - Linting issues</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_3","title":"Recovery Procedure","text":"<pre><code>1. Review agent-verification-checklist.md\n2. Identify which quality gate(s) failed\n3. For EACH failed gate:\n   a. Capture evidence (logs, reports)\n   b. Determine if fixable:\n      - Yes \u2192 Apply fix, re-run check\n      - No \u2192 Document blocker\n   c. If blocker \u2192 ask user for decision:\n      - Add exception/waiver?\n      - Change requirement?\n      - Delay release?\n4. If ALL gates pass \u2192 proceed to Stage 6\n5. If ANY gate blocked \u2192 WAIT for user decision\n</code></pre>"},{"location":"reference/failure-scenarios/#example-coverage-below-threshold","title":"Example: Coverage Below Threshold","text":"<p>Scenario: Level 3 requires 80% coverage, but achieved only 76%</p> <p>AI Response \u2705:</p> <p>\"## \u26a0\ufe0f Quality Gate Failure: Coverage Below Threshold</p> <p>Required: \u2265 80% (Level 3 - Pre-Production) Achieved: 76%</p> <p>Uncovered areas: - <code>payment_service/refund_handler.py</code>: 45% coverage - <code>template_business_api/webhooks/stripe.py</code>: 62% coverage</p> <p>Options: 1. Add tests (recommended): I can generate tests for these areas (~15 minutes) 2. Lower threshold: Accept 76% (not recommended for Level 3) 3. Defer to next iteration: Mark as technical debt</p> <p>Your decision: _____\"</p>"},{"location":"reference/failure-scenarios/#references_3","title":"References","text":"<ul> <li><code>docs/quality/agent-verification-checklist.md</code></li> <li><code>docs/reference/maturity-levels.md</code> (for thresholds)</li> </ul>"},{"location":"reference/failure-scenarios/#scenario-5-mid-workflow-requirement-changes","title":"Scenario 5: Mid-Workflow Requirement Changes","text":"<p>Stage: Any (typically 3-5)</p> <p>Symptoms: - User requests new feature during code generation - User changes maturity level mid-workflow - User removes previously approved feature</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_4","title":"Recovery Procedure","text":"<pre><code>1. Acknowledge the change request\n2. Assess impact:\n   - Stage 1-2: Easy \u2014 update Requirements Intake, continue\n   - Stage 3: Moderate \u2014 update Implementation Plan, get re-approval\n   - Stage 4-5: High \u2014 may require rollback or separate iteration\n3. Communicate impact to user:\n   - Estimated time to incorporate change\n   - Which stages need rework\n   - Risk of introducing bugs\n4. Offer options:\n   - Option A: Incorporate now (with rework time)\n   - Option B: Complete current plan, add change in next iteration\n   - Option C: Rollback to earlier stage\n5. WAIT for user decision\n6. Execute chosen option\n</code></pre>"},{"location":"reference/failure-scenarios/#example-user-adds-feature-at-stage-4","title":"Example: User Adds Feature at Stage 4","text":"<p>User Request (mid-generation):</p> <p>\"Can we add real-time chat feature?\"</p> <p>AI Response \u2705:</p> <p>\"## \ud83d\udd04 Change Request: Add Real-Time Chat</p> <p>Current stage: 4.3 (Business Logic generation - 60% complete)</p> <p>Impact analysis: - Requires WebSocket support (new module) - Needs Redis pub/sub (new infrastructure) - Chat message storage (new PostgreSQL tables) - Estimated additional time: ~20 minutes</p> <p>Options: 1. Add now (recommended if critical):    - Pause at current sub-stage    - Generate WebSocket module (4.Y)    - Resume remaining sub-stages    - Total delay: ~20 min</p> <ol> <li>Add in next iteration (recommended if not urgent):</li> <li>Complete current plan first</li> <li>Deliver working app without chat</li> <li>Add chat as Phase 2 (~25 min total)</li> </ol> <p>Your decision: _____\"</p>"},{"location":"reference/failure-scenarios/#scenario-6-external-dependency-failures","title":"Scenario 6: External Dependency Failures","text":"<p>Stage: Any (typically 4-5)</p> <p>Symptoms: - Docker registry unavailable - Package registry (PyPI) down - External API (Stripe, Twilio) unavailable - Git submodule fetch fails</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_5","title":"Recovery Procedure","text":"<pre><code>1. Detect the external failure (timeout, 404, 500 error)\n2. Classify severity:\n   - BLOCKER: Cannot proceed without it\n   - WORKAROUND: Can use alternative temporarily\n   - INFORMATIONAL: Doesn't affect current stage\n3. For BLOCKERS:\n   - Document the issue\n   - Notify user immediately\n   - Provide workaround if available\n   - WAIT until dependency is restored\n4. For WORKAROUNDS:\n   - Use alternative (cached, local, mock)\n   - Document temporary solution\n   - Add TODO to switch back\n5. For INFORMATIONAL:\n   - Log for later\n   - Continue workflow\n</code></pre>"},{"location":"reference/failure-scenarios/#example-pypi-unavailable","title":"Example: PyPI Unavailable","text":"<p>AI Response \u2705:</p> <p>\"## \ud83d\udeab External Dependency Failure: PyPI Unavailable</p> <p>Issue: Cannot install <code>fastapi==0.115.0</code> from PyPI (timeout after 60s)</p> <p>Impact: BLOCKER for Stage 4 (cannot generate FastAPI service)</p> <p>Workarounds: 1. Use cached packages (if available locally) 2. Use alternative PyPI mirror (e.g., Alibaba mirror) 3. Wait for PyPI to restore (typically &lt; 30 min)</p> <p>Recommended action: Try alternative mirror first. If fails, wait for PyPI.</p> <p>Your decision: _____\"</p>"},{"location":"reference/failure-scenarios/#scenario-7-rollback-to-previous-stage","title":"Scenario 7: Rollback to Previous Stage","text":"<p>Stage: 3-6 (any stage after planning)</p> <p>Symptoms: - User realizes requirements were wrong - Major defect found during verification - User wants to change approach</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_6","title":"Recovery Procedure","text":"<pre><code>1. Confirm rollback request with user (explain data loss)\n2. Identify target stage for rollback\n3. Execute rollback:\n   - Stage 3 \u2192 2: Discard Implementation Plan, update Requirements Intake\n   - Stage 4 \u2192 3: Discard generated code, revise Implementation Plan\n   - Stage 5 \u2192 4: Keep code, re-run specific sub-stages\n   - Stage 6 \u2192 5: Re-run verification with adjusted criteria\n4. Document reason for rollback (for QA report)\n5. Resume workflow from target stage\n6. Update delivery timeline estimate\n</code></pre>"},{"location":"reference/failure-scenarios/#example-rollback-from-stage-4-to-stage-3","title":"Example: Rollback from Stage 4 to Stage 3","text":"<p>User Request:</p> <p>\"I realized we don't need MongoDB, only PostgreSQL. Can we simplify?\"</p> <p>AI Response \u2705:</p> <p>\"## \ud83d\udd04 Rollback Request: Stage 4 \u2192 Stage 3</p> <p>Current progress: - \u2705 Infrastructure (4.1) \u2014 completed - \u2705 PostgreSQL data service (4.2) \u2014 completed - \u23f8\ufe0f MongoDB data service (4.2b) \u2014 50% complete - \u23f8\ufe0f Business Logic (4.3) \u2014 not started</p> <p>Rollback impact: - Discard MongoDB service code - Update Implementation Plan (remove MongoDB phases) - Time saved: ~5 minutes - Time lost: ~2 minutes (MongoDB work done) - Net benefit: ~3 minutes faster delivery</p> <p>Proceeding: 1. Rollback to Stage 3 (planning) 2. Update Implementation Plan (remove MongoDB) 3. Get your approval 4. Resume Stage 4 with simplified plan</p> <p>Confirmed?\"</p>"},{"location":"reference/failure-scenarios/#scenario-8-user-aborts-workflow","title":"Scenario 8: User Aborts Workflow","text":"<p>Stage: Any</p> <p>Symptoms: - User explicitly says \"stop\", \"cancel\", \"abort\" - User stops responding for extended period</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_7","title":"Recovery Procedure","text":"<pre><code>1. Confirm abort intent with user:\n   - \"Do you want to abort the workflow?\"\n   - Explain current progress\n   - Explain what will be saved/lost\n2. If confirmed abort:\n   - Stop all work immediately\n   - Save current progress (if any code generated)\n   - Generate partial QA report:\n     - What was completed\n     - What was in progress\n     - Reason for abort\n   - Provide handoff package (partial deliverables)\n3. If user wants pause (not abort):\n   - Save state\n   - Document stopping point\n   - Provide resume instructions\n4. Close session gracefully\n</code></pre>"},{"location":"reference/failure-scenarios/#example_3","title":"Example","text":"<p>User Says: \"Stop, I need to rethink this.\"</p> <p>AI Response \u2705:</p> <p>\"## \u23f8\ufe0f Workflow Pause Requested</p> <p>Current stage: 4.3 (Business Logic - 40% complete)</p> <p>Completed so far: - \u2705 Infrastructure setup (Docker Compose, Nginx) - \u2705 PostgreSQL data service (fully functional) - \u23f8\ufe0f FastAPI business service (2 of 5 endpoints done)</p> <p>Options: 1. Pause: Save current state, you can resume later 2. Abort: Discard all work, start fresh next time 3. Continue: I can keep going while you think</p> <p>If pausing: I'll provide: - Partial codebase (zipped) - Progress report (where we stopped) - Resume instructions (how to continue)</p> <p>Your choice: _____\"</p>"},{"location":"reference/failure-scenarios/#scenario-9-conflicting-quality-requirements","title":"Scenario 9: Conflicting Quality Requirements","text":"<p>Stage: 5 (Verification)</p> <p>Symptoms: - User wants high coverage but minimal tests - User wants production readiness but chose Level 1 (PoC) - User wants compliance but no audit logging</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_8","title":"Recovery Procedure","text":"<pre><code>1. Identify the contradiction\n2. Explain the conflict to user with evidence:\n   - What they requested\n   - What maturity level provides\n   - The gap between them\n3. Offer resolution options:\n   - Option A: Upgrade maturity level (recommended)\n   - Option B: Accept lower quality (document risk)\n   - Option C: Add specific features a-la-carte\n4. WAIT for user decision\n5. Update Requirements Intake / Implementation Plan\n6. Re-run verification with adjusted criteria\n</code></pre>"},{"location":"reference/failure-scenarios/#example_4","title":"Example","text":"<p>Conflict: User wants GDPR compliance but chose Level 1 (PoC)</p> <p>AI Response \u2705:</p> <p>\"## \u26a0\ufe0f Conflicting Requirements Detected</p> <p>Your requirements: - GDPR compliance (audit logging, encryption, right to deletion) - Maturity Level: 1 (PoC)</p> <p>Conflict: Level 1 (PoC) does NOT include: - \u274c Audit logging - \u274c Encryption at rest - \u274c RBAC / access controls - \u274c GDPR deletion workflows</p> <p>GDPR compliance requires at minimum Level 4 (Production).</p> <p>Options: 1. Upgrade to Level 4 (recommended for GDPR):    - Full compliance features    - Time: ~30 min (instead of ~5 min)</p> <ol> <li>Stay at Level 1, defer GDPR:</li> <li>Accept that app is NOT GDPR compliant</li> <li>Add compliance in future iteration</li> <li> <p>Risk: Cannot deploy in EU</p> </li> <li> <p>Hybrid approach (Level 2 + manual GDPR):</p> </li> <li>Generate Level 2 base (~10 min)</li> <li>You manually add GDPR features later</li> </ol> <p>Your decision: _____\"</p>"},{"location":"reference/failure-scenarios/#scenario-10-infinite-loop-stuck-state","title":"Scenario 10: Infinite Loop / Stuck State","text":"<p>Stage: Any</p> <p>Symptoms: - AI keeps asking same question - Test fails repeatedly with same fix attempts - User and AI disagree on requirements</p>"},{"location":"reference/failure-scenarios/#recovery-procedure_9","title":"Recovery Procedure","text":"<pre><code>1. Detect loop (if same action repeated &gt; 3 times)\n2. STOP immediately\n3. Escalate to user:\n   - \"I'm unable to proceed due to [issue]\"\n   - Summarize what was attempted\n   - Ask for explicit guidance or decision\n4. Offer to:\n   - Rollback to previous stage\n   - Skip problematic component\n   - Defer to manual implementation\n5. WAIT for user decision (do NOT continue loop)\n</code></pre>"},{"location":"reference/failure-scenarios/#example-test-keeps-failing","title":"Example: Test Keeps Failing","text":"<p>After 3 failed fix attempts:</p> <p>AI Response \u2705:</p> <p>\"## \ud83d\udd04 Unable to Fix Test Failure</p> <p>Issue: <code>test_user_authentication</code> keeps failing</p> <p>Attempts made: 1. Fixed JWT token generation \u2192 still failed 2. Updated test fixtures \u2192 still failed 3. Changed timing (added delays) \u2192 still failed</p> <p>Root cause: Unclear. Possibly environment-specific issue.</p> <p>I'm stuck. Options: 1. Skip this test (not recommended): Mark as known failure, document in QA report 2. Simplify auth (recommended): Use simpler auth mechanism for now 3. Debug together: Share full logs, you help identify issue 4. Rollback auth feature: Remove authentication, add later</p> <p>Your decision: _____\"</p>"},{"location":"reference/failure-scenarios/#decision-tree-reference","title":"Decision Tree Reference","text":"<p>Use this flowchart when any failure occurs:</p> <pre><code>                           [Failure Detected]\n                                  |\n                    +-------------+-------------+\n                    |                           |\n          [Can I fix automatically?]   [Need user decision?]\n                    |                           |\n              +-----+-----+                     |\n              |           |                     |\n          [YES]        [NO]               [Ask user]\n              |           |                     |\n         [Fix it]   [Try alternative]     [WAIT for input]\n              |           |                     |\n         [Re-run]         |              +------+------+\n              |           |              |             |\n        +-----+-----+     |          [Proceed]    [Rollback]\n        |           |     |              |             |\n    [PASS]      [FAIL]   |         [Continue]   [Go back]\n        |           |     |              |             |\n   [Continue] [Escalate] |         [Next stage]  [Fix &amp; retry]\n                    |     |\n                    +-----+\n                          |\n                   [User decides]\n                          |\n                   [Document &amp; proceed]\n</code></pre>"},{"location":"reference/failure-scenarios/#maintenance","title":"Maintenance","text":"<ul> <li>Update this document when new failure patterns are identified</li> <li>Keep aligned with <code>ai-code-generation-master-workflow.md</code></li> <li>Reference from <code>agent-context-summary.md</code></li> <li>Follow <code>STYLE_GUIDE.md</code> for formatting</li> </ul> <p>Last Updated: 2025-10-02</p>"},{"location":"reference/maturity-levels/","title":"Maturity Levels","text":"<p>Purpose: Define four incremental maturity levels for AI-generated applications, from proof-of-concept to production-ready enterprise systems. Each level adds specific infrastructure, observability, and security layers on top of the previous level.</p>"},{"location":"reference/maturity-levels/#overview","title":"Overview","text":"<p>When starting a new project, users must select a Target Maturity Level that matches their current needs. The AI will generate only the features and infrastructure appropriate for that level, avoiding over-engineering while maintaining a clear upgrade path.</p> <pre><code>Level 1 (PoC)  \u2192  Level 2 (Development)  \u2192  Level 3 (Pre-Production)  \u2192  Level 4 (Production)\n    Core              + Observability           + Infrastructure              + Security &amp; HA\n</code></pre>"},{"location":"reference/maturity-levels/#level-1-proof-of-concept-poc","title":"Level 1: Proof of Concept (PoC) \ud83e\uddea","text":""},{"location":"reference/maturity-levels/#goal","title":"Goal","text":"<p>Validate business idea, build MVP, demonstrate to stakeholders.</p> <p>Scope Strategy: Level 1 includes approximately 20-30% of total planned features, but each included feature must be 100% complete, fully tested, and production-quality. Maturity levels differ by scope (how many features), NOT by implementation completeness (quality of code).</p>"},{"location":"reference/maturity-levels/#target-audience","title":"Target Audience","text":"<ul> <li>Solo developers testing an idea</li> <li>Startups building first prototype</li> <li>Teams creating demo for investors</li> <li>Learning projects</li> </ul>"},{"location":"reference/maturity-levels/#time-to-generate","title":"Time to Generate","text":"<p>~5-7 minutes</p>"},{"location":"reference/maturity-levels/#whats-included","title":"What's Included","text":""},{"location":"reference/maturity-levels/#core-services-mandatory","title":"Core Services (MANDATORY)","text":"<ul> <li>\u2705 FastAPI (REST API business service)</li> <li>\u2705 PostgreSQL Data Service (single database)</li> <li>\u2705 Docker Compose (local development only)</li> <li>\u2705 Basic Configuration (<code>.env</code> file)</li> <li>\u2705 Pytest (unit tests, minimal coverage)</li> </ul>"},{"location":"reference/maturity-levels/#infrastructure","title":"Infrastructure","text":"<ul> <li>\u2705 Docker Compose for local dev</li> <li>\u2705 Simple Dockerfiles (single-stage builds)</li> <li>\u274c No Nginx</li> <li>\u274c No SSL/TLS</li> <li>\u274c No production deployment configs</li> </ul>"},{"location":"reference/maturity-levels/#observability","title":"Observability","text":"<ul> <li>\u2705 Structured logging (JSON format via python-json-logger)</li> <li>\u274c No request ID tracking</li> <li>\u274c No metrics</li> <li>\u274c No tracing</li> <li>\u274c No error tracking</li> </ul>"},{"location":"reference/maturity-levels/#security","title":"Security","text":"<ul> <li>\u274c No authentication (or basic hardcoded tokens only)</li> <li>\u274c No authorization</li> <li>\u274c No security headers</li> <li>\u274c No secrets management</li> </ul>"},{"location":"reference/maturity-levels/#quality","title":"Quality","text":"<ul> <li>\u2705 Basic linting (Ruff)</li> <li>\u2705 Basic type checking (Mypy)</li> <li>\u2705 Unit tests (\u226560% coverage required)</li> <li>\u274c No security scanning</li> <li>\u274c No integration tests</li> </ul>"},{"location":"reference/maturity-levels/#generated-structure","title":"Generated Structure","text":"<pre><code>project/\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 template_business_api/              # FastAPI\n\u2502   \u2502   \u251c\u2500\u2500 src/                            # DDD structure (see project-structure-patterns.md)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/v1/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 application/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 infrastructure/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 tests/unit/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 template_data_postgres_api/         # Data service\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u2502   \u251c\u2500\u2500 api/v1/\n\u2502       \u2502   \u251c\u2500\u2500 models/\n\u2502       \u2502   \u251c\u2500\u2500 repositories/\n\u2502       \u2502   \u2514\u2500\u2500 core/\n\u2502       \u251c\u2500\u2500 tests/unit/\n\u2502       \u251c\u2500\u2500 Dockerfile\n\u2502       \u2514\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 shared/                       # Cross-service DTOs, events\n\u251c\u2500\u2500 docker-compose.yml            # Local dev only\n\u251c\u2500\u2500 .env.example\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Note: Level 1 uses full DDD/Hexagonal structure (<code>src/</code> directory) from the start to enable additive evolution to higher levels without restructuring. All included features must be 100% complete and functional \u2014 the 60% coverage threshold applies to complete, production-quality code, not partial implementations. Higher levels add more features and infrastructure, not completion of unfinished work. See <code>docs/atomic/architecture/project-structure-patterns.md</code> for details.</p>"},{"location":"reference/maturity-levels/#use-cases","title":"Use Cases","text":"<ul> <li>MVP for investors</li> <li>Proof of concept</li> <li>Learning microservices</li> <li>Hackathon projects</li> <li>Internal tools (low traffic)</li> </ul>"},{"location":"reference/maturity-levels/#level-2-development-ready","title":"Level 2: Development Ready \ud83d\udee0\ufe0f","text":""},{"location":"reference/maturity-levels/#goal_1","title":"Goal","text":"<p>Enable active team development with proper observability and debugging tools.</p>"},{"location":"reference/maturity-levels/#target-audience_1","title":"Target Audience","text":"<ul> <li>Small teams (2-5 developers)</li> <li>Startups preparing for beta launch</li> <li>Projects transitioning from PoC to active development</li> <li>Staging environments</li> </ul>"},{"location":"reference/maturity-levels/#time-to-generate_1","title":"Time to Generate","text":"<p>~10-12 minutes</p>"},{"location":"reference/maturity-levels/#whats-added-to-level-1","title":"What's Added to Level 1","text":""},{"location":"reference/maturity-levels/#observability_1","title":"Observability (+++)","text":"<ul> <li>\u2705 Request ID Tracking (middleware for request correlation)</li> <li>\u2705 Health Check Endpoints (<code>/health</code>, <code>/ready</code>)</li> <li>\u2705 Error Tracking Integration (Sentry-ready, not deployed)</li> <li>\u2705 OpenAPI Documentation (Swagger UI auto-generated)</li> <li>Note: Structured JSON logging already present in Level 1</li> <li>\u274c No Prometheus metrics yet</li> <li>\u274c No distributed tracing</li> <li>\u274c No ELK stack</li> </ul>"},{"location":"reference/maturity-levels/#development-experience","title":"Development Experience","text":"<ul> <li>\u2705 Hot Reload (dev mode)</li> <li>\u2705 Debug Mode (detailed error pages)</li> <li>\u2705 Docker Compose Dev Overrides (<code>docker-compose.dev.yml</code>)</li> <li>\u2705 Environment Separation (dev/test configs)</li> </ul>"},{"location":"reference/maturity-levels/#quality_1","title":"Quality","text":"<ul> <li>\u2705 Integration Tests (with testcontainers)</li> <li>\u2705 Coverage Target (\u2265 75%)</li> <li>\u2705 Pre-commit Hooks (optional)</li> </ul>"},{"location":"reference/maturity-levels/#generated-structure-additional-files","title":"Generated Structure (Additional Files)","text":"<pre><code>services/\n\u251c\u2500\u2500 template_business_api/\n\u2502   \u2514\u2500\u2500 src/\n\u2502       \u251c\u2500\u2500 middleware/            # NEW: Request ID, error handling\n\u2502       \u2502   \u251c\u2500\u2500 request_id.py\n\u2502       \u2502   \u2514\u2500\u2500 error_handler.py\n\u2502       \u251c\u2500\u2500 api/v1/\n\u2502       \u2502   \u2514\u2500\u2500 health_router.py   # NEW: Health check endpoints\n\u2502       \u2514\u2500\u2500 core/\n\u2502           \u2514\u2500\u2500 logging.py         # UPDATED: Add request ID to JSON logs\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 integration/               # NEW: Integration tests\n\u2502       \u2514\u2500\u2500 test_api_integration.py\ndocker-compose.dev.yml             # NEW: Dev overrides\ndocker-compose.test.yml            # NEW: Test environment\n</code></pre> <p>Note: All Level 1 files unchanged. Only additions: <code>middleware/</code>, <code>health_router.py</code>, <code>integration/</code> tests, and docker-compose overrides.</p>"},{"location":"reference/maturity-levels/#use-cases_1","title":"Use Cases","text":"<ul> <li>Active development teams</li> <li>Beta testing (closed)</li> <li>Staging environments</li> <li>Internal demos</li> </ul>"},{"location":"reference/maturity-levels/#level-3-pre-production-staging","title":"Level 3: Pre-Production (Staging) \ud83d\ude80","text":""},{"location":"reference/maturity-levels/#goal_2","title":"Goal","text":"<p>Prepare for public access with production-like infrastructure and basic security.</p>"},{"location":"reference/maturity-levels/#target-audience_2","title":"Target Audience","text":"<ul> <li>Startups launching to public beta</li> <li>Scale-ups preparing production release</li> <li>Projects needing public staging environment</li> <li>Teams with &lt; 10,000 users</li> </ul>"},{"location":"reference/maturity-levels/#time-to-generate_2","title":"Time to Generate","text":"<p>~15-18 minutes</p>"},{"location":"reference/maturity-levels/#whats-added-to-level-2","title":"What's Added to Level 2","text":""},{"location":"reference/maturity-levels/#infrastructure_1","title":"Infrastructure (+++)","text":"<ul> <li>\u2705 Nginx API Gateway (reverse proxy, load balancing)</li> <li>\u2705 SSL/TLS Support (Let's Encrypt or self-signed)</li> <li>\u2705 Multi-Stage Docker Builds (optimized images)</li> <li>\u2705 Production Docker Compose (<code>docker-compose.prod.yml</code>)</li> <li>\u2705 Health Check Probes (Docker healthchecks)</li> </ul>"},{"location":"reference/maturity-levels/#observability_2","title":"Observability (+++)","text":"<ul> <li>\u2705 Prometheus Metrics (request rate, latency, errors)</li> <li>\u2705 Basic Grafana Dashboards (pre-configured)</li> <li>\u2705 Alerting Rules (basic threshold alerts)</li> <li>\u274c No distributed tracing yet</li> <li>\u274c No ELK stack yet</li> </ul>"},{"location":"reference/maturity-levels/#security_1","title":"Security (+)","text":"<ul> <li>\u2705 Rate Limiting (Nginx-based, per IP)</li> <li>\u2705 CORS Configuration (for frontend)</li> <li>\u2705 Security Headers (basic: CSP, X-Frame-Options)</li> <li>\u2705 Basic Secrets Management (Docker secrets)</li> <li>\u274c No OAuth/JWT yet (can use API keys)</li> <li>\u274c No RBAC</li> </ul>"},{"location":"reference/maturity-levels/#quality_2","title":"Quality","text":"<ul> <li>\u2705 Security Scanning (Bandit, Safety)</li> <li>\u2705 Service Tests (end-to-end tests)</li> <li>\u2705 Coverage Target (\u2265 80%)</li> <li>\u2705 Load Testing Scripts (basic)</li> </ul>"},{"location":"reference/maturity-levels/#generated-structure-additional-files_1","title":"Generated Structure (Additional Files)","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 nginx/                         # NEW: API Gateway\n\u2502   \u251c\u2500\u2500 nginx.conf\n\u2502   \u251c\u2500\u2500 ssl/\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 rate_limit.conf\n\u251c\u2500\u2500 prometheus/                    # NEW: Metrics\n\u2502   \u251c\u2500\u2500 prometheus.yml\n\u2502   \u2514\u2500\u2500 rules.yml\n\u2514\u2500\u2500 grafana/                       # NEW: Dashboards\n    \u251c\u2500\u2500 provisioning/\n    \u2514\u2500\u2500 dashboards/\n        \u2514\u2500\u2500 api_overview.json\nservices/\n\u251c\u2500\u2500 template_business_api/\n\u2502   \u251c\u2500\u2500 metrics.py                 # NEW: Prometheus metrics\n\u2502   \u2514\u2500\u2500 Dockerfile.prod            # NEW: Multi-stage build\ndocker-compose.prod.yml            # NEW: Production config\nscripts/\n\u2514\u2500\u2500 load_test.sh                   # NEW: Load testing\n</code></pre>"},{"location":"reference/maturity-levels/#use-cases_2","title":"Use Cases","text":"<ul> <li>Public beta launch</li> <li>Staging for production</li> <li>Small-scale production (&lt; 10K users)</li> <li>Client demos</li> </ul>"},{"location":"reference/maturity-levels/#level-4-production","title":"Level 4: Production \ud83c\udfe2","text":""},{"location":"reference/maturity-levels/#goal_3","title":"Goal","text":"<p>Enterprise-grade system with full security, high availability, and operational excellence.</p>"},{"location":"reference/maturity-levels/#target-audience_3","title":"Target Audience","text":"<ul> <li>Production deployments</li> <li>Enterprise applications</li> <li>Scale-ups (&gt; 10,000 users)</li> <li>Compliance-sensitive industries (fintech, healthcare)</li> <li>Teams requiring SLA guarantees</li> </ul>"},{"location":"reference/maturity-levels/#time-to-generate_3","title":"Time to Generate","text":"<p>~25-35 minutes</p>"},{"location":"reference/maturity-levels/#whats-added-to-level-3","title":"What's Added to Level 3","text":""},{"location":"reference/maturity-levels/#security_2","title":"Security (+++)","text":"<ul> <li>\u2705 OAuth 2.0 / JWT Authentication (full implementation)</li> <li>\u2705 Role-Based Access Control (RBAC) (permissions system)</li> <li>\u2705 Session Management (secure, distributed)</li> <li>\u2705 Input Validation (comprehensive sanitization)</li> <li>\u2705 Secrets Management (Vault-ready integration)</li> <li>\u2705 Security Headers (full suite: CSP, HSTS, etc.)</li> <li>\u2705 Encryption at Rest (database encryption)</li> <li>\u2705 Audit Logging (security events)</li> </ul>"},{"location":"reference/maturity-levels/#observability_3","title":"Observability (+++)","text":"<ul> <li>\u2705 ELK Stack (Elasticsearch, Logstash, Kibana)</li> <li>\u2705 Distributed Tracing (Jaeger)</li> <li>\u2705 Full Grafana Suite (advanced dashboards)</li> <li>\u2705 Alerting (Prometheus Alertmanager + PagerDuty/Slack)</li> <li>\u2705 APM Integration (Application Performance Monitoring)</li> <li>\u2705 Log Aggregation (centralized, searchable)</li> </ul>"},{"location":"reference/maturity-levels/#high-availability","title":"High Availability (+++)","text":"<ul> <li>\u2705 Database Replication (master-slave PostgreSQL)</li> <li>\u2705 Service Redundancy (multiple instances)</li> <li>\u2705 Graceful Shutdown (signal handling)</li> <li>\u2705 Rolling Updates (zero-downtime deployments)</li> <li>\u2705 Circuit Breakers (resilience patterns)</li> <li>\u2705 Health Checks (advanced liveness/readiness)</li> </ul>"},{"location":"reference/maturity-levels/#cicd","title":"CI/CD (+++)","text":"<ul> <li>\u2705 GitHub Actions / GitLab CI (full pipelines)</li> <li>\u2705 Automated Testing (unit, integration, e2e)</li> <li>\u2705 Security Scanning (SAST, dependency scanning)</li> <li>\u2705 Automated Deployment (staging + production)</li> <li>\u2705 Rollback Procedures (automated)</li> <li>\u2705 Version Tagging (semantic versioning)</li> </ul>"},{"location":"reference/maturity-levels/#backup-recovery","title":"Backup &amp; Recovery (+++)","text":"<ul> <li>\u2705 Automated DB Backups (scheduled, encrypted)</li> <li>\u2705 Disaster Recovery Plan (documented)</li> <li>\u2705 Point-in-Time Recovery (PostgreSQL PITR)</li> <li>\u2705 Backup Monitoring (alerts on failures)</li> </ul>"},{"location":"reference/maturity-levels/#documentation","title":"Documentation (+++)","text":"<ul> <li>\u2705 Architecture Decision Records (ADRs) (major decisions documented)</li> <li>\u2705 Runbooks (incident response procedures)</li> <li>\u2705 API Documentation (comprehensive, versioned)</li> <li>\u2705 Deployment Guide (step-by-step)</li> <li>\u2705 Monitoring Guide (alert responses)</li> </ul>"},{"location":"reference/maturity-levels/#generated-structure-additional-files_2","title":"Generated Structure (Additional Files)","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 elk/                           # NEW: Log aggregation\n\u2502   \u251c\u2500\u2500 elasticsearch.yml\n\u2502   \u251c\u2500\u2500 logstash.conf\n\u2502   \u2514\u2500\u2500 kibana.yml\n\u251c\u2500\u2500 jaeger/                        # NEW: Distributed tracing\n\u2502   \u2514\u2500\u2500 jaeger.yml\n\u251c\u2500\u2500 monitoring/                    # NEW: Full observability\n\u2502   \u251c\u2500\u2500 prometheus.yml\n\u2502   \u251c\u2500\u2500 alertmanager.yml\n\u2502   \u2514\u2500\u2500 grafana/\n\u2502       \u2514\u2500\u2500 dashboards/            # Advanced dashboards\n\u251c\u2500\u2500 security/                      # NEW: Security configs\n\u2502   \u251c\u2500\u2500 vault/\n\u2502   \u2514\u2500\u2500 secrets/\n\u2514\u2500\u2500 databases/                     # NEW: Replication\n    \u2514\u2500\u2500 postgres-replication/\nservices/\n\u251c\u2500\u2500 template_business_api/\n\u2502   \u251c\u2500\u2500 security/                  # NEW: Auth &amp; RBAC\n\u2502   \u2502   \u251c\u2500\u2500 oauth.py\n\u2502   \u2502   \u251c\u2500\u2500 jwt.py\n\u2502   \u2502   \u2514\u2500\u2500 rbac.py\n\u2502   \u251c\u2500\u2500 observability/\n\u2502   \u2502   \u251c\u2500\u2500 tracing.py             # NEW: Jaeger integration\n\u2502   \u2502   \u2514\u2500\u2500 apm.py\n\u2502   \u2514\u2500\u2500 resilience/                # NEW: Circuit breakers\n\u2502       \u2514\u2500\u2500 circuit_breaker.py\n.github/                           # NEW: CI/CD\n\u2514\u2500\u2500 workflows/\n    \u251c\u2500\u2500 ci.yml\n    \u251c\u2500\u2500 security-scan.yml\n    \u251c\u2500\u2500 deploy-staging.yml\n    \u2514\u2500\u2500 deploy-production.yml\ndocs/\n\u251c\u2500\u2500 adr/                           # NEW: Architecture decisions\n\u2502   \u2514\u2500\u2500 001-use-improved-hybrid.md\n\u251c\u2500\u2500 runbooks/                      # NEW: Incident response\n\u2502   \u251c\u2500\u2500 database-failover.md\n\u2502   \u251c\u2500\u2500 high-memory-usage.md\n\u2502   \u2514\u2500\u2500 service-degradation.md\n\u2514\u2500\u2500 deployment/\n    \u251c\u2500\u2500 deployment-guide.md\n    \u2514\u2500\u2500 rollback-procedure.md\nscripts/\n\u251c\u2500\u2500 backup.sh                      # NEW: Automated backups\n\u251c\u2500\u2500 restore.sh\n\u2514\u2500\u2500 health-check.sh\n</code></pre>"},{"location":"reference/maturity-levels/#use-cases_3","title":"Use Cases","text":"<ul> <li>Production deployments (any scale)</li> <li>Enterprise applications</li> <li>Regulated industries (fintech, healthcare, government)</li> <li>SaaS platforms</li> <li>High-traffic systems (&gt; 10K users)</li> </ul>"},{"location":"reference/maturity-levels/#feature-comparison-matrix","title":"Feature Comparison Matrix","text":"Feature PoC (L1) Development (L2) Pre-Production (L3) Production (L4) Core Services FastAPI + PostgreSQL \u2705 \u2705 \u2705 \u2705 Docker Compose \u2705 \u2705 \u2705 \u2705 Basic Tests \u2705 \u2705 \u2705 \u2705 Observability Structured Logging (JSON) \u2705 \u2705 \u2705 \u2705 Request ID Tracking \u274c \u2705 \u2705 \u2705 Health Endpoints \u274c \u2705 \u2705 \u2705 Prometheus Metrics \u274c \u274c \u2705 \u2705 Grafana Dashboards \u274c \u274c \u2705 \u2705 Distributed Tracing \u274c \u274c \u274c \u2705 ELK Stack \u274c \u274c \u274c \u2705 Infrastructure Nginx Gateway \u274c \u274c \u2705 \u2705 SSL/TLS \u274c \u274c \u2705 \u2705 Multi-Stage Builds \u274c \u274c \u2705 \u2705 Security Rate Limiting \u274c \u274c \u2705 \u2705 CORS \u274c \u274c \u2705 \u2705 OAuth/JWT \u274c \u274c \u274c \u2705 RBAC \u274c \u274c \u274c \u2705 Secrets Management \u274c \u274c \u274c \u2705 Encryption at Rest \u274c \u274c \u274c \u2705 High Availability DB Replication \u274c \u274c \u274c \u2705 Service Redundancy \u274c \u274c \u274c \u2705 Circuit Breakers \u274c \u274c \u274c \u2705 CI/CD Automated Pipelines \u274c \u274c \u274c \u2705 Security Scanning \u274c \u274c \u2705 \u2705 Automated Deployment \u274c \u274c \u274c \u2705 Backup &amp; Recovery Automated Backups \u274c \u274c \u274c \u2705 Disaster Recovery \u274c \u274c \u274c \u2705 Documentation Basic README \u2705 \u2705 \u2705 \u2705 ADRs \u274c \u274c \u274c \u2705 Runbooks \u274c \u274c \u274c \u2705 Test Coverage \u2265 60% \u2265 75% \u2265 80% \u2265 85% Generation Time ~5 min ~10 min ~15 min ~30 min"},{"location":"reference/maturity-levels/#upgrade-path","title":"Upgrade Path","text":"<p>Projects naturally evolve from one level to the next. The framework supports incremental upgrades:</p>"},{"location":"reference/maturity-levels/#poc-development","title":"PoC \u2192 Development","text":"<p>Typical trigger: Team grows, need debugging tools Upgrade effort: ~2 hours Key additions: Logging, health checks, integration tests</p>"},{"location":"reference/maturity-levels/#development-pre-production","title":"Development \u2192 Pre-Production","text":"<p>Typical trigger: Public beta launch Upgrade effort: ~1 day Key additions: Nginx, SSL, metrics, alerting</p>"},{"location":"reference/maturity-levels/#pre-production-production","title":"Pre-Production \u2192 Production","text":"<p>Typical trigger: Enterprise contract, compliance requirements Upgrade effort: ~1 week Key additions: OAuth, RBAC, ELK, CI/CD, HA, backups</p>"},{"location":"reference/maturity-levels/#selection-guide","title":"Selection Guide","text":"<p>Choose Level 1 (PoC) if: - You're validating a business idea - Building an MVP for investors - Learning microservices architecture - Budget/time constrained (&lt; 1 week delivery)</p> <p>Choose Level 2 (Development) if: - You have a small team (2-5 developers) - Need observability for debugging - Preparing for beta launch - Transitioning from prototype to product</p> <p>Choose Level 3 (Pre-Production) if: - Launching public beta - Need SSL and basic security - Expecting moderate traffic (&lt; 10K users) - Staging environment for production</p> <p>Choose Level 4 (Production) if: - Enterprise deployment - Compliance requirements (GDPR, HIPAA, PCI-DSS) - High traffic (&gt; 10K users) - Need SLA guarantees - Mission-critical application</p>"},{"location":"reference/maturity-levels/#maintenance","title":"Maintenance","text":"<ul> <li>Update this matrix when new features are added to atomic documentation.</li> <li>Keep generation time estimates accurate based on testing.</li> <li>Cross-reference with <code>conditional-stage-rules.md</code> for implementation details.</li> <li>Follow <code>STYLE_GUIDE.md</code> for formatting consistency.</li> </ul>"},{"location":"reference/project-structure/","title":"Project Structure Guide","text":"<p>This document provides comprehensive guidance on organizing projects when using the microservices framework as a Git submodule.</p>"},{"location":"reference/project-structure/#framework-usage-patterns","title":"Framework Usage Patterns","text":"<p>This framework can be used in two ways: - Direct: Working in this repository directly (use paths like <code>docs/</code>) - Submodule: Added as <code>.ai-framework/</code> submodule to your project (use paths like <code>.ai-framework/docs/</code>)</p>"},{"location":"reference/project-structure/#recommended-project-structure","title":"Recommended Project Structure","text":"<p>When you add this framework as a submodule, your project structure should follow this pattern:</p> <pre><code>my_awesome_app/                      # Your project repository\n\u251c\u2500\u2500 .ai-framework/                   # Git submodule (this repository)\n\u2502   \u251c\u2500\u2500 docs/                       # Atomic knowledge base and guides\n\u2502   \u2514\u2500\u2500 AGENTS.md                   # AI instructions\n\u251c\u2500\u2500 services/                        # All microservices (independent deployable units)\n\u2502   \u251c\u2500\u2500 template_business_api/                # FastAPI REST API service (port 8000)\n\u2502   \u2502   \u251c\u2500\u2500 src/                    # Service source code (DDD/Hexagonal structure)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/                # Transport adapters (FastAPI routers)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 application/        # Use cases, orchestrators\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 domain/             # Entities, value objects\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 infrastructure/     # Repositories, HTTP clients\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/            # Pydantic DTOs\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 core/               # Configuration, logging, settings\n\u2502   \u2502   \u251c\u2500\u2500 tests/                  # Service-specific tests\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 unit/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 integration/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 conftest.py\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile              # Service-specific container\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt        # Service dependencies\n\u2502   \u2502   \u2514\u2500\u2500 pyproject.toml          # Service Python config\n\u2502   \u251c\u2500\u2500 template_business_bot/                # Aiogram Telegram bot service\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u251c\u2500\u2500 template_business_worker/             # AsyncIO background workers\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u251c\u2500\u2500 template_data_postgres_api/        # PostgreSQL data access service (port 8001)\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 template_data_mongo_api/           # MongoDB data access service (port 8002)\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u251c\u2500\u2500 tests/\n\u2502       \u251c\u2500\u2500 Dockerfile\n\u2502       \u2514\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 shared/                          # Shared components across services\n\u2502   \u251c\u2500\u2500 dtos/                       # Shared Data Transfer Objects\n\u2502   \u251c\u2500\u2500 events/                     # Shared Event Schemas\n\u2502   \u2514\u2500\u2500 utils/                      # Shared stateless utility functions\n\u251c\u2500\u2500 nginx/                           # API Gateway / Reverse Proxy\n\u2502   \u251c\u2500\u2500 nginx.conf                  # Main nginx configuration\n\u2502   \u251c\u2500\u2500 conf.d/                     # Configuration modules\n\u2502   \u2502   \u251c\u2500\u2500 api-gateway.conf        # Routing rules for all services\n\u2502   \u2502   \u251c\u2500\u2500 upstream.conf           # Upstream service definitions\n\u2502   \u2502   \u2514\u2500\u2500 ssl.conf                # SSL/TLS configuration\n\u2502   \u251c\u2500\u2500 Dockerfile                  # Nginx container\n\u2502   \u2514\u2500\u2500 certs/                      # SSL certificates (gitignored)\n\u251c\u2500\u2500 infrastructure/                  # Infrastructure and observability (optional)\n\u2502   \u251c\u2500\u2500 monitoring/                 # Prometheus, Grafana configs\n\u2502   \u2502   \u251c\u2500\u2500 prometheus/\n\u2502   \u2502   \u2514\u2500\u2500 grafana/\n\u2502   \u2514\u2500\u2500 logging/                    # ELK stack configs\n\u2502       \u251c\u2500\u2500 elasticsearch/\n\u2502       \u251c\u2500\u2500 logstash/\n\u2502       \u2514\u2500\u2500 kibana/\n\u251c\u2500\u2500 docker-compose.yml               # Orchestration for all services\n\u251c\u2500\u2500 .env.example                     # Configuration template\n\u251c\u2500\u2500 pyproject.toml                   # Root-level Python config (optional)\n\u251c\u2500\u2500 Makefile                         # Development automation commands\n\u251c\u2500\u2500 .gitignore                       # Version control exclusions\n\u2514\u2500\u2500 README.md                        # Project documentation\n</code></pre>"},{"location":"reference/project-structure/#creating-the-project-structure","title":"Creating the Project Structure","text":"<p>This section provides explicit commands to create the complete directory structure before generating any code.</p>"},{"location":"reference/project-structure/#automated-setup-recommended","title":"Automated Setup (Recommended)","text":"<p>If using the provided templates with Makefile:</p> <pre><code>make setup  # Creates all directories with DDD/Hexagonal layers\n</code></pre> <p>See <code>templates/infrastructure/Makefile</code> for complete automation.</p>"},{"location":"reference/project-structure/#manual-setup-step-by-step","title":"Manual Setup (Step-by-Step)","text":"<p>If generating from scratch or customizing the structure, execute these commands:</p> <pre><code># Core service directories with DDD/Hexagonal layers\n# FastAPI Business Logic Service\nmkdir -p services/template_business_api/src/{api/v1,application/{use_cases,dtos},domain/{entities,value_objects,services},infrastructure/{http_clients,rabbitmq},schemas,core}\nmkdir -p services/template_business_api/tests/{unit,integration,service}\n\n# Aiogram Telegram Bot Service\nmkdir -p services/template_business_bot/src/{handlers,middlewares,filters,core}\nmkdir -p services/template_business_bot/tests/{unit,integration}\n\n# AsyncIO Background Worker Service\nmkdir -p services/template_business_worker/src/{workers,tasks,core}\nmkdir -p services/template_business_worker/tests/{unit,integration}\n\n# PostgreSQL Data Access Service\nmkdir -p services/template_data_postgres_api/src/{api/v1,models,repositories,core}\nmkdir -p services/template_data_postgres_api/tests/{unit,integration}\nmkdir -p services/template_data_postgres_api/alembic/versions\n\n# MongoDB Data Access Service (optional)\nmkdir -p services/template_data_mongo_api/src/{api/v1,models,repositories,core}\nmkdir -p services/template_data_mongo_api/tests/{unit,integration}\n\n# Shared components across services\nmkdir -p shared/{dtos,events,utils}\n\n# API Gateway (Level 3+)\nmkdir -p nginx/{conf.d,certs,html}\n\n# Infrastructure and Observability (Level 3+)\nmkdir -p infrastructure/monitoring/{prometheus,grafana/provisioning/datasources,grafana/dashboards}\n\n# Logging Infrastructure (Level 4)\nmkdir -p infrastructure/logging/{elasticsearch,logstash,kibana}\n\n# Working directories\nmkdir -p logs backups\n</code></pre>"},{"location":"reference/project-structure/#conditional-directories-by-maturity-level","title":"Conditional Directories by Maturity Level","text":"<p>Level 1-2 (Core - PoC, Development): - \u2705 <code>services/</code> - All microservices with DDD layers - \u2705 <code>shared/</code> - Cross-service components - \u2705 <code>logs/</code> - Application logs - \u274c Skip nginx/, infrastructure/</p> <p>Level 3+ (Pre-Production, Production): - \u2705 All Level 1-2 directories - \u2705 <code>nginx/</code> - API Gateway with SSL/TLS - \u2705 <code>infrastructure/monitoring/</code> - Prometheus, Grafana</p> <p>Level 4 (Production with Full Observability): - \u2705 All Level 3 directories - \u2705 <code>infrastructure/logging/</code> - ELK Stack - \u2705 Enhanced security and backup directories</p> <p>Reference: See Maturity Levels for complete feature matrix per level and conditional generation rules.</p>"},{"location":"reference/project-structure/#service-specific-layer-details","title":"Service-Specific Layer Details","text":"<p>For complete explanation of DDD/Hexagonal layers within each service's <code>src/</code> directory, see Project Structure Patterns.</p> <p>Quick layer reference: - <code>src/api/</code> - Transport adapters (FastAPI routers, REST endpoints) - <code>src/application/</code> - Use cases, orchestration logic, application DTOs - <code>src/domain/</code> - Business entities, value objects, domain services - <code>src/infrastructure/</code> - Repositories, HTTP clients, message broker integrations - <code>src/schemas/</code> - Pydantic models for request/response validation - <code>src/core/</code> - Configuration, logging setup, dependency injection</p>"},{"location":"reference/project-structure/#verification","title":"Verification","text":"<p>After creating the structure, verify it:</p> <pre><code># Verify service directories exist\ntree -L 3 -d services/\n\n# Verify shared components\nls -la shared/\n\n# Verify infrastructure (Level 3+)\nls -la nginx/conf.d/\nls -la infrastructure/monitoring/\n</code></pre> <p>Expected output: All directories should exist before generating any code files.</p>"},{"location":"reference/project-structure/#directory-structure-explanation","title":"Directory Structure Explanation","text":""},{"location":"reference/project-structure/#framework-directory-ai-framework","title":"Framework Directory (<code>.ai-framework/</code>)","text":"<ul> <li>Immutable: Never modify framework content when used as submodule</li> <li>Patterns: Contains atomic rules, implementation guides, and automation rule sets</li> <li>Documentation: All patterns documented in <code>docs/atomic/</code> with single responsibility per file</li> <li>Updates: Use <code>git submodule update --remote .framework</code> to get latest improvements</li> </ul>"},{"location":"reference/project-structure/#root-level-configuration","title":"Root-Level Configuration","text":"<ul> <li><code>docker-compose.yml</code>: Single orchestration file for all services, nginx, databases, and infrastructure</li> <li><code>pyproject.toml</code>: Optional root-level Python config for shared tooling</li> <li><code>Makefile</code>: Development automation commands (build, test, deploy)</li> <li><code>.gitignore</code>: Version control exclusions</li> <li><code>.env.example</code>: Environment configuration template with all variables</li> <li>Framework template: <code>.ai-framework/templates/infrastructure/.env.example</code> (203 lines with all variables)</li> <li>Usage: Copy to project root and customize for your environment</li> </ul>"},{"location":"reference/project-structure/#services-directory-services","title":"Services Directory (<code>services/</code>)","text":"<ul> <li>Purpose: All microservices as independent deployable units</li> <li>Structure: Each service has its own <code>src/</code>, <code>tests/</code>, <code>Dockerfile</code>, and dependencies</li> <li>Isolation: Services can be extracted to separate repositories without refactoring</li> <li>DDD/Hexagonal: Each service follows layered architecture (see Project Structure Patterns)</li> </ul>"},{"location":"reference/project-structure/#service-types","title":"Service Types","text":""},{"location":"reference/project-structure/#business-services","title":"Business Services","text":"<ul> <li><code>template_business_api/</code>: FastAPI REST API service (Port: 8000)</li> <li><code>template_business_bot/</code>: Aiogram Telegram bot service</li> <li><code>template_business_worker/</code>: AsyncIO background workers</li> <li>Purpose: Business logic only, HTTP-only data access</li> </ul>"},{"location":"reference/project-structure/#data-services","title":"Data Services","text":"<ul> <li><code>template_data_postgres_api/</code>: PostgreSQL data access service (Port: 8001)</li> <li><code>template_data_mongo_api/</code>: MongoDB data access service (Port: 8002)</li> <li>Purpose: Centralized database operations, no business logic</li> </ul>"},{"location":"reference/project-structure/#shared-components-shared","title":"Shared Components (<code>shared/</code>)","text":"<ul> <li>Cross-Service Code: DTOs, events, and utilities used across multiple services</li> <li>Ownership: Clear ownership and versioning for shared contracts</li> <li>Stateless: Utilities remain pure functions without side effects</li> </ul>"},{"location":"reference/project-structure/#nginx-directory-nginx","title":"Nginx Directory (<code>nginx/</code>)","text":"<ul> <li>Purpose: API Gateway and reverse proxy for all services</li> <li>SSL/TLS: Centralized certificate management and termination</li> <li>Routing: Path-based routing to internal services</li> <li>Security: Rate limiting, CORS, security headers</li> <li>Single Instance: One nginx serves all microservices</li> </ul>"},{"location":"reference/project-structure/#infrastructure-directory-infrastructure","title":"Infrastructure Directory (<code>infrastructure/</code>)","text":"<ul> <li>Optional: Observability and monitoring configurations</li> <li>Monitoring: Prometheus, Grafana, alerting rules</li> <li>Logging: ELK stack (Elasticsearch, Logstash, Kibana) configurations</li> <li>Separation: Infrastructure concerns isolated from business services</li> </ul>"},{"location":"reference/project-structure/#service-file-structure","title":"Service File Structure","text":"<p>The structure below is a simplified overview for quick setup. For the complete, mandatory source code organization inside a service (including the <code>src/</code> layout, DDD/Hexagonal layers, and testing directories), see Project Structure Patterns for the mandatory layout.</p> <p>Each service contains at a minimum: - <code>Dockerfile</code>: Service-specific container configuration - <code>main.py</code>: Service implementation - <code>requirements.txt</code>: Service dependencies - <code>config.py</code>: Service-specific configuration</p>"},{"location":"reference/project-structure/#test-organization","title":"Test Organization","text":"<ul> <li><code>tests/unit/</code>: Individual test files per service (e.g., <code>test_api_service.py</code>)</li> <li><code>tests/integration/</code>: Cross-service communication tests</li> <li><code>conftest.py</code>: Centralized test fixtures and configuration</li> </ul>"},{"location":"reference/project-structure/#docker-compose-organization","title":"Docker Compose Organization","text":""},{"location":"reference/project-structure/#single-root-compose-setup-mandatory","title":"Single Root Compose Setup (Mandatory)","text":"<p>Use one main <code>docker-compose.yml</code> in the project root, not individual compose files per service.</p> <p>Example Structure: <pre><code>services:\n  # API Gateway\n  nginx:\n    build: ./nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    depends_on:\n      - template_business_api\n      - template_business_bot\n    networks:\n      - app_network\n\n  # Business Services (no exposed ports, internal only)\n  template_business_api:\n    build: ./services/template_business_api\n    networks:\n      - app_network\n\n  template_business_bot:\n    build: ./services/template_business_bot\n    networks:\n      - app_network\n\n  template_business_worker:\n    build: ./services/template_business_worker\n    networks:\n      - app_network\n\n  # Data Services (internal ports only)\n  template_data_postgres_api:\n    build: ./services/template_data_postgres_api\n    networks:\n      - app_network\n\n  template_data_mongo_api:\n    build: ./services/template_data_mongo_api\n    networks:\n      - app_network\n\n  # Infrastructure\n  postgres:\n    image: postgres:16\n    networks:\n      - app_network\n\n  mongodb:\n    image: mongo:7\n    networks:\n      - app_network\n\n  redis:\n    image: redis:7-alpine\n    networks:\n      - app_network\n\n  rabbitmq:\n    image: rabbitmq:3-management\n    networks:\n      - app_network\n\nnetworks:\n  app_network:\n    driver: bridge\n</code></pre></p> <p>Benefits: - Single Entry Point: Nginx handles all external traffic, services isolated internally - Service Isolation: Business services never expose ports directly - Data Service Isolation: Centralized database expertise and optimization - Shared Infrastructure: Redis, RabbitMQ, observability stack shared across all services - Proper Service Networking: HTTP communication between business and data services via internal network - Unified Environment: Single command deployment with proper dependency management - Security: Only nginx is exposed; services communicate via internal Docker network</p>"},{"location":"reference/project-structure/#framework-management","title":"Framework Management","text":""},{"location":"reference/project-structure/#submodule-operations","title":"Submodule Operations","text":"<pre><code># Update framework to latest version\ngit submodule update --remote .framework\ngit add .framework &amp;&amp; git commit -m \"Update framework\"\n\n# Clone project with framework\ngit clone --recursive &lt;your-project-repo&gt;\n\n# If you forgot --recursive\ngit submodule init &amp;&amp; git submodule update\n</code></pre>"},{"location":"reference/project-structure/#development-workflow","title":"Development Workflow","text":"<ol> <li>Add framework as submodule to your project</li> <li>Generate application code in <code>services/</code>, <code>shared/</code>, and <code>nginx/</code> using AI or manual development</li> <li>Follow framework patterns from <code>docs/</code> (or <code>.ai-framework/docs/</code> when used as submodule)</li> <li>Never modify <code>.ai-framework/</code> content</li> <li>Update framework periodically with <code>git submodule update --remote</code></li> </ol> <p>Key Principles: - Services at root level (<code>services/</code>), not buried in <code>src/</code> - Each service is self-contained with own <code>src/</code>, <code>tests/</code>, and dependencies - Nginx at root level for API Gateway functionality - Infrastructure concerns (monitoring, logging) separated in <code>infrastructure/</code></p>"},{"location":"reference/project-structure/#quick-setup-guide","title":"Quick Setup Guide","text":"<pre><code># 1. Create your project\nmkdir my_awesome_app &amp;&amp; cd my_awesome_app &amp;&amp; git init\n\n# 2. Add framework as submodule\ngit submodule add &lt;framework-repo-url&gt; .framework\ngit submodule init &amp;&amp; git submodule update\n\n# 3. Generate application with AI (AI reads framework patterns)\n# Ask AI: \"Create [your app] using .ai-framework/ patterns\"\n\n# 4. Deploy ready application\ndocker-compose up -d\n</code></pre>"},{"location":"reference/project-structure/#architecture-compliance","title":"Architecture Compliance","text":"<p>When organizing your project:</p>"},{"location":"reference/project-structure/#critical-constraints","title":"Critical Constraints","text":"<ul> <li>PROHIBITED: Direct database connections in business services</li> <li>PROHIBITED: Running multiple event loop managers in same process</li> <li>MANDATORY: Python 3.12+ for all services</li> <li>MANDATORY: Underscore-only naming convention (no hyphens)</li> </ul>"},{"location":"reference/project-structure/#service-communication","title":"Service Communication","text":"<ul> <li>Business \u2192 Data: HTTP APIs only</li> <li>Inter-service: RabbitMQ for events</li> <li>Service Isolation: Each service type in separate containers</li> </ul>"},{"location":"reference/project-structure/#documentation-references","title":"Documentation References","text":"<ul> <li>Architecture Details: Architecture Guide</li> <li>Development Commands: Development Commands</li> <li>Technology Stack: Technical Specifications</li> </ul>"},{"location":"reference/prompt-templates/","title":"Prompt Templates","text":"<p>Purpose: Provide reusable prompt snippets for human\u2013agent interaction across the workflow. Always adapt placeholders to the specific context.</p>"},{"location":"reference/prompt-templates/#usage-guidelines","title":"Usage Guidelines","text":"<ul> <li>Keep responses and generated documents aligned with <code>docs/STYLE_GUIDE.md</code>.</li> <li>Do not bypass architectural constraints; reference <code>docs/guides/architecture-guide.md</code> and <code>docs/architecture/*.mdc</code> when clarifying requirements.</li> <li>Use the templates below to fill gaps identified in <code>docs/guides/prompt-validation-guide.md</code>.</li> </ul>"},{"location":"reference/prompt-templates/#prompt-augmentation-validation","title":"Prompt Augmentation (Validation)","text":"Scenario Prompt Body Variables Expected Agent Output References Missing business context \"Please provide the business problem we are solving, the target users, and the success metrics so I can confirm alignment with the framework.\" None Structured description of context <code>docs/guides/prompt-validation-guide.md</code> Missing maturity level \"Choose target maturity level:\\n\\n1. \ud83e\uddea PoC (Proof of Concept)\\n   - Core functionality only (FastAPI + PostgreSQL)\\n   - Time: ~5 min | Use: MVP, demo, learning\\n\\n2. \ud83d\udee0\ufe0f Development Ready\\n   - + Structured logging, health checks, error tracking\\n   - Time: ~10 min | Use: Active development, staging\\n\\n3. \ud83d\ude80 Pre-Production\\n   - + Nginx, SSL, Prometheus metrics, rate limiting\\n   - Time: ~15 min | Use: Public beta, small production\\n\\n4. \ud83c\udfe2 Production\\n   - + Security (OAuth, RBAC), ELK, tracing, CI/CD, HA\\n   - Time: ~30 min | Use: Enterprise, compliance\\n\\nYour choice (1-4): _____\" None Selected level (1-4) <code>docs/reference/maturity-levels.md</code> Missing optional modules \"Optional modules (available at any maturity level):\\n  [ ] Telegram Bot (Aiogram)\\n  [ ] Background Workers (AsyncIO)\\n  [ ] MongoDB (NoSQL database)\\n  [ ] RabbitMQ (event messaging)\\n  [ ] Redis (caching)\\n  [ ] File Storage (S3/MinIO)\\n  [ ] Real-Time (WebSockets)\\n\\nYour selection (comma-separated or 'none'): _____\" None List of selected modules or \"none\" <code>docs/reference/maturity-levels.md</code> Missing functional requirements \"List the core features or user stories that the application must support. Prioritize them if possible.\" None Ordered feature list <code>docs/guides/prompt-validation-guide.md</code> Missing non-functional constraints \"Share performance, security, and compliance expectations. I need these to verify architecture and quality rules.\" None Non-functional requirements <code>docs/guides/architecture-guide.md</code> Missing dependencies \"Describe external systems, queues, or databases we must integrate with. Mention protocols or APIs if known.\" None Integration details <code>docs/atomic/infrastructure/</code> Missing scope boundaries \"Clarify what is explicitly out of scope so the plan does not include unnecessary features.\" None Out-of-scope list <code>docs/guides/implementation-plan-template.md</code> Missing deliverables/acceptance criteria \"Specify required deliverables (code, documentation, reports) and acceptance criteria such as tests or coverage targets.\" None Deliverables and acceptance list <code>docs/reference/deliverables-catalog.md</code>, <code>docs/quality/agent-verification-checklist.md</code> Missing scalability requirements \"Please clarify scalability expectations:\\n\\n**Traffic &amp; Load**:\\n- Expected requests per second (RPS): _____\\n- Expected daily active users (DAU): _____\\n- Peak load multiplier (e.g., 3x normal): _____\\n\\n**Scaling Strategy**:\\n- [ ] Horizontal scaling (multiple service instances)\\n- [ ] Vertical scaling (larger containers)\\n- [ ] Database read replicas needed?\\n- [ ] Caching strategy required?\\n\\n**Performance Targets**:\\n- API response time (p95): _____ ms\\n- Database query time (p95): _____ ms\\n- Acceptable downtime per month: _____\\n\\nNote: Horizontal scaling and DB replication typically require Level 4 (Production).\" None Scalability requirements (RPS, DAU, SLA targets, scaling strategy) <code>docs/reference/maturity-levels.md</code>, <code>docs/atomic/infrastructure/databases/postgresql-replication.md</code> Missing compliance requirements \"Please specify compliance and regulatory requirements:\\n\\n**Regulations** (check all that apply):\\n- [ ] GDPR (EU General Data Protection Regulation)\\n- [ ] HIPAA (US Healthcare data protection)\\n- [ ] PCI-DSS (Payment Card Industry)\\n- [ ] SOC 2 (Security &amp; availability controls)\\n- [ ] CCPA (California Consumer Privacy Act)\\n- [ ] Other: _____\\n\\n**Data Protection**:\\n- Data residency requirements (EU, US, Asia): _____\\n- Data retention period: _____\\n- Right to deletion (GDPR Article 17): Yes / No\\n- Encryption at rest required: Yes / No\\n- Encryption in transit required: Yes / No\\n\\n**Audit &amp; Logging**:\\n- Audit log retention: _____ years\\n- Security event logging required: Yes / No\\n- User consent tracking required: Yes / No\\n\\nNote: Full compliance features typically require Level 4 (Production) with audit logging, encryption, and access controls.\" None Compliance requirements (regulations, data protection, audit needs) <code>docs/reference/maturity-levels.md</code>, <code>docs/atomic/security/authentication-authorization-guide.md</code>, <code>docs/atomic/observability/logging/sensitive-data-handling.md</code>"},{"location":"reference/prompt-templates/#planning-confirmation","title":"Planning &amp; Confirmation","text":"Scenario Prompt Body Variables Expected Agent Output References Confirm ready to plan \"I have validated the prompt. Summarize the requirements and confirm we can proceed to the implementation plan.\" None Intake summary + go/no-go <code>docs/guides/requirements-intake-template.md</code> Request plan approval \"Here is the proposed implementation plan: {{plan_link}}. Please review the stages, DoD, and risks. Confirm or provide adjustments.\" <code>plan_link</code> Plan approval or change requests <code>docs/guides/implementation-plan-template.md</code> Clarify risks \"Highlight any additional risks or dependencies we should track before coding begins.\" None Risk updates Plan template"},{"location":"reference/prompt-templates/#coding-execution","title":"Coding &amp; Execution","text":"Scenario Prompt Body Variables Expected Agent Output References Kick off implementation \"Proceed with implementing the plan. Reference the architecture and service rules as you create code.\" None Execution acknowledgement <code>docs/guides/ai-code-generation-master-workflow.md</code> Stage 4, <code>docs/atomic/services/*</code> Request progress update \"Provide a status update for each stage in the implementation plan, including blockers.\" None Status report Implementation plan"},{"location":"reference/prompt-templates/#verification-release","title":"Verification &amp; Release","text":"Scenario Prompt Body Variables Expected Agent Output References Trigger verification \"Run the full verification checklist and report results for linting, typing, security, tests, and coverage.\" None Checklist results <code>docs/quality/agent-verification-checklist.md</code> Request QA report \"Compile the QA report summarizing checks, test evidence, and outstanding risks.\" None QA report draft <code>docs/quality/qa-report-template.md</code> Final hand-off \"Summarize deliverables, link to artefacts, and state whether acceptance criteria are met.\" None Final summary <code>docs/reference/deliverables-catalog.md</code>"},{"location":"reference/prompt-templates/#anti-patterns","title":"Anti-Patterns","text":"<ul> <li>Avoid prompts asking the agent to ignore architecture or quality rules.</li> <li>Do not solicit direct database access or merged service processes (violates <code>docs/architecture/data-access-rules.mdc</code>).</li> <li>Never request code generation without validated requirements.</li> </ul>"},{"location":"reference/prompt-templates/#maintenance","title":"Maintenance","text":"<ul> <li>Update scenarios when new workflow steps are introduced.</li> <li>Keep references synchronized with <code>docs/INDEX.md</code> and <code>docs/reference/agent-context-summary.md</code>.</li> <li>Follow <code>docs/STYLE_GUIDE.md</code> when editing.</li> </ul>"},{"location":"reference/tech_stack/","title":"Technology Stack","text":"<p>CANONICAL TECHNOLOGY REFERENCE: This document is the single source of truth for all technology versions, configurations, and specifications used in the project. All other documentation references this file.</p> <p>Related Documentation: For development guidance, see Development Commands. For service-specific patterns, see Documentation Index (architecture/, services/, infrastructure/, observability/, quality/). For troubleshooting, see Troubleshooting Guide.</p>"},{"location":"reference/tech_stack/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Architecture</li> <li>Service Types and Event Loop Separation</li> <li>Version Control and Tools</li> <li>Asynchronous Frameworks</li> <li>Microservices and Infrastructure</li> <li>Observability and Monitoring</li> <li>Servers and Deployment</li> <li>Asynchronous Libraries</li> <li>Implementation Guidelines</li> </ul>"},{"location":"reference/tech_stack/#architecture","title":"Architecture","text":""},{"location":"reference/tech_stack/#architectural-patterns","title":"Architectural Patterns","text":"<ul> <li>Technology: DDD/Hexagonal architecture, Test Driven Design</li> <li>Comment: DDD/Hex works well with FastAPI, SQLAlchemy repositories and queues (RabbitMQ), isolating domain from infrastructure. Suitable for asynchronous code (port/adapter separation), Python 3.12+ compatible. Compatible with other libraries (Pydantic v2, Uvicorn, Alembic), simplifies testing (pytest-asyncio, testcontainers) and scaling in Docker Compose.</li> <li>Detailed implementation: See Microservices Best Practices for complete DDD/Hex architecture guide.</li> </ul>"},{"location":"reference/tech_stack/#technology-implementation-summary","title":"Technology Implementation Summary","text":"<p>ARCHITECTURAL PRINCIPLES: For complete architectural guidelines and patterns, see the Architecture Guide.</p> <p>This section provides technology-specific implementation details for the Improved Hybrid Approach:</p> <ul> <li>Data Services: FastAPI + SQLAlchemy 2.x (PostgreSQL) / Motor (MongoDB)</li> <li>Business Services: FastAPI + httpx for HTTP-only data access</li> <li>Communication: RabbitMQ for events, HTTP for data access</li> <li>Runtime: Python 3.12+ unified across all services</li> </ul>"},{"location":"reference/tech_stack/#service-types-and-event-loop-separation","title":"Service Types and Event Loop Separation","text":""},{"location":"reference/tech_stack/#critical-architecture-constraints","title":"Critical Architecture Constraints","text":"<ul> <li>MANDATORY: Each service type must run in separate processes/containers to avoid event loop conflicts</li> <li>PROHIBITED: Running FastAPI and Aiogram in the same process - this creates conflicting event loop claims</li> <li>MANDATORY: Use RabbitMQ or other message brokers for communication between different service types</li> </ul>"},{"location":"reference/tech_stack/#microservice-types-and-technologies","title":"Microservice Types and Technologies","text":""},{"location":"reference/tech_stack/#http-api-services","title":"HTTP API Services","text":"<ul> <li>Technology: FastAPI + Uvicorn</li> <li>Event Loop: Managed by FastAPI/Uvicorn</li> <li>Integration: Redis and RabbitMQ via dependency injection</li> <li>Process: Separate container/process</li> <li>Guide: See FastAPI Rules</li> </ul>"},{"location":"reference/tech_stack/#telegram-bot-services","title":"Telegram Bot Services","text":"<ul> <li>Technology: Aiogram</li> <li>Event Loop: Managed by Aiogram via <code>asyncio.run(dp.start_polling(bot))</code></li> <li>Integration: Redis and RabbitMQ via dependency injection in Dispatcher</li> <li>Process: Separate container/process</li> <li>Guide: See Aiogram Rules</li> </ul>"},{"location":"reference/tech_stack/#background-worker-services","title":"Background Worker Services","text":"<ul> <li>Technology: AsyncIO + aio-pika + redis.asyncio</li> <li>Event Loop: <code>asyncio.run(main())</code> in separate process</li> <li>Integration: Direct use of async libraries</li> <li>Process: Separate container/process</li> <li>Guide: See AsyncIO Rules</li> </ul>"},{"location":"reference/tech_stack/#inter-service-communication","title":"Inter-service Communication","text":"<ul> <li>Synchronous: HTTP API between services (FastAPI \u2194 FastAPI)</li> <li>Asynchronous: RabbitMQ events between all service types</li> <li>Caching: Redis for all service types (idempotency, cache, sessions)</li> <li>Tracing: Request ID and OpenTelemetry trace propagation</li> </ul>"},{"location":"reference/tech_stack/#version-control-and-tools","title":"Version Control and Tools","text":""},{"location":"reference/tech_stack/#version-control-system","title":"Version Control System","text":"<ul> <li>Technology: Git</li> <li>Comment: Standard for code management and CI/CD. Fully compatible with any stack and workflows, independent of sync/async and Python version. Fits perfectly into microservice development and GitOps.</li> </ul>"},{"location":"reference/tech_stack/#package-manager","title":"Package Manager","text":"<ul> <li>Technology: UV</li> <li>Comment: Fast environment/dependency manager. Compatible with Python 3.12+, works with Docker and CI pipeline, supports reproducible builds (lock files). No conflicts with FastAPI/SQLAlchemy/Pydantic.</li> </ul>"},{"location":"reference/tech_stack/#linter","title":"Linter","text":"<ul> <li>Technology: Ruff</li> <li>Libraries: ruff&gt;=0.1.0</li> <li> <p>Comment: Ruff provides fast PEP8/style and formatting. Compatible with Python 3.12+, async-independent. Works well in CI and doesn't conflict with other libraries.</p> </li> <li> <p>Technology: Bandit</p> </li> <li>Libraries: bandit&gt;=1.8.0</li> <li>Comment: Bandit performs static security analysis. Compatible with Python 3.12+, async-independent. Complements Ruff, integrates easily into CI/CD.</li> </ul>"},{"location":"reference/tech_stack/#type-annotation-checking","title":"Type Annotation Checking","text":"<ul> <li>Technology: Mypy</li> <li>Libraries: mypy&gt;=1.8.0</li> <li>Comment: Static type checking improves reliability. Compatible with Python 3.12+ and Pydantic v2 (via typed models), suitable for async code and entire used stack.</li> </ul>"},{"location":"reference/tech_stack/#asynchronous-frameworks","title":"Asynchronous Frameworks","text":""},{"location":"reference/tech_stack/#async-library-for-rest-api","title":"Async Library for REST API","text":"<ul> <li>Technology: FastAPI</li> <li>Libraries: fastapi&gt;=0.115.0</li> <li>Comment: Native async/await, works excellently with Uvicorn, Pydantic v2, SQLAlchemy asyncio, Redis and RabbitMQ. Full compatibility with Python 3.12+ and DDD/Hex architecture (routers/services/repositories).</li> </ul>"},{"location":"reference/tech_stack/#async-library-for-telegram","title":"Async Library for Telegram","text":"<ul> <li>Technology: Aiogram</li> <li>Libraries: aiogram&gt;=3.22.0</li> <li>Comment: Fully asynchronous, compatible with Python 3.12+. Integrates well with Redis (cache/FSM), RabbitMQ (background processing) and FastAPI (webhooks). Fits DDD/Hex via bot adapters.</li> </ul>"},{"location":"reference/tech_stack/#async-framework","title":"Async Framework","text":"<ul> <li>Technology: AsyncIO</li> <li>Libraries: asyncio</li> <li>Comment: Base event loop for entire stack. Full compatibility with Python 3.12+, used by Uvicorn, httpx, aio-pika, aiogram and others. Foundation of async architecture.</li> </ul>"},{"location":"reference/tech_stack/#llm-framework","title":"LLM Framework","text":"<ul> <li>Technology: LangChain</li> <li>Libraries: langchain&gt;=0.2.11, langchain-core&gt;=0.2.22, langchain-openai&gt;=0.2.5</li> <li>Comment: Supports integrations with OpenAI and ChromaDB, has async API. Compatible with Python 3.12+, applicable as separate domain module (DDD) and adapter to LLM providers.</li> </ul>"},{"location":"reference/tech_stack/#async-code-testing","title":"Async Code Testing","text":"<ul> <li>Technology: Pytest-asyncio</li> <li>Libraries: pytest&gt;=8.3.0, pytest-asyncio&gt;=0.24.0, pytest-cov&gt;=6.0.0, testcontainers&gt;=4.8.0</li> <li>Comment: Provides async tests and coverage. Compatible with Python 3.12+. Testcontainers allows spinning up real PostgreSQL/Redis/RabbitMQ/ChromaDB for integration tests.</li> </ul>"},{"location":"reference/tech_stack/#orm-object-relational-mapping","title":"ORM (Object-Relational Mapping)","text":"<ul> <li>Technology: SQLAlchemy</li> <li>Libraries: sqlalchemy[asyncio]&gt;=2.0.36</li> <li>Comment: Native asyncio support in 2.x branch. Compatible with Python 3.12+, asyncpg, Alembic and DDD (repositories/unit of work). Works well in UoW patterns.</li> </ul>"},{"location":"reference/tech_stack/#sqlalchemy-migrations","title":"SQLAlchemy Migrations","text":"<ul> <li>Technology: Alembic</li> <li>Libraries: alembic&gt;=1.13.2</li> <li>Comment: De-facto migration standard, compatible with SQLAlchemy 2.x and Python 3.12+. Suitable for microservices (separate schemas/DBs) and CI/CD.</li> </ul>"},{"location":"reference/tech_stack/#ai-providers","title":"AI Providers","text":"<ul> <li>Technologies: OpenAI, OpenRouter</li> <li>Libraries: openai&gt;=1.0.0</li> <li>Comment: Compatible with Python 3.12+, supports async client. Integrates with LangChain and used via ENV/secrets configuration. Works in Docker/Compose.</li> </ul>"},{"location":"reference/tech_stack/#microservices-and-infrastructure","title":"Microservices and Infrastructure","text":""},{"location":"reference/tech_stack/#application-containerization","title":"Application Containerization","text":"<ul> <li>Technology: Docker</li> <li>Image/Version: Docker version 27.0.0+, base image: python:3.12-slim</li> <li>Comment: Foundation for service packaging. Base image with Python 3.12 compatible with entire stack. Supports multi-layer builds, caching, healthchecks and network isolation.</li> </ul>"},{"location":"reference/tech_stack/#container-orchestration","title":"Container Orchestration","text":"<ul> <li>Technology: Docker Compose</li> <li>Version: v2.29.0+</li> <li>Comment: Describes multi-service environment (Postgres, Redis, RabbitMQ, ChromaDB, ELK, Prometheus/Grafana, Nginx). Compatible with async services and dependencies.</li> </ul>"},{"location":"reference/tech_stack/#api-gateway-web-server","title":"API Gateway / Web Server","text":"<ul> <li>Technology: Nginx</li> <li>Version: 1.25+ (recommended: 1.26.1)</li> <li>Image: nginx:1.26.1-alpine</li> <li>Purpose: API Gateway and reverse proxy for production deployments</li> <li>Responsibilities:</li> <li>TLS/SSL termination (HTTPS)</li> <li>Reverse proxy and load balancing across backend services</li> <li>Rate limiting and DDoS protection</li> <li>CORS and security headers</li> <li>Request routing and URL rewriting</li> <li>Integration:</li> <li>Proxies requests to FastAPI services (Port: 8000)</li> <li>Proxies webhook requests to Aiogram Bot (Port: 8000)</li> <li>Load balances across multiple instances of each service</li> <li>Integrates with Prometheus exporters and ELK logging</li> <li>Configuration: See Nginx Setup, Load Balancing, and Security Hardening</li> <li>Environment:</li> <li>Development: Optional (can access services directly)</li> <li>Production: MANDATORY for all deployments</li> <li>Comment: Compatible with Uvicorn, TLS/HTTP2, WebSocket proxying. Essential for production security and performance.</li> </ul>"},{"location":"reference/tech_stack/#python-interpreter","title":"Python Interpreter","text":"<ul> <li>Technology: Python</li> <li>Version: 3.12+ (STANDARD for all services)</li> <li>Image: python:3.12-slim (builder stage)</li> <li>Comment: Single version for all microservices. Compatible with all libraries, optimal for slim builds. Supports async/await, Pydantic v2, SQLAlchemy 2.x etc. All services MUST use Python 3.12+.</li> </ul>"},{"location":"reference/tech_stack/#relational-database","title":"Relational Database","text":"<ul> <li>Technology: PostgreSQL</li> <li>Image: postgres:16</li> <li>Comment: Primary relational database for structured data, transactions, and business entities. Accessed ONLY via template_data_postgres_api in the Improved Hybrid Approach. Supports complex queries, joins, and ACID transactions.</li> <li>Integration: Business services access PostgreSQL data via HTTP calls to template_data_postgres_api (Port: 8001).</li> <li>Use Cases: Users, products, orders, payments, structured business data requiring transactions.</li> </ul>"},{"location":"reference/tech_stack/#postgresql-driver","title":"PostgreSQL Driver","text":"<ul> <li>Technology: asyncpg</li> <li>Libraries: asyncpg&gt;=0.30.0</li> <li>Comment: Used ONLY in template_data_postgres_api for direct database access. Native asyncio driver with superior performance. Fully compatible with SQLAlchemy 2.x, Python 3.12+. Business services MUST NOT use asyncpg directly - use HTTP client instead.</li> </ul>"},{"location":"reference/tech_stack/#message-broker","title":"Message Broker","text":"<ul> <li>Technology: RabbitMQ</li> <li>Image: rabbitmq:3.13-management</li> <li>Comment: Critical component for inter-service communication. MANDATORY for communication between different service types (FastAPI \u2194 Aiogram \u2194 AsyncIO). Ensures reliable event delivery and service decoupling.</li> <li>Integration:</li> <li>FastAPI: via <code>app.state.rabbitmq</code> and dependency injection</li> <li>Aiogram: via <code>dp.startup.register()</code> and dependency injection</li> <li>AsyncIO: via global client in <code>main()</code> function</li> <li>Detailed implementation: See RabbitMQ Rules</li> </ul>"},{"location":"reference/tech_stack/#rabbitmq-driver","title":"RabbitMQ Driver","text":"<ul> <li>Technology: aio-pika (ONLY async version)</li> <li>Libraries: aio-pika&gt;=9.5.0</li> <li>Comment: Only acceptable client for async services. Mandatory use of <code>connect_robust()</code> for reliability. Key requirements: Request ID in headers (<code>x-request-id</code>), Pydantic DTOs for validation, idempotency via Redis.</li> <li>CRITICAL: CANNOT create separate event loops when using with FastAPI/Aiogram.</li> <li>PROHIBITED: Using synchronous <code>pika</code> library in async services.</li> </ul>"},{"location":"reference/tech_stack/#nosql-database","title":"NoSQL Database","text":"<ul> <li>Technology: MongoDB</li> <li>Image: mongo:7.0.9</li> <li>Comment: Document-oriented storage for analytics, user behavior, and flexible schemas. Accessed ONLY via template_data_mongo_api in the Improved Hybrid Approach. Supports aggregation pipelines and real-time analytics.</li> <li>Integration: Business services access MongoDB data via HTTP calls to template_data_mongo_api (Port: 8002).</li> <li>Use Cases: Analytics events, user behavior tracking, application logs, flexible document storage.</li> </ul>"},{"location":"reference/tech_stack/#mongodb-driver","title":"MongoDB Driver","text":"<ul> <li>Technology: Motor</li> <li>Libraries: motor==3.5.0 (async library)</li> <li>Comment: Used ONLY in template_data_mongo_api for direct database access. Fully async driver over pymongo, compatible with Python 3.12+. Business services MUST NOT use Motor directly - use HTTP client instead.</li> </ul>"},{"location":"reference/tech_stack/#cache-and-idempotency","title":"Cache and Idempotency","text":"<ul> <li>Technology: Redis</li> <li>Image: redis:7-alpine</li> <li>Comment: In-memory cache/sessions/locks/idempotency. Critical for avoiding operation duplication between services. Integrates via dependency injection in all service types.</li> <li>Integration:</li> <li>FastAPI: via <code>app.state.redis</code> and dependency injection</li> <li>Aiogram: via <code>dp.startup.register()</code> and dependency injection</li> <li>AsyncIO: via global client in <code>main()</code> function</li> <li>Detailed implementation: See Redis Rules</li> </ul>"},{"location":"reference/tech_stack/#redis-driver","title":"Redis Driver","text":"<ul> <li>Technology: redis.asyncio</li> <li>Libraries: redis&gt;=5.0.1</li> <li>Comment: Only acceptable client for all async services. Connection pooling via <code>from_url()</code>. Key patterns: idempotency via <code>SETNX</code>, unified key naming (<code>context:entity:id</code>), Request ID integration.</li> <li>CRITICAL: CANNOT create separate event loops when using with FastAPI/Aiogram.</li> </ul>"},{"location":"reference/tech_stack/#rag-database","title":"RAG Database","text":"<ul> <li>Technology: ChromaDB</li> <li>Image: chromadb/chroma:0.5.0</li> <li>Comment: Vector storage for RAG. Used as HTTP API; compatible with LangChain and Python 3.12+. For async applications used via httpx.</li> </ul>"},{"location":"reference/tech_stack/#chromadb-driver","title":"ChromaDB Driver","text":"<ul> <li>Technology: chromadb</li> <li>Libraries: chromadb==0.5.0</li> <li>Comment: Client for ChromaDB. Synchronous API, in async applications used via httpx or thread pools. Combines with LangChain.</li> </ul>"},{"location":"reference/tech_stack/#log-database","title":"Log Database","text":"<ul> <li>Technology: Elasticsearch</li> <li>Image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0</li> <li>Comment: Log search and analytics. Updated to v8.x for security support. Compatible with Logstash/Kibana and Python clients, deployed in Compose.</li> </ul>"},{"location":"reference/tech_stack/#elasticsearch-driver","title":"Elasticsearch Driver","text":"<ul> <li>Technology: elasticsearch-async</li> <li>Libraries: elasticsearch&gt;=8.15.0</li> <li>Comment: Updated to ES8 with async support, compatible with Python 3.12. Integrates with FastAPI for logging/search.</li> </ul>"},{"location":"reference/tech_stack/#log-collector","title":"Log Collector","text":"<ul> <li>Technology: Logstash</li> <li>Image: docker.elastic.co/logstash/logstash:8.15.0</li> <li>Comment: Log ingestion/enrichment/routing. Compatible with Elasticsearch/Kibana and container environment; easily connects to Nginx and applications.</li> </ul>"},{"location":"reference/tech_stack/#log-dashboard","title":"Log Dashboard","text":"<ul> <li>Technology: Kibana</li> <li>Image: docker.elastic.co/kibana/kibana:8.15.0</li> <li>Comment: Log and metrics visualization. Compatible with Elasticsearch 8.x, deployed in Compose, integrates with SSO/Reverse proxy.</li> </ul>"},{"location":"reference/tech_stack/#metrics","title":"Metrics","text":"<ul> <li>Technology: Prometheus</li> <li>Image: prom/prometheus:v2.53.0</li> <li>Comment: Service and infrastructure metrics collection. Integrates with Python <code>prometheus_client</code>, Nginx exporters and Grafana. Compatible with Docker Compose.</li> </ul>"},{"location":"reference/tech_stack/#prometheus-driver","title":"Prometheus Driver","text":"<ul> <li>Technology: prometheus_client</li> <li>Libraries: prometheus_client&gt;=0.20.0</li> <li>Comment: Metrics export from FastAPI/Uvicorn. Compatible with Python 3.12 and async applications (metric endpoints/middleware), displayed in Grafana.</li> </ul>"},{"location":"reference/tech_stack/#dashboards","title":"Dashboards","text":"<ul> <li>Technology: Grafana</li> <li>Image: grafana/grafana:11.2.0</li> <li>Comment: Universal metrics/logs dashboards. Integration with Prometheus/Elasticsearch, deployment in Compose, compatible with rest of stack.</li> </ul>"},{"location":"reference/tech_stack/#error-tracker","title":"Error Tracker","text":"<ul> <li>Technology: Sentry</li> <li>Image: sentry/sentry:24.10.0</li> <li>Comment: Error monitoring/tracing. SDK compatible with FastAPI/ASGI and Python 3.12+. Easily integrates with Docker and CI/CD.</li> </ul>"},{"location":"reference/tech_stack/#sentry-driver","title":"Sentry Driver","text":"<ul> <li>Technology: sentry-sdk</li> <li>Libraries: sentry-sdk&gt;=2.11.0</li> <li>Comment: ASGI middleware support, logging integration. Compatible with Python 3.12+ and other dependencies; no conflicts with Prometheus/ELK.</li> </ul>"},{"location":"reference/tech_stack/#observability-and-monitoring","title":"Observability and Monitoring","text":""},{"location":"reference/tech_stack/#metrics-collection-and-visualization","title":"Metrics Collection and Visualization","text":"<ul> <li>Technology: Prometheus + Grafana</li> <li>Image: prom/prometheus:v2.53.0, grafana/grafana:11.2.0</li> <li>Libraries: prometheus_client&gt;=0.20.0</li> <li>Comment: Complete metrics collection using Golden Signals methodology. Prometheus scrapes metrics from all services, Grafana provides visualization and alerting. Integrates with existing Request ID system from <code>logging_rules.mdc</code>.</li> <li>Detailed implementation: See Metrics Rules for service-specific patterns.</li> </ul>"},{"location":"reference/tech_stack/#distributed-tracing","title":"Distributed Tracing","text":"<ul> <li>Technology: Jaeger + OpenTelemetry</li> <li>Image: jaegertracing/all-in-one:1.50</li> <li>Libraries: opentelemetry-api&gt;=1.21.0, opentelemetry-sdk&gt;=1.21.0, opentelemetry-instrumentation-fastapi&gt;=0.42b0</li> <li>Comment: End-to-end request tracing across microservices. Builds on existing OpenTelemetry setup in <code>logging_rules.mdc</code>. Automatic correlation with Request ID system for complete observability.</li> <li>Detailed implementation: See Tracing Rules for comprehensive setup.</li> </ul>"},{"location":"reference/tech_stack/#log-aggregation-and-analysis","title":"Log Aggregation and Analysis","text":"<ul> <li>Technology: ELK Stack (Elasticsearch + Logstash + Kibana + Filebeat)</li> <li>Image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0, docker.elastic.co/logstash/logstash:8.15.0, docker.elastic.co/kibana/kibana:8.15.0, docker.elastic.co/beats/filebeat:8.15.0</li> <li>Comment: Centralized log aggregation and analysis. Enhances existing structured logging from <code>logging_rules.mdc</code> with powerful search, visualization, and alerting capabilities. Replaces Loki+Promtail approach for better complex log analysis.</li> <li>Detailed implementation: See ELK Rules for complete ELK setup.</li> </ul>"},{"location":"reference/tech_stack/#error-tracking-and-performance-monitoring","title":"Error Tracking and Performance Monitoring","text":"<ul> <li>Technology: Sentry</li> <li>Image: sentry/sentry:24.10.0</li> <li>Libraries: sentry-sdk&gt;=2.11.0</li> <li>Comment: Application error tracking with automatic grouping, performance monitoring, and release tracking. ASGI middleware support for FastAPI integration. Compatible with existing logging and tracing systems.</li> <li>Integration: Correlates with Request ID and trace context from existing observability foundation.</li> </ul>"},{"location":"reference/tech_stack/#infrastructure-monitoring","title":"Infrastructure Monitoring","text":"<ul> <li>Technology: Exporters (PostgreSQL, Redis, RabbitMQ, Node)</li> <li>Images: Various community exporters</li> <li>Comment: Infrastructure-level metrics for databases, message brokers, and system resources. Integrates with Prometheus for unified monitoring and alerting.</li> </ul>"},{"location":"reference/tech_stack/#comprehensive-observability-strategy","title":"Comprehensive Observability Strategy","text":"<ul> <li>Foundation: Builds on excellent <code>logging_rules.mdc</code> with Request ID correlation</li> <li>Four Pillars: Logs (ELK), Metrics (Prometheus), Traces (Jaeger), Errors (Sentry)</li> <li>Integration: Unified Request ID correlation across all observability data</li> <li>Deployment: Docker Compose integration with existing infrastructure</li> <li>Detailed architecture: See Observability Rules for complete strategy</li> </ul>"},{"location":"reference/tech_stack/#servers-and-deployment","title":"Servers and Deployment","text":""},{"location":"reference/tech_stack/#asgi-server","title":"ASGI Server","text":"<ul> <li>Technology: Uvicorn</li> <li>Libraries: uvicorn&gt;=0.30.0</li> <li>Comment: High-performance ASGI server, fully async. Compatible with FastAPI, Python 3.12+, Prometheus metrics and Nginx as frontend.</li> </ul>"},{"location":"reference/tech_stack/#deployment","title":"Deployment","text":"<ul> <li>Technology: VPS</li> <li>Comment: Deployment via Docker Compose on VPS. Compatible with reverse-proxy Nginx, TLS, monitoring (Prometheus/Grafana) and logging (ELK).</li> </ul>"},{"location":"reference/tech_stack/#asynchronous-libraries","title":"Asynchronous Libraries","text":""},{"location":"reference/tech_stack/#async-photo-compression","title":"Async Photo Compression","text":"<ul> <li>Technology: Pillow</li> <li>Libraries: Pillow&gt;=11.3.0</li> <li>Comment: Synchronous library; in async code runs in thread pools. Compatible with Python 3.12+ and containers.</li> </ul>"},{"location":"reference/tech_stack/#async-http-requests","title":"Async HTTP Requests","text":"<ul> <li>Technology: httpx</li> <li>Libraries: httpx&gt;=0.27.0</li> <li>Comment: Native async client, supports timeouts/retries. Compatible with Python 3.12+, FastAPI, Sentry, Prometheus and Nginx proxy.</li> </ul>"},{"location":"reference/tech_stack/#high-performance-json","title":"High-Performance JSON","text":"<ul> <li>Technology: orjson</li> <li>Libraries: orjson&gt;=3.9.0</li> <li>Comment: Very fast serializer, compatible with Python 3.12+. Integrates with Pydantic v2 and FastAPI for response acceleration.</li> </ul>"},{"location":"reference/tech_stack/#data-validation","title":"Data Validation","text":"<ul> <li>Technology: Pydantic</li> <li>Libraries: pydantic&gt;=2.6.3</li> <li>Comment: Validation/schemas, foundation for FastAPI. Full compatibility with Python 3.12+, dataclass/typing support and high-performance in v2.</li> </ul>"},{"location":"reference/tech_stack/#settings-management","title":"Settings Management","text":"<ul> <li>Technology: pydantic-settings</li> <li>Libraries: pydantic-settings&gt;=2.10.1</li> <li>Comment: Configuration loading from ENV/files. Compatible with Python 3.12+, works with Docker/Compose and secrets.</li> </ul>"},{"location":"reference/tech_stack/#uuidv6-generation","title":"UUIDv6 Generation","text":"<ul> <li>Technology: uuid6</li> <li>Libraries: uuid6&gt;=0.6.0</li> <li>Comment: Time-ordered UUID (v6) generation for DB/logs. Compatible with Python 3.12+ and PostgreSQL, async-independent.</li> </ul>"},{"location":"reference/tech_stack/#async-file-operations","title":"Async File Operations","text":"<ul> <li>Technology: aiofiles</li> <li>Libraries: aiofiles&gt;=24.1.0</li> <li>Comment: Async file I/O. Compatible with Python 3.12+ and FastAPI (file upload/serve), works well under Uvicorn.</li> </ul>"},{"location":"reference/tech_stack/#async-web-frameworkclient","title":"Async Web Framework/Client","text":"<ul> <li>Technology: aiohttp</li> <li>Libraries: aiohttp&gt;=3.9.0</li> <li>Comment: Async HTTP server/client. Compatible with Python 3.12+, alternative to httpx/Starlette stack; can be used as adapter in DDD.</li> </ul>"},{"location":"reference/tech_stack/#implementation-guidelines","title":"Implementation Guidelines","text":""},{"location":"reference/tech_stack/#cursor-rules-mandatory-study","title":"Cursor Rules (Mandatory Study)","text":"<p>This technology stack must be implemented according to detailed guides in docs root categories (architecture/, services/, infrastructure/, observability/, quality/). These rules contain specific patterns, requirements and code examples.</p>"},{"location":"reference/tech_stack/#core-architecture-rules","title":"Core Architecture Rules","text":"<ul> <li>Microservices Best Practices - Main guide for microservice architecture, DDD/Hex patterns, project structure and quality requirements</li> <li>Testing Standards - Testing standards with mandatory 100% coverage for critical paths</li> </ul>"},{"location":"reference/tech_stack/#service-type-rules","title":"Service Type Rules","text":"<ul> <li>FastAPI Rules - Detailed rules for HTTP API services on FastAPI</li> <li>Aiogram Rules - Standards for Telegram Bot services on Aiogram</li> <li>AsyncIO Rules - Rules for Background Worker services on AsyncIO</li> </ul>"},{"location":"reference/tech_stack/#infrastructure-rules","title":"Infrastructure Rules","text":"<ul> <li>Logging Rules - Unified logging standard with Request ID tracing</li> <li>Redis Rules - Redis patterns for caching and idempotency</li> <li>RabbitMQ Rules - RabbitMQ standards for inter-service communication</li> </ul>"},{"location":"reference/tech_stack/#critical-implementation-principles","title":"Critical Implementation Principles","text":""},{"location":"reference/tech_stack/#1-event-loop-separation","title":"1. Event Loop Separation","text":"<ul> <li>Each service type (FastAPI, Aiogram, AsyncIO) MUST run in separate process</li> <li>PROHIBITED to mix FastAPI and Aiogram in same process</li> <li>Use RabbitMQ for communication between service types</li> </ul>"},{"location":"reference/tech_stack/#2-dependency-injection-patterns","title":"2. Dependency Injection Patterns","text":"<ul> <li>FastAPI: <code>app.state.redis</code>, <code>app.state.rabbitmq</code> + dependency injection</li> <li>Aiogram: <code>dp.startup.register()</code> + dependency injection in handlers</li> <li>AsyncIO: global clients in <code>main()</code> + pass as arguments</li> </ul>"},{"location":"reference/tech_stack/#3-tracing-and-idempotency","title":"3. Tracing and Idempotency","text":"<ul> <li>Request ID MUST be generated and passed through all services</li> <li>Redis MUST be used for idempotency checking</li> <li>All operations MUST be idempotent</li> </ul>"},{"location":"reference/tech_stack/#4-testing","title":"4. Testing","text":"<ul> <li>100% coverage for critical paths</li> <li>Use testcontainers for integration tests</li> <li>Real databases instead of mocks in integration tests</li> </ul>"},{"location":"reference/tech_stack/#development-commands-reference","title":"Development Commands Reference","text":"<p>COMMANDS: For all development commands, see the Development Commands. This includes Docker, testing, linting, and deployment commands.</p>"},{"location":"reference/tech_stack/#working-examples-reference","title":"Working Examples Reference","text":"<p>For comprehensive, working implementations of all service types with real-world scenarios: - FastAPI Service: Complete user management API with authentication, caching, and events - Aiogram Bot: Media processing bot with file handling and RabbitMQ integration - AsyncIO Worker: Background processing with retry logic and status tracking - Inter-Service Communication: HTTP API calls and event-driven patterns - Testing Examples: Unit, integration, and end-to-end testing patterns</p> <p>See Use Case Implementation Guide for end-to-end implementation patterns.</p>"},{"location":"reference/tech_stack/#troubleshooting-reference","title":"Troubleshooting Reference","text":"<p>For common issues and solutions including: - Development environment setup problems - Docker and service connectivity issues - Event loop and async conflicts - Database and migration problems - Observability stack configuration</p> <p>See Troubleshooting Guide for diagnostic steps and solutions.</p>"},{"location":"reference/tech_stack/#project-structure","title":"Project Structure","text":"<p>Status: Implemented - Infrastructure and service framework complete</p> <p>COMPLETE PROJECT STRUCTURE: For detailed project structure, directory organization, service types, and setup instructions, see Project Structure.</p> <p>Key Principles: - All application code in <code>src/</code> directory - Service-specific Dockerfiles in each service folder - Root-level Docker Compose configuration - Shared components and utilities organization</p> <p>Next Steps: Implement business logic in services according to rule patterns (architecture/, services/, infrastructure/, observability/, quality/).</p>"},{"location":"reference/tech_stack/#docker-compose-organization","title":"Docker Compose Organization","text":"<p>COMPLETE DOCKER COMPOSE GUIDE: For detailed Docker Compose organization, benefits, and setup instructions, see Project Structure.</p> <p>Key Points: - Single root <code>docker-compose.yml</code> file (recommended) - Shared infrastructure across all services - Proper dependency management and networking</p> <p>Deployment Commands: See Development Commands for complete command reference.</p>"},{"location":"reference/tech_stack/#compliance-verification","title":"Compliance Verification","text":"<p>All implementations MUST comply with cursor rules. For verification:</p> <ol> <li>Study relevant <code>../*/*.mdc</code> files</li> <li>Follow code examples from rules</li> <li>Use verification commands from each rule</li> <li>Achieve 100% test coverage for critical paths</li> </ol> <p>IMPORTANT: Cursor rules are the source of truth for implementation. In case of conflicts between tech_stack.md and cursor rules, cursor rules take priority.</p>"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide covers common issues and solutions when working with the microservices architecture.</p>"},{"location":"reference/troubleshooting/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Development Environment Issues</li> <li>Docker and Compose Issues</li> <li>Service Communication Issues</li> <li>Database and Migration Issues</li> <li>Event Loop and Async Issues</li> <li>Observability and Monitoring Issues</li> <li>Performance Issues</li> </ul>"},{"location":"reference/troubleshooting/#development-environment-issues","title":"Development Environment Issues","text":""},{"location":"reference/troubleshooting/#python-version-conflicts","title":"Python Version Conflicts","text":"<p>Problem: Services fail to start due to Python version mismatch <pre><code>Error: Python 3.12 found, but 3.12+ required\n</code></pre></p> <p>Solution: <pre><code># Check current Python version\npython --version\n\n# Install Python 3.12+ using pyenv (recommended)\npyenv install 3.12.7\npyenv local 3.12.7\n\n# Or update using system package manager\nsudo apt update &amp;&amp; sudo apt install python3.12\n</code></pre></p>"},{"location":"reference/troubleshooting/#uv-package-manager-issues","title":"UV Package Manager Issues","text":"<p>Problem: <code>uv</code> commands fail or dependencies not installing <pre><code>Error: uv: command not found\n</code></pre></p> <p>Solution: <pre><code># Install UV\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Reload shell\nsource ~/.bashrc\n\n# Verify installation\nuv --version\n\n# If dependencies fail to install\nuv sync --refresh\n</code></pre></p>"},{"location":"reference/troubleshooting/#environment-variables-missing","title":"Environment Variables Missing","text":"<p>Problem: Services fail with configuration errors <pre><code>Error: DATABASE_URL not found\n</code></pre></p> <p>Solution: <pre><code># Copy example environment file\ncp .env.example .env\n\n# Edit with your configuration\nnano .env\n\n# Verify environment variables are loaded\ndocker-compose config\n</code></pre></p>"},{"location":"reference/troubleshooting/#docker-and-compose-issues","title":"Docker and Compose Issues","text":""},{"location":"reference/troubleshooting/#port-conflicts","title":"Port Conflicts","text":"<p>Problem: Services fail to start due to port conflicts <pre><code>Error: bind: address already in use\n</code></pre></p> <p>Solution: <pre><code># Check what's using the port\nsudo netstat -tulpn | grep :5432\n\n# Kill process using the port\nsudo kill -9 &lt;PID&gt;\n\n# Or change port in docker-compose.yml\n# ports:\n#   - \"5433:5432\"  # Use different host port\n</code></pre></p>"},{"location":"reference/troubleshooting/#container-build-failures","title":"Container Build Failures","text":"<p>Problem: Docker build fails with dependency errors <pre><code>Error: Unable to locate package python3.12\n</code></pre></p> <p>Solution: <pre><code># Clean Docker cache\ndocker system prune -a\n\n# Rebuild without cache\ndocker-compose build --no-cache\n\n# Check Dockerfile base image\n# Ensure using: FROM python:3.12-slim\n</code></pre></p>"},{"location":"reference/troubleshooting/#volume-mount-issues","title":"Volume Mount Issues","text":"<p>Problem: Database data not persisting or permission errors <pre><code>Error: permission denied\n</code></pre></p> <p>Solution: <pre><code># Fix permissions\nsudo chown -R $USER:$USER ./data\n\n# Reset volumes\ndocker-compose down -v\ndocker-compose up\n</code></pre></p>"},{"location":"reference/troubleshooting/#service-communication-issues","title":"Service Communication Issues","text":""},{"location":"reference/troubleshooting/#rabbitmq-connection-failures","title":"RabbitMQ Connection Failures","text":"<p>Problem: Services can't connect to RabbitMQ <pre><code>Error: ConnectionError: [Errno 111] Connection refused\n</code></pre></p> <p>Solution: <pre><code># Check RabbitMQ is running\ndocker-compose ps rabbitmq\n\n# Check RabbitMQ logs\ndocker-compose logs -f rabbitmq\n\n# Restart RabbitMQ\ndocker-compose restart rabbitmq\n\n# Access management UI\n# http://localhost:15672 (admin/admin)\n</code></pre></p>"},{"location":"reference/troubleshooting/#redis-connection-issues","title":"Redis Connection Issues","text":"<p>Problem: Services can't connect to Redis <pre><code>Error: redis.exceptions.ConnectionError\n</code></pre></p> <p>Solution: <pre><code># Check Redis is running\ndocker-compose ps redis\n\n# Test Redis connection\ndocker-compose exec redis redis-cli ping\n\n# Check Redis logs\ndocker-compose logs -f redis\n\n# Restart Redis\ndocker-compose restart redis\n</code></pre></p>"},{"location":"reference/troubleshooting/#inter-service-http-communication","title":"Inter-Service HTTP Communication","text":"<p>Problem: HTTP requests between services fail <pre><code>Error: ConnectionError: Cannot connect to host template_business_api\n</code></pre></p> <p>Solution: <pre><code># Check services are in same network\ndocker network ls\ndocker network inspect try_microservices_default\n\n# Use service names in URLs\n# http://template_business_api:8000/api/v1/users\n# http://localhost:8000/api/v1/users\n\n# Check service health endpoints\ncurl http://localhost:8000/health\n</code></pre></p>"},{"location":"reference/troubleshooting/#database-and-migration-issues","title":"Database and Migration Issues","text":""},{"location":"reference/troubleshooting/#postgresql-connection-failures","title":"PostgreSQL Connection Failures","text":"<p>Problem: Cannot connect to PostgreSQL database <pre><code>Error: could not connect to server: Connection refused\n</code></pre></p> <p>Solution: <pre><code># Check PostgreSQL is running\ndocker-compose ps postgres\n\n# Check PostgreSQL logs\ndocker-compose logs -f postgres\n\n# Test connection\ndocker-compose exec postgres psql -U postgres -d microservices_db\n\n# Reset database\ndocker-compose down\ndocker volume rm try_microservices_postgres_data\ndocker-compose up postgres\n</code></pre></p>"},{"location":"reference/troubleshooting/#migration-failures","title":"Migration Failures","text":"<p>Problem: Alembic migrations fail <pre><code>Error: Target database is not up to date\n</code></pre></p> <p>Solution: <pre><code># Check current migration status\nuv run alembic current\n\n# Run migrations\nuv run alembic upgrade head\n\n# If migrations conflict, reset\nuv run alembic downgrade base\nuv run alembic upgrade head\n\n# Generate new migration\nuv run alembic revision --autogenerate -m \"description\"\n</code></pre></p>"},{"location":"reference/troubleshooting/#sqlalchemy-session-issues","title":"SQLAlchemy Session Issues","text":"<p>Problem: Database sessions hanging or errors <pre><code>Error: QueuePool limit of size 5 overflow 10 reached\n</code></pre></p> <p>Solution: <pre><code># Check connection pool configuration\nSQLALCHEMY_DATABASE_URL = \"postgresql+asyncpg://user:pass@host/db?pool_size=20&amp;max_overflow=30\"\n\n# Ensure proper session management\nasync with get_db_session() as session:\n    # Use session\n    pass  # Session automatically closed\n</code></pre></p>"},{"location":"reference/troubleshooting/#event-loop-and-async-issues","title":"Event Loop and Async Issues","text":""},{"location":"reference/troubleshooting/#event-loop-conflicts","title":"Event Loop Conflicts","text":"<p>Problem: Multiple event loops causing conflicts <pre><code>Error: RuntimeError: There is no current event loop\n</code></pre></p> <p>Solution: <pre><code># DON'T run multiple event loop managers in same process\n# app = FastAPI()  # Creates event loop\n# asyncio.run(main())  # Creates another event loop\n\n# DO use separate containers/processes\n# FastAPI in one container\n# Aiogram in another container\n# AsyncIO workers in third container\n</code></pre></p>"},{"location":"reference/troubleshooting/#blocking-code-in-async-context","title":"Blocking Code in Async Context","text":"<p>Problem: Synchronous code blocking event loop <pre><code>Warning: Synchronous code in async context\n</code></pre></p> <p>Solution: <pre><code># DON'T use blocking code\ndef blocking_operation():\n    time.sleep(5)  # Blocks event loop\n\nawait blocking_operation()  # Will block everything\n\n# DO use async alternatives\nasync def async_operation():\n    await asyncio.sleep(5)  # Non-blocking\n\n# Or run in thread pool\nimport concurrent.futures\n\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    result = await loop.run_in_executor(executor, blocking_operation)\n</code></pre></p>"},{"location":"reference/troubleshooting/#async-library-compatibility","title":"Async Library Compatibility","text":"<p>Problem: Mixing sync and async libraries <pre><code>Error: SyncError: You have tried to use a sync method\n</code></pre></p> <p>Solution: <pre><code># DON'T use sync libraries in async code\nimport pika      # Sync library (deprecated)\n\n# DO use async libraries\nimport asyncpg    # Async PostgreSQL\nimport aio_pika   # Async RabbitMQ\n</code></pre></p>"},{"location":"reference/troubleshooting/#observability-and-monitoring-issues","title":"Observability and Monitoring Issues","text":""},{"location":"reference/troubleshooting/#prometheus-metrics-not-appearing","title":"Prometheus Metrics Not Appearing","text":"<p>Problem: Metrics not showing in Prometheus <pre><code>Error: No targets found\n</code></pre></p> <p>Solution: <pre><code># Check Prometheus configuration\ndocker-compose exec prometheus cat /etc/prometheus/prometheus.yml\n\n# Verify service metrics endpoints\ncurl http://localhost:8000/metrics\n\n# Check Prometheus targets\n# http://localhost:9090/targets\n\n# Restart Prometheus\ndocker-compose restart prometheus\n</code></pre></p>"},{"location":"reference/troubleshooting/#grafana-dashboard-issues","title":"Grafana Dashboard Issues","text":"<p>Problem: Grafana shows no data <pre><code>Error: No data points\n</code></pre></p> <p>Solution: <pre><code># Check Grafana data source\n# http://localhost:3000/datasources\n\n# Verify Prometheus connection\n# URL: http://prometheus:9090\n\n# Import dashboard JSON\n# Copy from infrastructure/observability/grafana/dashboards/\n\n# Check time range in dashboard\n</code></pre></p>"},{"location":"reference/troubleshooting/#elk-stack-issues","title":"ELK Stack Issues","text":"<p>Problem: Logs not appearing in Kibana <pre><code>Error: No indices found\n</code></pre></p> <p>Solution: <pre><code># Check Elasticsearch health\ncurl http://localhost:9200/_health\n\n# Check Logstash pipeline\ndocker-compose logs -f logstash\n\n# Create index pattern in Kibana\n# http://localhost:5601\n# Management &gt; Index Patterns &gt; Create\n# Pattern: logstash-*\n</code></pre></p>"},{"location":"reference/troubleshooting/#jaeger-tracing-issues","title":"Jaeger Tracing Issues","text":"<p>Problem: Traces not appearing in Jaeger <pre><code>Error: No traces found\n</code></pre></p> <p>Solution: <pre><code># Check OpenTelemetry configuration\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\n\n# Ensure proper setup\ntracer = trace.get_tracer(__name__)\n\n# Add spans to your code\nwith tracer.start_as_current_span(\"operation_name\"):\n    # Your code here\n    pass\n</code></pre></p>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: Services consuming too much memory <pre><code>Error: OOMKilled\n</code></pre></p> <p>Solution: <pre><code># Add memory limits to docker-compose.yml\nservices:\n  template_business_api:\n    deploy:\n      resources:\n        limits:\n          memory: 512M\n        reservations:\n          memory: 256M\n</code></pre></p> <pre><code># Optimize database connections\nSQLALCHEMY_DATABASE_URL = \"postgresql+asyncpg://user:pass@host/db?pool_size=5&amp;max_overflow=10\"\n</code></pre>"},{"location":"reference/troubleshooting/#slow-database-queries","title":"Slow Database Queries","text":"<p>Problem: Database operations are slow <pre><code>Warning: Query took 5.2 seconds\n</code></pre></p> <p>Solution: <pre><code>-- Add database indexes\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_posts_user_id ON posts(user_id);\n\n-- Analyze query performance\nEXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';\n</code></pre></p> <pre><code># Use connection pooling\nasync def get_db_session():\n    async with SessionLocal() as session:\n        yield session\n</code></pre>"},{"location":"reference/troubleshooting/#high-cpu-usage","title":"High CPU Usage","text":"<p>Problem: Services using too much CPU <pre><code>Error: CPU usage at 100%\n</code></pre></p> <p>Solution: <pre><code># Add async delays to prevent busy loops\nasync def worker_loop():\n    while True:\n        await process_tasks()\n        await asyncio.sleep(0.1)  # Prevent busy loop\n\n# Use connection pooling for external services\nasync def make_request():\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.json()\n</code></pre></p>"},{"location":"reference/troubleshooting/#quick-diagnostic-commands","title":"Quick Diagnostic Commands","text":"<p>FULL COMMAND REFERENCE: For complete development and troubleshooting commands, see Development Commands.</p> <p>Essential diagnostic commands: <pre><code># Check services status and logs\ndocker-compose ps\ndocker-compose logs -f [service_name]\n\n# Test connectivity (full commands in development-commands.md)\ncurl http://localhost:8000/health  # API service\ncurl http://localhost:8001/health  # PostgreSQL data service\ncurl http://localhost:8002/health  # MongoDB data service\n</code></pre></p>"},{"location":"reference/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered in this guide:</p> <ol> <li>Check logs: Always start with service logs using <code>docker-compose logs -f &lt;service&gt;</code></li> <li>Verify configuration: Use <code>docker-compose config</code> to validate compose files</li> <li>Check connectivity: Test service-to-service communication</li> <li>Review documentation: Refer to Main Entry Point and Technical Specifications</li> <li>Check IDE rules: Review relevant <code>../*/*.mdc</code> files (architecture/, services/, infrastructure/, observability/, quality/)</li> </ol> <p>For more detailed debugging, enable debug logging in your services by setting <code>LOG_LEVEL=DEBUG</code> in your <code>.env</code> file.</p>"}]}